ID,title,content,date
izy2kf,Rotating an image recursively. One of my favorite algorithms!,N/A,2020-09-26 03:09:44
he9tqw,Happy birthday Alan Turing!,N/A,2020-06-23 06:59:56
1bqzdg1,My maze solver is drunk,N/A,2024-03-29 21:07:32
dnv7wj,Logic gates using liquids,N/A,2019-10-27 15:52:02
e0i9ap,"Logic gates with fluid, part 2",N/A,2019-11-23 14:05:35
ltznmg,An engineer wiring an early IBM computer.1958,N/A,2021-02-27 23:07:36
p3a2nn,"A steal for $10, I’m overjoyed",N/A,2021-08-12 22:06:43
o42n3b,"The man, The myth, The legend.",N/A,2021-06-20 10:20:04
gc32e1,To what degree Would Augmented Reality change the way we study math?,N/A,2020-05-02 08:29:32
ncbplp,Map of Computer Science,N/A,2021-05-14 15:46:03
rkhplt,Implemented local collision avoidance (ORCA),N/A,2021-12-20 07:36:56
j3hxzm,Some more fun with recursive image transformations. Flips and rotations! Source code in comments!,N/A,2020-10-01 21:40:29
16vinxr,Built a cpu out of 2000 transistors,"Finally finished my computer built entirely from transistors! 
Had some problems which delayed the build but it is over now.
Tested it on several programs, like the above helloworld and dinosaur game (which for some reason i cannot upload).

It is an
- 11 bit cpu
- more than 2000 transistors
- Arduino as memory
- 32 micromemory/ROM addresses
- accumulator architecture
- 8 branch flags
- connects to LCD and keyboard
- has stack pointer register so supports recursive function calling

Currently on a trip but will open source it when I get back and clean the repo.

Posted here before and got requests to go more in depth, so i made an interactive blog where I explain it all (havent finished all the posts yet):

[Overview](https://howcpuworks.com/blogs/processsorbook/building-processors-from-the-ground-up)

[Logic gate construction](https://howcpuworks.com/blogs/processsorbook/building-logic-gates-from-mosfets)

[Decoder construction](https://howcpuworks.com/blogs/processsorbook/how-decoder-works)

[Register](https://howcpuworks.com/blogs/processsorbook/makeing-a-register)

(You can see all the planned posts in burger top left they include [micromemory](https://howcpuworks.com/pages/building),   [signals](https://howcpuworks.com/pages/building),   [stack](https://howcpuworks.com/pages/building)...).

I also made a web based simulator for it: [simulator](https://howcpuworks.com/pages/cpu-simulator).

Some supported instructions are:
- Add addr (adds value at addr to accumulator)
- Addi val (adds val to acc)
- Not, Nand
- B addr (Branch to addr)
- Bz (beanch zero), Bnz, ...
- sp2acc (move stack pointer to acc)
- acc2sp, pc2acc, acc2sp...",2023-09-29 18:03:36
kvrxnp,I taught a neural network to play Flappy Bird with Java/Kotlin,N/A,2021-01-12 13:46:40
eenu7q,"On popular demand, the Spiral of Theodorus is now back in dark mode!",N/A,2019-12-23 17:47:28
kgpu68,This guy's art is super cool and I immediately thought it would make an interesting algorithm! Does anyone think they're up to designing one?,N/A,2020-12-20 07:21:28
ljtnga,Fine art dropout. Had to choose between politics and CS. Chose CS.,N/A,2021-02-14 18:07:23
l05j7l,Simulate Newton's law of universal gravitation with C++,N/A,2021-01-18 22:30:07
78isb9,Sorting Algorithms Visualized [gifv],N/A,2017-10-24 20:58:41
jr1j2m,Animation of Doo-Sabin subdivision. Source code and more in comments.,N/A,2020-11-09 17:06:56
fmye47,Ever wonder how rendering works from your perspective?,N/A,2020-03-22 11:18:57
hu099v,Found this while reading SICP from MIT.,N/A,2020-07-19 13:10:54
j8wc4h,Felt like doing a portrait of one of our founding fathers,N/A,2020-10-11 01:17:39
nio1lv,Drew my idol Alan M Turing for our CS library,N/A,2021-05-22 17:50:13
rxnw1g,Simple 8-bit CPU I designed for my school project as an 18 year old in high school. Top right is program memory with machine code i created. Bottom right is memory in which program stores prime numbers up to 255.,N/A,2022-01-06 20:18:15
f3co43,My library has a tribute to Alan Turing,N/A,2020-02-13 16:41:07
l628s7,Probability Distribution in Monopoly Using Markov Chains,N/A,2021-01-27 11:05:06
wk8yuu,Made a computer vision basketball referee,N/A,2022-08-09 17:17:05
pblz3a,My late grandfather's 1969 Master's Thesis(1/4),N/A,2021-08-25 22:23:25
lc9nmm,I built a 4-bit multiplier in Minecraft! (I know it isn’t super complicated but I am proud of it),N/A,2021-02-04 06:38:19
x17pe5,I taught a neural network to play Flappy Bird with Java/Kotlin,N/A,2022-08-30 02:51:44
f74vtw,"Donald Knuth Deemed Me ""A Gentleman and a Hacker""",N/A,2020-02-21 03:12:46
j0q361,Jump Rope + AI! Made this application on top of OpenPose (Python). Link to the Medium tutorial and the GitHub Repo in the thread.,N/A,2020-09-27 12:12:02
gvae0o,YAWYSIWYGEE: Yet another what-you-see-is-what-you-get equation editor,N/A,2020-06-02 16:23:20
no5azy,Turing-Machine in Minecraft that computes sqrt(2) to infinite-precision,N/A,2021-05-30 06:44:09
zgrx84,How would you write an algorithm to solve this?,N/A,2022-12-09 09:01:38
iku09s,Map of Computer Science,N/A,2020-09-01 22:03:23
juw3ud,"A comparison between a few subdivision algorithms (Catmull-Clark, Doo-Sabin, and Midedge). Source code in comments",N/A,2020-11-15 23:37:19
kjj7c5,"Demonstration of a reverse image search algorithm for detecting transformed images, partial images, and sub-images (link in comments)",N/A,2020-12-24 17:29:47
xo9hdg,A* vs BFS in snake game,N/A,2022-09-26 04:50:19
ald44f,A full adder using dominoes,N/A,2019-01-30 14:20:30
pjqau2,"I built an interactive map for self-teaching online. It's like a skill tree for learning. The first map is ML, but want to add CS next",N/A,2021-09-07 16:18:32
9j27d6,"Well, damn!",N/A,2018-09-26 12:50:55
mkvk3u,TIL Dijkstra invented Dijkstra's algorithm in 20 minutes in a coffee shop while shopping with his young fiance,N/A,2021-04-05 21:36:03
dqzosi,Bought a few things for my personal project. Looking forward to digging in soon!,N/A,2019-11-03 12:22:40
kv9dcq,Dead simple points interpolation with good old C++,N/A,2021-01-11 19:02:03
133eqm2,I made a Python package to do adaptive sampling of functions in parallel [OC],N/A,2023-04-30 03:31:18
oyb9bp,I made Conway's game of life into Minecraft!(sharing cuz thought you would appreciate it),N/A,2021-08-05 05:49:44
buh512,Cornell's entire Machine Learning class (CS 4780) is now entirely on You Tube. Taught by one of the funniest and best professors from UCornell,N/A,2019-05-29 16:55:17
tl5g2b,My first (shared) paper was finally published,N/A,2022-03-23 18:17:08
jxz3u7,[R] Impersonator++ Human Image Synthesis – Smarten Up Your Dance Moves!,N/A,2020-11-20 22:34:51
igs5lv,I wish my OS textbook was like this,N/A,2020-08-26 04:18:53
z7d5yp,"Researchers found that accelerometer data from smartphones can reveal people's location, passwords, body features, age, gender, level of intoxication, driving style, and be used to reconstruct words spoken next to the device.",N/A,2022-11-28 23:57:19
navkf0,[OC] Multiple Object Tracking With YOLOv5 and OpenCV,N/A,2021-05-12 18:20:37
62x9g9,PowerPoint is Turing Complete!,N/A,2017-04-02 02:27:39
cdg4h9,Alan Turing to feature on new £50 note,N/A,2019-07-15 11:10:22
i3t2l1,[R] AI Generator Learns to ‘Draw’ Like Cartoonist Lee Mal-Nyeon in Just 10 Hours,N/A,2020-08-04 22:15:21
np8hle,Boolean gardening tips,N/A,2021-05-31 17:21:02
r0i38v,I built a roadmap editor: first map is on ML. You can make skill trees for real life skills!,N/A,2021-11-23 17:15:23
u0nvdv,"Artificial Life Simulation ""Dark Forest""",N/A,2022-04-10 18:36:07
ei4qu9,Full 1-bit adder using fluids,N/A,2019-12-31 16:06:26
4pnh2w,"My master's thesis on circle packing, in the form of an IKEA assembly instruction",N/A,2016-06-24 15:33:04
lfygtz,[Explainable AI] Interpret complex neural network's decisions with simple linear regressions,N/A,2021-02-09 08:59:08
ibjaq7,are non-square circuits on the edge of wafers used for anything?,N/A,2020-08-17 18:03:48
gj94gg,[P] Nifty Online Tool Animates Your Actions in Real-Time,N/A,2020-05-13 22:15:36
kv03fn,I used some Java Swing to visualize a neural network's output,N/A,2021-01-11 10:26:26
7qc3zu,Tim Berner Lees anouncment of the world wide web (Last paragraph),N/A,2018-01-14 14:29:08
if0qz3,Just wanted to share my current favorite algorithm. Do you know a more elegant way to do it?,N/A,2020-08-23 10:08:20
n5sa4t,"Researchers found that accelerometer data from smartphones can reveal people's location, passwords, body features, age, gender, level of intoxication, driving style, and be used to reconstruct words spoken next to the device.",N/A,2021-05-05 22:21:23
lt0bat,A Computer Architecture Built in Logicly (Fibonacci Sequence),N/A,2021-02-26 15:43:13
zmp93u,Found this while reading SICP from MIT.,N/A,2022-12-15 16:25:57
di9npd,I made an interactive solver for the traveling salesman problem to visualize different algorithms. Each step of progress is drawn to the map in real-time and can be controlled all in the browser at tspvis.com.,N/A,2019-10-15 15:40:24
i1opdz,"A python bot that attends your online classes for you and marks your attendance while answering in class using Speech recognition, Image processing and a bit of NLP.",N/A,2020-08-01 08:09:31
n3b6wc,Digital logic simulator I made in Unity,N/A,2021-05-02 17:21:18
fkodr0,EARN-IT Act threatens end to end secure encryption by requiring communications technology to install back door for Feds,N/A,2020-03-18 11:59:06
srdssr,A 32-bit RISC-V based computer built from scratch in Logisim.,N/A,2022-02-13 08:14:14
efgqqi,"My 2019 curated list of articles, resources and links on programming, math and computer science.","Hi /r/compsci! 

Every year I bookmark many websites, tutorials and articles on mostly programming, math, technology and computer science. I go through them all in the end of the year and curate the best, unique and interesting stuff to make a list for myself (and discard the others).

I hope some will benefit you, ignite your interests further in computer science or find something interesting to read and learn. Enough talk, let's get to the meat!

---

- [Paperdigest](https://www.paperdigest.org), tracks and analyzes all new papers (ai, machine learning, vision, robotics, etc) uploaded to Arxiv and published on selected conferences, and then generates a one sentence summary for each paper to capture the paper highlight. 
- [r/cogsci reading list](https://www.reddit.com/r/cogsci/wiki/readinglist), the cognitive science subreddit's reading list is an amazing resources with a lot of books, papers and articles if you're into cognitive science.
- [Gwern's Blog/Website](https://www.gwern.net), about psychology, statistics, and technology; Gwern writes about darknet markets & Bitcoin, blinded self-experiments & Quantified Self analyses, dual n-back & spaced repetition, and modafinil.
- [Superkeuh's Blog](http://www.superkuh.com/blog/blog.html), A web log about sci-fi, technology.
- [endtoendAI](https://www.endtoend.ai), high quality information on different aspects of Artificial Intelligence, including Machine Learning, Reinforcement Learning, and Computer Vision.
- [list of classic CS books](https://www.reddit.com/r/learnprogramming/comments/dd6e0g/what_are_your_favorite_books_on_general_cs/f2f270w/?context=3) on different topics by samort7.
- [Arrival's scientific and philosophical themes by DrTenmaz](https://www.reddit.com/r/movies/comments/5cc7fb/official_discussion_arrival_spoilers/d9wzd1r/?context=3) on Reddit.
- [Is the Universe Euclidean or Non-Euclidean?](https://arxiv.org/pdf/0911.1479.pdf), a paper titled ""Is the spacetime metric Euclidean rather than Lorentzian?"", by Rafael D. Sorkin.
- [Terms of Service, Didn't Read](https://tosdr.org), summarizes ToS of stuff, very useful as I always accept most of those, I mean, really? you have got time to read that?
- [Ask Historian's Master Book List](https://www.reddit.com/r/AskHistorians/comments/timi4/the_askhistorians_master_book_list/), wanna read something old? then this post is gold!
- [LessWrong](https://www.lesswrong.com) is a place to 1) develop and train rationality, and 2) apply one’s rationality to real-world problems.
- [Neural Ambigrams](http://hardmath123.github.io/ambigrams.html), generate ambigrams using neural nets.
- [DeepIndex](https://deepindex.org), Keeping track of what AI can do and where it is being applied
- [Project Lovelace](https://projectlovelace.net), Project Lovelace is a bunch of free scientific programming problems.
- [Farmer and Farmer Review](http://farmerandfarmer.org/index.html) Eassay's on technology and the arts, exploring the relationship between humans and technology. 
- A huge list of [Mathematical Fiction](http://kasmana.people.cofc.edu/MATHFICT/readinglists.php) by Alex Kasman.
- [Zip Bomb](https://www.bamsoftware.com/hacks/zipbomb/), an article by David Fifield that shows how to construct a non-recursive zip bomb that achieves a high compression ratio by overlapping files inside the zip container. 
- [How to pick a random number from 1-10, _uniformly_ ](https://torvaney.github.io/projects/human-rng) An excellent blog post on how to write a random number generator to pick a number uniformly, duh.
- [Words and Buttons Online](https://wordsandbuttons.online/index.html) — a growing collection of interactive tutorials, guides and quizzes about things generally considered boring. Maths, algorithms, performance, and programming languages.
- [Jane Street Puzzle Archieve](https://www.janestreet.com/puzzles/archive/), lot's of programming challenges at Jane Street.
- [Melting Asphalt](https://meltingasphalt.com), Es­says about phi­los­o­phy, hu­man be­hav­ior, and oc­ca­sion­al­ly soft­ware.  Amazing content!
- [Unravelling the JPEG](https://parametric.press/issue-01/unraveling-the-jpeg/), a great interactive post on the JPEG format by parametric press.
- [Yehar's Blog](http://yehar.com/blog/), the very unique, interesting website of Olli Niemitalo who had also [written about/had an idea](https://web.archive.org/web/20120312111546/http://yehar.com:80/blog/?p=167) about GANs waaay before it was published.
- [Nikoli](https://www.nikoli.co.jp/en/puzzles/index.html) is the first puzzle magazine in Japan. It has some great unique puzzles.
- [Building Blocks for Theoretical Computer Science](http://mfleck.cs.illinois.edu/building-blocks/) by Margaret M. Fleck
- [Toy Wiki](https://toywiki.xyz), a collection of math notes.
- [Write yourself a Git!](https://wyag.thb.lt), implement git on your own using python.
- [Resources for Students & Scholars](http://people.csail.mit.edu/fredo/student.html) by Frédo Durand, I read these reguarly.
- [What Lecture Notes Should Everyone Read?](https://cstheory.stackexchange.com/questions/4074/what-lecture-notes-should-everyone-read), self explanatory.
- [The Rendering of the Rise of the Tomb Raider](http://www.elopezr.com/the-rendering-of-rise-of-the-tomb-raider/), an excellent post on the rendering capabilities of the Crystal Engine used in the video game developed by Crystal Dynamics. The website has other interesting posts as well.

---

Mods, in case this violates any guidelines please remove it and if possible tell me the best subreddit to post. 

Raising a glass or two for 2020!
Thank you and have fun!",2019-12-25 13:56:53
adl0bz,"OR, AND, XOR gates using dominoes",N/A,2019-01-07 19:10:59
16wzgq,Lightning strike recorded at over 7000 FPS. It's like a natural recursive pathfinding algorithm.,N/A,2013-01-20 05:13:26
u7vi7p,Ant colony simulation,N/A,2022-04-20 12:36:11
mg0one,[Side-project] An fluid dynamics simulation done with C++,N/A,2021-03-29 21:58:32
ezwand,Time to go back to the table — hex multiplication table that is.,N/A,2020-02-06 18:11:33
te9ux,"A professor of mine, sick of students paying way too much for textbooks, has made an open source data structures book. Feel free to find errors, and suggest changes!",N/A,2012-05-09 05:29:34
12us2lt,Visualizing the Traveling Salesman Problem with the Convex hull heuristic.,N/A,2023-04-22 02:44:42
laaag,Dennis Ritchie has passed away. R.IP.,N/A,2011-10-13 01:35:43
u58jcu,Boids : An artificial life simulation of flock of birds,N/A,2022-04-16 22:11:48
eybhpf,"A list of 30+ free textbooks from calculus, linear algebra to discrete math, proof, combinatorics and programming",N/A,2020-02-03 18:34:04
gigu45,A physics engine in python (pygame),N/A,2020-05-12 18:13:27
iv595s,"A single-cycle ARMV7 processor that I designed from scratch looking at the arm instruction set for a course. Main board, control unit, main decoder, register file, and ALU in order.",N/A,2020-09-18 12:36:50
i4jt8p,"For any python/pandas users I've been building this visualizer for dataframes for the last year, let me know what you think",N/A,2020-08-06 02:56:08
pmauya,Simulation of a Virtual Bustling City With Pedestrian / Vehicle AI,N/A,2021-09-11 16:47:50
iwal6n,Why don't non-compsci posts get removed?,"I don't want to sound unappreciative, but I believe this sub is a disappointment for computer science enthusiasts and researchers. There's a lot of spam about cloud computing, devops, various libraries and frameworks, etc. by users like u/Techbiason, u/itbloggy, and others. Can we ban them? There is also a high volume of posts about programming or software engineering topics that are largely irrelevant to computer science. What's up with the low signal-to-noise in this sub? Are the mods stretched too thin?

Obviously people can have differing opinions on what constitutes ""computer science"", but I wouldn't include things like ""[Review\[ing\] client's brand standards](https://www.reddit.com/r/compsci/comments/itpv0a/phases_of_website_development/)"". Other subs seem to be more strict about only allowing appropriate content that adheres to the relevant standards. Is there anything we can do to make the content here more relevant to the name of this sub? Or are there so many members (1.1m!) that it's too hard to curate everything?

I recognize that I have biases regarding what I consider to be ""relevant"", and I don't want to give off gatekeeper vibes. But surely I'm not the only one who thinks this sub could be improved by changing our posture on moderation.

**Update:** I am now a moderator. Initial thoughts:

* This is not really what I was asking for, and my bandwidth is limited. I'll try to encourage more germane content when I am around. But before I do anything, I will continue to follow this discussion to hear more about what the community wants.
* I am not the mod who removed the deleted comments that I replied to in this thread, but I agree with their removal. As a matter of principle, I personally will not remove comments that are replies to my own, unless they violate the [Reddit Content Policy](https://www.redditinc.com/policies/content-policy).
* I appreciate u/_--__/ for engaging in this discussion, enacting one of the proposed bans, and being attentive to feedback in general.",2020-09-20 09:09:15
bbxrqg,The Black Hole Photo is the result of a gigantic engineering project in which numerous telescopes around the world were synchronized using atomic clocks so accurate that they lose just one second per hundred million years,N/A,2019-04-11 09:24:34
7fded8,More than a Million Pro-Repeal Net Neutrality Comments were Likely Faked,N/A,2017-11-25 06:04:18
regudt,"I implemented the Time-Based One Time Password (TOTP) algorithm on my phone, I think 2FA is such a cool concept.",N/A,2021-12-12 04:19:29
kz4k06,How the CLite language parses an assignment (corrected).,N/A,2021-01-17 11:05:08
c15nbn,PSA: This is not r/Programming. Quick Clarification on the guidelines,"As there's been recently quite the number of rule-breaking posts slipping by, I felt clarifying on a handful of key points would help out a bit (especially as most people use New.Reddit/Mobile, where the FAQ/sidebar isn't visible)

&#x200B;

First thing is first, this is ***not a programming specific subreddit***! If the post is a better fit for r/Programming or r/LearnProgramming, that's exactly where it's supposed to be posted in. Unless it involves some aspects of AI/CS, it's relatively better off somewhere else.

&#x200B;

r/ProgrammerHumor: Have a meme or joke relating to CS/Programming that you'd like to share with others? Head over to r/ProgrammerHumor, please.

&#x200B;

r/AskComputerScience: Have a ***genuine*** question in relation to CS that isn't directly asking for homework/assignment help nor someone to do it for you? Head over to r/AskComputerScience.

&#x200B;

r/CsMajors: Have a question in relation to CS academia (**such as ""Should I take CS70 or CS61A?"" ""Should I go to X or X uni, which has a better CS program?"")**, head over to r/csMajors.

&#x200B;

r/CsCareerQuestions: Have a question in regards to jobs/career in the CS job market? Head on over to to r/cscareerquestions. (or r/careerguidance if it's slightly too broad for it)

&#x200B;

r/SuggestALaptop: Just getting into the field or starting uni and don't know what laptop you should buy for programming? Head over to r/SuggestALaptop 

&#x200B;

r/CompSci: Have a post that you'd like to share with the community and have a civil discussion that is in relation to the field of computer science (that doesn't break any of the rules), r/CompSci is the right place for you.  


&#x200B;

And *finally*, **this community will** ***not*** **do your assignments for you.** Asking questions directly relating to your homework or hell, copying and pasting the entire question into the post, will not be allowed.

I'll be working on the redesign since it's been relatively untouched, and that's what most of the traffic these days see. That's about it, if you have any questions, feel free to ask them here!",2019-06-16 03:26:55
15u0qgo,An engineer wiring an early IBM computer.1958,N/A,2023-08-17 21:42:02
3ivsda,Here's a GIF of a slime mold finding food in a petri dish. It's like a natural path finding algorithm,N/A,2015-08-29 20:36:25
6f6ylu,I made a search engine to show the best paths for learning anything,"[Here](https://learn-anything.xyz/) is the search engine and here is a [mind map for learning computer science](https://learn-anything.xyz/computer_science).

I always wanted to build a search engine that shows the most efficient paths to [learn anything in a linear way](https://learn-anything.github.io/future/2017/05/27/future-of-learning.html).

The most awesome thing is that if anyone thinks there is a better way to learn the topic, one can say it since it is an [open source project](https://github.com/nikitavoloboev/learn-anything). 

Would love to hear your thoughts on it.",2017-06-04 11:47:45
1fv6b5,"On this day in 1954, Alan Turing took his own life. He wrote this letter to a friend in 1952.",N/A,2013-06-07 15:16:44
z36xpv,Computer History Museum to release historical source code,"Hi all!

I’m a curator at the Computer History Museum and we’re making some epic source code releases in the next few months:

Adobe Postscript source code – release date: Dec 2022

Apple Lisa source code – release date: January, 2023

Xerox PARC Alto source code: release date: March, 2023

This is part of the Museum’s Art of Code program, sign up to receive updates on code releases here: [https://info.computerhistory.org/subscribe-aoc](https://info.computerhistory.org/subscribe-aoc)

For background on our Art of Code program, be sure to read our Art of Code blog here: [https://computerhistory.org/blog/the-art-of-code-at-chm/](https://computerhistory.org/blog/the-art-of-code-at-chm/)

CHM is home to the world’s largest collection of computer hardware, software, media, documentation and ephemera and everything we offer is free, but it is not without cost. If you’d like to support our efforts – even a small token amount sends us a signal you think we’re doing good work – have a look here: [https://chm.secure.nonprofitsoapbox.com/donate](https://chm.secure.nonprofitsoapbox.com/donate)

Thanks everyone – this is going to be a great year for software history!

\-- Dag.

Dag Spicer

Senior Curator

Computer History Museum

E-m: [spicer@computerhistory.org](mailto:spicer@computehistory.org)",2022-11-24 01:43:12
fzjbfm,John Conway has died.,N/A,2020-04-11 21:15:55
1bragad,Maze solver has gone to AA*,N/A,2024-03-30 05:46:24
13en5o8,"Researchers found that inconspicuous smartphone sensors can reveal people's location, passwords, body features, age, gender, level of intoxication, driving style, and be used to reconstruct words spoken next to the device.",N/A,2023-05-11 13:17:00
u4ho2n,More on Evoloop cellular automaton: different evolution patterns depending on the initial genome,N/A,2022-04-15 20:59:26
b71ke5,"American computer science graduates appear to enter school with deficiencies in math and physics compared to other nations, but graduate with better scores in these subjects.",N/A,2019-03-29 19:28:51
xajpme,My Logisim RISC-V Computer executing Dijkstra's Shunting Yard algorithm written in C to evaluate single digit arithmetic expressions.,N/A,2022-09-10 08:11:16
svh56p,A classic cellular automata,N/A,2022-02-18 12:47:24
fwanlw,"I have started a new Youtube channel about making the ""theory"" classes in CS as easy as possible.","(If this subreddit is not the right place to post this, I would be happy to know where would be.)

I am a professor of computer science. Since I left my home university (ASU), my public page has disappeared, and so the PDFs of all my homeworks, labs, recitations, tests, etc. are all gone. I do have them all saved on my computer, thankfully.

I have created a new Youtube channel, Easy Theory (https://www.youtube.com/channel/UC3VY6RTXegnoSD_q446oBdg), to help students with the ""undergraduate theory"" class, to understand concepts from that class in the easiest way possible.

I would appreciate if you subscribe, and even if you don't, I hope you and others will benefit from this effort to help students in CS Theory who cannot benefit from my course materials any more.",2020-04-07 00:41:18
kczkk1,"My 2020 curated list of articles, resources and links on programming, math and computer science.","# 

Hi [/r/compsci](https://www.reddit.com/r/compsci)!

**2019 list**: [My 2019 curated list of articles, resources and links on programming, math and computer science.](https://www.reddit.com/r/compsci/comments/efgqqi/my_2019_curated_list_of_articles_resources_and/)

---

Every year I bookmark many websites, tutorials and articles on mostly programming, math, technology and computer science. I go through them all in the end of the year and curate the best, unique and interesting stuff to make a list for myself (and discard the others). 

---

This year wasn't the one to celebrate but we came out stronger, wiser and more prepared. I hope these resources help you in some way and most importantly I hope you'll learn something fun and enjoyable. 

---

**Interesting Experiments**

- https://pointerpointer.com, pretty cool right? 
- https://explainshell.com/ & http://showthedocs.com/ for shell help and to find docs for stuff you need
- [GUI Programming: 7 Tasks](https://eugenkiss.github.io/7guis/), 7GUIs defines seven tasks that represent typical challenges in GUI programming + provides a recommended set of evaluation dimensions.
- [Artvee](https://artvee.com), browse and download high-resolution, public domain classical artworks. 
- [tixy.land: creative code golfing](https://tixy.land),
- [These cool examples at Three JS](https://threejs.org/)
- Text only versions of news websites: [CNN lite](http://lite.cnn.com/en), [NPR](https://text.npr.org ). I wish news websites be fast and minimal like these. 
- [arXiv Vanity](https://www.arxiv-vanity.com), render arXiv papers as responsive web pages.
- [Carbon](https://carbon.now.sh/), Create and share beautiful images of your source code.
- https://cdecl.org: C gibberish to English, very useful when I learnt to program in C/C++
- [Super Mario Bros. 3 in 3 Minutes](https://www.youtube.com/watch?v=WWbZFj-cLvk), this extremely well made and informational video explaining how the WR in Super Mario Bros. 3 was done in 3 mins using stack underflow and memory exploits.

**Books, Courses, Blogs and More**

- [Cornell's Advanced Compilers: The Self-Guided Online Course](https://www.cs.cornell.edu/courses/cs6120/2020fa/self-guided/)
- [Web Design in 4 minutes](https://jgthms.com/web-design-in-4-minutes/), by Jeremy Thomas, creator of Bulma CSS
- [High Perf. Browser Networking by Ilya Grigorik](https://hpbn.co)
- [CMU's Foundations of Software Engineering](https://cmu-313.github.io)
- [Excellent detailed explanations of various stuff](https://ciechanow.ski/archives/)
- [Nicholas Carlini's Blog](https://nicholas.carlini.com/writing) where he dissects papers related to security and ML.
- [Computer Graphics from Scratch](https://www.gabrielgambetta.com/computer-graphics-from-scratch/introduction.html)
- [Shirley's Ray Tracing in One Weekend Book in HTML](https://raytracing.github.io/books/RayTracingInOneWeekend.html), I fondly remember this book as I had gone through it for my CG coursework.
- [Data Structures and Algorithms I actually used day to day by Gergely Orosz, Uber, ex-Microsoft employee](https://blog.pragmaticengineer.com/data-structures-and-algorithms-i-actually-used-day-to-day/)
- [Jim Hefferon's Free Theory of Computation Book](https://hefferon.net/computation/index.html)
- [MIT's Distributed Systems course](https://pdos.csail.mit.edu/6.824/index.html)

**Hacker-News Posts:** 

- [Your Favorite C Programming Trick](https://news.ycombinator.com/item?id=25176531)
- [Good C++ Codebases To Read](https://news.ycombinator.com/item?id=24901244)
- [Mind Bending Books](https://news.ycombinator.com/item?id=23151144) 
- [What Are You Learning](https://news.ycombinator.com/item?id=22786287)....during the pandemic
- [Ask HN: What's the best paper you've read in 2020?](https://news.ycombinator.com/item?id=25346456)
- [Ask HN: Learning about philosophy](https://news.ycombinator.com/item?id=25312681)
- [Ask HN: Top Coursera Courses?](https://news.ycombinator.com/item?id=25245125)

**Reddit Posts**

Mostly math, ml and more.

- [What's your favorite pathological object?](https://www.reddit.com/r/math/comments/je58m6/whats_your_favorite_pathological_object/)
- [Latest developments in Graph Neural Networks: A list of recent conference talks](https://www.reddit.com/r/MachineLearning/comments/j6wzut/r_latest_developments_in_graph_neural_networks_a/)
- [What are some of the best stories in mathematics that you know of?](https://www.reddit.com/r/math/comments/j5b4u1/what_are_some_of_the_best_stories_in_mathematics/)
- [What branches of mathematics would aliens most likely share?](https://www.reddit.com/r/math/comments/ipg7g3/what_branches_of_mathematics_would_aliens_most/)
- [Do you think we will reach a point where we can no longer do math because of the small lifetime humans have?](https://www.reddit.com/r/math/comments/inckss/do_you_think_we_will_reach_a_point_where_we_can/)
- [Reproducing 150 research papers: the problems and solutions](https://www.reddit.com/r/MachineLearning/comments/ioq8do/n_reproducing_150_research_papers_the_problems/)
- [Your favourite maths puns and jokes](https://www.reddit.com/r/math/comments/i0l33j/your_favourite_maths_puns_and_jokes/)
- [How does a mathematician “pick a problem” for research and ensure that their work is indeed new?](https://www.reddit.com/r/math/comments/gsio4r/how_does_a_mathematician_pick_a_problem_for/)
- [Well-written paper examples](https://www.reddit.com/r/MachineLearning/comments/85cwiu/d_wellwritten_paper_examples/)
- [10 algorithms every computer science student must implement at least once in life](https://www.reddit.com/r/compsci/comments/fuaudc/10_algorithms_every_computer_science_student_must/)
- [r/ML's Advanced courses update](https://www.reddit.com/r/MachineLearning/comments/fdw0ax/d_advanced_courses_update/)
- [Are there any courses, websites or books where you thought: ""Damn, they did really good work.""](https://www.reddit.com/r/learnprogramming/comments/f67n2n/are_there_any_courses_websites_or_books_where_you/)
- [NeurIPS 2019 videos](https://www.reddit.com/r/MachineLearning/comments/e8mut3/n_neurips_2019_videos/), [[D\] ICML 2019 Reinforcement Learning talks](https://www.reddit.com/r/reinforcementlearning/comments/doy9ni/d_icml_2019_reinforcement_learning_talks/)
- [What's your favourite title of a research paper?](https://www.reddit.com/r/MachineLearning/comments/ditivx/d_whats_your_favourite_title_of_a_research_paper/)
- [Multi Subreddit (96) of all national photo subs of the world](https://www.reddit.com/user/I_AM_STILL_A_IDIOT/m/nationalphotosubs/) :)

---

**Various Misc. Stuff** 

- [Rest of the World](https://restofworld.org), global nonprofit publication covering the impact of technology beyond the Western bubble.
- [Physics Today](https://physicstoday.scitation.org/journal/pto)
- Nikita Voloboev's Knowledge [Github Repo](https://github.com/nikitavoloboev/knowledge), [Web version](https://wiki.nikitavoloboev.xyz/)
- [8 years at Roblox](https://zeux.io/2020/08/02/eight-years-at-roblox/)
- [James Somers's Website full of ideas, articles, etc](https://jsomers.net)
- [Cool Machine Learning Books by Mat Kelcey](http://matpalm.com/blog/cool_machine_learning_books/)
- [Interesting Article on making Mass Effect Not Require Administrator Rights, on Reverse Engineering and more](https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/)
- [Tiny, Weird and Fascinating C Programs](https://zserge.com)
- [Greatest Space Stories](https://www.supercluster.com) 
- [Physics Meets ML](http://www.physicsmeetsml.org) 
- [List of Emerging Tech, Wikipedia](https://en.wikipedia.org/wiki/List_of_emerging_technologies), fiction?
- [Graphics Research Papers of Pixar](https://graphics.pixar.com/library/), Pixar's research papers.
- [Crossminds.ai](https://crossminds.ai/explore/), personalized research video platform for tech professionals, academics, etc
- [Protein DataBank Archive](http://pdb101.rcsb.org)
- [Buried Treasure](https://buried-treasure.org), undiscovered indie gaming gems.
- [The Cutting Room Floor](https://tcrf.net/The_Cutting_Room_Floor), a site dedicated to unearthing and researching unused and cut content from video games.
- [At the bottom of the sea](https://blog.demofox.org), a blog on Programming, Graphics, Gamedev, Exotic Computation, Audio Synthesis

---

**Personal Interest 2020+.**

(*You can skip this if you're not into competitive programming.*)

Preparing and competing for the ACM-ICPC during my undergrad was fun and exciting but as I (my team) didn't make it to the WF and I had lost interest to continue this sport. It's back baaaaby!

There are a lot, literally a plethora of CP websites, tutorials and stuff to read and do. If you want huge list of it check [this github repo](https://github.com/lnishan/awesome-competitive-programming). 

I'm going to note down the best of them. 

*Online Judges + Contests*

- https://codeforces.com/, very high quality problems, matured platform, huge, active community. Great contests, fast editorials, lookup solutions, etc. Currently the best out there.
- https://atcoder.jp/, a new Japanese platform which is improving and becoming one the best. Kenkoo has made a [nice website](https://kenkoooo.com/atcoder#/table/) to see which problems you have solved and categorizes them in difficulty. 
- https://www.codechef.com, with a new management it's working hard to be a great platform.

There are many more such as SPOJ, Peking Online Judge, Timus Online Judge, CS Academy, Hacker-Rank/Earth, etc. where you can practice. 

More useful resources:

- https://cp-algorithms.com: implementations of many algorithms
- https://cses.fi + [Competitive Programmer’s Handbook](https://cses.fi/book/book.pdf) by Antti Laaksonen
- [KTH Algorithm Competition Template Library](https://github.com/kth-competitive-programming/kactl), very good implementations of various algorithms useful in contests.
- [Benq's general resources for Competitive Programming](https://github.com/bqi343/USACO)
- [Data Structures Visualizations](https://www.cs.usfca.edu/~galles/visualization/Algorithms.html)
- Errichto's [Github Wiki](https://github.com/Errichto/youtube/wiki/FAQ), [YouTube Channel](https://www.youtube.com/channel/UCBr_Fu6q9iHYQCh13jmpbrg)
- YouTubers: [William Lin](https://www.youtube.com/channel/UCKuDLsO0Wwef53qdHPjbU2Q/about), [Umnik](https://www.youtube.com/channel/UC3-pkjZ8-D4aW8QfaExuMjw), [Second Thread](https://www.youtube.com/channel/UCXbCohpE9IoVQUD2Ifg1d1g)
- Petr Mitrichev's [YouTube](https://www.youtube.com/user/petrmitrichev) and [Blog](https://petr-mitrichev.blogspot.com).
- [Bit Twiddling Hacks](https://graphics.stanford.edu/~seander/bithacks.html) at Stanford.
- [online-judge](https://onlinejudge.org) has many contest problems and [uHunt](https://uhunt.onlinejudge.org) by Steven Halim + [his book](https://cpbook.net) complement it and are a great resource to practice.
- [A2 Online Judge](https://a2oj.com/ladders) has many problems categorized (ladder)
- https://clist.by: the definitive calendar for competitions (and more!)

Have fun!

---

Let the not the ghosts of the past (2020) dim our bright future (2021+).

Stay safe 😷 and happy holidays! 

u/sudoankit",2020-12-14 15:20:51
8k4zpx,Programming Books for Professionals. All the available books are free of cost and legit.,N/A,2018-05-17 15:12:31
cr8aof,P vs NP explained using only loops,N/A,2019-08-16 15:54:02
1171crb,Man beats machine at Go in human victory over AI,N/A,2023-02-20 08:13:55
tgf3ut,Generating 3 kinds of plants with L-Systems,N/A,2022-03-17 17:11:55
8u0eci,Who would be interested in a Youtube series of introductory theoretical CS topics?,"I think this would be an interesting idea. As an instructor for a university, I have seen repeatedly students not able to understand even the basics of TCS topics. I would hope that a series would rectify this somewhat.

Some ideas I had are:

* Discrete math + applications (sets, relations, etc.)
* Probability theory + applications (probabilistic method, Lovasz local lemma, etc.)
* Graph theory
* Finite automata
* Computability + intro complexity theory

However I know that there are many videos on these topics on Youtube (and elsewhere) already, and it may seem like I'm throwing my hat into an already crowded pool.

Thoughts?",2018-06-26 14:22:06
7j3yoq,"Google researchers show that machine-learned indexes are faster than traditional data structures like B-trees, hashes, and bloom filters",N/A,2017-12-11 18:09:33
q91nrm,"Guide to Important Computational Complexity Classes (P, NP, PSPACE, EXP, R, hardness, completeness)",N/A,2021-10-16 01:02:30
nsz4ym,2D Turing-Machine that computes any 1D Cellular-Automaton in Minecraft,N/A,2021-06-05 16:11:04
iru7ok,Unix time reaches 1600000000 Today!,N/A,2020-09-13 07:57:10
147anfb,Should we make r/compsci private for the June 12th protest?,"Edit: it seems like people mostly support doing it. I attempted to switch the community to Private but get an error from the app. Other kinds of settings can be modified and saved, so for now I have made the community 18+.

Edit 2: now private.",2023-06-12 00:53:18
9cw4yq,"World's first binary text encoding: Francis Bacon's 5-bit ""Bi-literarie Alphabet"" (1624)",N/A,2018-09-04 14:32:02
uup1s2,Computing Expert Says Programmers Need More Math | Quanta Magazine,N/A,2022-05-21 15:08:15
rhonek,I used a Genetic Algorithm to generate Cellular Automata.,N/A,2021-12-16 11:14:55
qgfn5e,My university's CompSci building running Conway's Game of Life simulation using programmable lights,N/A,2021-10-26 20:38:16
mct1ae,Bank of England unveils new banknote celebrating WW2 code-breaker Turing,N/A,2021-03-25 08:00:15
lhrtjv,Uncovering a 24-year-old bug in the Linux Kernel,N/A,2021-02-11 19:00:46
zx1eu8,Von Neumann was admonishing people who built assemblers (Snapshot from a book called The History of Fortran),N/A,2022-12-28 05:30:11
2qjrdv,Would anyone be interested in reading a paper every week and discussing it?,I see papers recommended here a lot but often times it is difficult to get through them be myself. People could pick papers and then we could vote on them.,2014-12-27 18:34:07
lh8d7f,Programmer calculator and LL parser made in C from scratch,N/A,2021-02-11 00:30:07
nv6810,"It's Alan Turing's Birthday on the 23rd of June, who wants to send flowers?","Alan Turing's Birthday is on the 23rd of June. We're going to make it special.

Every   year, people from Reddit pledge bunches  of flowers to be placed at  Alan Turing's statue in Manchester UK for his  birthday. In the process  we raise money for the amazing charity [Special Effect](https://www.specialeffect.org.uk/), which helps people with disabilities access computer games.

Since   2013 we've raised about £7600 doing this, and we'd like 2021 to  be  our  biggest year ever. Anyone who wants to get involved is welcome.    Donations are made up of £3.50 to cover the cost of your flowers and a    £14 charity contribution to Special Effect for a total of £17.50.

Manchester   city council have confirmed they are fine with it, and we  have people   in Manchester who will help handle the set up and clean up.

To find out more and to donate, click [here](https://equalitytime.github.io/FlowersForTuring/?utm_source=Reddit&utm_content=compsci).

Joe",2021-06-08 15:10:33
y8w9hq,Evolving two joined rigid bodies to throw another one the farthest,N/A,2022-10-20 11:56:57
2e47te,1 KB Hard Drive in Vanilla Minecraft,N/A,2014-08-20 20:52:19
92cba4,"How the media gets AI alarmingly wrong: ""There are policymakers earnestly having meetings to discuss the rights of robots when they should be talking about discrimination in algorithmic decision making. But this issue is terrestrial and sober, so not many people take an interest.""",N/A,2018-07-27 13:01:59
8puki1,Maze Game - algorithms visualized using JavaFX,N/A,2018-06-09 17:58:18
jnaj96,Are Pop Lyrics Getting More Repetitive? - A story about compression,N/A,2020-11-03 13:47:58
liik4x,Mathematician solves 30 year old conjecture in two pages....and on Twitter,N/A,2021-02-12 19:23:35
bt0q2o,Google and Oracle’s $9 billion “copyright case of the decade” could be headed for the Supreme Court,N/A,2019-05-25 22:50:12
iar7fd,I recently did a livestream where I solved and explained over 300 exam problems in theoretical CS in a row.,"Here is the livestream: https://youtu.be/kwKj0GYTSag?t=309

One of the biggest exams in Computer Science is the GATE exam, along with others, and one of the big components of that is of ""theory"". I had another video go viral-ish about solving 240 exam problems at once. Well, now I upped that to 300! 

I also explain why the solutions are the way they are, and how to approach getting a deeper understanding for each of the questions. 

Let me know if you have any questions!",2020-08-16 12:04:36
7140ur,I researched the web and came up with this collection of free online courses that will provide you with an equivalent of a full Bachelor of Science in CS,N/A,2017-09-19 16:10:51
cvrh7n,"Humans Don’t Realize How Biased They Are Until AI Reproduces the Same Bias, Says UNESCO AI Chair",N/A,2019-08-26 17:50:04
k42krt,‘It will change everything’: DeepMind’s AI makes gigantic leap in solving protein structures,N/A,2020-11-30 19:01:32
6h75kh,"I built a mechanical computer powered by marbles over the last two years. (Sorry for self promoting link, but it's the most descriptive.)",N/A,2017-06-14 12:26:01
1jwa5b,Computer Science: A Guide for Undergrads,"It's the summer,  I'm now waiting to start my Ph.D., and I've recently graduated at the top of my year. Needless to say, I have a lot of time on my hands. I'm writing this guide for CS undergrads to offer a bit of advice that I feel would have been helpful when I was doing my degree.

[Edit: I'm British so this guide will reflect that. Also, you may notice my bad teeth and love of bangers and mash.]

This guide uses a UK CS degree for examples but I'm sure most of it will be relevant wherever you are. It is probably more catered to those who are doing a CS degree because they actually want to work with computers, as opposed to people who are doing it as a continuation of school.

Also, if I make any bold statements you can assume it's because I'm British and I have an ego the size of my penis.

**Working on campus and Dolly Parton**
Go to uni (campus) to get work done. It may seem obvious, but I think it's so important to work somewhere other than where you live. The problem with working at home is that it's the place where you'll play xbox, get drunk, and relax. And because of this, when you take a procrasti-break you're more likely to get distracted. At uni you have little other choice than to do work. 

Try to work 9—5 (10—4) five days a week. Getting into a routine really helps and is important around crunch time. You'll probably find you have more free time, and all of your work will get done. Then you can relax and go partying in the evenings and weekends, and most importantly you won't have that niggling feeling that you aren't getting any work done.

**Prioritise your workload**
Prioritise how long you spend doing certain bits of work, i.e. remember to do the boring stuff. A bunch of my mates love doing games programming, and in the second year they devoted a massive amount of time to completing a game (coursework) during the exam period. The problem with this was that they'd concentrated so much on the game (worth 40% of one module) that they'd almost entirely neglected to revise for their exams (a number of 60% exams for different modules). Of course, it is a lot easier, and possibly more rewarding, to do something you really enjoy, but it's worth bearing in mind that you need to focus on other modules as well.

**Chose another programming language**
The uni I went to taught Java as the main programming language. Now, I don't personally understand the animosity towards using Java as a teaching language, but I do think it's prudent to pick another language and learn that. Personally, I'd say something like C++ (or C) and Python. Not only will it give you more general programming experience, it also looks good to employers. Have a read around online, try a few out, and pick the one that you feel you want to use.

It is also likely that for your final year project you'll be able to use any programming language you want, and this is a good time to really learn whatever it is you have chosen.

And remember, certain languages are better at certain things. If you're doing a piece of work that requires a lot of string manipulation (parsing logs), don't use MATLAB, and maybe not C++ either. I saw far too many people do this in my final year, and it's excruciating to watch when what has taken them two hours to get working can be done in five minutes in Python.

**Do projects in your spare time**
For those of you who know what you want to do after your degree, do projects in your spare time. For example, if you want to do games programming then make a few games in your spare time, record some videos, and put them on youtube. If you want to do web development then make some websites for a few friends and get them online. The reason I suggest this is that when it comes to applying for jobs you'll easily stand out. If an employer is looking at 10 applications from recent CS grads and one of them has shown to be putting in effort outside of their degree, then they're going to be at the top of the pile.

If you don't know what you want to do after, but you like computers, then pick something. I'd suggest learning Prolog as it's super easy.

**Your first year**
The first year is for having fun. Go out and party, meet as many new people as you can, join clubs and generally experience living as more of an adult. You're going to be meeting lots of people who love computers as much as you (presumably) do. This means lots of gaming, drinking beer, and whatnot.

However, you may still want to consider doing well. Although you may only need 40% to pass, that's probably not the best way of looking at things. If you're applying for a year in industry, or you want to look for jobs in the summer, then being able to prove your academic performance is important.

I thought I'd mention this as an aside. If, like me, you have problems, or are worrying about, conversing with “normal” people, i.e. those who do humanities degrees, you needn't worry. I found that people who do CS are a far more accepting bunch than most, and you will meet plenty of people who don't care that you're a little “weird”.

**Commenting code**
When it comes to code-based coursework, you need to comment. I wouldn't say there's a limit to how much you should comment when you're at uni, but don't go for the “this is a variable called 'x' that I add one to every now and then”. Also, consider following code guidelines and documenting standards. If you're wanting to get a job where software will be your main thing, then getting into best habits will really bode well.

**Technical Reports**
Reports seem to confuse a lot of people who do CS. Although many of us are happy writing code for hours on end, the thought of stringing some words together seems like a horrific waste of time. The thing about reports is that they are a way for the lecturer to know that you have undertsood what you did. This may appear obvious, but if you can explain what it is that you've done then they, and you, can be sure you've understood it properly. Plus, they'll catch out a few people who have used Freelancer for their coursework.

As for general tips. Don't use 'I', 'We', etc., and don't bitch and whine about using LaTeX. No, people who write normal software in normal CS jobs don't use LaTeX to write reports, but that's not the point. It's something you have to do and it really does look better than Word. 

Also, reading up on how to write technical reports is a wise idea. 

**Exams: everything, not just the past papers**
You need to know everything for exams. A degree is not the same as GCSEs or A-levels. You can't just learn what has been in the past papers and expect to do well. You may know people who had revised using past papers and they did extremely well, but I can guarantee that those same people will be the ones who complain after they do bad because an exam doesn't cover topics from the previous years. Having said that, make sure you do use past papers for revision to get a general idea as to how the questions are asked and how the marks are distributed.

**Look at jobs early**
Start job hunting in the summer before your final year. I say this because it gives you enough time to get further experience and to do stuff that will greatly help you in getting a job. You don't have to actually be applying for jobs (although you will for graduate schemes), but get a general idea of what's out there and what you need to do to make yourself just that little bit better.

**Final thoughts**
Try and use all of Windows, Linux and Mac OS X. Despite the fact that you may hate Apple, put your prejudices aside and use it. It's all experience, and as a CS person you *really* should know how to use each.

Learn about how computers actually work. As in the CPU, hard drive, assembly language, memory, scheduling, et cetera. I found this has not only given me a better understanding of computing in general, but it's another vast area of CS that can be explored.

Use the library and electronic resources. My uni spent £1000 per student per year on subscriptions for journals and new books. Before you buy that £60 book that you may only read twice, see if the library has it.

And for a small minority of you: make sure you wash. Seriously. Also, foist (think week old moist swimming towel that has been kept in a bag in a warm cupboard) is much worst than BO. With BO you may have just been for a run in the morning, but foist means you don't wash either yourself, or your clothes.
",2013-08-07 17:40:18
m3rjxg,Decomposing 1810's top hit with C++ and DFT,N/A,2021-03-12 21:24:42
a98wkn,MIT lecturer Ana Bell discusses the best books to learn computer science and programming.,N/A,2018-12-24 21:22:42
9r07hp,I spent a long time making a P vs. NP video that is grounded in concrete terms & visuals - no hand waving.,N/A,2018-10-24 14:33:54
exhaa1,"UC Berkeley told to cough up $5m in compensation to comp-sci, engineering students recruited to teach classes",N/A,2020-02-02 02:26:57
b25os8,I Bought Used Voting Machines on eBay for $100 Apiece. What I Found Was Alarming,N/A,2019-03-17 14:28:51
5thqpz,Algorithm complexity cheat sheet,N/A,2017-02-11 21:46:42
c9hc2k,I wanted to thank to the person that recommended to read the book Operating Systems: Three Easy Pieces,"I'm near the end and this is really an amazing book.

I will literally read anything that the authors will publish.

&#x200B;

Thanks to the person that recommended this book in some post that I red when I began my OS course.

&#x200B;

It's like a gold mine. Anyone can recommend some great books in the same ""attitude"" that the OS book goes with ?

With ""attitude"" I mean  that the content of the book is a combination of ELI5 and askreddit or askscience (but the posts and comments  that have high quality content)",2019-07-05 15:36:05
l13wfx,Someone please explain. How will an electron microscope gain access to encrypted data?,N/A,2021-01-20 06:56:59
9epd17,Piping shell scripts,N/A,2018-09-10 17:47:22
poy0la,"I designed a CPU and made it print ""Hello World"" via DMA requests(details in comments).",N/A,2021-09-15 20:15:49
53s8se,"Three computer scientists have produced, through the use of a supercomputer, a 200-terabyte file containing the solution to a Boolean Pythagorean triples problem, a puzzle that has eluded mathematicians for decades.",N/A,2016-09-21 08:50:37
5icuv3,"""The Talk"" - The Quantum Computing Talk | SMBC Comic",N/A,2016-12-14 20:10:21
ecu9n6,The internet is 50 years old,Just a quick reminder. In 1969 the first packet was sent through the internet. The technology of sending a bit from a computer to another opened various ways how this could be used.,2019-12-19 14:56:14
8d4xwg,Detailed Computer Science notes,N/A,2018-04-18 11:37:50
gr39fk,I made some UX/performance improvements and added additional algorithms to my traveling salesman problem visualizer based on feedback I received here. This is a browser-based educational resource for learning common algorithms.,N/A,2020-05-26 19:02:40
jzyjrx,"You might not need machine learning: ""Machine learning is a trendy topic, so naturally it’s often used for inappropriate purposes where a simpler, more efficient, and more reliable solution suffices.""",N/A,2020-11-24 04:58:00
1g1oug,No internship? Wanna fill in the resume this summer? Fix bugs in opensource projects!,"Yes, it's a bit painful to get started, but start on smaller, newer projects, and it's easier.  Then, on your resume, you can put actual URLs of bugzilla/github issues/etc.   That kind of tracable, concrete evidence of ability is frankly wonderful.  I interview a candidate a week, and seeing a meaningless list of buzzwords tells me nothing of what to expect.  If I see a URL on a resume, I'll click on it (we get the PDFs), and read.

Also, you can choose your project, for whatever you like.  That lets you show off the skills that you want to show off, for the industry that you want.  

Some initial suggestions:

* Gaming: [Torque](http://www.garagegames.com/community/blogs/view/21886)
* Functional Programming: [XMonad](https://code.google.com/p/xmonad/)
* Compilers: [LLVM](http://llvm.org) ([Bugzilla](http://llvm.org/bugs/describecomponents.cgi))

Thoughts?  Other suggestions?",2013-06-10 14:45:04
ws6rma,System Design course for everyone! (free),"Hi everyone, today I open-sourced my free System Design course which is suitable for all levels.

This course also covers everything from basics to advanced topics of system design along with interview problems such as designing Twitter, WhatsApp, Netflix, Uber, and much more!

I hope this course provides a great learning experience.

Link: [https://github.com/karanpratapsingh/system-design](https://github.com/karanpratapsingh/system-design)",2022-08-19 06:35:35
gppst5,Aubrey de-Grey's Unit-Distance Graph of 1585 Vertices & 7909 Edges that Proves that the Chromatic № of the Plane is Atleast 5 [909×902],N/A,2020-05-24 13:37:05
42yu2r,Google’s AI Masters the Game of Go a Decade Earlier Than Expected,N/A,2016-01-27 18:25:48
jd3ept,Pixar has a public webpage dedicated to papers on simulation and other methods written by their staff,N/A,2020-10-17 21:19:21
v8hx5r,"A US Supercomputer Just Broke The Exascale Barrier, Ranking Fastest in The World",N/A,2022-06-09 14:21:36
korw0y,Disabled Programmer Blog?,"Hello everyone! I'm a legally blind woman learning how to code, currently working my way through college towards an computer science degree. For a while now, I have been considering starting a blog to share the code I've written and maybe some of my experiences as a disabled female in this field. Would anyone be interested in reading/following something like that?

I am trying to see if there would be interest in me starting a blog like this as well as advice on where to post and what content to post as I have never tried blogging before

Thank you! :)

&#x200B;

Ps: Please feel free to PM me if you have any specific questions about my vision, what it's like being blind in a visual world, how I do things (whether in tech or not), accessibility or anything like that. I'm super open about my disability and how it affects my day to day life. I'm always excited when I get the opportunity to educate others about it :) ",2021-01-02 05:45:09
1bzcy4,The First Level of Super Mario Bros. is Easy with Lexicographic Orderings and Time Travel... after that it gets a little tricky.,N/A,2013-04-09 10:42:10
70hgbp,Math cheat sheet,N/A,2017-09-16 15:25:39
9linm4,Going Through Introduction to Theory of Computation by A. Maheshwari,N/A,2018-10-05 03:07:45
2n8do4,"This is my grandfather working on the Eniac, the world's first computer(sitting at the table)",N/A,2014-11-24 04:20:12
1p1fvv,So I made a .gif to ASCII .gif converter...,N/A,2013-10-23 09:12:42
hrn5c6,Data Structures & Algorithms I Actually Used Working at Tech Companies,N/A,2020-07-15 13:03:03
g7l0rj,So sorry to hear that mathematician John Conway passed away due to COVID-19 complications,N/A,2020-04-25 01:34:10
5vo58i,I got the Google Foobar challenge today!,N/A,2017-02-23 04:17:19
vkqxkb,Computing a 3×3 determinant using < 9 multiplications,"I’ve read that it’s unknown whether a 3×3 determinant can be computed using fewer than 9 multiplications. [1]

If that was ever true, it’s not any more. Earlier today I found a way to do it with 8 multiplications. If the matrix is

    ⎛a b c⎞
    ⎜d e f⎟
    ⎝g h i⎠

then we can define

    D = d(h-i)
    E = e(i-g)
    F = f(g-h)
    G = g(e-f)
    H = h(f-d)

using 5 multiplications, and then compute the determinant as a(E+F+G) + b(D+F+H) - c(F+G+H), using another 3 multiplications.

I’m interested in whether this really is a new discovery. If you know of previous work on this, I’d love to hear about it.

(I realise this doesn’t have massive practical applications. Maaaaaaybe there are specialised geometric applications involving 3d vectors of some non-machine numeric type, like bignums or super-high-precision floats, where multiplication is a lot more expensive than addition: in cases like that, it could be a win to compute a cross-product using 5 multiplications rather than 6, even at the expense of more additions.)

1. I read it in a comment by Jeffrey Shallit on [this StackExchange post](https://cstheory.stackexchange.com/questions/37017/the-minimum-number-of-arithmetic-operations-to-compute-the-determinant).",2022-06-25 23:10:19
ynyh8o,Evolving a rigid body to throw another one the farthest with UI,N/A,2022-11-06 18:36:05
62o9lz,Guy writes an executable research paper by compiling C to printable x86 instructions. Some jokes may occur.,N/A,2017-03-31 21:26:22
ep2gwi,P vs NP explained with loops,N/A,2020-01-15 13:42:04
dds6gc,Non-linear formal proof is actually pretty neat,N/A,2019-10-05 19:42:06
jmm6ch,"For those taking a ""theoretical computer science"" class, and want some help in preparing for your final exam, I will be streaming the entire course over the next few weeks.","The first stream link is https://youtu.be/bK8LVFWA0L8, and will occur this Sunday at 10AM EST. 

I am a professor who has taught this course quite a bit before, and always am wanting to help as many students as possible in it. I run this YouTube channel as well. 

Let me know if you have any questions on any topics I can cover to make things clearer, or any problems you want to go over. I would appreciate if you shared this with any of your colleagues taking this class as well, as it may help them greatly. 

See you Sunday!",2020-11-02 12:01:13
i9sez0,"Scientists discover way to make quantum states last 10,000 times longer",N/A,2020-08-14 19:22:22
58e9dv,"I'm a 16 year old student super interested in Computer Science, and tonight I'm analyzing the third debate using python + the initialstate dashboard!",N/A,2016-10-20 01:49:56
g0kydp,I write long tech articles about consoles in my free time for everyone to read and enjoy. Today I found out the official IEEE computer society copied my content with no attribution. Thank you!,N/A,2020-04-13 15:20:15
41owk3,"Why do most computer science courses not teach the use of a Version Control System, despite it being very very important?","Every start up i've approached for a job requires you to know at least the basics of version controlling, but no one teaches it to you. Wondering why!",2016-01-19 14:28:47
gq6sv3,Just started a blog post on the math behind various things in CS. I would appreciate it if you could check it out,"I'm a hobbyist who loves to code in Python and Java. Recently, I started a blog called [https://www.byteofmath.com](https://www.byteofmath.com) where I basically talk about the math behind different coding concepts. I wrote a blog post on the math behind Support Vector Machines using Lagrangian Optimization, and I would love it if anyone who is interested in machine learning or really just loves computer science and math could check it out. Any advice is appreciated! Please subscribe to get updated content! (P.S Also if you want to write on my blog, you can go to the contact me page, send me a message, and we can make glorious content together!)

EDIT: OMG, GUYS! You are the best! Thanks for checking out the blog, and yeah I will take the tips into account and make my blog a lot less gaudy. (P.S I just woke up and we have 1500+ views)

EDIT 2: This is very new for me. So I changed the theme of the blog, and I was just wondering if you guys could check it out and see if it works better.

EDIT 3: Redesigning the blog again, this time to improve website loading speeds. Thanks for the support guys!

EDIT 4: Kept the same design, but fixed loading issues :), I combined some files and got rid of lots of unnecessary requests and plugins.",2020-05-25 07:47:10
cuxp1p,Quick Sort with pure λ-calculus,N/A,2019-08-24 19:11:53
73gc4o,This week we tragically lost one of the brightest rising stars in computer science. RIP Michael B. Cohen.,N/A,2017-09-30 17:47:57
vf8rp,"Happy 100th Birthday, Alan Turing!",N/A,2012-06-22 05:24:17
n4yd0d,Generate Lego-based images and video,N/A,2021-05-04 21:09:53
cjdcu8,What is the most unbelievable or most interesting computer science paper you've read?,N/A,2019-07-29 16:13:01
8nsf92,Visibility graph simulator built using Python and Pyvisgraph,N/A,2018-06-01 14:50:49
f7yvog,Artificial Intelligence Finds a Strong New Antibiotic for The Very First Time,N/A,2020-02-22 21:08:55
65gxbx,Competitive Programmer’s Handbook,N/A,2017-04-15 02:51:39
3wdvoz,Here's a computer I made in Minecraft two years ago.,N/A,2015-12-11 15:24:20
4zoftv,"""How I Got Started With Programming Side Projects"" - My experience with personal projects in college, and some advice for computer science students",N/A,2016-08-26 12:53:33
1kcal2,Algorithims Everyone Should Know?,"What are some of you're favourite algoritms or concepts that you think everyone should know, whether they solve problems that crop up frequently, or are just beautiful in their construction?

",2013-08-14 10:57:41
3adofn,"I'm watching Cosmos on Netflix right now, and am thinking, damn it would be awesome if there was something like this for Comp Sci to share with my non Comp Sci friends","Do you think it would generate interest? Or are there even stuff like this out? Most of what I see is Khan Academy type things and nothing about the sheer awesomeness, depth, and application of the subject (which I feel can be shared with normal people and appreciated if done in a similar fashion to Cosmos).

EDIT: Wow this generated way more interest than I thought it would. It was just a passing thought, but I think I'll maybe contact one of my professors from UC Berkeley and talk about trying to make it happen in some way shape or form. ",2015-06-19 07:19:41
h9wi6n,"Skiena's famous book ""The Algorithm design manual"" is currently free from the publisher!",N/A,2020-06-16 04:24:02
8pqnqt,I made a Boolean game. Hopefully the CS community might appreciate it.,N/A,2018-06-09 05:18:11
djsc4c,Math for Computer Science in just 1000 pages (or less),N/A,2019-10-18 19:16:48
8b602k,[xpost r/comics] Algorithms,N/A,2018-04-10 08:08:28
5z9pzk,Teach Yourself Computer Science,N/A,2017-03-14 03:01:40
5lducd,Top 10 algorithms in Interview Questions,N/A,2017-01-01 05:55:57
mbyctv,"What exactly does a Computer Scientist (with a PhD or Masters) work on, compared to a regular software engineer?",N/A,2021-03-24 05:28:40
d70bge,"Google claims to have achieved ""quantum supremacy"" - quantum computers are able to solve problems beyond the reach of normal computers",N/A,2019-09-20 20:03:11
48ie3a,Whitfield Diffie and Martin E. Hellman win the Turing Award for their invention of public-key cryptography,N/A,2016-03-01 20:19:11
iygj9c,I am trying to compile a list of Computer Science books on different topics that you highly recommend based on your personal learning experience.,"As the title says, I am trying to compile a list of Computer Science books that were undoubtedly helpful in both forming your basic understanding and building in-depth concepts of those topics.

I occasionally come across posts in this sub where people ask for recommendations for books, and people come up with really great recommendations. Some of the books I have read and greatly benefited from, some I have not read or heard about for the first time,

I am asking you to come forward with books on any Computer Science topic that you really found helpful during learning that topic and you highly recommend.

For example- people mention the ***""dragonbook""*** for learning compilers, [Operating Systems: Three Easy Pieces](http://pages.cs.wisc.edu/~remzi/OSTEP/#:~:text=The%20book%20is%20centered%20around,virtualization%2C%20concurrency%2C%20and%20persistence.) also gets mentioned a lot.

Don't shy away from mentioning *classics* such as CLRS, TAOCP, etc.

***Extra credits if your teacher mentioned the book as 'the Bible' for that topic! Or the book is a classic!***

I believe everyone can benefit from this.

Help is highly appreciated.

NB: I got the idea of the post from [this comment](https://www.reddit.com/r/compsci/comments/iu0lus/how_does_the_internet_work_on_the_most_granular/g5i6m9y) in this sub.",2020-09-23 18:59:19
cq9n8t,"Anime4K, a real-time anime upscaling algorithm for video.","&#x200B;

https://preview.redd.it/kqe1zd181fg31.png?width=1703&format=png&auto=webp&s=7b76f7d8940738049ec86631263898ee317f97c6

For usage instructions (if the reader wants to try it out for themselves), source code and implementation details (for the curious), please visit the GitHub repository.

HLSL Shaders are included for those who use MPC with madVR.

[https://github.com/bloc97/Anime4K](https://github.com/bloc97/Anime4K)

&#x200B;

**Abstract**

We present a state-of-the-art high-quality real-time SISR alorithm designed to work with japanese animation and cartoons that is extremely fast *(\~3ms with Vega 64 GPU)*, temporally coherent, simple to implement *(\~100 lines of code)*, yet very effective. We find it surprising that this method is not currently used *'en masse'*, since the intuition leading us to this algorithm is very straightforward.

Remarkably, the proposed method does not use any machine-learning or statistical approach, and is tailored to content that puts importance to well defined lines/edges while tolerates a sacrifice of the finer textures. The proposed algorithm can be quickly described as an iterative algorithm that treats color information as a heightmap and 'pushes' pixels towards probable edges using gradient-ascent. This is very likely what learning-based approaches are already doing under the hood (eg. VDSR^(\[1\]), waifu2x^(\[2\])).",2019-08-14 13:26:29
sf20fr,"I don't think quantum computing is complicated. That's why I went ahead and a made a video series on it, explaining it without dumbing it down. It covers some cool quantum concepts, more details below.","Quantum computing is simple, but that doesn't mean it's intuitive. This series focuses on one of the non-intuitive algorithms discovered by quantum computing researchers, an algorithm that is both cool and scary at the same time. See the series below!

[https://www.youtube.com/playlist?list=PL-R4p-BRL8NSCoZAsClRd-fz0\_IJ1am0C](https://www.youtube.com/playlist?list=PL-R4p-BRL8NSCoZAsClRd-fz0_IJ1am0C)

And if you want transcripts of the videos so that you can get a feel for the videos, here they are:

Part 1 (Quantum computing): [https://github.com/finedesignvideos/finedesignvideos.github.io/blob/main/transcripts/quantumPart1.txt](https://github.com/finedesignvideos/finedesignvideos.github.io/blob/main/transcripts/quantumPart1.txt)

Part 2: [https://github.com/finedesignvideos/finedesignvideos.github.io/blob/main/transcripts/quantumPart2.txt](https://github.com/finedesignvideos/finedesignvideos.github.io/blob/main/transcripts/quantumPart1.txt)

Part 3 (Bonus video, including Grover's algorithm): [https://github.com/finedesignvideos/finedesignvideos.github.io/blob/main/transcripts/quantumPart3Bonus.txt](https://github.com/finedesignvideos/finedesignvideos.github.io/blob/main/transcripts/quantumPart1.txt)",2022-01-28 22:03:29
cpvbz4,"My AI is so bright, I gotta wear shades.","I've built a pair of AI-enabled glasses that allow you to interact with objects in the real world just by gesturing to them.  For example, if you wave at the lamp you're looking at, it will turn on.  Or, if you wave at your smart speaker, it will play music.  It is extensible and can be adapted to control any number of objects, with full details on my GitHub page.  The entire BOM is under $150 making it very accessible.

I can also envision many additional applications of the technology, such as assistive applications for those with a disability, or fast charting/order entry for medical practitioners to name a few.

See it in action:

[https://youtu.be/7UYi-exvHr0](https://youtu.be/7UYi-exvHr0)

Full details on GitHub:

[https://github.com/nickbild/shaides](https://github.com/nickbild/shaides)

Hope you like it!",2019-08-13 16:14:31
lkhil0,Is anyone else still in awe of coding/programming and what all it can accomplish?,"I’ve had about 4 years of experience in computer science now, and I’m still in awe at all that I’ve learned.

I still remember what it was like to not know anything. When I explain what I do to people who aren’t familiar, they say “It’s all Greek to me!” And I totally get that because even though I know how to program now and I know the computer science concepts behind it, I’m still not entirely convinced that the whole CompSci field isn’t magic.

Edit: just a typo",2021-02-15 16:48:13
m2q629,Must watch video on mathematics (the guts) of neural networks,N/A,2021-03-11 13:34:39
3gj6mc,"For 40 years, computer scientists looked for a solution that doesn’t exist",N/A,2015-08-11 00:38:34
kcduvq,"Did anyone else enjoy computer science academically, but dislike the process of actually studying it in undergrad?","I currently work as a software engineer, graduated two years ago, and my original plan was to get a PhD in CS, which I ended up not pursuing.  I still love the subject of CS, but I really did not like going to school for it.




First of all, I expected going to school to be a fantastic networking experience, but I never expected CS students to be so competitive and non-collaborative.  The worst example was the competition for grades.  I personally never cared about grades, as long as I passed and learned from the class.  For that reason, it was hard making friends in class.




Getting into clubs was also hard as they required interviews, and positions in the clubs seemed reserved for students who had family connections in the tech industry or who somehow obtained freshman and sophomore summer internships.  I feel like I really missed out meeting big companies who came to campus through those clubs because I never got into a club.




I ended up getting lucky and getting a single internship during my time in school that lead to a full time offer.  But I feel like I never made a single professional connection through college.  All of my connections in the tech industry are through my current job.



Because of all this competition, I decided not to pursue a PhD, even though it was my previous career goal.  Did I just attend a bad university, or is this experience normal in CS?",2020-12-13 16:48:35
10apa6s,You should be reading academic computer science papers,N/A,2023-01-13 08:22:43
44ztw5,President Obama pledges $4 billion in Computer Science for All program,N/A,2016-02-10 00:11:58
kyg6oy,Big O Notation - explained as easily as possible,N/A,2021-01-16 09:49:21
swcvqz,I bought this Turing Patent Poster for my nephew but I don't understand it myself. Can anyone help a 7 year old understand it? (Also is it a real patent or a gimmick),N/A,2022-02-19 15:45:37
eme491,‘Brains Are Amazing’ — Neuroscientists Discover L2/3 Human Neurons Can Compute the XOR Operation,N/A,2020-01-09 18:56:35
c4gyeu,On the Birthday of Father of Computer Science and Artificial intelligence,N/A,2019-06-24 02:19:30
tukd1d,"Evoloop : self reproducing, evolving, dissolving cellular automata",N/A,2022-04-02 14:39:49
sy40ct,The spinning paradise of my self replicating loops in ALiEn: Artificial Life Environment,N/A,2022-02-21 20:48:52
8623kp,John Hennessy and David Patterson win the Turing Award for their contributions to computer architecture,N/A,2018-03-21 13:34:56
js66qm,Computer Scientists Achieve ‘Crown Jewel’ of Cryptography - A cryptographic master tool called indistinguishability obfuscation has for years seemed too good to be true. Three researchers have figured out that it can work.,N/A,2020-11-11 11:00:49
6qa6id,The Evolution of Trust,N/A,2017-07-29 09:55:47
1yyqgd,if I went back in time 45 years and gave one of the R&D guys at IBM my ...Nintendo 3DS (the first thing I saw on my desk with a computer in it) would they be able to make much use of it with regard to reverse engineering?,N/A,2014-02-26 05:12:12
in0mqm,"I will be making a text book that will synergistically combine Algorithms, Discrete Math, and Theory of Computation to show the connections between them.","What the title says. During a recent livestream someone came up with the idea of making an “Easy Theory” textbook (a YouTube channel I run) and having thought about it more, I think it’s worth pursuing. So we are going to make a textbook! The goal is to have a combination of theory, algorithms, and discrete math to synergistically make the best of all three. I want this to be a book that helps people see the inter-connections between all three of these, without having to jump back and forth between them. 

I created a channel on my Discord server to facilitate discussion. I would like to get your feedback from you all about what you want to see in such a work, and any ideas you have on bridging the gaps between the three. Please tell me any and all experiences you’ve had with existing textbooks, and what you want to see in one. There are some topics that seem at first to be “standalone” (i.e., don’t require any of the two areas, such as minimum spanning trees), but I want to get any and all perspectives here. 

Additionally, my goal will be to make the book freely available online because I truly believe that’s the best way for those to learn. If at all possible, I’d like to have a paperback version for purchase as well.

The structure of the book will be divided into chapters, where each of the chapters has plenty of exercises, but none of them are “the same” as others. In other words, they show something even deeper than what the normal chapter material gives. An example would be regex derivatives.

Come join us at my Discord server (https://discord.com/invite/SD4U3hs) if you want to contribute!",2020-09-05 12:54:25
5e2ga7,Computer Science courses with video lectures,N/A,2016-11-21 05:30:45
gwgnir,Hot qubits made in Sydney break one of the biggest constraints to practical quantum computers,N/A,2020-06-04 12:38:07
cmptq6,"Data scientist skeptical about data: ""Data doesn’t say anything. Humans say things. They say what they notice or look for in data—data that only exists in the first place because humans chose to collect it, and they collected it using human-made tools.""",N/A,2019-08-06 12:16:23
t15fmd,Computer Scientists Prove Why Bigger Neural Networks Do Better,N/A,2022-02-25 14:34:02
7hnk3v,"Fractal tree (xpost from r/perfectloop, by u/Blokatt)",N/A,2017-12-05 05:19:25
ggbxwh,"My first baby steps towards learning compiler design. I started off by using lex and yacc to make a translator. It converts a ""made up C language"" to actual C code. It's definitely not sophisticated, but I had a blast building this nonetheless!",N/A,2020-05-09 08:45:44
fq1vqe,Crash Course Computer Science by Carrie Anne Philbin,"I want to post [this](https://www.youtube.com/playlist?list=PL8dPuuaLjXtNlUrzyH5r6jN9ulIgZBpdo) absolutely fantastic 7 hour and 53 mins YT playlist made back in 2017. It is wonderfully narrated, animated and curated by someone with endless enthusiasm for the subject. If anyone is just starting with CS and wants to go deeper into it, I think this is an amazing introduction.

NOTE: This is not a programming tutorial.",2020-03-27 17:57:44
11x8bg7,What are the chances are that quantum computers capable of breaking current cryptography already exists with one or more countries and is kept secret and probably weaponised like the British did during World War 2,"During the world war 2, the British team lead by Alan Turing, created Bomba, by improving techniques of polish bombe, to secretly breaking cryptographic messages of the Nazi Enigma machines. They kept it secret and didn't act on the decrypted intel until the D-Day.

That brings me to this question.

The information that quantum computing can eventually break all cryptography algorithms that is in use today, is in public domain. Definitely, that is a threat most defence experts are likely working on a priority. So how likely is that one of the defence research group of the world already have it and probably breaking into anything they want?",2023-03-21 05:56:00
93h2bl,"Why Study Compiler Construction? (From 'Engineering A Compiler' by Cooper and Torczon, 2011)",N/A,2018-07-31 18:29:27
8m1dx0,"Data Structures for Beginners: Arrays, HashMaps, and Lists!",N/A,2018-05-25 12:34:05
hava1j,How to work smart rather than hard as a computer scientist/programmer?,"I have seen myself go down that rabbit hole one too many times where before any project, whether it be an assignment or a simple class task, I find myself burning myself out just getting familiar with the topic, absorbing all material that I can even though I'm aware that the best way to learn is through practice. Basically, I feel absolutely incompetent of starting anything unless and until I'm absolutely sure of what I'm doing and am a somewhat expert in the field theoretically. Without a shadow of a doubt, this has done more harm than good from what I've seen. 

Firstly, way too time-consuming. 

Secondly, I end up forgetting everything that I learned after the project is over. 

And I'm sure there must be someone out there who may also be going through the same issue. So from your experience and knowledge,  Is there any advice you can give on how to efficiently complete the projects that one has no background knowledge of and how a person can avoid going down a rabbit hole of irrelevant information?",2020-06-17 17:01:55
g4j2gp,Tor needs YOU to keep the Internet uncensored and anonymous!,N/A,2020-04-20 00:47:45
e5ktr0,"Top 10 ""proof techniques"" sanctioned in a MIT CS class",N/A,2019-12-03 17:56:15
7bczxo,"Ethics of imperfect self-driving cars: ""[T]ens or even hundreds of thousands of lives could be saved by self-driving cars, even if regulators allow less-than-perfect cars on the road.""",N/A,2017-11-07 12:59:26
6x5c1b,Norbert Blum Has Acknowledged His P vs NP Paper Was Flawed,N/A,2017-08-31 07:02:38
xwewgw,"What is that one obscure, perhaps neglected/random Theorem or Law you learned in class that is actually relevant to your job?","I'll go first:

For me, it's DeMorgan's Law. This Law first gets taught in your Discrete Structures/Discrete Mathematics course, and it is a law regarding logical equivalences. It goes somewhat like this:

!(a and b) = !a or !b  
!(a or b) = !a and !b

I'm a SQL programmer, and the concept of logical equivalences is extremely important when trying to include/exclude data.",2022-10-05 16:16:28
8osudu,Free MIT philosophy/math course -- 24.118x Paradox & Infinity -- covers philosophy of the foundations of compsci -- starts June 6!,N/A,2018-06-05 17:42:50
2uqzpm,Alan Turing's notes found being used as roof insulation in Hut 6 at Bletchley Park,N/A,2015-02-04 12:45:36
hnkvbe,Little Ball of Fur - A Python graph sampling library for NetworkX (links in comment),N/A,2020-07-08 17:04:32
hd5oub,Fun With Data Structures: Simple Tricks for Technical Interviews,N/A,2020-06-21 11:49:59
d8qlsi,Researchers Use Vile Comments from Trump Subreddit to Train AI to Battle Hate Speech,N/A,2019-09-24 17:41:28
43ykvb,TIL It took Edsger W. Dijkstra 20 minutes to design the algorithm for shortest path.,"[Link](http://cacm.acm.org/magazines/2010/8/96632-an-interview-with-edsger-w-dijkstra/fulltext) to the interview. It's in the 4th question.    
[Shortest Path Algorithm](https://www.cs.berkeley.edu/~daw/teaching/cs170-s03/Notes/lecture7.pdf).",2016-02-03 06:15:12
8z3lp3,Wittgenstein and Turing incidentally anticipate integer overflow while discussing the foundation of mathematics in 1939 (Wittgenstein's Lectures on the Foundations of Mathematics),N/A,2018-07-15 18:00:54
13rfckl,"Every year, r/compsci sends flowers to Alan Turing's statue in Manchester for his Birthday, who wants to be involved?","Alan Turing's Birthday is on the 23rd of June. We're going to make it special for the tenth year in a row. 

Every year, people from subreddits like r/compsci, r/maths and a few others pledge bunches  of flowers to be placed at Alan Turing's statue in Manchester in the UK for his  birthday. In the process we raise money for the amazing charity [Special Effect](https://www.specialeffect.org.uk/), which helps people with disabilities access computer games.

Since 2013 we've raised over £12,700 doing this, and 2023 is our tenth anniversary! Anyone who wants to get involved is welcome.  Donations are made up of £3.50 to cover the cost of your flowers and a  £14 charity contribution to Special Effect for a total of £17.50.

Manchester city council have confirmed they are fine with it, and we have people in Manchester who will help handle the set up and clean up.

To find out more and to donate, click [here](https://equalitytime.github.io/FlowersForTuring/?utm_source=Reddit&utm_content=UnitedKingdom).   We've curently raised £600 from previous donors and r/maths.

Joe",2023-05-25 11:35:40
bj32c9,"Health implants should have open source code. Pacemaker or insulin-releasing implant can be lifesaving, but they are also vulnerable not just to malicious attacks, but also to faulty code.",N/A,2019-04-30 13:05:12
64t7lw,"Fourier Transform: The math trick behind MP3s, JPEGs, and more (2013)",N/A,2017-04-11 19:44:13
cgbihi,Great CS Books with Solutions,"# r/compsci, what are your favorite books that have solutions?

Testing your knowledge/skills is proven to be the most effective learning strategy. (Check Coursera's How to Learn or Make it Stick by Brown et al) I waste too much time reading books w/o solutions and inevitably hitting a wtf moment. Please, help me build a library of books with a good feedback loop.

## Math
* **Concrete Mathematics - Knuth et al** (solutions in book)
* **Discrete Math - Rosen** (separate solutions book)
* **Book of Proof - Hammack** (solutions in book)

## Programming
* **SICP** (solutions all over github)
* **Cracking the Coding Interview - McDowwell** (solutions in book)
* **C Programming Language - Kernighan + Ritchie** (official solution book + unofficials online)
* **Intro to Algorithms - Cormen et al.** (instructor's manual)
* **The Art of Computer Programming - Knuth** (solutions in book)
* **Elements of Programming Interviews - Aziz et al** (test your solutions)

## Programming language theory
* **Software Foundations - Pierce** (solutions in book)
* **Types and Programming Languages - Pierce** (solutions in book)
* **An Invitation to Applied Category Theory: Seven Sketches in Compositionality - Fong + Spivak** (solutions in book)

## Theory of Computation
* **Intro to Automata Theory, Languages, and Computation - Hopcroft** (solutions on book web site)
* **Introduction to the Theory of Computation - Sipser** (instructor's manual)

## Systems
* **The Elements of Computing Systems, Nisan + Schocken** (test your solutions)
* **OSTEP (Operating Systems) - Arpaci-Dusseau** (test your solutions)
* **Computer Systems: A Programmer's Perspective - Bryant + O’Hallaron** (solutions in book)

## Cryptography
* **Understanding Cryptography - Paar and Pelzl** (solutions online)

## AI
* **Artificial Intelligence: A Modern Approach - Russell + Norvig** (solutions in book)

Please post any and all of your favorite books that **have solutions**, I'll add them to the list, and also probably read them :) Thanks

Edit: Thank you for all the replies! I'll add any more that are posted (once I verify they have solutions) I suddenly have a lot of reading to do. And let me know if I can restructure the categories better in any way, everything's so interconnected and I'm still a noob",2019-07-22 10:31:13
jjf8ys,"I just updated my Pandas GUI project to have some sample datasets, here it is working with a Simpsons dataset and proving that the early seasons are the best...",N/A,2020-10-28 02:07:44
dprkfx,Google Introduces Huge Universal Language Translation Model: 103 Languages Trained on Over 25 Billion Examples,N/A,2019-10-31 18:20:04
4jusoe,Computer scientists have developed a new method for producing truly random numbers,N/A,2016-05-18 03:40:20
42ovs4,"Marvin Minsky, Pioneer in Artificial Intelligence, Dies at 88 (NYT)",N/A,2016-01-26 00:53:50
ia77ty,"CompSci4Good: Art project Letters from Nature, uses GPT3 to write letters to world leaders on behalf of glaciers, islands and coral reefs under threat",N/A,2020-08-15 13:19:35
fuzjtu,Home-made 8bit CPU from scratch,N/A,2020-04-04 19:19:46
5uck4o,Crash Course Computer Science Preview,N/A,2017-02-16 03:59:28
63fhth,Sir Tim Berners-Lee wins the 2016 ACM Turing Award for his invention of the World Wide Web,N/A,2017-04-04 17:14:58
6e1kyy,30 things software developers and testers wished they did not learn the hard way,N/A,2017-05-29 17:26:43
60mgmv,Beautiful Online version of: Structure and Interpretation of Computer Programs,N/A,2017-03-21 08:41:37
vyxqqt,Which books shaped you most as a computer scientist?,"Books are a fundamental source of knowledge in any field. Same for computer scientists. 

Whatever domain of CS you work in, there must be some books that you remember for all the good reasons. 

What are those? And why do you love those?",2022-07-14 14:51:55
ptpvdq,Tried animating a DFS traversal using python,N/A,2021-09-23 07:17:30
ctyy0o,Is anyone interested in weekly coding interview problems with detailed solutions newsletter?,"Hi friends,

I am running a newsletter that sends out 3-6 coding interview problems with detailed solutions in Go. My goal is to build a database of **top 100, most frequently appeared problems that I think are the most valuable and productive to spend time on.** For each one, I am including my thoughts of process on how to approach and solve it, adding well-documented solutions with test cases, time and space complexity analysis.

Let me know if you're interested in the idea. Here is the link to:

\- its blog post: [https://medium.com/@hoanhan101/i-am-making-ultimate-study-guides-for-mastering-coding-interview-challenges-3f88a228441a?source=friends\_link&sk=999d12c966d910736764fefbc9b8a0d3](https://medium.com/@hoanhan101/i-am-making-ultimate-study-guides-for-mastering-coding-interview-challenges-3f88a228441a?source=friends_link&sk=999d12c966d910736764fefbc9b8a0d3)

\- the newsletter itself: [https://www.getrevue.co/profile/hoanhan101](https://www.getrevue.co/profile/hoanhan101)

Best,

Hoanh",2019-08-22 15:24:32
iy169u,"A solid review of '50 Years of Computer Architecture' by David Patterson, distinguished engineer @ Google & UC Berkley professor. He covers everything from mainframe CPUs to Neural-Network TPUs, the differences between ARM, Intel, and AMD, and the trends of computer architecture.",N/A,2020-09-23 01:52:44
n43u3n,"« Words in a Day » This project was made for a four-days workshop on data visualization in relation to the idea of ""quantified self"" (See link in Comment for more) IUAV University of Venice",N/A,2021-05-03 18:42:24
8uczre,How to Read a Paper,N/A,2018-06-27 20:19:46
15t4fap,"Collecting the greats, any suggestions?",N/A,2023-08-16 22:32:59
3ri3fo,"""Earlier today, I was tipped off to what might be the theoretical computer science result of the decade."" - Researcher Laszlo Babai claims to have found a quasi-polynomial time algorithm for the graph isomorphism problem.",N/A,2015-11-04 15:32:45
forxix,What are the most generalized wrong ideas about computers from someone who just started to study computer science?,That's me!,2020-03-25 15:12:28
ji5gvk,I love learning about computer science,"I'm currently a sophomore undergrad learning about assembly, and for some reason, I just felt this deep love for programming as a whole after today's lecture. It is the only discipline that really fascinates me, and the only subject that I am actually interested in learning about. Computers have been part of my life since I've been young, and seeing how they work unravels that magic that has captivated my mind for years. It is daunting since it feels like there is a lot left to learn, but I can't deny that my passion is increasing.",2020-10-26 01:20:54
ffd4xx,What is the most exciting paper you have read ever in the field of Computer Science or interdisciplinary (relating to Computer Science)?,"I am frustrated just reading the standard text books.

I want to read more research papers relating to Computer Science this year.

I assume there are at least a few research fellows here who can recommend some good reads.

I will appreciate your recommendations along with sources.

Top 10 lists are also welcomed.  


**EDIT**: I would like to thank everyone who (has recommended/ will recommend) Research Papers and other reads on this post. I did not expect such overwhelming recommendations. Hopefully these will keep me busy for the upcoming months.",2020-03-08 14:21:13
dkfr67,College killed my love for CS and learning. How do I find joy in it again?,Will post in AskCS.,2019-10-20 05:58:03
10kme1,Pretty sure reddit just saved my career in computer science...,"I'm a Sophomore Computer Science major and I'm currently taking Discrete Math.  My professor is a visiting instructor from Japan who not only has an incredibly difficult accent to understand, but also speaks in recursive riddles.  The worst part is when you ask a question, most times my prof. doesn't even understand what you're trying to ask.

To further complicate matters, the textbook is also incredibly vague.

So I did what anyone would do: I searched reddit for Discrete Math (lol).

One of you fine redditors posted a link to University of Illinois Discrete Math class web page, complete with full and comprehensive lecture notes.  All of a sudden Discrete Math sounds a lot less like gibberish.

TL;DR - Thank you reddit, you have quite conceivably just saved my career in computer science.

edit:
If you were curious, the link: [http://courses.engr.illinois.edu/cs173/fa2011/](http://courses.engr.illinois.edu/cs173/fa2011/)
",2012-09-27 17:36:55
etbph8,"Neso Academy, one of the leading YouTube channels in Computer Science has been hacked, and deleted","Chances are if you have used YouTube for understanding CS topics, you have came across Neso Academy.

&#x200B;

On January 19, their account was hacked and deleted, meaning all their content is now gone.

&#x200B;

They covered essential topics such as Computational theory, database management systems, operating systems to name a few and were one of the top providers of free education in the CS YouTube world (in English).

&#x200B;

Please consider supporting them here, and spreading the news.

&#x200B;

[https://twitter.com/nesoacademy/status/1218972715077357569](https://twitter.com/nesoacademy/status/1218972715077357569)

&#x200B;

The more you retweet, the more likely YouTube support will be able to do something about this incident.",2020-01-24 15:16:18
ng2sdo,The Unparalleled Genius of John von Neumann,N/A,2021-05-19 11:03:56
4f3ib3,Study of non-programmers' solutions to programming problems [PDF],N/A,2016-04-16 20:12:20
9mhs48,Graduate Student Solves Quantum Verification Problem | Quanta Magazine,N/A,2018-10-08 18:58:14
g6l55w,Excellent Operating system class notes,"Well structured notes of the 9th edition of ""Operating System Concept"" from UIC, made by a Professor

 [https://www.cs.uic.edu/\~jbell/CourseNotes/OperatingSystems/](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/) 

I find it much easier to understand than typical course slides since it has more detailed explanation. Wish I knew about this when I was taking the course -.-",2020-04-23 11:41:24
ebr600,Simple speech recognition,N/A,2019-12-17 04:56:19
3g3kw1,Self posts temporarily disabled,"Greetings Computer Scientists, professionals, and students, and others

The Reddit CompSci sub was started as a place where like-minded the computer scientists could hang out and discuss topics that interest them, such as new research and its implications. We love learning and discussing new ideas to make us explore and *wonder*.

A great post is one that's relevant to most or all of the community, shares a new idea, and makes you stop to think. Maybe there's even an application to your current research or engineering. Bottom line: We're here for the computer science.

Recently, the mods and I have noticed that there are an increasing number of self posts that each help their author with a specific problem. The answer might help the author, and a small set of coincidentally interested readers, but that's about it. Such questions typically cover: how to learn CS, choosing a career or major, other career-related questions, how to study CS / with which books, clarifying something about the author's knowledge, etc.

(I have been removing these types of questions as we go, letting the author know that they're off-topic, so late comers to this thread might wonder what I'm referring to. This evening when I started, most of the frontpage was self-posts.)

While these are *completely legitimate* topics to discuss, the issue is that they don't fit with /r/compsci's mission to be a place for computer scientists. Consider another perspective: you're a professional or an academic in computer science. You're done for the day, at your job or at uni, and you want to kick back and relax and see what's being said about the latest SIGGRAPH papers, so you load /r/compsci. Except instead of seeing computer science topics, all you see are self-posts about studying CS, CS as a career, etc. and little discussion of content or research. /r/compsci survives on its experts and we want to keep everyone interested.

I think the pendulum has swung too far in the direction of /r/compsci becoming a Q&A place. I'd like to swing it back toward the content direction. With that in mind, I've temporarily disabled self-posts. In the meantime, you may want to use other resources for these questions, such as: /r/cscareerquestions , /r/learnprogramming , and /r/askcomputerscience (thanks /u/ReneDiscard)

I'd like to emphasize that beginners, learners, and students are absolutely welcome on /r/compsci. Please post questions in comment threads where issues are being discussed - we encourage it. However, we will discourage self-posting (currently suspended), When the Q&A feature comes back, it needs to keep a low profile. A number of posters of lower-quality material also have minimal connection to the community. I expect to establish establish the expectation that for each self/Q&A post you make to /r/compsci, you have made ~10+ comments in regular threads helping regular users with other issues. Asking the entire subreddit for help is a privilege, and one that needs to be earned by helping others. So if you'd like to earn the ability to post Q&A threads, start now by demonstrating your helpfulness when people raise questions on comment threads. (Self-posting questions in a way that drains the community, and does not give back, is unacceptable.)

/r/compsci strives to be **a subreddit *by* computer scientists, *for* computer scientists**. If you are not a computer scientist, then you are still welcome by all means, but take a moment and reflect before posting. You wouldn't walk into a geologists' convention and start loudly talking about your 6th grade rock collection or whether you should become a geologist. You wouldn't visit a medical conference and drop trough in front of everyone to ask the dermatologist about a strange mole on your buttocks. There are times and places for these other types of questions. /r/compsci aims to be for computer scientists.

If you are not a computer scientist, then please tiptoe as appropriate, and please be aware that the best place for your question might be somewhere else. /r/compsci is not a place for *learning* CS; there are other resources for that. A good place to start is understanding the material in [How to ask smart questions](http://www.catb.org/esr/faqs/smart-questions.html#intro)

All that said, /r/compsci's goal is not to help people satisfy their idle curiosity, nor solve homework problems, nor to provide career advice. If you're not a computer scientist, and if you are not sure whether your question is a good fit, the answer is probably ""no"" (though feel free to ask the moderators for a second opinion).

As always we're open to feedback about how this is going. The change will be temporary, and we'll do our best to keep the subreddit interesting and relevant to everyone. If you'd like to publish a self-post while they're still disabled, then message the mods with the content you'd like to post, and we'll supply feedback on whether it meets our guidelines, and help you get it posted if so. We do not want good content or good questions in any way to be held back by this temporary change.

Kind regards",2015-08-07 05:45:37
hs8yc9,Major Quantum Computing Advance Made Obsolete by Teenager,N/A,2020-07-16 12:44:09
aktl6c,Harvard works to embed ethics in computer science curriculum,N/A,2019-01-28 23:27:00
8rco06,Google's Image Classification Model is now Free to Learn for Everyone,N/A,2018-06-15 17:18:17
6tngew,A Solution of the P versus NP Problem,N/A,2017-08-14 16:14:56
a9ohk6,How the letter 'λ` was chosen to denote function abstraction in the λ-calculus,"""We end this introduction by telling what seems to be the story how the letter 'λ' was chosen to denote function abstraction. In Principia Mathematica the notation for the function *f* with *f(x)* = 2x + 1 is 2x̂ + 1. Church originally intended to use the notation x̂.2x + 1. The typesetter could not position the hat on top of the x and placed it in front of it, resulting in ∧.2x + 1. Then another typesetter changed it into λx.2x + 1.""

\-- Henk Barendregt, 1997, ""The Impact of the Lambda Calculus in Logic and Computer Science"", in *The Bulletin of Symbolic Logic* 3.2, p. 182.",2018-12-26 13:16:44
5vt95b,SHA-1 broken in practice,N/A,2017-02-23 21:30:29
180vhe,"Hey Reddit, I made a site for quickly jumping to specific concepts in long CS lectures",N/A,2013-02-06 21:50:42
blpj2y,Microsoft is Open-Sourcing Quantum Computing Development Tools,N/A,2019-05-07 11:26:43
bg1y3p,"Machine learning accurately classifies age of toddlers based on eye tracking. Results demonstrate that machine learning is an effective tool for understanding how looking patterns vary according to age, providing insight into how toddlers allocate attention and how that changes with development.",N/A,2019-04-22 13:11:53
2o044h,Battleship algorithms. This is awesome.,N/A,2014-12-02 02:03:19
ktpbxj,Dominating Monopoly Using Markov Chains,"After learning about how cool Markov Chains are I wanted to apply them to a real scenario and used it to solve monopoly. And they didn't disappoint. I got the frequencies that each square is visited using Markov Chains and then used some excel, sorry, to figure out which properties are best to invest in.It turns out that the orange one is the best. The second best is the red one. Which makes sense since they are after Jail, which is the most visited spot.

I made the video that explains Markov Chains and that goes over how I used it to solve monopoly.

Here is the video if you'd like to take a look at it: [https://youtu.be/Mh5r0a23TO4](https://youtu.be/Mh5r0a23TO4)

Here is the code and the excel spreadsheet if you want to skip the video and go straight to it: Github: [https://github.com/challengingLuck/youtube/tree/master/monopoly](https://github.com/challengingLuck/youtube/tree/master/monopoly)",2021-01-09 11:31:28
ho3h70,"Karate Club - An unsupervised machine learning library for graph data (repository, paper, and documentation in comment)",N/A,2020-07-09 13:55:12
bggxj4,'Magic: The Gathering' is Turing Complete [abstract + link to PDF],N/A,2019-04-23 14:19:49
787wpi,Tech Giants Are Paying Huge Salaries for Scarce A.I. Talent,N/A,2017-10-23 14:03:06
18lusx,"Computer science students successfully boycott class final, exploiting a loophole to get perfect scores",N/A,2013-02-15 22:51:12
xcjeo8,"I created a website that shows the effects of different noises and filters and their combinations on images. I plan to add more filters, like lowpass, and deep learning methods. Link to the website and GitHub are in the comments.",N/A,2022-09-12 17:51:27
dlrz2s,Art of the Problem on secret sharing (amazing two page paper from 1979),N/A,2019-10-23 01:20:02
94w1bd,How can I use my CompSci degree to work for the benefit of society while still making a living wage?,"I am a software dev. working at a Fortune 20 tech giant and have begun to feel that my work is basically meaningless. I hope this doesn't make me sound like a fat tool, but I have a lot of sadness and dread about not feeling like I am working for the betterment of society/humanity. Please share your thoughts on what some options might be.",2018-08-05 22:59:22
2j04f2,Mihai Partascu - A MIT Phd Computer Science genius wrote down 5 still unsolved problems regarding data structure lower bounds that he did not have time to solve due to his death 2 weeks later of brain tumor at the age of 29,"So this Romanian guy won tons of math, physics, informatics competitions in high school. Got accepted to MIT. For Bachelor thesis he solved a problem with data structure lower bounds that was unsolved for 15 years. This won him best undergraduate research paper in USA in 2005. He wrote an additional 10+ papers during his undergraduate+masters studies while getting 5.0/5.0 GPA in MIT. Then he proceeded to get Phd while doing amazing research.  Then he died at the age of 29 of brain tumor in 2011.

https://docs.google.com/file/d/0B8ttd1KbGd3EWktsR29qNVdNVEE/edit

His name was Mihai Patrascu (Fight club style)",2014-10-12 04:22:15
mtj1a,"Grady Booch, a chief scientist at IBM Research, launchs project to tell the story of computing in an 11-episode TV series similar to Carl Sagan’s Cosmos.",N/A,2011-11-29 17:32:40
f9691b,It's Claude Shannon memorial day,"Every now and then, the human race produces someone who does something so differently it makes me wonder how they made that mental 90 degree turn. Like the first guy who looked at an egg and decided to separate the white from yoke to make mayonnaise. In lieu of information indicating otherwise, I like to think Claude Shannon is one such person. The underappreciated father of comp hardware and programming. Whom looked at electric circuits and wondered, what if we used electricity to solve math problems at the speed of light, and in turn used math to juggle balls.

Those familiar with his work knows he is the one whom gave us information theory. The idea that information is both quantifiable and measurable. He also designed some of the first logic circuits, which became the foundation of the device you're currently reading this post on. When we think about scientists in comp, many of us think Von Neumann and Turing. But it was Shannon's work that made theirs possible.

His accomplishments are many, I encourage you to do your own reading. He also lived an interesting life, some points i enjoyed are:

* Like most scientists of his time, he was involved in the war against the Nazis, specifically in cryptanalysis
* He proved one time pad is unbreakable, placating all my fellow tinfoil hat enthusists, and that all perfect encryption schemes has the same limitations of OTP, satisfying my perf obsessed brethren.
* Built one of the first juggling robots ever
* He was into unicycling
* Built one of the first ""useless"" machines (the currently attributed inventor is an associate of his)
* Built a flamethrower trumpet

Most importantly, or one would say fortunately, his life did not appear to be a tragic one. He wasn't betrayed by his government like with Turing. His life wasn't cut short by cancer like with Von Neumann. He died on Feb 24th 2001 at the age of 84, a father, a grandfather.

I propose we take a moment out of our day to remember the light speed calculating, robot ball juggling, unicycling scientist that made the mental 90 degree turn that made both our careers and hobbies things.

`01000110` for Dr. Claude Elwood Shannon.",2020-02-25 06:50:38
3vuh2f,What Makes Tom Hanks Look Like Tom Hanks,N/A,2015-12-07 22:03:25
msrly,Matrix multiplication breakthrough: O(n^2.373) time algorithm [link goes to pdf],N/A,2011-11-29 01:56:18
231zcd,A Lego Turing Machine. :),N/A,2014-04-15 01:10:25
wp0bz,"Mathematics for Computer Science [800 page PDF, as used at MIT, CC licensed]",N/A,2012-07-17 09:43:08
1doj6k,Big-O Algorithm Complexity Cheat Sheet,N/A,2013-05-04 15:28:27
pfdke1,Emulating a CPU in software (plus a basic assembler),N/A,2021-08-31 20:00:11
lypcka,Functioning Logic Gate Displays.,N/A,2021-03-06 00:00:57
gexmkl,Text of the 1992 forum clash between compsci student Linus Torvalds and professor Tanenbaum,N/A,2020-05-07 01:57:15
6xsnzu,what skills do you guys think are lacking in computer science courses that every student should have ?,"coming close to graduation and starting to look for jobs now , what skills do you think graduates like me lack coming fresh out of college that arent taught in our modules that could be hugely beneficial to earn now ? 
thanks.",2017-09-03 11:35:21
10fhtmd,"Finally, a Fast Algorithm for Shortest Paths on Negative Graphs",N/A,2023-01-18 20:30:33
gbgarv,"An example of how compilers parse a segment of code, this uses the CLite language spec.",N/A,2020-05-01 11:21:51
r5pmks,What are your favorite Comp Sci YouTube channels?,"I watch a bit of YouTube before bed every night and I find whatever I watch really sticks in my head so I figured maybe I should be watching more applicable content to what I like.

I like to program with python and C++ and would love to find some good channels that revolve around these languages and concepts within them such as data structures, OOP, etc.

Also a huge fan of machine learning, AI, and data science.

Thanks!

Edit: Thank you guys for all the suggestions! Looking forward to digging through them! Hope this post helps those in my shoes as well",2021-11-30 15:24:26
h7qavx,Microsoft has partnered with Udacity to offer 300 scholarships in Machine Learning Nanodegree program,N/A,2020-06-12 18:31:33
ftvfbg,Trying not to screw everything up,N/A,2020-04-02 21:54:20
ehq2db,"Donald Knuth: Algorithms, TeX, Life, and The Art of Computer Programming | Artificial Intelligence Podcast",N/A,2019-12-30 18:43:14
a74fzo,"Donald Knuth, The Yoda of Silicon Valley",N/A,2018-12-17 21:59:12
6cj3c8,14 Free Master’s Programmes in Computer Science in Europe,"Hello guys,

For those who would like to earn a master's degree in Computer Science, in English, from one of the tuition free universities in Germany and Norway but don't know where to start, below is a link to 14 tuition-free master's degree programmes in Computer Science in Norway and Germany.

These programmes are free for everyone and not just for EU students. They also taught completely in English. You can find links that take you straight to application page of each programme. Hope you find it useful.

https://hubpages.com/education/14-Free-Masters-in-Computer-Science-in-Europe",2017-05-21 21:23:29
uxerka,"Every year, various subreddits lay flowers at Alan Turing's statue in Manchester for his Birthday, who wants to send some?","It's that time of year!^(1)

Alan Turing's Birthday is on the 23rd of June. We're going to make it special.

Every year, people from Reddit pledge bunches of flowers to be placed at Alan Turing's statue in Manchester in the UK for his  birthday. In the process we raise money for the amazing charity [Special Effect](https://www.specialeffect.org.uk/), which helps people with disabilities access computer games.

Since 2013 we've raised over £10,000 doing this, and we want 2022 to be our biggest year ever. Anyone who wants to get involved is welcome.  Donations are made up of £3.50 to cover the cost of your flowers and a  £14 charity contribution to Special Effect for a total of £17.50.

Manchester city council have confirmed they are fine with it, and we  have people in Manchester who will help handle the set up and clean up.  So far we've raised about £500 this year already!2

To find out more and to donate, click [here](https://equalitytime.github.io/FlowersForTuring/?utm_source=Reddit&utm_content=UnitedKingdom).

Joe

^(1) For crossposting to a carefully selected set of subreddits.

^(2) From previous donors and, as of yesterday, r/math",2022-05-25 10:57:16
jh2wf1,How does compression work really?,"This may not be the best place to ask this question but I can't find a better place. Ubuntu 20.10 came out for Raspberri Pi and the download file is 1.68 GB, but when the file is extracted, the extracted .iso file is 8.75 GB! How are they able to achieve these levels of compression? I'm sorry if this is a dumb question, I just want to learn.",2020-10-24 04:39:55
l726m9,A neat visualization of a convex hull,N/A,2021-01-28 16:56:03
9qdbtk,What are some CompSci books (Or books that are close to the field) you can read to relax? Something interesting which I can enjoy without taking notes or re-reading a definition over and over again.,"Hey!

I would sometimes love to open a book about CS, read and relax, but most books in the field are so dense that it hurts my head to read them after a long day of math and programming. So I am not talking about 'Introduction to programming 101', 'Complexity Theory 101' etc. I know those by heart. Instead something creative? Crazy? Philosophical? Something where I can read without being scared that by missing one definition I am completely lost on the next page.

What are your favorites that one can read without too much focus? I loved the more simple books (Secrets and Lies, etc.) by Bruce Schneier for example. Cool topic (IntSec) but not too much hard science. Goedel, Escher, Bach was pretty fun as well. I can enjoy those with a glass of Whiskey in my hand :)",2018-10-22 12:23:38
fg2xc6,Quantum Tetris,"Hey r/compsci, check out our senior thesis project Quantum Tetris - a simple game that teaches you the basics of quantum computing. It’s a fun take on Tetris and the quantum twists actually make it quite challenging!

Read about the project: [https://medium.com/@tglasgow31/quantum-tetris-6452a0c96227](https://medium.com/@tglasgow31/quantum-tetris-6452a0c96227)

Play our game here: [http://quantumtetris.com/](http://quantumtetris.com/)

&#x200B;

Edit: Windows version fixed and Linux version added, let us know if they work for you!",2020-03-09 22:11:20
56jjrg,Latency numbers every computer scientist should know,N/A,2016-10-08 23:08:34
eyywv8,The Missing Semester of Your CS Education From MIT,N/A,2020-02-04 23:00:32
el05j2,My undergrad CS and math notes with an emphasis on the foundational math," [https://github.com/alptheexplorer/epflLectureNotes](https://github.com/alptheexplorer/epflLectureNotes) 

enjoy. Im posting this again cuz the moderator removed it for no apparent reason and never replied to my message asking him why....",2020-01-06 20:54:37
7jb7hf,"Scott Galloway Says Amazon, Apple, Facebook, And Google should be broken up",N/A,2017-12-12 14:54:54
fh9u6j,"""Magic: the Gathering"" is as Hard as Arithmetic. ""In this paper we show that the ``mate-in-$n$'' problem for Magic is $\Delta^0_n$-hard and that optimal play in two-player Magic is non-arithmetic in general."" [abstract + link to PDF]",N/A,2020-03-12 03:13:48
8y860c,Intro to Quantum Computing for Computer Scientists [lecture: 1h 28m] by Andrew Helwer of Microsoft Research,N/A,2018-07-12 09:19:04
hmyf82,Art of the Problem just published a new video on Manifold Hypothesis using paper folding analogy,N/A,2020-07-07 17:01:06
cwnwp4,What Sci-Fi Can Teach Computer Science About Ethics: Schools are adding ethics classes to their computer-science curricula. The reading assignments: science fiction.,N/A,2019-08-28 17:25:29
4st86x,My Interviews with Amazon,N/A,2016-07-14 13:23:38
40mq3q,What are the canon books in Computer Science?,"I checked out /r/csbooks but it seems pretty dead. Currently, I'm reading SICP. What else should I check out (Freshman in Computer Engineering)?",2016-01-12 14:57:10
rwnhrd,What is an eigenvector? A 2-minute visual guide. [OC],"&#x200B;

https://preview.redd.it/j84qxscukv981.png?width=2048&format=png&auto=webp&s=b1c505f5a207323214744bccd4f541946f8f4694

https://preview.redd.it/rha5axcukv981.png?width=2048&format=png&auto=webp&s=c9e55bbbed87c2e26ed067bd39d220eb9078e4ea

https://preview.redd.it/13m86pdukv981.png?width=2048&format=png&auto=webp&s=b0fcbaafb41bf75777706ae46f54364d450f249f

https://preview.redd.it/p9k6q0dukv981.png?width=2048&format=png&auto=webp&s=333896008a503a17e0d720666ba66efe872d0b88

🔵 Eigenvectors 🔵

🚀 An eigenvector is a special vector associated with a linear transform. It's special in the sense that after applying the said transform it does not change direction but only gets scaled (multiplied by a scalar value) by the eigenvalue.

🔨 Each eigenvector comes with a corresponding scalar called the eigenvalue. Breaking a matrix M into its eigenvalues and corresponding eigenvectors is called eigendecomposition.

🔭 The word ""Eigenvector"" comes from ""eigen"" in German where it means ""its own"". It was originally used to study rigid body motion and in the discovery of principal axes. However, nowadays it has found its way into a wide array of applications from my favorite: principal component analysis, differential equations, and problems in physics and chemistry relating to wave transport and molecular orbitals.

🎭 Another one of the classical applications is the Eigenfaces project for facial recognition. Eigenfaces decompose a face as a composition of face templates (basis) called eigenfaces. Imagine N eigenfaces E\_1, ..., E\_n when given a new face F it can be written as a composition of each of these N eigenfaces for example: F = (10% of E\_1 + 55% of E\_2 + 35% of E\_3). Each eigenface would represent a meaningful feature in the high-dimensional space of faces.

\---------------------------------------------------------------------------------

I have been studying and practicing Machine Learning and Computer Vision for 7+ years. As time has passed I have realized more and more the power of data-driven decision-making. Seeing firsthand what ML is capable of I have personally felt that it can be a great inter-disciplinary tool to automate workflows. I will bring up different topics of ML in the form of short notes which can be of interest to existing practitioners and fresh enthusiasts alike.

The posts will cover topics like statistics, linear algebra, probability, data representation, modeling, computer vision among other things. I want this to be an incremental journey, starting from the basics and building up to more complex ideas.

If you like such content and would like to steer the topics I cover, feel free to suggest topics you would like to know more about in the comments.",2022-01-05 13:57:54
n87ksz,There is no proof that factoring semiprimes is NP complete nor that it is NP Hard. Breaking RSA would not be a proof of P=NP,"I was motivated to make this post in reaction to the massive confusion displayed in the comments of a nearby thread.   It is possible that integer factoring was always in class P all along, and so some shifty eyed anonymous internet person cracking RSA challenges would only indicate that an efficient algorithm exists for factoring.  

Nevertheless, almost a dozen posters on that other thread are asking OP to crack RSA as a way to indicate he is in possession of a constructive proof of P=NP. Again this would be no indication of such a proof.",2021-05-09 05:36:49
hfb3qy,How do code plagiarism detection systems work?,"Because they don't work for me. Just got a 80-85% similarity and got disqualified for my finals because my code was similar to the random person in class who I've never talked before my entire life.


No internet copypaste as well. Just me and myself.


I even don't think it is possible to cheat for this code.


No way he finds out my code, I typed in notepad pasted to the system.


Edit: Code was 60lines long and only getter setter program structure extends and implements stuff with no working parts, like.... reserveSeat() {Sout(""Seat reserved"")}",2020-06-24 22:37:11
9l78l3,50+ Data Structure and Algorithms Interview Questions for Programmers,N/A,2018-10-04 01:01:46
5yecuw,I made some puzzles inspired by logic gates. You don't need to be a CompSci major to get them. (x-post /r/puzzles),N/A,2017-03-09 10:33:11
3qhi8o,"What's the best computer science paper, you've ever read?","Today I had a lesson about scientific writing in university. It was all about structuring and writing papers, dissertations and other scientific documents. One of my class mates asked for a good paper to guide us in writing. So, what's the best paper you've ever read?

Edit: Please give an explanation why the mentioned paper is the best one you've ever read. Especially I am interested in well-structured papers.",2015-10-27 23:07:45
110litc,Dijkstra Comparing Computer Science to Alchemy (1989),N/A,2023-02-12 17:45:02
trnbhw,"I assembled a Computer Science Curriculum that helps practice the acquired academic knowledge in Rust. If you want to learn systems programming in Rust or just be a better programmer, this is for you! Critiques and Contributions are welcome!",N/A,2022-03-29 21:29:23
52iav3,"""In the future, everyone is going to be a software engineer, but only a few will learn how to code."" -written by someone who has no idea how to code",N/A,2016-09-13 02:46:51
11k5na6,Google reveals another experimental operating system: KataOS,N/A,2023-03-06 17:23:49
kb5el0,"I am a computer science student, when I solve problems I solve them the hard way though when I find other friend's answers I find them better and more easy so is there a way to improve at problem solving and be efficient?",N/A,2020-12-11 15:57:51
fkjrgr,Cambridge gave HTML access to their textbooks due to COVID-19 to assist readers until the 31st May 2020.,N/A,2020-03-18 04:33:31
6gndu1,What is an optimal algorithm to solve this white puzzle for humans. [X-Post],N/A,2017-06-11 19:45:24
dlepmf,Writing software in multiple languages and keeping up with all the idioms was getting hard so I made my list of idiomatic resources,N/A,2019-10-22 07:58:39
qlph1m,19-State Universal Cellular-Automaton (left) simulating all the Elementary Cellular-Automata (right),N/A,2021-11-03 07:43:19
n0mv9p,Stanford Professor Wins 'Nobel Prize' of Computer Science World | San Jose Inside,N/A,2021-04-28 19:36:17
hjsf5z,New algorithm verified the Collatz problem for all numbers below 2^68,N/A,2020-07-02 07:14:48
bk6zyh,UPDATE: Got a really bad grade on my final (first semester of CS) maybe this isn’t for me?,"I really wanted to make this post because you guys helped me out so much. I honestly thought I was stupid and maybe the entire major wasn't for me. But all the motivation I got in the comments helped me see otherwise. So let me tell you, I took my first 'object-oriented programming' in Java this semester, and I got an A! I know this was just a basic course, but I'm really happy that I didn't give up and more importantly that I believed in myself (thanks to you guys<3). I even joined a programming club! Thank you all so much for the support you gave me, and I hope this helps anyone that was in my situation.",2019-05-03 10:44:07
u7xx5,How *Not* To Rank Items - This Bothers Me,N/A,2012-05-28 00:06:37
jeoqe4,A collection of not-so-common online courses in Computer Science,"(I hope this post isn't breaking any rules - mods please let me know if it is).

Since most semesters have moved online where I live, a lot of professors are putting up their courses online for the general public. Here's a small list of courses I've found (other than the more common ones which are found easily online). I hope these are useful to people. 

[Algorithmic Game Theory - IIT Kharagpur](http://cse.iitkgp.ac.in/~palash/Courses/2020AlgorithmicGameTheory/agt2020.html)

[Parameterized Algorithms - IIT Kharagpur](http://cse.iitkgp.ac.in/~palash/Courses/2020ParameterizedAlgo/paramAlgo.html)

[Parameterized Complexity - IMSc, Chennai](https://sites.google.com/view/sakethome/teaching/parameterized-complexity)

[Algorithms for Big Data - IMSc Chennai](https://sites.google.com/view/sakethome/teaching/algorithms-for-big-data-fall-2020)

[Analysis of Boolean Functions - TIFR, Bombay](https://www.tcs.tifr.res.in/~ramprasad/courses/2020-ABF/)

[Advanced Computer Architecture - IIT Delhi](http://www.cse.iitd.ac.in/~srsarangi/courses/2020/col_718_2020/index.html)

[Foundations of Intelligent and Learning Agents - IIT Bombay](https://www.cse.iitb.ac.in/~shivaram/teaching/cs747-a2020/index.html)

[Advanced Graph Algorithms - IIT Madras](https://www.youtube.com/channel/UCID2PH2C8hL5m7hTBdG6zaA/videos)

[Information Theory, IISc Bengaluru](https://nptel.ac.in/courses/108/108/108108168/) (This might not be so advanced, but is intended as a graduate level course where I study)

If you have other courses available from your uni/country which are publicly available, please do share them!",2020-10-20 12:44:01
84vk47,KWICK SÖRT,N/A,2018-03-16 13:52:27
4fmsyl,Why is processing a sorted array faster than an unsorted array?,N/A,2016-04-20 11:04:40
43elf1,(x-post from /r/technology) White House announces CS for All initiative with $4 billion in funding to drastically expand computer science education in the US,N/A,2016-01-30 15:58:51
bifkqo,overcrowded field my ass,N/A,2019-04-28 20:21:52
948jgy,My bare bone 16 bit calculator!,"So for the last 4 days I wanted to try and make a very basic calculator in order to teach myself some logic gate type things! I was pretty proud with the final thing so I decided I'd post it here.

[The entire calculator in view.](https://preview.redd.it/qogznsyhuud11.png?width=1108&format=png&auto=webp&s=fc29aabab2102f0f086b0683e0141248d014ae8e)

[Here's my little \\""control area\\"" if you will, the red circled switch is essentially a 1bit memory address, just to save having two 16 bit input rows. the blue circled button is the reset button just to clear both pieces of memory on the calculator. You can also see the current values of the two memory units in top left in BCD, and the sum of them on the right \(Also in BCD\)](https://preview.redd.it/yy3dz3unuud11.png?width=1288&format=png&auto=webp&s=5c29504da4203901464acb7f0371d01eb1a94fdf)

[The memory, two 2byte modules \(The simulator I'm using allows you to create circuits and make \\""integrated circuits\\""\) so I will show the inside of each of my created circuits.](https://preview.redd.it/rqu98jqzuud11.png?width=521&format=png&auto=webp&s=a62028de0937fc881c5055469070fdda0b219538)

[This is the inside of each of my 2byte memory items, it's just 16 1 bit modules stacked](https://preview.redd.it/riy9dme6vud11.png?width=1133&format=png&auto=webp&s=1ee8d452270239b6518718f751ce088c9688876d)

[This is my 1bit module, top switch resets it, second switch sets it to 1](https://preview.redd.it/hfh30r6cvud11.png?width=361&format=png&auto=webp&s=2a6487b4b56a0bb0b720d59ec31bdc15d102896d)

[This is my adding chain to add the two values that are currently in memory. I tried to stay consistent with having the least significant bit on the left if horizontal and at the top if vertical.](https://preview.redd.it/h83boswgvud11.png?width=1092&format=png&auto=webp&s=032852761c4c14dd879ca66848e0a9dce8a9739e)

[Each is a standard full adder circuit](https://preview.redd.it/kg7p5itmvud11.png?width=671&format=png&auto=webp&s=965f19c55b3b17b1527239c959d1ad80f6079155)

[Then there's my binary to BCD converters \(Binary Coded decimal for those of you who don't know\) just because I really disliked having my answers in hex.](https://preview.redd.it/35h5p38rvud11.png?width=1254&format=png&auto=webp&s=73e4b3490347d87078c786ea735f97342c82b232)

[Here's the converter's inner workings, just a long string of conditional adders performing what is called the Dibble Dabble algorithm \(I'm pretty it was called that\)](https://preview.redd.it/zqnh5a8wvud11.png?width=1742&format=png&auto=webp&s=15547ec2263215b5a68b67e547e00c247b68e5b1)

[Finally is my conditional adder, Just simple adds 3 to the input if it's greater than 4. I didn't take stack overflow into account here because in my usage it would never occur.](https://preview.redd.it/hgkvqlz1wud11.png?width=843&format=png&auto=webp&s=90a209dce287067fecfaed3b50041524fa2bae38)

And here are some examples of it working!

[Easy one to start off](https://preview.redd.it/g7ixwv09wud11.png?width=1400&format=png&auto=webp&s=64ce52dfdb5a33a0444f9efea316ff691426fea1)

[Another one just to try and demonstrate the BCD's functionality](https://preview.redd.it/u66u6r7dwud11.png?width=1389&format=png&auto=webp&s=51078e23bd5b257d0ff07c6f822f5c99fff2d927)

[And yet another](https://preview.redd.it/9qpul66iwud11.png?width=1262&format=png&auto=webp&s=8a45eaed833062f013ce92dac11ee363485bfb12)

I'm open to all/any feedback you can give on ways I can improve this and such :)",2018-08-03 10:47:02
17xna7,The 48th known Mersenne Prime has been found,N/A,2013-02-05 15:01:05
zp7c1,Magic: the Gathering is Turing Complete,"[Magic: the Gathering is Turing Complete](http://www.toothycat.net/~hologram/Turing/)

A little while ago, someone asked [""Is Magic Turing-complete?""](http://draw3cards.com/questions/2851/is-magic-turing-complete) over on Draw3Cards. I decided to answer the question by actually assembling a universal Turing machine out of Magic cards such that the sequence of triggered abilities cause all the reads, writes, state changes etc. (That is, the players of the game don't need to make any decisions to be part of the Turing machine - it's all encoded in the game state.)

I kept meaning to do a bit more with the site before posting it to Reddit and places, but never got around to it. Eventually someone by the name of fjdkslan posted it over on the [Magic the Gathering subreddit](http://www.reddit.com/r/magicTCG/comments/zoojk/magic_is_apparently_turing_complete/). JayneIsAGirlsName suggested we repost it over here on /compsci, so... [here you go](http://www.toothycat.net/~hologram/Turing/) :) ",2012-09-11 08:09:18
qecftb,Programming/computer science stories with real-world consequences?,"There was a really interesting story about how people with the last name ‘null’ can’t buy plane tickets. 

Curious about any other wacky computer science stories with real-world, unexpected consequences people may have heard of!",2021-10-23 20:07:28
om8eb9,The Mozilla Common Voice project is building a free language database for machine learning to enable independent language technology. The final spurt for the next release of the data set is until July 20th.,N/A,2021-07-17 17:14:56
cnn1b9,South Korean Game Developer’s AI Turns Your Selfie Into an Anime Face,N/A,2019-08-08 15:08:08
fdqtbo,Landmark Computer Science Proof Cascades Through Physics and Math,N/A,2020-03-05 05:53:56
cf8yhq,Tribute to Alan Turing,N/A,2019-07-19 15:30:17
muphul,I made a simple algorithm for NFS Most Wanted in under 500 lines of code!,"Hi guys !

[Source code](https://github.com/LupascuAndrei/nfs_most_wanted)

[Short youtube video with the result](https://www.youtube.com/watch?v=UkYxKu2pllw)

Would love to hear your thoughts!",2021-04-20 12:45:50
eea9qt,"The Antikythera mechanism is a 2,000 year old analog computer.",N/A,2019-12-22 21:02:47
cffczt,"Professor Patrick Winston, former director of MIT’s Artificial Intelligence Laboratory, dies at 76",N/A,2019-07-20 00:14:48
b9uljk,DeepMind AI Flunks High School Math Test,N/A,2019-04-05 18:11:16
39t1uo,How a computer learns to play super mario using neural networks,N/A,2015-06-14 14:22:17
1ru77a,Mathematics for Computer Science PDF Book (November 2013),N/A,2013-12-01 14:24:50
mhgnpg,Columbia's Alfred Aho and Stanford's Jeffrey Ullman receive 2020 ACM A.M. Turing Award,N/A,2021-03-31 21:50:42
11imdno,Warning: CSCE - the latest sketchy CS conference by Hamid Arabnia,"I'm a CS professor and lately, my academic email account has received multiple Call for Participation emails from ""IEEE CPS - Computer Science, Computer Engineering & Applied Computing"" CSCE'23 conference. My colleagues noted they got the same emails and were wondering about it so I did a little investigating because their CFP looked eerily familiar.

* First warning sign: their website has a banner for the ""American Council on Science and Education"" which is not an established professional organization like ACM or IEEE.

* Second warning sign: the [conference lists 21 different tracks](https://american-cse.org/csce2023/committees) that span the gamut of CS research areas from Bioinformatics & Computational Biology (BIOCOMP) and e-Learning, e-Business, Enterprise Information Systems, & e-Government (EEE) to Foundations of Computer Science (FCS) and Grid, Cloud, & Cluster Computing (GCC). It doesn't have a concentration.

* Third warning sign: it advertises as ""IEEE CPS"" upfront likely to feign credibility. The fact is that **doesn't mean it is sponsored by IEEE**. CPS is IEEE's ""Conference Publication Services"" where they [index papers published by other conferences for a fee](https://ieeecps.org). 

* Forth warning sign: ""Professor Hamid R. Arabnia"" is the chair. From what I can find, he's actually retired. If you're unfamiliar with him, he has gained a notorious reputation for running fraudulent conferences with these same red flags. He used to run [WORLDCOMP which got roasted in this subreddit 11 years ago](https://www.reddit.com/r/compsci/comments/qmf46/worldcomp_the_worlds_biggest_sham_computer/) and a sock puppet account even replied in that thread to defend it with [a copy-and-paste post it had in another one of its four total posts -- all alleging a conspiracy to defame him](https://www.reddit.com/user/truth10000/). Alarms were also raised [5 years ago when he rebranded it as ""CSCI""](https://www.reddit.com/r/computerscience/comments/84pdzz/worldcomp_or_csci_are_fake/). In fact, the old WORLDCOMP website [world-academy-of-science.org](http://www.world-academy-of-science.org/) currently redirects to the latest renaming of the conference, ""CSCE"" at [american-cse.org](https://american-cse.org).

Allegations about these conferences (including on the previous reddit threads as well as [elsewhere](https://www.ripe.net/ripe/mail/archives/dns-wg/2013-December/002831.html)) are that there is no real peer review happening and it is a predatory conference that just accepts anything and cashes in on registration fees. Many legitimate researchers have complained that they were duped by the conference and when they attended it (always in Las Vegas, as far as I can tell), there were some real research presentations but it was obvious that there was no meaningful peer review being conducted to assure that the research was sound.

*update* - after filtering ""@american-cse.org"" as spam, I'm now getting daily emails for the same CFP from ""@world-comp.org"" addresses.",2023-03-05 03:35:44
kvnrwp,(C++) A simulation of Coulomb's inverse square law for electrically charged particles (with electric field),N/A,2021-01-12 08:31:30
5ux45f,Design Patterns for Humans,N/A,2017-02-19 06:49:22
20vbaw,What book made you a better computer scientist?,N/A,2014-03-20 02:27:06
xmzeaa,Can you efficiently solve this problem?,N/A,2022-09-24 17:53:17
2dfqcn,Humans Need Not Apply,N/A,2014-08-13 13:52:01
1dse6d,Solve the halting problem for $1000,N/A,2013-05-06 12:28:11
12xap3o,[OC] Office Simulator to Analyse Workspaces,N/A,2023-04-24 10:12:26
n7j2hc,"Suppose that P = NP, and that I have a constructive proof","What to do now? Say for example that I even managed to apply it to the 3SAT problem, so that it could essentially be solved in O(n), aka in polynomial time, what is the next step?

I understand that logically it would be to write a paper and publish it, but here comes several of my problems, where they mainly start off this that I to some extent just don't want it completely out there, just for anyone and everyone to be able to see the proof, since if I understand correctly, this may turn this discovery from a helpful one to a hurtful one.

I am sure you of all people on Reddit would know both sides of the coin, and that we wouldn't be able to reap the benefits of this discovery without unfortunate malicious side products, which is why I am not completely certain that just posting it online would be the best move.

Nevertheless, when I thought about it a bit more I discovered that, don't all discoveries have that same property? That they could all be maliciously exploited? Sure they may not all have the same magnitude, but they still do have it, and what was the result? We still published them, and I believe that its because the benefits out weigh the negatives, and that we only think about it with P vs NP, because the negatives are actually well known, more prone to usage, related to all of us, and will affect almost everyone.

I guess one could say that its simply a major trolley problem, where our issue lies in that both tracks have so many people we can't even see which has more so that we could even take that into consideration. Its not like the numbers make it easier, but if we were to go with the same logic as that, we choose the most beneficial route in saving the most number of people it would help then. You could also say that we shouldn't publish at all, i.e. stop the train, but wouldn't that just delay the train? The train is inevitable if it is the case that P=NP, its just a matter of time before someone could prove it, in result sooner or later we will face the same issue once again.

So kind of like a TLDR summary, if it was that I have a constructive proof that P=NP, applied to the 3SAT problem, how could I publish it in a way that we could benefit the most from it and decrease the number of ways it could maliciously be used?",2021-05-08 06:27:42
2u3y2u,"A new documentary about Grace Hopper, who wrote the first compiler, came out today",N/A,2015-01-29 18:58:24
y9bdv,Khan Academy adds computer science courses,N/A,2012-08-15 12:38:47
8ilkwc,It's Alan Turing's Birthday next monday - who wants to send flowers?,"Alan Turing's Birthday is on the 23rd of June. We're going to make it special.

Every year, people (mostly from reddit, it turns out) pledge bunches of flowers to be placed at Alan Turing's statue in Manchester for his birthday. In the process we raise money for the amazing charity Special Effect, which helps people with disabilities access computer games.

Since 2013 we've raised about £3900 doing this, and we'd like 2018 to be our biggest year ever. Anyone who wants to get involved is welcome. Donations are made up of £3.50 to cover the cost of the flowers and a £13 charity contribution to Special Effect for a total of £16.50.

If you'd like a bunch of flowers placed in your name you can donate (or see how much we've raised so far) at our [PayPal Pool](https://www.paypal.com/pools/c/83f5W4qZXG)

Manchester city council have confirmed they are fine with it, and we have people in Manchester who will help handle the set up and clean up. Sound like fun? Joe

(via some previous donors and r/Math(s) we are currently up to £489.50, which is amazing) 

(edit, 'Month' NOT 'Monday' - my bad)",2018-05-11 06:08:16
3xjjbc,"What books are a must-read for programmers that are starting out, and why? What have you gained from reading those books?","Please don't post books that you haven't read or are too advanced for the average person.
",2015-12-20 03:56:46
nyvc78,"I made a YouTube series on a very interesting coding competition called the ""C Bignum Bakeoff"" held in 2001. Participants write a short C program and the biggest output wins. Going through the entries, one hits upon a lot of fun compsci topics; the link is in the post, along with a few more details.","Here's the link to the series: [https://www.youtube.com/playlist?list=PL-R4p-BRL8NR8THgjx\_DW9c92VHTtjZEY](https://www.youtube.com/playlist?list=PL-R4p-BRL8NR8THgjx_DW9c92VHTtjZEY)

The videos in the series touch the following topics:

1. The series starts with some basic analysis of simple-to-implement fast growing functions, quickly outstripping Graham's number. Some of the entries managed impressive results using just this logic.
2. Then appears an unexpected function that is shockingly fast growing despite looking so innocent. We analyze how fast this function grows.
3. We then make a detour into undecidability and how certain ideas for the competition are forbidden by math.
4. We finally look at the winning entry that uses lambda calculus(!) to implement their crazy idea.",2021-06-13 12:33:38
becq9h,Artificial intelligence is getting closer to solving protein folding. New method predicts structures 1 million times faster than previous methods.,N/A,2019-04-17 20:37:44
103s9t,You know you are in for a good time when your book opens with this paragraph:,"""Writing the first edition of this book was a grueling task that took two and a half years and the help of many people. After the toll it took on my health and sanity, I promised that I'd never put myself through such an experience again. ""

That poor, poor soul who wrote the O'reilly book ""Mastering Regular Expressions"" 

Why do i read this?
I am a sick sort of person.",2012-09-18 22:50:32
91dqwy,"Rockstar - a dynamically typed Turing-complete programming language designed for creating computer programs that are also song lyrics, and heavily influenced by the lyrical conventions of 1980s hard rock and power ballads.",N/A,2018-07-24 03:11:01
124kes,e-Petition Reminder: Put Alan Turing on the next £10 note -- 20% of the way there!,N/A,2012-10-26 15:16:31
37ij6r,"Path Finding Algorithms, Visually",N/A,2015-05-27 21:57:11
33r9cs,Why are most computer science journals behind paywalls? I would have thought this field would be the first to subscribe to the Open Access movement.,RIP Aaron Swartz.,2015-04-24 21:29:25
1suiap,"Belated birthday wishes to pioneering MIT computer scientist and the first female U.S. Navy Admiral, ""Amazing Grace"" Hopper, born December 1, 1906.",N/A,2013-12-14 04:22:47
l0yf7s,What is your favorite computer science podcast?,I just got done with an interview where he asked how I stay in touch with the industry. So I thought I would ask y’all how do you keep up with the changing technologies and tech accomplishments?,2021-01-20 01:23:33
c60bbb,The first AI universe sim is fast and accurate—and its creators don't know how it works,N/A,2019-06-27 03:18:24
buvd6s,AI Restores Photos of ’90s Hong Kong Film Stars,N/A,2019-05-30 16:39:50
8qmzyz,Graph Data Structures for Beginners,N/A,2018-06-12 21:50:17
qtg09,Mathematics for Computer Science PDF Book,N/A,2012-03-12 20:53:42
pfz27w,Do programmers actually use Flowcharts/Pseudocode when planning a project?,N/A,2021-09-01 17:46:22
km6muh,Maybe we can help revive r/compscipapers,The sub is dead and I just feel like it’s a waste. I think there might be enough postgrad/undergrad compsci theoretical students in this group to essentially get it up and running again! Is it a good idea?!,2020-12-29 04:03:04
4v8zzi,We Should Not Accept Scientific Results That Have Not Been Repeated,N/A,2016-07-29 21:40:50
118svz,SmoothLife - a continuous version of Conway's Game of Life,N/A,2012-10-10 09:08:02
cgysz4,An interesting consequence of Lempel-Ziv compression is the ability to explicitly write a compressed file that decompresses into an exact copy of itself.,N/A,2019-07-23 21:30:41
8of46q,"Why AI researchers are boycotting new Nature journal: don't let the broken academic publishing system spread into fields that have open, community driven sharing.",N/A,2018-06-04 06:18:02
7atmsf,What is backpropagation and what is it actually doing?,N/A,2017-11-04 22:04:03
6iyo1o,Origami anything: New algorithm generates practical paper-folding patterns to produce any 3-D structure.,N/A,2017-06-23 03:24:03
6dw9o7,Linux Inside: How the Linux Kernel Works,N/A,2017-05-28 21:24:37
dfk41a,"Watch Out, MIT’s New AI Model Knows What You’re Doing Behind That Wall",N/A,2019-10-09 17:12:17
hq6az0,"Over the last 24 hours, my brother and I held a mini-hackathon. We built a web scraping bot that,given a subreddit, timeframe, and amount of posts to scrape, searches the title of each post on that sub, counts how often each word occurs, and scores each word based on upvotes. Checkout the data!",N/A,2020-07-13 01:32:31
6qj964,What are some skills every CS major should have?,This will help out a lot of the people just getting into this field (Like myself),2017-07-30 19:18:52
4oqgmz,Computer in minecraft + Design documents,N/A,2016-06-18 21:45:45
o0hjee,"What do you think about the statement ""You don't learn software engineering at university""?","I have read such statements so many times...

Also at my university, people would recommend me to just skip courses which deal with SWE topics like agile software development and paradigms. ""Skip that course and take more substantial courses like advanced algorithms or algorithm projects. For the absolute basics you can just take a good book and learn it by yourself but the 'real' software engineering comes with the job.""

What do you think about this point of view?",2021-06-15 15:51:40
8vr32n,Do you believe that coding classes should be mandatory within schooling before college?,"The way the world is moving I think students should be taught at least the basic principles of coding, thats not to say they'll be needing it or using it within their lives if they choose not to pursue the CompSci field, but more as a reflection of the technologically dependent world we live in.

",2018-07-03 10:18:07
5702b0,New Algorithm Solves Cake-Cutting Problem,N/A,2016-10-11 20:05:29
3ij8r4,"Joseph F. Traub, who founded the computer science department at Columbia University and who helped develop algorithms used in scientific computing in physics and mathematics as well as on Wall Street, died on Monday in Santa Fe, N.M. He was 83.",N/A,2015-08-27 00:08:37
2jp6ia,I made a website to simply explain how computers work.,N/A,2014-10-19 16:02:21
qjz6bz,Any Really Good Computer Science or Coding Channels on YT?,"Any good YouTube channels for new people learning coding and coding fundamentals. I watch lots of math videos on YT and if anyone where to recommend me for math channels I would say 1blue3brown, Veritasium (sometimes). I was wondering If anyone knows any good channels that doesn't sticky teach how to learn a certain langue step by step but more deep understandings and good advice that I will keep back in my head as I keep learning to code. Interesting topics as well, like those math channels. Thanks",2021-10-31 21:28:32
motynj,The Cursed Computer Iceberg 🧊,[https://suricrasia.online/iceberg/](https://suricrasia.online/iceberg/),2021-04-11 16:31:43
glndvb,How do people even come up with these models of data algorithms?,"I'm not in the CS field but some of my friends are. It's always crazy to see how they get some random math concept like topology and then suddenly say ""therefore you can treat data like a 5 dimensional sphere and then do this math and it will be more efficient"". Like what kind of mindset do you need to come up with these ideas?",2020-05-17 21:06:03
5xq56p,A Brief Introduction To Computational Geometry Concepts with C++,N/A,2017-03-06 00:26:23
900nl2,Data Structures for Beginners: Trees,N/A,2018-07-18 23:41:54
kposlx,"I made a simple diagram on history of OS, feel free to comment","I tried to make the details as simplified as possible.

Please confirm if I gave justice to each OS distributions by correctly summarizing the key characteristics. :)

&#x200B;

// Edit:

Thanks for all the details feedbacks! You guys are great. :)

I'm making changes slowly -- but keep in mind this is simplified to only include the most major developments (what an engineer should know, etc) so the diagram cannot include everything.

&#x200B;

https://preview.redd.it/azoeztp0a2a81.png?width=4613&format=png&auto=webp&s=73997fe6f2b0467f73905452be9fde1aa45302c6

// edit: changed MS branch to proprietary, minix and ms dos is not unix derivative, included cp/m, split ms branch to DOS/NT, chromeos is gentoo derivative, separated gnu & linux, add pre-darwin mac os's, solaris in system v, ios after macos, child nodes somewhat chronological, android user count, etc...",2021-01-03 17:37:21
iusuys,"[R] After 15 Long Years, a NumPy Paper Finally Appears!","Since[ NumPy](https://numpy.org/) was introduced to the world 15 years ago, the primary array programming library has grown into the **fundamental package for scientific computing with Python.** NumPy serves as an efficient multi-dimensional container of generic data and plays a leading role in scientific computing. It is an essential component in research analysis pipelines across fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. NumPy is open-sourced and has myriad contributors.

But one thing has always been missing. A thorough review paper that is fully representative of the team behind Numpy’s genesis has never been published.

The missing chapter in the NumPy story was written yesterday — with the appearance of the paper *Array Programming with NumPy* in leading scientific journal *Nature.*

Here is a quick read: [After 15 Long Years, a NumPy Paper Finally Appears!](https://syncedreview.com/2020/09/17/after-15-long-years-a-numpy-paper-finally-appears/)

The paper *Array Programming with NumPy* is on [*Nature*](https://www.nature.com/articles/s41586-020-2649-2).",2020-09-17 21:29:22
ghmnhb,Richard Feynman’s Advice to a Young Stephen Wolfram (1985),N/A,2020-05-11 12:30:27
b636od,Fathers of the Deep Learning revolution receive 2018 ACM A.M. Turing Award,N/A,2019-03-27 11:14:10
2k4abi,New Evidence of the NSA Deliberately Weakening Encryption,N/A,2014-10-23 18:28:38
qw8wig,Theoretical breakthrough could boost data storage,N/A,2021-11-17 21:02:52
5jbves,Game where you build a CPU,N/A,2016-12-20 06:52:15
262tw7,Knuth on why he believes P=NP [Question 17],N/A,2014-05-21 00:30:51
2ke01y,Large collection of Computer Science books and blogs.,N/A,2014-10-26 18:34:42
k3byzb,Artificial intelligence makes blurry faces look more than 60 times sharper: This AI turns even the blurriest photo into realistic computer-generated faces in HD,N/A,2020-11-29 16:14:31
b4ceq4,"New ""photonic calculus"" metamaterial solves calculus problem orders of magnitude faster than digital computers",N/A,2019-03-23 00:00:10
9lzuwy,Ultimate List of Youtube Channels for Deep Learning and Computer Vision,N/A,2018-10-06 21:44:53
8klan8,Edsger W. Dijkstra - Lecture: Reasoning About Programs - Solving 2 problems using programming - 1990,N/A,2018-05-19 13:35:32
eo8uu7,"I made a search engine for CS/Math/EE/Physics papers. Uses state of the art machine learning / NLP techniques (Bert) for a natural language search, so it's less dependent of specific keywords and keyphrases.","https://i.imgur.com/AEnLxK3.png

This can be thought of as a Bert-based search engine for computer science research papers. 

https://thumbs.gfycat.com/DependableGorgeousEquestrian-mobile.mp4

https://github.com/Santosh-Gupta/NaturalLanguageRecommendations

Brief summary: We used the Semantic Scholar Corpus and filtered for CS papers. The corpus has data on papers' citation network, so we trained word2vec on those networks. We then used these citation embeddings as a label for the output of Bert, the input being the abstract for that paper. 

This is an inference colab notebook

https://colab.research.google.com/github/Santosh-Gupta/NaturalLanguageRecommendations/blob/master/notebooks/inference/DemoNaturalLanguageRecommendationsCPU_Autofeedback.ipynb#scrollTo=wc3PMILi2LN6

which automatically and anonymously records queries, that we'll just to test future versions of our model against. If you do not want to provide feedback automatically, here's a version where feedback can only be send manually:

https://colab.research.google.com/github/Santosh-Gupta/NaturalLanguageRecommendations/blob/master/notebooks/inference/DemoNaturalLanguageRecommendationsCPU_Manualfeedback.ipynb

We are in the middle of developing much more improved versions of our model; more accurate models which contain more papers (we accidentally filtered a bunch of important CS papers in the first version), but we had to submit our initial project for a Tensorflow Hackathon, so we decided to do an initial pre-release, and use the opportunity to perhaps collect some user data in further qualitative analysis of our models. Here is our hackathon submission:

https://devpost.com/software/naturallanguagerecommendations

----

As a sidequest, we also build a TPU-based vector similarity search library. We are eventually going to be dealing with 9 figures of paper embeddings of size 512 or 256. TPUs have a ton of memory, and are very fast, so it might be helpful when dealing with a ton of vectors. 

https://i.imgur.com/1LVlz34.png

https://github.com/srihari-humbarwadi/tpu_index

-----

Stuff we used: Keras / Tensorflow 2.0, TPUs, SciBert, HuggingFace, Semantic Scholar. 

Let me know if you have any questions.",2020-01-13 19:23:49
18nrtt,"Learn how a computer really works, build one from logic gates to OS.",N/A,2013-02-16 22:37:31
kw4pq,"""Algorithm"" is Not a Four-Letter Word",N/A,2011-09-30 04:37:36
88a48p,What was the most revolutionary idea in computer science?,N/A,2018-03-30 12:54:57
tfowm,Simplest explanation of P vs NP I've come across,N/A,2012-05-10 01:14:46
nvrro,Cory Doctorow: The coming war on general computation,N/A,2011-12-30 03:26:08
qve2q6,First all-atom simulation of respiratory aerosol with COVID-19 virus inside!!,"Our group (51 authors from 10+ institutions) used high performance computing and national supercomputing networks (TACC/Frontera, Summit, Oracle Cloud) to simulate (with all atom detail and physical descriptions) a respiratory aerosol with a SARS-CoV-2 virus inside. Here is a trailer highlighting our groups model. Additionally all details about this work can be found at: [https://www.biorxiv.org/content/10.1101/2021.11.12.468428v1](https://www.biorxiv.org/content/10.1101/2021.11.12.468428v1)

As one of 6 finalists for the ACM Gordon Bell Prize for Application of HPC to COVID-19 investigations, our work will be presented this week at Supercomputing 2021 in St. Louis, Missouri. [https://sc21.supercomputing.org/presentation/?id=gbv104&sess=sess249](https://sc21.supercomputing.org/presentation/?id=gbv104&sess=sess249)

(EDIT, transcript of movie below:)

""Our work opens a new for modeling and simulation of airborne diseases broadly speaking. And almost more importantly, our work shows how HPC has the potential to illuminate the fundamental mechanisms of how people are connected, through the challenges we face and the air we breathe.""

https://reddit.com/link/qve2q6/video/og3268hxzzz71/player",2021-11-16 18:11:11
ejdc8f,Computer Science Resources for 2020,N/A,2020-01-03 09:51:58
71vdmn,Silicon Zeroes - a game about CPU design!,N/A,2017-09-23 01:16:01
5hjx74,"A python script to repair music files (Adds album art, album name, artist name, lyrics)",N/A,2016-12-10 12:33:38
14ji6j5,Designing and Building a computer from transistors - 2/4,"The computer will have programmable micromemory which means I will be able to change the instruction set.

I have also previously built x86 compiler and also intend to make one for this computer.

Maybe write some tutorial too if enough ppl ask.",2023-06-26 14:02:14
pgs5x9,Most important foundational papers in Computer Science,"Hello,

I'm a pure math person which is very much interested in the foundations of computer science (well, at the time was just called math, maybe that's why). I already read Alan Turing's On Computable Numbers and it was totally worth it, it even got me into a wild rabbit hole of metamathematics. What should one read next to understand the foundation of CS theory? What papers were written in response to Turing's? Let's make a big list!

(Just to make sure, I don't mean introductory material, I mean hardcore theoretical writings which shapped the field).

As a bonus, it would also be nice to see some papers that rewrite the foundational ideas into a modern light. That said, I'm not interested into just ""history of CS"", althought historical context is nice, I'd like to read papers that do get deep into the theory. 

Show me the good stuff, computer-people!",2021-09-02 22:26:15
driuh7,Program to generate it's own source code,"Today  in my Theory of Computation class we discussed about recursion theorem. And it got me thinking about the title of the post. 

Then ,I  came across the concept of Quine (https://en.wikipedia.org/wiki/Quine_%28computing%29).

It is essentially a program that generates the source code of itself. I would suggest you to give it a try before having a look at some actual examples.

I found this very fascinating and thought about sharing it with you. I'll post a source code that satisfies this if requested.",2019-11-04 15:06:52
12qhqkz,Meet the Computer Scientist Who Solved 50-Year Old ‘Einstein’ Tiles Problem,N/A,2023-04-18 09:45:57
hv8xzb,Collection for Learning Algorithms and Data Structures for Beginners,"Hello everyone,

I hope you’re doing well. One of my friends wants to learn programming. So, he asked me which language to start.

I never believed, learning a specific language is so much related to learn coding. I agree with Kevin's advice in [this video](https://www.youtube.com/watch?v=mvK0UzFNw1Q). 

Best way to learn programming is to solve your own problem and make toys with it. So, you can find small problems that you care about, and try to solve them. Of course, after learning couple of basics.

I think those basics are data structures and algorithms. Start learning those and choosing any language to implement them would be a great start.

I’m also not a big believer in online courses. The Internet is a big library of different resources. I know it’s a mess and it’s hard to find useful pieces. Also, it’s almost impossible to know where to start as a beginner.

Therefore, I have curated a list of articles, depositories, videos and exercises as a micro-course for data structures and algorithms.

I thought this sub might like this, hope it helps :)

Here’s the collection: [Algorithms and Data structures](https://jooseph.com/modules/733?utm_source=reddit.com&utm_medium=social&utm_campaign=Algorithms%20and%20Data%20Structures)",2020-07-21 15:06:31
h131iw,Has anyone seen any interesting computer science lectures/keynotes during quarantine that you could recommend,"I am both bored and writing a personal statement, so if anyone has seen an interesting lecture(maybe on the royal institute yt channel) that they would recommend that would be great!",2020-06-11 16:51:35
d88vc6,Why did Google post--then take down--its claim of quantum supremacy?,N/A,2019-09-23 16:27:16
54ak6s,Using Neural Networks to Edit Photos (Github in Description),N/A,2016-09-24 15:26:00
3sjpu1,A Quasipolynomial Time Algorithm for Graph Isomorphism: The Details,N/A,2015-11-12 16:15:36
1tl7f3,Alan Turing receives posthumous pardon,N/A,2013-12-24 05:43:01
ud8sgg,"If quantum computers can break normal encryption easily, won't there be a MASSIVE security issue when only a few corporations will have access to them?","Assuming that humanity will work on making quantum computers available for everyone: in this process, at some point they will become affordable for a few people in the world, but not cheap enough for the general population. At that point, the security of almost all the devices in the world will be compromised, no?

One way to counter this would be to have way longer keys, hashes, etc, for example instead of a 256 bit hash to have a 2^24 bit hash, but I don't know if that won't become at some point too resource-intensive for normal computers and still be rather easy to break for quantum computers.

So, can this be a real problem or am I missing something? And what could be a way to counter it?",2022-04-27 17:20:06
2vz42n,Computer science podcasts?,Are there any good podcasts related to computer science?,2015-02-15 15:14:49
17kzo5,Computer scientists find new shortcuts for Traveling Salesman problem.,N/A,2013-01-30 20:48:42
10gyqrg,Infinite Tetris is Turing-complete,N/A,2023-01-20 14:46:27
covh2f,"In all time top 10 coursera courses, no1. is machine learning course with 2.45 million enrollments..",N/A,2019-08-11 11:04:58
7m1uo4,The Philosophy of Computer Science (via Stanford Encyclopedia of Philosophy),N/A,2017-12-25 15:27:37
1g5f2f,What would you do with all that NSA data?,"Ok, so assuming you had full access to all of that data.  And assuming that they had some really good shit on all of us.  What interesting nuggets of data could we mined from there. What would you look for?",2013-06-11 21:21:54
mz2vk6,New Proof Reveals That Graphs With No Pentagons Are Fundamentally Different,N/A,2021-04-26 17:22:22
8e0rmg,Is Stephen Wolfram’s “A New Kind of Science” Bullshit?,"Here’s one critique by physicist Steven Weinberg I found interesting: He says, “Wolfram himself is a lapsed elementary particle physicist, and I suppose he can't resist trying to apply his experience with digital computer programs to the laws of nature. This has led him to the view (also considered in a 1981 paper by Richard Feynman) that nature is discrete rather than continuous. He suggests that space consists of a set of isolated points, like cells in a cellular automaton, and that even time flows in discrete steps. Following an idea of Edward Fredkin, he concludes that the universe itself would then be an automaton, like a giant computer. It's possible, but I can't see any motivation for these speculations, except that this is the sort of system that Wolfram and others have become used to in their work on computers. So might a carpenter, looking at the moon, suppose that it is made of wood.”
",2018-04-22 03:23:26
78ohha,Pathfinding algorithms visualized [OC],N/A,2017-10-25 15:40:42
pei4z,BBC News - Government rejects pardon request for Alan Turing,N/A,2012-02-07 09:48:51
gxvbst,"My algorithmic teacher shared a beautiful song about red-black trees with us, love it",N/A,2020-06-06 17:36:06
mw737r,Scott Aaronson receives 2020 ACM Prize in Computing,N/A,2021-04-22 15:19:33
3yow1k,Springer is offering free pdf downloads of books older than 10 years,N/A,2015-12-29 19:52:23
pkucdm,GitHub Copilot Generated Insecure Code In 40% Of Circumstances During Experiment,N/A,2021-09-09 09:23:03
m5jzxf,Donate your voice to an open-source project by Mozilla,"I want to show you the Common Voice Project, a project of Mozilla Foundation (Mozilla build Firefox, Thunderbird, MDN, etc.).  
This project powers mycroft.ai (a privacy focussed alternative to Google Home)  
The project name is Common Voice; its goal is to collect voices of people to create a free and open-source dataset, which you could use for various topics, like educational, AI, etc. and currently just ""Big tech"" have projects like this and they required many money to use their datasets. In addition, ""Big tech"" develop their datasets and language models just for the most spoken languages. Mozilla, instead, wants to collect ALL languages (you can add your language also if it's a less spoken one): because Mozilla doesn't get anything (any earnings!) from this project.  
This is the project's website (but wait, continue to read this post, :)): https://commonvoice.mozilla.org  
Helping this project is very simple, you are asked to record sentences that are shown to you or you can validate recordings from other people.  
All your information and data are protected, in fact you can contribute anonymously (without creating a profile).  
u/sav22999 is maintaining the Android app ""CV Project"" to make it easier for people using smartphones to contribute to this dataset .  
The app is free and open-source, available on all major Android app stores (Google Play, F-Droid, GitHub, Huawei AppGallery and Amazon AppStore).  
You can download it here: https://play.google.com/store/apps/details?id=org.commonvoice.saverio  
the code of the app is here: https://github.com/Sav22999/common-voice-android/  
\--  
Why am I promoting this project?  
I'm not paid by Mozilla, I didn't earn anything, I do this as volunteering.  
You can find more information the developer of the android app here. He is a volunteer of the Italian Mozilla community: https://people.mozilla.org/p/Sav22999  
You can also come join is in the subreddit for this project r/cvp",2021-03-15 12:51:35
gzi176,Is there a “right age” to start studying computer science?,"I’m 18 and I’m considering start studying code and some languages right now. 

Data science is something that interests me and I know that it would’ve been better if I had built basic knowledge about programming earlier in my life, but I only started to admire this area last year.

Do you think that “the earlier the better” or that “age is just a number”? Am I at the right age to start coding?",2020-06-09 07:07:23
f2d3a6,ELI5: What is the difference between a container and a virtual machine?,"I understand that a virtual machine is a self contained operating system running on another piece of hardware(ex - running a windows virtual machine on linux) - emulation

I know all virtual machines on a machine will share that machine's resources(RAM, CPU, Storage)

From reading about containers, I can't differentiate them and virtual machines and identify what problems containers are supposed to address that virtual machines can't.

One thing I did learn was that containers require less overhead than virtual machines because you're emulating an entire operating system with virtual machines

Can someone give an ELI5  explanation of the difference between a virtual machine and a container? When would you want to use one over the other?",2020-02-11 19:02:20
etndot,Degree in computer science and yet know nothing,"As the title says, I don't think I know enough. I'd like if someone can point me to resources which explain computer science technologies and concepts in simple terms. 
eg: i had to set up an ingress controller at work. I read that ingress is a reverse proxy. This is where i got stuck. I have no idea what a reverse proxy is. 

This is just an example. I realized a lot of my comp sci concept are not clear and it affects me at work",2020-01-25 06:40:08
5k3try,What your favorite algorithm?,"I personally like the Tower of Hanoi, but I know so few... ",2016-12-24 16:44:31
hgdxv0,Programming in Lambda Calculus,"I have written a little paper:

[Programming in Lambda Calculus](https://hbr.github.io/Lambda-Calculus/)

The text looks at lambda calculus from a programmers point of view. Everyone with some programming experience should be able to read and understand the text.

Special effort is given on how to represent algebraic data types in lambda calculus.

I hope some of you might enjoy the paper.",2020-06-26 19:14:00
fo7atv,"We are Carnegie Mellon University Students, and we help build CMU CS Academy: a free, online, High School programming curriculum. AMA about remote instruction for Computer Science education!",N/A,2020-03-24 15:48:00
6n2bkr,"By day, Claude Shannon labored on top-secret war projects at Bell Labs. By night, he worked out the details of information theory.",N/A,2017-07-13 15:29:13
2tua4k,P vs. NP and the Computational Complexity Zoo,N/A,2015-01-27 14:12:07
vu34p,THE PH.D. GRIND,N/A,2012-06-30 08:34:34
eqhv4j,'Remarkable' Mathematical Proof Describes How to Solve Seemingly Impossible Computing Problem,N/A,2020-01-18 15:43:31
dme8s1,Would aliens understand lambda calculus?,N/A,2019-10-24 10:05:04
yfszv3,What are the greatest breakthroughs in Computer Science?,I am interested in what are the biggest breakthroughs for you in Computer Science? I am asking since I want to explore more interesting topics for a podcast and also for some students of mine.,2022-10-28 16:24:50
fghf1x,How Canadian AI start-up BlueDot spotted coronavirus before anyone else had a clue,N/A,2020-03-10 17:23:56
dp761m,Short video on a famous 2 page paper on Secret Sharing (Art of the Problem),N/A,2019-10-30 14:03:50
d7so98,Actual Paper: Quantum Supremacy Using a Programmable Superconducting Processor : Paper that was Deleted On Nasa Site but cached by Bing:,N/A,2019-09-22 16:22:04
8ft823,Just committed to a university for Computer Science! My dreams are finally becoming a reality!,N/A,2018-04-29 18:29:28
v90xu5,Researchers Achieve ‘Absurdly Fast’ Algorithm for Network Flow | Quanta Magazine,N/A,2022-06-10 06:01:28
i2a87x,Back of the envelope estimation hacks,N/A,2020-08-02 10:56:07
3r7e65,What are some of the best computer / programming related documentaries out there?,"If you're anything like me, watching shows or movies related to computers or programming or even people that have been extremely successful in the tech field while working on side projects helps inspire and motivate me. What are some of your favorites?",2015-11-02 12:53:20
zcgwp,Crazy Man's Operating System Now Has New WebSite with Source Code Posted On-Line,N/A,2012-09-04 17:54:51
r14di,Is there any interest in a Computational Geometry subreddit?,N/A,2012-03-17 19:32:42
tq0xtk,What cool algorithms or technologies came out of video games?,I saw that the fast inverse square root came out of the video game Quake. I was wondering what other things came from video games?,2022-03-28 04:13:04
qbb4p2,Podcast about computer science or topics related ?,"Hello! I've been looking a little bit for podcasts about general computer science discussions and I have made little to no progress. Would anyone mind recommending a podcast where they discuss topics like new technologies versus old technologies, or just discussing and explaining different topics about software development ?
Thank you very much in advance and sorry for my english.",2021-10-19 13:06:07
h91dyi,[D] Facebook and Kaggle Face Backlash After Disqualifying Apparent ‘Deepfake Detection Challenge’ Winner,"Facebook and Kaggle are facing an online backlash after the apparent winners of the Deepfake Detection Challenge (DFDC) were disqualified. Facebook launched the competition last year to encourage the development of new technologies to detect deepfakes and manipulated media, and there were more than 2,000 entries were submitted. The data science and machine learning community site Kaggle hosted the DFDC challenge and leaderboard. 

Here is a quick read:  [Facebook and Kaggle Face Backlash After Disqualifying Apparent ‘Deepfake Detection Challenge’ Winner](https://syncedreview.com/2020/06/14/facebook-and-kaggle-face-backlash-after-disqualifying-apparent-deepfake-detection-challenge-winner/)",2020-06-14 20:45:17
d5v4bv,AI Agents Startle Researchers With Unexpected Hide-and-Seek Strategies,N/A,2019-09-18 09:14:04
c5fdgy,Intel Is Working On A New 'Data Parallel C++' Programming Language,N/A,2019-06-25 21:09:41
2xc3td,Great papers/texts every Comp Sci should have read at least once.,"I'm always looking for inspiring papers and texts from great names in our field. As such I thought it would be a nice idea to gather a list here. Let me start of with the following two:

* [Richard Hamming - You and your research](http://www.cs.virginia.edu/~robins/YouAndYourResearch.html)
* [Edsger Dijkstra - The humble programmer](https://www.cs.utexas.edu/~EWD/transcriptions/EWD03xx/EWD340.html)

# yours here",2015-02-27 09:05:42
1rxfze,"If you liked E.W. Dijkstra's paper ""On the cruelty of really teaching computing science"", this if for you: fully self-contained, and online course, on computing science from a formal methods perspective","**First, the meat of the matter:** I struggled for a long time to find a course that actually taught me what Dijkstra advocated in his famous paper ""On the cruelty of really teaching computing science"". I finally found one after much digging and sleeping, and a good dose of kindness from a fellow human being: http://www.cs.utoronto.ca/~hehner/FMSD/

**The meat contains various motivating papers:**

* http://www.cs.utoronto.ca/~hehner/FMSD/Hoare-CACM.pdf
* http://www.cs.utoronto.ca/~hehner/FMSD/vstte-hoare-misra.pdf
* http://www.cs.utoronto.ca/~hehner/FMSD/VSI-manifesto.pdf

**but my personal favourite motivation:**

* [E.W. Dijkstra's ""On the cruelty of really teaching computing science""](http://www.cs.utexas.edu/~EWD/ewd10xx/EWD1036.PDF)
* see discussion on this paper [here](http://www.reddit.com/r/compsci/comments/1rvdq0/dijkstras_classic_on_the_cruelty_of_really/) and [here](http://www.reddit.com/r/programming/comments/1rveo6/dijkstras_classic_on_the_cruelty_of_really/)


**note 0:** While the theory in this book is completely self-contained, it is sometimes useful to refer to (inferior, *snort*, you wish I was joking, but I am not) resources like [this book](http://www.reddit.com/r/compsci/comments/1ru77a/mathematics_for_computer_science_pdf_book/) for insight. Always try your hand at formalizing what is informally presented!

**note 1:** Print out the textbook if you can (textbook: A Practical Theory of Programming, free for download from above course link)! The author has given permission as long as you include the cover page, and it shouldn't cost you more than $15 at a decent printing+binding shop.

**note 2:** If you need a study buddy, send me a PM.

**What can I learn in conjunction with or after I have made some progress through this course? (warning: these are just suggestions by me, and I am not a professor):**

* try this book in conjunction with the course (see if you can better formalize the informal explanations in the book; are your formalizations clearer than the informal explanations? do they explain more?): http://www.amazon.com/Introduction-Algorithms-A-Creative-Approach/dp/0201120372

* try this book too, but be aware, you must read through it slowly and you should not be surprised if you learn little from it by speeding through: http://www.amazon.com/Discipline-Programming-Edsger-W-Dijkstra/dp/013215871X/ref=sr_1_1?s=books&ie=UTF8&qid=1386010150&sr=1-1&keywords=a+discipline+of+programming

**note and clue 3:** If you are a bad enough person, with terrible, terrible morals, and a contemptible nature in general, you can find both of these books using Google, for free, on the genesis of a library. 

**why are you making this post?:** So that I can share with you precious information that every part of my being says that I *should not* share so that I can continue to feel smarter than you. I hope you return the favour someday, today, or tomorrow. Now please, don't learn more than I did, and if you do, please share. I hope karma is real, because I need it badly.

**if you want to laugh, because you are sad:** http://www.youtube.com/watch?v=4NIJbj92QEM",2013-12-02 18:58:39
izk9r2,I made some UX/performance improvements and added additional algorithms to my traveling salesman problem visualizer based on feedback I received here. This is a browser-based educational resource for learning common algorithms.,N/A,2020-09-25 14:20:02
icknih,"CyberLand has been launched in the UK, a game to promote awareness around cyber security which gives you the opportunity to win prizes",N/A,2020-08-19 09:48:11
i7848h,Which rather unknown algorithm that was recently published do you deem very impressive and why?,N/A,2020-08-10 16:30:15
7v8r3i,"Slideshow of Mathematical Surfaces, viewable on snapchat!",N/A,2018-02-04 19:06:31
5uz9lb,Top Algorithms/Data Structures/Concepts every computer science student should know,N/A,2017-02-19 17:21:32
sxqg5h,Another classic CA : Byl's loop,N/A,2022-02-21 10:31:15
8szkbr,"Finally, a problem that only Quantum Computers will ever be able to solve.",N/A,2018-06-22 07:54:05
8hwozu,8 time complexities that every programmer should know,N/A,2018-05-08 13:31:20
1dh3w7,I DID Want Computer Science: A different perspective on CS expectations and realities.,N/A,2013-05-01 11:11:53
135fjgc,‘The Godfather of A.I.’ Leaves Google and Warns of Danger Ahead,N/A,2023-05-02 08:55:47
kivs69,Dijsktra's SP IRL,N/A,2020-12-23 16:08:56
z1oulg,Why Neural Networks Can Approximate Any Function (The Universal Approximation Theorem),"Hi guys,

I have made a video on YouTube [here](https://youtu.be/O45AaRPQhuI) where I explain why neural networks are considered universal function approximators.

I hope it may be of use to some of you out there. As always, feedback is more than welcomed! :)",2022-11-22 08:59:56
mwt29f,New Algorithm that overcomes limitations by hash and B-tree indexes. Search by any possible search key combination in consistent high performance.,N/A,2021-04-23 11:23:02
bzbhi1,Small collection of animations of algorithms and data structures,N/A,2019-06-11 11:51:27
dmxja3,What's the best CS material you have ever use?,Best course/book/articles/videos that help you learn the most. The more specific the better :),2019-10-25 13:34:55
cm8cqw,A Decades-Old Computer Science Puzzle Was Solved in Two Pages,N/A,2019-08-05 08:31:28
5iz1z2,Ever wanted to add LaTeX to your Github Readme? readme2tex is a simple tool that helps you typeset equations and figures for Github Markdown.,N/A,2016-12-18 06:42:48
3tlg7q,TIFU by using Math.random(),N/A,2015-11-20 18:25:19
3scx8a,"Two hundred years after her birth, the Science Museum in London celebrates Ada Lovelace, the woman who prophesied the computer age [X-post /r/math]",N/A,2015-11-11 02:34:54
2przuw,"Defending my thesis today: ""Private, trustless and decentralized message consensus and voting schemes"". Wish me luck!","Hi everybody,

Today I'm giving the defense of my Master's thesis in Computer Science. The title of the thesis is *Private, trustless and decentralized
message consensus and voting schemes*.

In case anybody wants to read it, it can be found [here](https://jesper.borgstrup.dk/master-thesis-report.pdf).

The abstract is as follows:

> This thesis proposes a protocol to conduct anonymous, trustless, decentralized elections over the internet. Only registered voters can vote, multiple votes from the same voter are easily detected and discarded, and it is infeasible to determine the identity behind a given vote with a better probability than random guessing.
> 
> The voting protocol builds on top of a \emph{decentralized deadline consensus protocol} which can form a consensus about which messages have been sent before a specific deadline. This consensus protocol can also be used to suit other purposes such as contests, auctions and applications in a decentralized manner.
> 
> The protocols use the Bitmessage protocol for communication. Bitcoin, blockchain-technology and Invertible Bloom Lookup Tables are used for defining deadlines and timestamping of messages. Linkable Ring Signatures provide a signature scheme suitable for signing votes.
> 
> A proof-of-concept client has been developed and implemented, where one can create and run elections with a basic ballot format.",2014-12-19 10:31:54
2a2tyo,"In 28 states, computer science doesn't count towards high school graduation math or science requirements.",N/A,2014-07-07 20:08:54
1jp0ar,Computer Science Multi-Reddit,"I made a [compsci multireddit](http://www.reddit.com/user/nxlyd/m/compsci) for when I want CS without the noise from the rest of reddit. It includes the related subreddits from the sidebar as well as a couple others I thought belonged (such as /r/puremathematics and /r/logic). 

Please feel free to copy the multireddit and add or remove whatever you think fits the theme better. Perhaps we could craft a good multi list and have a link in the sidebar for others to copy?

The current list I've made is as follows:

> /r/compsci 

> /r/cscareerquestions 

> /r/AskComputerScience 

> /r/math 

> /r/programming

> /r/algorithms

> /r/types 

> /r/machinelearning

> /r/crypto 

> /r/philosophyofmath

> /r/learnprogramming

> /r/tinycode 

> /r/CSEducation 

> /r/puremathematics 

> /r/logic 
",2013-08-04 19:24:16
xv1gmq,PH = PSPACE?,"Using PSPACE-completeness of quantified boolean logic Valerii Sopin claimed to have obtained that **PH = PSPACE**, see [https://arxiv.org/abs/1411.0628](https://arxiv.org/abs/1411.0628)

*True quantified Boolean formula is indeed a generalisation of the Boolean Satisfiability Problem, where determining of interpretation that satisfies a given Boolean formula is replaced by existence of Boolean functions that makes a given QBF to be tautology. Such functions are called the Skolem functions.* 

*The essential idea of the proof is to skolemize, and then use additional formulas from the second level of the polynomial hierarchy inside the skolemized prefix to enforce that the skolem variables indeed depend only on the universally quantified variables they are supposed to. However, some dependence is lost when the quantification is reversed. It is called ""XOR issue"" because the functional dependence can be expressed by means of an XOR formula. Thus, it is needed to locate these XORs, but there is no need to locate all chains with XORs: any chain includes a XOR of only two variables. The last can be done locally in each iteration (keep in mind the algebraic normal form (ANF)), when all arguments are specified.*

&#x200B;

**Relativization** is defeated due to the well-known fact: PH = PSPACE iff second-order logic over finite structures gains no additional power from the addition of a transitive closure operator. Boolean algebra is finite. The exchange is possible due to finite possibilities for arguments. So, the theorems with oracles are not applicable since a random oracle is an arbitrary set. And that’s why Polynomial Hierarchy is infinite relative to a random oracle with probability 1.",2022-10-04 01:24:22
xsqplg,Knuth's TAOCP Volume 4B is coming SOON.,"First of all, sorry if this was already posted, I couldn't find any reference on this subreddit.

Looks like the long awaited TAOCP 4B, or more formally,  ""Combinatorial Algorithms, Part 2"" will be available on 11 October, i.e. ten days from now! I'm quite excited, this will be one of the most interesting books in the series.

See [Knuth's page on the books](https://www-cs-faculty.stanford.edu/~knuth/taocp.html) for reference.

https://preview.redd.it/nmr43ysju5r91.png?width=1053&format=png&auto=webp&s=74463a2b37141b77656ed78c70b8a4defd2079de",2022-10-01 09:12:53
sfm99a,How important is maths in programming?,N/A,2022-01-29 16:57:12
lx0uxx,"Berkeley Lab-led team developing code for exascale that will explore laser-plasma interactions, perhaps leading to compact particle accelerators",N/A,2021-03-03 18:31:27
dwc44c,Cardiologists and physicists have developed a machine learning algorithm to predict the life expectancy in heart failure patients.,N/A,2019-11-14 16:46:40
87teh6,Rice U uses 81 million processor hours on Titan to trace protein conformations that may contribute to autoimmune disease,N/A,2018-03-28 16:41:41
6w8iyc,Norbert Blum will deliver a public lecture regarding his claimed proof that P is not equal to NP on 29 August 2017.,N/A,2017-08-26 22:20:22
3z1su9,I made a java program that implements L-systems and turtle graphics to draw fractals! Here's a Penrose tiling.,N/A,2016-01-01 19:54:59
moc8dl,Rainbow Tables (probably) aren’t what you think - An explanation of how rainbow tables differ from lookup tables,N/A,2021-04-10 20:19:53
hqr86j,The Magical Math behind Modern Cryptography,"This presentation: https://youtu.be/mSMQ-xowqAg

Introduces the magical math that secures our digital lives. It is presented graphically so complex ideas can be appreciated by the expert and layperson alike.

Presentation topics include:

How to achieve privacy when someone is always listening. (encryption)

How to decide on a secret when everyone is watching. (key agreement)

How to turn one random number into unlimited random numbers. (PRNGs)

How to speak in a way that's impossible to imitate. (digital signatures)

How to help protect data without possessing it. (secret sharing)

How to check work you can't see. (zero knowledge proofs)

How to process data you don't have access to. (homomorphic encryption)",2020-07-14 00:22:07
fprlga,Folding@Home Network Breaks the ExaFLOP Barrier In Fight Against Coronavirus,N/A,2020-03-27 05:45:53
bq8lkj,I started a series to explain algorithms and programming concepts,"Hey Redditors,

I'm a software engineer with more than 10 years of experience, and I just started a youtube channel to help newbies carve their way into the software programming industry.

The purpose of the channel is to explain the challenging programming algorithms and concepts.

My priority is to provide ""**High quality**"" content that is engaging and valuable to all interested programmers.

I'm sure this will take time from my side to craft, but without feedback, I would not know which areas I should improve. Therefore, I'm coming to you today with the first video lesson which explains the concept if Recursion. Please find it below:

[https://www.youtube.com/watch?v=\_I0zspi93ow](https://www.youtube.com/watch?v=_I0zspi93ow)

If you want to help, I would appreciate your honest opinion.",2019-05-18 20:43:46
bf2yka,How the Boeing 737 Max Disaster Looks to a Software Developer,N/A,2019-04-19 19:05:07
b59vb6,TeXmacs creator is coauthor on paper that shows how to multiply integers in O(n log n) time.,N/A,2019-03-25 12:07:31
7fkd81,The Disappearing American Grad Student [NYTimes],N/A,2017-11-26 03:45:00
u6tl6,For Those Who Are Curious: The Reddit Algorithm,N/A,2012-05-27 03:04:48
l2ofs4,Are there story books/Novels revolving around computer science?,Did anyone read any novel/story book that was entertaining while helping you get a bigger picture and better understanding of the IT/Software industry and it's practices?,2021-01-22 14:08:06
2t5coa,Eigenvectors and eigenvalues explained visually,N/A,2015-01-21 07:04:10
2gwgx4,Microsoft shuts down research labs in Silicon Valley which includes among other top scientists the current Turing Award winner,"MSR SV was considered to be among the top centres outside of academia for research in Theory and this move affects ~50 scientists employed there. 

This may be an isolated incident but I cannot help but wonder if this marks a paradigm shift in what types of CS Research is encouraged in industry. 

[[Source](http://www.zdnet.com/microsoft-to-close-microsoft-research-lab-in-silicon-valley-7000033838/)] 
[[Unofficial Blog by MSR Researchers where several former employees and interns have posted odes](http://windowsontheory.org/2014/09/19/farewell-microsoft-research-silicon-valley-lab/)]",2014-09-19 22:16:14
vw07vc,World's first ultra-fast photonic computing processor using polarization,N/A,2022-07-10 20:24:11
hjelxl,Masters in computer science but not many practical skills,"So I've just finished a master's in computer science with focusses on ML and robotics. My undergraduate was in electronic engineering. My problem is that I feel I have good skills in specific tasks but I'm quite poor with general coding skills and some other basic compsci knowledge an employer looks for which I missed by not doing compsci undergrad.

Does anyone have any sources I could use to build/brush up some basic knowledge and python/C++ skills which would be useful in developer roles?",2020-07-01 17:20:50
f1k28n,How I convinced my government to apologise to Alan Turing,N/A,2020-02-10 03:07:34
b3637f,"As part of a technical writing course for my degree, I have to edit README's on github, if you have a README file you want a second opinion on let me know!","I know this is an unorthodox post, and mods, if this is against the rules please remove it.

I'm doing really well in this course, but I'm in danger of being screwed by this assignment, so if you're interested send me a PM and I'll get to work!

EDIT: An edit to my post about editing, ironic I know. I should note, this course is literally a CompSci English course (it's mandatory), so I have to go and make grammar changes and whatnot. I really appreciate the responses so far, but just a heads up there, because I'll be calling you out on misplaced commas...",2019-03-20 01:51:47
6pnq7e,What are potential disadvantages of functional programming? For which areas does functional programming work best and for which ones not?,"I am wondering what other people experience as disadvantages of functional programming? (**edit:** with this I mean avoiding [side effects](https://en.wikipedia.org/wiki/Side_effect_%28computer_science%29) in functions, or, in FP jargon, making extensive use of ""[referential transparency](https://en.wikipedia.org/wiki/Referential_transparency)"" where possible and practical, see below).

Of course one can define functional programming so that *no* local mutable state and *no* side effects are possible, and then point out the obvious disadvantages. But that's perhaps a [""no true Scotsman"" kind of argument](https://en.wikipedia.org/wiki/No_true_Scotsman). If you would define object-oriented programming with the same strictness, everything that is not an object and uses mutable values would be forbidden. Even something such as y = sin(x), copy-on-write or returning constant objects or containers from a function would be off-limits. That is, I am asking with a very pragmatic definition of FP in mind!

What I am wondering is rather, do you observe pragmatic functional programming as  [John Carmack](https://en.wikipedia.org/wiki/John_Carmack) described it  [here](http://www.gamasutra.com/view/news/169296/Indepth_Functional_programming_in_C.php) -- for C++! -- as valuable? And of course this question goes also to people who have tried it to some extend, as a purely theoretical discussion would be boring. I am interested in good examples!

I think there are also several interrelated but not strictly connected issues, like immutability, GC, memory safety, immutable data structures and so on, so it could be valuable to mention the point of view and background you are using as a reference. 

Another question I am wondering is, for what kind of programming and level is functional programming turning out more, or less, useful for people? Some critics mention systems programming but even this is a wide notion - writing docker code, a HTTP library or a compiler is obviously not the same as writing a filesystem, a process scheduler, or a network driver.

There is at least one area where I think that everyone is using FP to some extend, but not everyone knows: It is the area of data analysis and numerical computation. Whether you use MATLAB, Numerical Python, LAPACK, R, the [GNU scientific library](https://en.wikipedia.org/wiki/GNU_Scientific_Library) or even a spreadsheet: In all these cases, input is never modified.

(To describe my own background, I know reasonably well C, C++98, Go, Java, Numerical Python, MATLAB, R, Clojure, some Scala, Rust basics, Pascal,  IEC 61131-3 Structured Text, a bit of FORTH and some other things which have been lost in some dark corners of my memory).

**Edit:** /u/PM_ME_UR_OBSIDIAN made an important observation which I want to mention here for matters of an efficient discussion - saying what matters is probably not immutability by itself but [referential transparency](https://en.wikipedia.org/wiki/Referential_transparency).


**Edit2** I want to sum up a few points which might be interesting for further discussion:

1. Familarity / mindshare: Functional languages are less well-known, this can be a hurdle. But functional concepts and features are definitively seeping into mainstream programming languages, that means somebody who learns a functional language can use these features better. (**edit:** People less familiar with functional programming and how to preserve referential transparency often think that functional programming is **not suited to program models of the outer world, such as simulations**, or systems which are often modeled by OOP approaches. It seems to turn out that in the domain of modeling / simulation, the functional approach seems to require serious re-thinking on how changing state is handled and what is represented in a program. However there are good examples and explanations how this can be done, see for example [this essay on state and identiy](https://clojure.org/about/state), or this [example on how to model and simulate  a rocket](https://aphyr.com/posts/312-clojure-from-the-ground-up-modeling). )

2. There seems to be consensus that functional approaches make it easier to reason about behavior of code but using them has some learning curve. The learning curve seems steeper when you go to static languages and to strict referential transparency even within each function.

3. Conciseness: Functional code apparently tends to be more dense which has both advantages and disadvantages. Generally, a higher density seems to reduce significantly the cognitive load for experienced programmers, while it can make it more difficult for unexperienced programmers to understand the code. 



4. Concurrency. It seems that FP has advantages for concurrent code, especially if performance is I/O bound. It is, however, not the only possible approach, and certainly no silver bullet as silver bullets don't exist outside of fairy tales.

5. One area I want to draw a bit of attention to is that, to me, functional languages seem to be more source-code centric and tend to have less layers of abstraction than typical object-oriented code - in my experience, sometimes surprisingly less. (Personally, I think the push for OOP in the nineties came also from the activities to lock programmers and users into platforms which rely on very heavy native GUI libraries. OOP seems to map relatively well to graphical user interfaces and given the commercial incentive it is probably not by chance that entire operating systems have been named according to graphical user interfaces. That incentive to platform vendors, however does not mean that thick layers of libraries with many levels of heavy abstractions are the best approach to efficiently writing programs. One could certainly argue that this is not good for performance either).

6. Determinism: Functional languages seem to be less deterministic and less suited for constrained real-time environments. They appear to be especially well-suited for data processing on a higher level, which may include web applications.

7. Somebody gave an example that FP language might increase the risk for certain types of bugs: https://www.reddit.com/r/compsci/comments/6pnq7e/what_are_potential_disadvantages_of_functional/dksa6hf/ - I'd be highly interested to learn more about that!

8. Performance: This is frequently seen as the biggest disadvantage. It is argued that functional languages are less efficient because they do not map as good to the underlying machine. I think this has three aspects: Functions, values, and memory. 

    Regarding functions, I think it is absolutely possible to represent CPU register operations as functions (usually with multiple input, and multiple output), and compile down to them, and many implementations of functional languages do (SBCL, Chez Scheme, Pixie, Racket). On the other hand, Clojure is in the same range as Java which is today for some benchmarks about a factor two slower than C. 

    Regarding values: Functional languages prefer values over mutable objects. Values with 32 or 64 bits of data can be represented as registers and modern CPUs have plenty of them - certainly more than an average programmer can juggle in his head. Modern CPUs also support 128-bit values which are less well supported by today's platforms and compilers, but this is a technical detail. So this comes down to compiler issues, and compilers are steadily becoming better. It seems to me that functional languages apart from Rust are *not yet* recommendable for highly performance-critical code, but this might change in the future.

    The third issue related to performance is memory, and this is more complex. Functional languages often use garbage collection (GC), and this has of course a cost. Garbage collection or reference counting has advantages and is used in most newer imperative languages as well. Garbage collection can be heavily optimized, as the hotspot JVM and Go's escape analysis show. And GC is not mandatory for a functional approach as the example of Rust shows. My take is that memory / GC performance depends a lot on the runtime environment. I also think that what is useful for code which needs high performance is probably a layered approach perhaps with low-level imperative implementations of computing-intensive functions, and ""pure"" or side-effect free high-level functions and application code. Such would, for example, be supported by a combination of Racket code calling into Rust code.

    Also, this comments gives positive examples on FP performance: https://www.reddit.com/r/compsci/comments/6pnq7e/what_are_potential_disadvantages_of_functional/dks9i0c/

    As an addition to the performance discussion, this page shows pixie, a language forked from Clojure, to compile a loop down to 6 CPU instructions: https://github.com/pixie-lang/pixie . Also interesting: the benchmarks in http://benchmarksgame.alioth.debian.org/ .

**Edit3:** 

* To clear up some potential misconception, I **do** think that functional approaches can have a performance disadvantage (depending on the domain, level of application, and not counting Rust). I do relate that largely to memory management more heavily using GC (which might be wrong - I am only aware of a very small piece of the whole picture). What I am interested in is **when do performance differences matter?** Do we need to write everything in assembly? And of course, are there possibly cases where performance is better?

**Edit4:** A few more points some of which were mentioned at /r/cpp :

* There is the idea that functional languages are more attractive / better matching the mind of people which are more mathematically inclined, because they are more focused on abstractions and expressions. This might or might not be correlated to use of functional languages in data science and data analysis.
* Some people think functional approaches can be used well in languages like C++11 and some think they are a poor match. I guess what would be most helpful here would be illustrative examples (personally, I would not even dream to claim that I understand ""Modern C++"" well enough to make any definite statement about such issues.)
* there are quite different opinions on how well functional languages match database access. Some argue that accesses are stateful and functional languages/approaches can't match them, some say that SQL statements are themselves like expressions (I am wondering whether this is true for LINQ). **edit:** People which are familiar with functional languages tend to reject the idea that functional approaches or functional lanugages cannot handle database access easily.
* As somebody mentioned, Leslie Lamport noted that functional languages don't make the difficulties of distributed systems go away. (I would be curious how libraries like Akka make distributed computation more manageable and what the relation to functional programming is). (**edit:** talking distributed systems, I think I should mention [Kyle Kingsburys Jepsen project](https://aphyr.com/tags/Jepsen) which uses Clojure for testing of consistency and correctenss issues in distributed databases)
* It is harder to estimate performance of complex functional constructs - sometimes, much harder. Writing efficient functional code seems to require some background knowledge, and also some knowledge in which places it's not that good an idea to use that approach.
* (Mentioned in /r/cpp :) Some people experience it as more difficult to debug functional code, especially because it is harder to use a debugger. They also seem to experience that code aggregates itself in more and more complex chunks which are hard to examine and understand separately. What I observe is that developers using dynamic functional languages tend to use more unit tests and a REPL - similar to Python.
* The opinions on a performance disadvantage in functional code vary very widely and depend likely on several crucial things. This could be due to unclear documentation, wrong expectations, or exaggerated praise on what functional languages can do well. Some people report performance disadvantages of up to a factor of 1000, but it might be that the corresponding code does not match best practices and recommendations around performance (e.g. they are using immutable data structures in local functions which are updated in hot loops, when performance recommendations strongly suggest to use mutable arrays; or they use parallelization and multiple threads to execute small tasks in parallel when the documentation says only sizable tasks should be parallelized that way). In other words, in some functional languages there exist recommendations *against* using such approaches in specific scenarios, and these recommendations should probably be observed.
",2017-07-26 12:35:18
6ds9nl,NSA Says New Encryption Standards Needed to Resist Quantum Computing,N/A,2017-05-28 05:38:23
nrux67,"Undecidability of Learnability. ""[T]here is no known general-purpose procedure for rigorously evaluating whether newly proposed [machine learning] models indeed successfully learn from data. We show that such a procedure cannot exist."" [abstract + link to PDF, 28pp]",N/A,2021-06-04 02:55:11
jk17d1,"Andrew Ng's new talk on ""Bridging AI's Proof-of-Concept to Production Gap"" shares key challenges facing AI deployments and possible solutions, covering small data, algorithms' generalizability & robustness, and change management.",N/A,2020-10-29 01:44:36
gt1xrn,[R] OpenAI Unveils 175 Billion Parameter GPT-3 Language Model,"When it comes to large language models, it turns out that even 1.5 billion parameters is not large enough. While that was the size of the GPT-2 transformer-based language model that OpenAI released to much fanfare last year, today the San Francisco-based AI company outdid itself, announcing the upgraded GPT-3 with a whopping 175 billion parameters.

GPT-3 adopts and scales up the GPT-2 model architecture — including modified initialization, pre-normalization, and reversible tokenization — and shows strong performance on many NLP tasks and benchmarks in zero-shot, one-shot, and few-shot settings.

Here is a quick read: [OpenAI Unveils 175 Billion Parameter GPT-3 Language Model](https://medium.com/@Synced/openai-unveils-175-billion-parameter-gpt-3-language-model-3d3f453124cd)

The paper *Language Models are Few-Shot Learners* is on [arXiv](https://arxiv.org/pdf/2005.14165.pdf), and more details are available on the project [GitHub](https://github.com/openai/gpt-3).",2020-05-29 21:42:17
6kqbmv,"What are the best materials to learn Machine Learning, Neural networks and deep learning?","Hello, folks. 
I would like to ask those who are many steps ahead of me and know the topics I stated in the question quite well. 

With which materials in the web you could recommend me to start? I would really appreciate your opinions! Thanks a lot in advance! ",2017-07-01 23:57:28
239uqh,"People with a degree in Computer Science, what do you do now?","I'm studying computer science, and I want to know what my options are after college. Please specify what degree(s) you have, your job now, and the tasks/ fields of computer science involved in it. Any information is helpful! ",2014-04-17 15:05:15
flauzx,A Brief History of Quantum Computers,N/A,2020-03-19 14:25:47
fczcdv,"Is there an algorithm that can take 10 crappy cell-phone videos of a concert, and produce a higher-quality audio track?","This sounds like it should be possible. If a neural network can separate audio from vocals, it also seems like you could pull out the signal from the combination of the phones and null out the noise, or something???

Not sure how this works from an information theory standpoint but curious what people can chime in with.",2020-03-03 18:51:26
ek0joc,Explaining how fighting games use delay-based and rollback netcode,N/A,2020-01-04 18:44:27
4hrk9h,The 8000th Busy Beaver number eludes ZF set theory,N/A,2016-05-03 23:46:18
2gg7c9,[meta] r/compsci has a relevance issue,"I like good technical subreddits with an interesting signal/noise ratio. I have been more and more frustrated with the state of r/compsci as a subreddit. Let me quote the description of the subreddit again:

> Welcome Computer Science researchers, students, and enthusiasts. The aim of this subreddit is to share interesting papers, blog posts, and questions about topics such as algorithms, formal languages, automata, information theory, cryptography, machine learning, computational complexity, programming language theory, etc...
>
> If you are new to Computer Science please read our FAQ before posting. Your question might have already been answered!
>
> Do not post questions such as ""should I study computer science?"", ""how do I get an internship?"", ""what sort of job can I get after school?"", etc... There have been too many of these threads; they bore the regulars and scare away experts. If you have a question like this, please consider posting on cscareerquestions or askcomputerscience. 

Does anyone believe that this description still corresponds to how this subreddit is used? I just did a quick measurement: of the 23 items I counted on my webpages, 9 could pass as relevant to this description (being very lenient), and 14 are irrelevant (mostly help about university courses on programming, or career advice). This means that **a strict majority of r/compsci content is out of topic**.

I think the disconnect between the description and the reality is a problem. Please, r/compsci users, could we discuss it and fix it?

I see basically two families of solutions:

1. make r/compsci closer to its description by being thougher on out-of-topic posts (for example, I noticed that ""self"" posts are almost always out of topic, we could remove the ability to post ""self"" posts)

2. admit that r/compsci is what people see in the name, rather than what the description says; change the description to be closer to reality, and possibly create another subreddit that corresponds to compsci's description. Any advice on the name this should have?

Am I the only one that is disturbed by this disconnect? What do you expect of r/compsci?

I think the solution (2) is the one that is most likely to succeed in practice. (1) looks like an unending spiral of policing, negativity and frustration.",2014-09-15 11:15:28
1umy0f,Peter Norvig solves XKCD 1313 by viewing it as a Set-Cover problem,N/A,2014-01-07 17:42:37
16ov26,Invited to talk to a 3rd grade,"Hello /r/compsci

My wife is a 3rd grade teacher and I have a computer science degree... this day was inevitable.  She asked me to speak to her classroom.

Looking for some help with ideas of things to talk about.

This is what I have floating around my head so far....

Basically, I want to tell them that computers are dumb machines but very good at following directions.  Computer scientists compose those directions in the form of programs which end users interact with.
When the users interact with the program by moving a mouse, clicking a button, pressing the keyboard or touchscreen, shaking or tilting their phone.... someone with a degree like mine wrote the instructions behind it that make your computer do what it does.

Then as an example of a programming task I was thinking about introducing them to the Bubble Sort algorithm.
Obviously I'd make the algorithms / recipes analogy so the word algorithm doesn't throw them off.
I'd also explain the many reasons why you'd want things sorted in a computer... for obvious reasons, and for parts of bigger problems.
Surely they could understand finding song they want to play from a sorted list, or knowing who has the highest score, etc.
I would start by explaining the algorithm in English (possibly side by side with pseudocode or Python).
Then I would act it out with pieces of cardboard...re-arranging them on the blackboard.

Perhaps afterwards I'll have 10 kids stand in line facing the class each holding up a number.
I could then have another kid act as the CPU telling the other kids what to do.
I'm not sure about them acting it out... I'll have to ask the wife if she thinks they'd be able to handle it.

I'd finish it off showing them the youtube video of the hungarian folk dancers performing Bubble Sort.

Do you guys think this is a good idea?
Any suggestions or comments are welcome.

Thanks,
~Eric",2013-01-16 16:19:21
dq6c0b,Careful when rounding: The Deadly Consequences of Rounding Errors,N/A,2019-11-01 16:09:41
77rxlo,How does this kind of stuff make it all the way to print?,N/A,2017-10-21 06:44:37
4z645h,"Did Facebook just invent an anniversary? I haven't found noticeable references to the ""Internaut Day"" before today",N/A,2016-08-23 12:03:51
26xlwu,Pulley Logic Gates,N/A,2014-05-31 04:05:07
1kmezu,I hate the Pumping Lemma,N/A,2013-08-18 20:11:32
g479ok,What is Object Oriented programming actually used for?,"I understand what OOP is, and how it functions, but I have been coding for about a year now and I still have never experienced a moment where I felt like I had any reason to create an object or class. I don't understand what anyone actually uses object oriented programming for.

&#x200B;

When I make a website, I create the database first (usually MySQL) move data to and from the page using PHP and then display the finished HTML client side, and sometimes have some JavaScript functions that will execute when someone clicks a button, or I want to move some text around from one place to another, but I have never needed to use JavaScript's object-oriented features or even come close and at this point I can't think of a situation I could find myself where I ever will. It really bothers me that I learned object oriented programming in college and have never used it, can someone explain what it is actually used for?",2020-04-19 12:59:22
efwvpv,A visual introduction to machine learning,N/A,2019-12-26 15:45:13
1100el,The $5000 Compression Challenge,N/A,2012-10-05 16:58:55
gdfrm,How to insult a computer scientist,N/A,2011-03-28 21:34:34
dbwcao,What Does ‘Broken’ Sound Like? First-Ever Audio Dataset of Malfunctioning Industrial Machines,N/A,2019-10-01 17:02:06
zkuhxn,Proofs about programs - an interactive tutorial I wrote,N/A,2022-12-13 12:26:38
g1oq6e,IBM Data Science and AI programs free for 30 days until 30th of June,N/A,2020-04-15 09:30:40
3cjlzx,"Continually updated Data Science Python Notebooks: Machine learning (scikit-learn, Kaggle), big data processing (Spark, Hadoop MapReduce, HDFS, AWS), statistical inference (scipy), Python data stack (pandas, NumPy, matplotlib), core python language essentials, and various command lines.","Hi Everyone,

I'd like to share a collection of continually updated IPython notebooks that I've prepared/maintain or reference/credit to other authors.  I frequently reference this set of notebooks while working with data in Python.

Topics include:

* Big data processing with Spark, Hadoop MapReduce, HDFS, Amazon Web Services
* Machine learning with scikit-learn, Kaggle
* Statistical inference with Scipy and the Python data stack
* Python data stack with pandas, NumPy, matplotlib
* Python language essentials geared towards data processing
* Business analyses (ie churn modeling)
* Various command lines

https://github.com/donnemartin/data-science-ipython-notebooks

-Donne

---

P.S. If you're interested in interactive, test-driven coding challenges focusing on algorithms and data structure questions found in coding interviews, check out my other repository of Python notebooks:

https://github.com/donnemartin/interactive-coding-challenges",2015-07-08 12:36:33
fvboab,"Machine Learning: How I made an AI that learns to play Tetris using Convolutional Neural Network (article, video, live demo)",N/A,2020-04-05 10:21:18
acbv6h,"How Space and Time Could Be a Quantum Error-Correcting Code: ""The same codes needed to thwart errors in quantum computers may also give the fabric of space-time its intrinsic robustness""",N/A,2019-01-03 23:45:23
8e8kaz,"Where can I learn good programming conventions and write more ""clean"" code?","I didn't major in CS in college, but I took courses in AI and Machine Learning. I learned data structure and algorithms on my own since there are tons of resources on those, but I still feel my code is not as ""clean"" as I'd like.

What can I do?

thanks",2018-04-23 03:33:27
1wnc09,"In a watershed moment for cryptography, computer scientists have proposed a solution to a fundamental problem called “program obfuscation.”",N/A,2014-01-31 15:03:49
1hl61k,Douglas Engelbart has died,N/A,2013-07-03 19:50:20
knvyzu,[R] Japanese Manga Translation Via Multimodal Context-Aware Framework,"A new machine translation method from Japanese start-up Mantra Inc., Yahoo Japan and the University of Tokyo enables global manga fans to enjoy immediate translations of their favourite Japanese comics. The researchers say this is the first comprehensive system for fully automated manga translation from the original Japanese into English or Chinese.

Here is a quick read: [Japanese Manga Translation Via Multimodal Context-Aware Framework](https://syncedreview.com/2020/12/31/japanese-manga-translation-via-multimodal-context-aware-framework/)

The paper *Towards Fully Automated Manga Translation* is on [arXiv](https://arxiv.org/pdf/2012.14271.pdf).",2020-12-31 19:08:01
6r4bxm,Chinese team breaks record for largest virtual universe,N/A,2017-08-02 13:57:34
5eo1h3,"There's recently been a scandal where it was revealed that reddit admins have edited users' comments. Is there any cryptographic method that can store your comments on reddit servers, but prevent editing?","Not all that familiar with crypto, but it seems like something may exist. Kind of like how Wikileaks would put out hashes for future documents, which would show us, upon the document's release, that no tampering had occurred. 

Such a system for reddit would need to be able to store the data, and allow comments to be deleted, but prevent a comment's content from being edited. Does this exist in the field of cryptography? 

EDIT: I'm not describing something for users to do as a personal ""add-on"" for reddit, I'm talking about a change the admins would make so they can show us the code and say ""Sorry we fucked up, but now, look! It's literally impossible for us to edit your comments! Problem solved!"". Is this possible?",2016-11-24 14:44:59
gprp0,Is there a list of the canonical introductory textbooks covering the major branches of computer science?,"For instance, if somebody asks for the best introductory reference for learning about algorithms and their analysis, most people would point them to CLRS.  Similarly, is wanting to learn about Compiler Theory, then something like the Dragon Book would often be mentioned.  Those searching for an introduction to Computability may be pointed to Sipser, whilst those wanting an introduction to Intractability will be pointed to Papadimitriou.

So, does a list like this exist, and if not, can we construct one?  What are the canonical references for Database Theory, Networks, Distributed Computation, Parallelism, Operating Systems (is this still Tanenbaum?), Machine Learning etc.",2011-04-14 08:31:38
fmr1ds,What practical skills should every computer scientist know?,"It's fairly clear that programmers are not computer scientists. But can every computer scientist work as a programmer?  


For example, a lot of my friends are programmers in industry. None of them have a CS degree, but are all pretty competent at their jobs and have a lot of knowledge about different languages, programming paradigms, data structures, some design, etc etc. They seem to have a vast knowledge of software development.  


Now, I am a CS graduate student coming from a math background. I can code pretty well in a couple languages. I can prove when an algorithm is correct and analyze its running time. I can implement algorithms I read in research papers and write most ML algorithms from scratch efficiently. But I've never made a web-app. Any kind of app. I know nothing about developing a piece of software from the ground up. I can implement the necessary algorithms, but I don't necessarily know how to fit them together to make a product.  


This is largely a function of my background. I did math before, only started coding because of statistics and machine learning, and went to graduate school to focus on that. But I am noticing that many of my peers are more ""Well-rounded"" than me in their technical skills. Many are excellent programmers and software developers, but are comparatively weaker on the mathematics (where I flourish).   


So: When someone graduates with an MS in CS, what is the bare minimum of ""real life"" skills do they need to know? What is the optimal intersection of CS skills and programmer skills?",2020-03-22 01:08:50
5dcnvv,Coding classes to become mandatory in Queensland (Aus) schools,N/A,2016-11-16 23:57:48
12gr7i,50 Places You Can Learn to Code (for Free) Online - Online College Courses,N/A,2012-11-01 16:55:29
wfwp5c,AI-generated text is not yet at the stage of being a reliable co-author for your writing projects. But it can be a great source of inspiration and get you started on a new topic. It can be as simple as supplying the title to a language model like GPT-3.,N/A,2022-08-04 09:28:09
c7eaf1,"""Despite its ubiquity in deep learning, Tensor is broken. It forces bad habits such as exposing private dimensions, broadcasting based on absolute position, and keeping type information in documentation. This post presents a proof-of-concept of an alternative approach, named tensors""",N/A,2019-06-30 13:58:48
626awt,"Harvard Dives Into Data Science – Harvard aims to build a significant data-science institute to support a rapidly growing field that University leaders say is clearly ""a new discipline."" There will soon be 3 new Master's Degree programs. (Also see the article titled ""Why 'Big Data' Is a Big Deal"")",N/A,2017-03-29 12:26:56
117xfsp,MINIX is an awesome way to learn a wide range of CS concepts,N/A,2023-02-21 07:22:29
hgs83k,How can I identify O(log(n)) and O(n!) algorithmic complexity?,"1, n, n² are easily distinguishable but what about log(n) and n! I personally can't find them.


Can someone with a proper knowledge maybe explain better than a CS book please?",2020-06-27 11:50:41
dwkgqa,Neural Networks explained with paint (Art of the Problem),N/A,2019-11-15 02:55:52
as1ltu,Huge New NSFW Dataset for Content Filtering,N/A,2019-02-18 20:24:42
ajho4a,The Hard Part of Computer Science? Getting Into Class,N/A,2019-01-24 21:46:25
q9u8y,The basics of encryption when two web browsers are communicating (awesome explanation),N/A,2012-02-28 16:38:24
9h8t0k,"I heard a professor say ""A computer can simulate itself, but that simulation must always run slower than the computer."" but what does that mean? Is this a law?",N/A,2018-09-19 20:34:48
7mi6ov,What are the most important/fundamental concepts in Computer Science?,"Currently a self-learning coder who would like some information as to foundational concepts that all aspiring computer scientists/CS majors should be aware of.

Thank you!",2017-12-27 22:08:33
7g4e6w,Tips for a CS student into AI,"I am CS student that is about to finish college, i wanna get into AI but for my own. What are some books/tips to get into it?",2017-11-28 14:12:03
7dhm6h,Magic: the Gathering is Turing Complete,N/A,2017-11-17 02:24:22
1e23yv,Anger at Academic Dishonesty,"I'm not sure where to go, as many of my classmates don't seem to give a shit. I'm in the computer security field, and, while there seems to be some good research (see: CMU), there also seems to be mountains and mountains of fraudulent garbage. A bit of background, I'm in a course right now focusing on securing social media (privacy, etc.) and the professor is extremely dishonest. She has has attached her name to many papers without knowing what they were about. So of course she doesn't know anything about the actual course materials and has turned it into an impromptu seminar course.

So I'm sitting here reading papers to review for her exam (that will somehow cover a couple dozen of them) and getting angrier with every paper I read.

The acceptance rate for a lot of these conferences is 15-25% and yet all I'm seeing is complete garbage. Examples:

[Faking results (via their ""no community"" data exception)](http://www.researchgate.net/publication/221273566_Local_Community_Identification_in_Social_Networks/file/d912f507db68a6d76d.pdf)

[Non-readable nonsense (just read the abstract if you can't get the whole thing)](http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=5992613&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D5992613)

[Complete garbage (uses 14/15 citations in a paragraph or so, evaluation consists of ""trust us we made it"")](http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=5562745&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D5562745)

There has been 1 paper out of about 15 or so that is even remotely acceptable. 

Is this a bubble? Are we going to see another [AI Winter](http://en.wikipedia.org/wiki/Ai_winter) with this kind of research? What can we do about academic frauds and grant money guzzlers? It seems like most of them are just mediocre mathematicians who are restating graph theory problems as OSN research and collecting the easy security grant money.

I'm enraged that the professor of this course is not only riding coattails through academia but also *the highest paid professor at my school*, and so I thought I would ask you all what I should do. Because at this point I feel dirty and want to get out. It's like an academic crisis of faith. I'd love to know if anyone else has experience or advice dealing with possible academic dishonesty at the highest political level at your university.",2013-05-10 08:07:58
j5gdgq,"A Fun Way of Solving Sudoku, And an Easy Way of Understanding Simulated Annealing","I  recently did a project where I solved sudoku using Simulated Annealing.  Simulated Annealing is a cost minimization algorithm that does so by making random moves and using probability.

Here is the video where I go over the solution if you'd like to take a look at it: [https://youtu.be/FyyVbuLZav8](https://youtu.be/FyyVbuLZav8)

Here is the code if you want to skip the video and go straight to it. It is written in python:  [https://github.com/challengingLuck/youtube/blob/master/sudoku/sudoku.py](https://github.com/challengingLuck/youtube/blob/master/sudoku/sudoku.py)

Let me know what you think!",2020-10-05 09:31:58
i5z26r,"New Vulkan FFT library - VkFFT (open-source, crossplatform, faster than cuFFT)","Hello, I would like to share my take on Fast Fourier Transform library for Vulkan. Due to the low level nature of Vulkan, I was able to match Nvidia's cuFFT speeds and in many cases outperform it, while making VkFFT crossplatform - it works on Nvidia, AMD and Intel GPUs. It also has support for many useful features, such as R2C/C2R transforms, convolutions and native zero padding, which opens up possibilities for Vulkan-based scientific applications (I will make a post on an example case of magnetism simulation software later).

github repository: [https://github.com/DTolm/VkFFT](https://github.com/DTolm/VkFFT)  


Some of the features, that can give an insight of how VkFFT works and why it is extremely fast:  
 

1. Each multidimensional FFT is decomposed into the set of 1D FFTs. This is a common approach to the problem. Each 1D sequence from the set is then separately uploaded to shared memory and FFT is performed there fully, hence the current 4096 dimension limit (4096xFP32 complex = 32KB, which is a common shared memory size). This is the reason why VkFFT only needs one read/write to the on-chip memory per axis to do FFT. It also allows to perform FFT in-place.
2. All memory accesses are non-strided. This is a very important part, as GPU can upload 32 nearest floats at once. For this, to perform FFT in strided directions (y or z), we have to transpose the data, which takes time roughly equal to one read + one write. As there is only power of two sizes, the transposition after some permutations on the sequence elements can be done in-place with no performance loss.
3. If sequence has a langth of <=256, we don't have to transpose the matrix. The non-strided access can be acheved by grouping 16 nearby complex numbers or performing 16 FFTs at once. This is the reason why small FFTs are so fast in VkFFT. However, this optimization messes up with the memory layout (see picture on the main page) but if you plan on doing convolutions, output data will return to the way it was before.
4. Convolutions. They are embedded in the last axis FFT, which reduces total memory read/writes by 1.
5. As the register file is usually bigger than shared memory (256KB) I have an implementation that relies on it for FFT, using shared memory as a communication buffer. This allows to do 8K and 16K sequences in one go, which is planned for a future update.
6. To summarize, most of the time is taken by data transfers from graphics card memory to the on-chip memory, and not by the FFT computation itself (I think it is close to 80% of time). This is why it is so advantageous to have explicit memory control provided by Vulkan API. For 256x256x256 FFT there are only 3 reads and 3 writes, which is an absolute possible minimum right now. The convolution for this system will only take 5 reads/writes (+kernel upload).  


Thank you for the read! Feedback is welcome!",2020-08-08 13:24:07
bkw7nm,Algorithms are learning to maximize profits for online retailers by colluding to set prices above where they would otherwise be in a competitive market.,N/A,2019-05-05 10:18:38
4810fv,"This video explains well about GameBoy in relation to assembly, very educational!",N/A,2016-02-28 08:55:18
l4tlu7,Secure voting systems," Hi All,

Given all the controversy that happened this last election, I'm wondering what the CS community honestly thinks of the current state of voting systems. Most of articles I've read, and my own understanding of the concerns, say that the current systems are not really secure, have known flaws and that in general, no one has come up with or even theorized a secure system that does not compromise anonymity.

So, real talk ... ethically, how can we allow these systems to continue to be used when we know they can be compromised? Also, if anyone is aware of theoretically how a secure system should be architected, I'm interested.

While I ""believe"" that most of the current systems are doing their best to behave ethically ... I feel that until a provably safe and verifiable system exists, perhaps for the public good we should abandon the concept of electronic voting to re-establish public trust in our voting process. Thoughts?

(relevant xkcd for fun: [https://xkcd.com/2030/](https://xkcd.com/2030/) )",2021-01-25 18:09:57
ij69xm,What is the point of inverting a binary tree?,"It might be obvious but for someone like me who primarily does web development and just general programming, I cannot see the point of inverting one.",2020-08-30 03:45:22
8zi3gf,"How a Kalman Filter works, in pictures",N/A,2018-07-17 04:27:13
66npy6,Raw Linux Threads via System Calls,N/A,2017-04-21 07:20:33
3vk53d,What are the most exciting recent developments in Computer Science?,N/A,2015-12-05 17:25:32
2ph7i9,Computer Science resources broken down by undergrad course,"I have been wanting to learn web design for a while now, so I decided to build a website and teach myself.  The site houses computer science related resources and breaks them down according to the undergraduate course they apply to. The site can be found here:

[csundergradresources.com](http://csundergradresources.com/)

I took all of the courses from my university's undergraduate curriculum, but I changed the names a little bit to make them more general.  All the resources on there so far are ones that I collected while I was an undergraduate (many, many of them from this and other CS/Programming related subreddits), but the list is far from complete.  Some of the topics don't have resources associated with them yet because I didn't take that course and don't have any.  If anyone has a resource that they would like to see added, there is a ""Suggest a resource"" link at the top of the page, or you could send them to me here on reddit.

Hopefully this will serve as a good resource for people learning computer science, or people needing to brush up on some concepts. This is my first website so I would love any feedback on it, and I would really love any other resources you guys have. I know the design is a little plain, but I was going for functionality first. I am going to be learning more about web design and trying to update it and make it prettier in the future. Anyway, enjoy! And thank you for helping me get through my undergrad years!
",2014-12-16 16:00:31
s3sqik,"The Year in Math and Computer Science: Mathematicians and computer scientists answered major questions in topology, set theory and even physics, even as computers continued to grow more capable.",N/A,2022-01-14 13:45:33
r97igl,How is a bit saved in disk? What physics happen so that the 0 or 1 is stored?,N/A,2021-12-05 04:29:33
noo07x,"Is it theoretically possible to create minecraft, in minecraft?",N/A,2021-05-31 00:07:35
jaaeki,What Makes Conway's Game of Life Turing Complete? A Short Documentary To Celebrate The 50th Anniversary Of Its Publication on Scientific American,N/A,2020-10-13 10:01:19
d1tlib,Computing Fibonacci Numbers In O(log n) using matrices and eigenvalues,N/A,2019-09-09 16:57:31
bbc5k1,‘Snip’ Converts Math Screenshots Into LaTeX,N/A,2019-04-09 19:25:05
i5cnp9,Meet Silq- The First Intuitive High-Level Language for Quantum Computers,N/A,2020-08-07 12:11:14
bmn680,Alan Turing Institute Releases ML Framework Written in Julia,N/A,2019-05-09 18:15:16
i13jtv,Book recommendation,Which academic books (that provide foundation) every computer science student should read regardless of their area of specialization?,2020-07-31 07:50:58
983thm,What are some non-programming books that have made you a better software engineer?,N/A,2018-08-17 16:41:31
5m030t,Graph Isomorphism not solvable in quasipolynomial time after all,N/A,2017-01-04 16:33:14
4tltgs,"Code Is Never “Perfect”, Code Is Only Ever “Good Enough”",N/A,2016-07-19 15:51:11
m6enk,Timsort,N/A,2011-11-09 19:07:15
ldtxy5,Connected Papers partners with arXiv: a visual tool to find and explore academic papers,"Hi everyone!  
We launched [Connected Papers](https://www.connectedpapers.com/) 7 months ago, with the goal to help researchers visually find and explore academic papers.

**Input:** a paper of your liking.  
**Output:** a full interactive graph of similar papers to explore.

For example, here is the here is the [graph for EfficientNet](https://www.connectedpapers.com/main/4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9/EfficientNet-Rethinking-Model-Scaling-for-Convolutional-Neural-Networks/graph):

https://preview.redd.it/1pze1jylttf61.png?width=1920&format=png&auto=webp&s=e692e92277afc76a5b185ce0a7d88c6091218b80

Since launch we've been positively overwhelmed with feedback from the scientific community and half a million researchers using the tool.

**Today is a big milestone for us - we have partnered with** [**arXiv.org**](https://arxiv.org/) **and from now on every paper page in arXiv will link to a corresponding Connected Papers graph.**

It looks like this:

https://preview.redd.it/masi2yigttf61.png?width=1250&format=png&auto=webp&s=49eff7c66132c7b99aaff272737e7b2a43f9a1ac

And works like this:

https://i.redd.it/rws9t3ahttf61.gif

In addition, we've lately integrated with the awesome team at [Papers with Code](https://paperswithcode.com/) and whenever a paper has a code implementation, it will be presented straight in the paper links in the graph:

[The icon links to the coreesponding Papers with Code page ](https://preview.redd.it/ejn03dvpttf61.png?width=401&format=png&auto=webp&s=b596aeb67c61f529afcb73d1327307bc82a6804a)

With the new additions, we hope Connected Papers will be even more helpful and accessible to Computer Science researchers and we invite you to [try us out](https://www.connectedpapers.com/)!

Welcoming questions and comments!",2021-02-06 09:32:16
h93djd,"If transistors can’t get smaller, then coders have to get smarter",N/A,2020-06-14 22:36:36
gz37bd,Is Anyone Here Interested in a Godel Escher Bach Group Read?,"Hi all,

Since lockdown started, I've used the opportunity to tackle a few books burning some space on my bookshelf, and GEB is one that I haven't quite gotten around to yet. I know there are some accompanying lectures from MIT OCW, etc., but I can't help but feel like this would be best served by having some companions along the way. 

Is anyone else interested in opening this strange loop with me this summer?

EDIT: Well awesome, seems like there's some interest!

I've gone ahead and created a [discord server](https://discord.gg/Ujvdnf) that I invite everyone to join. I'm not quite sure how to get the ball rolling, but I'm sure we'll figure it out. Feel free to invite people who you think might be interested!

I'm also going to x-post this to /r/geb. 

Cheers!",2020-06-08 17:02:33
cvn5xa,Rope: Data Structure used by text editors like Sublime to handle large strings,N/A,2019-08-26 12:05:45
91sa0w,University of Pennsylvania’s School of Engineering Launches Online Master’s in Computer Science,N/A,2018-07-25 14:24:38
iu0lus,How does the Internet work on the most granular level ?,"Ok...so this question must have been asked before. But I am still very confused to understand the very basics of it. I would love to read various resources that you guys can point me to.

Some areas which I need to understand on a deeper level (lots of free time right now ):

1. How does it work on the bit level.
2. How the data gets transferred all over the globe.
3. Is there any entity actually controlling the Internet.
4. Can it fail ? (As an entity or a concept)",2020-09-16 17:49:58
5gzyf8,How terrible code gets written by perfectly sane people,N/A,2016-12-07 13:48:06
hfyl1c,"CS people, how much do you actually know about computers?","Aside from knowing how to use the programs that you use on a regular basis, how much do you actually know about your computers? Do you consider yourselves knowledgeable of the internal workings of your machines?",2020-06-26 01:36:43
56w8hy,"arxiv paper claiming ""NP = PSPACE"". Any immediate red flags for experts?",N/A,2016-10-11 03:49:06
10yxud0,Mathematicians Complete Quest to Build ‘Spherical Cubes’ | Quanta Magazine | s it possible to fill space “cubically” with shapes that act like spheres? A proof at the intersection of geometry and theoretical computer science says yes.,N/A,2023-02-10 17:36:39
ohu0jk,The Duties of John von Neumann’s Assistant in the 1930s,N/A,2021-07-11 00:09:13
955rue,"Software engineers, what would you say are the most essential CS course?"," I'm entering my 3rd year in CS and I'm interested in becoming a software engineer. For the first time after 2 years in university, I finally have a variety of CS courses to choose from. And I want to use that opportunity to take classes that would help me with my goal of becoming a software eng. ",2018-08-06 22:13:19
8zkedr,Must Read Books for a Computer Scientist,I have found some lists of great computer science books [**HERE**](http://www.doradolist.com/stanford.html) and [**HERE**](http://www.doradolist.com/mit-computerscience.html). Do you know of similar websites that have list of great computer science books? Also what are top 3 CS books ever?,2018-07-17 11:42:30
73lou3,"Vladimir Voevodsky, Fields Medalist, Dies at 51",N/A,2017-10-01 13:42:47
gk5ea5,Was anyone scared or felt under prepared compared to others when starting their comp sci major?,Hello! I am currently a freshman going onto sophomore year after summer as a computer science major and I can’t help myself but feel like everyone knows way more than I do. I studied a year of python and a year of java so I can understand the basics and do simple things but as i’ve talked to other people it seems like they are coding experts and know way more than I do. Did anyone else feel the same way when going into their major? How do you feel now about it? Thank you in advance :)),2020-05-15 08:39:11
a7dca3,Easy-To-Read Summary of Important AI Research Papers of 2018,N/A,2018-12-18 17:48:50
t3cug4,Lambda Calculus in 400 bytes,N/A,2022-02-28 10:47:35
ewq4q4,"What is an interesting, lesser known OS for me to study?","Admittedly, this is for an assignment so I may be breaking the rules, but the assignment is to write a 5-10 page paper over an OS. However, I think it does not as I am not asking for any help; just an interesting list for me to consider.

 I don't want to do something boring and typical so I wanted to know about niche, abnormal, or just plain fascinating OS.",2020-01-31 15:36:01
d1ih3y,Philosophy of Computer Science [pdf],N/A,2019-09-08 23:08:20
bxzbyb,Google Announces TensorFlow 2.0 Beta,N/A,2019-06-07 20:20:08
o73dt,"TIL that the ACM supports the AAP and, as a result, is supporting SOPA .",N/A,2012-01-07 20:54:05
d6jtan,What is it like to be a researcher in theoretical Computer Science?,"Hey! I am a final year undergrad in CS. I am having a difficult time thinking about which area to choose for research in CS. I have research experience in the field of Systems and AI. Research in these fields is more on the experimentation and evaluation side. 

I wanted to know how the research in Theoretical CS (like Quantum Computing, Algorithms, etc.) differs from this ""applied"" sort of research. Do people spend all their day looking at the board thinking how the math would work out in some problem? Please share your experience.",2019-09-19 20:28:23
8zstku,Assembly Language for Beginners [pdf],N/A,2018-07-18 05:53:19
5ssoa1,What Programming Languages Are Used Most on Weekends?,N/A,2017-02-08 13:31:35
50q019,Should every CS major take operating systems?,"Hi /r/compsci

I'm in my final semester of college, and i'm considering dropping autonomous robotics for operating systems.  The idea of robots seems very cool, but I don't plan on working in that area.  I've taken a concurrency course that overlaps the OS material (forking processes, threads, mutex/locks, etc), which was my hesitation with taking it.  I am interested in learning how exactly scheduling and system calls work though, among other things.

Is OS really useful?  I'm likely already going to drop robotics for it, just wanted some opinions.

Edit: wow at all the replies. I think the consensus is I probably should take it. I will mention that I've had a systems course so that at a high level I do know some OS concepts. I know about caching and the memory hierarchy, page faults, virtual memory, how to walk through assembly, how interrupts and system calls work, context switching, forking processes and threads. Im probably forgetting some.

Taking OS though I believe I'll learn how to actually implement those things I listed above. I think a lot of the material will not necessarily be new, but is valuable to hear again.",2016-09-01 22:40:03
g3rpxj,What are useful CS certifications to have on a resume for a student?,"Hi all,

I’m currently at a CC looking to transfer into the UC system. I haven’t done my first internship yet, and am waiting till the summer before I transfer which would be a year from this summer. I'll be applying this fall. What are some CS certifications that could really boost my resume as to attract internship offers? 

Much appreciated!",2020-04-18 17:51:00
fsgl04,Books to learn Data Structures and Algorithms from?,"Hello everyone,

I am an undergrad pursuing my B.E. in CS, I'm in my third year and given that I don't code efficiently, I'd like to get much better at data structures and algorithms, so I've decided to start from scratch.

And is it okay if I code in python and the book is in some other language?

Thanks!",2020-03-31 16:58:42
ch9jwq,Google BlazeFace Performs Submillisecond Neural Face Detection on Mobile GPUs,N/A,2019-07-24 15:22:08
c8kue8,India's First CPUs Are Ready for App Development,N/A,2019-07-03 06:51:11
bo2b44,Best Artificial Intelligence Books in 2019,N/A,2019-05-13 11:33:07
apnfnk,A couple of Edsger Dijkstra quotes i thought this sub might appreciate,">In the long run I expect computing science to transcend its parent disciplines, mathematics and logic, by effectively realizing a significant part of Leibniz's Dream of providing symbolic calculation as an alternative to human reasoning. (Please note the difference between 'mimicking' and 'providing an alternative to': alternatives are allowed to be better.)  
>  
>Needless to say, this vision of what computing science is about is not universally applauded. On the contrary, it has met widespread —and sometimes even violent— opposition from all sorts of directions. I mention as examples  
>  
>(0) the mathematical guild, which would rather continue to believe that the Dream of Leibniz \[i.e. ""providing symbolic calculation as an alternative to human reasoning""\] is an unrealistic illusion  
>  
>(1) the business community, which, having been sold to the idea that computers would make life easier, is mentally unprepared to accept that they only solve the easier problems at the price of creating much harder ones  
>  
>(2) the subculture of the compulsive programmer, whose ethics prescribe that one silly idea and a month of frantic coding should suffice to make him a life-long millionaire  
>  
>(3) computer engineering, which would rather continue to act as if it is all only a matter of higher bit rates and more flops per second  
>  
>(4) the military, who are now totally absorbed in the business of using computers to mutate billion-dollar budgets into the illusion of automatic safety  
>  
>(5) all soft sciences for which computing now acts as some sort of interdisciplinary haven  
>  
>(6) the educational business that feels that, if it has to teach formal mathematics to CS students, it may as well close its schools.

\-- ""[On the cruelty of really teaching computer science](https://www.cs.utexas.edu/users/EWD/transcriptions/EWD10xx/EWD1036.html)"" (1988)

>The required techniques of effective reasoning are pretty formal, but as long as programming is done by people that don't master them, the software crisis will remain with us and will be considered an incurable disease. And you know what incurable diseases do: they invite the quacks and charlatans in, who in this case take the form of Software Engineering gurus.""

\-- ""[Answers to questions from students of Software Engineering](http://www.cs.utexas.edu/users/EWD/transcriptions/EWD13xx/EWD1305.html)"" (2000)",2019-02-12 01:00:24
67b56f,"Harry Huskey, Pioneering Computer Scientist, Is Dead at 101",N/A,2017-04-24 18:58:55
1uwqxq,"New entropy coding: faster than Huffman, compression rate like arithmetic",N/A,2014-01-10 20:54:31
jkmz2,Remember the free AI class that Stanford's offering in the fall? They've expanded to Machine Learning and Databases as well!,N/A,2011-08-16 17:13:57
wybzlv,The Toxic Culture of Rejection in Computer Science,N/A,2022-08-26 15:23:04
20pu6d,Leslie Lamport awarded Turing Award,N/A,2014-03-18 13:52:37
1c88xz,"So cute! Evolving Soft Robots with Multiple Materials (muscle, bone, etc.)",N/A,2013-04-12 20:23:23
14lsmic,"The Curse of Recursion: Training on Generated Data Makes Models Forget. ""What will happen to GPT-{n} once LLMs contribute much of the language found online? We find that use of model-generated content in training causes irreversible defects in the resulting models"" [abstract + link to PDF, 18pp]",N/A,2023-06-29 02:30:12
pmrrej,Computer Science related book that may interest a non computer science student?,"I would like to gift a book to non-CS student but I want it to be something interesting and fun to read and not full of technical jargon. 

The person in question gave me a book related to their field of study but it was light and not very technical, so it’s a nice gift even if I’m not in the field. 

I was thinking of getting them “Dreaming In Code: Ada Byron Lovelace” but I’m scared based on the reviews that it’s not fit for a college student’s reading level. 

Any suggestions? Or does a book like that not really exist and I should look for something else?

Edit: Thank you for all the suggestions! I naturally cannot gift them all but the ones I can’t gift may go on my own reading list or further book recommendations.",2021-09-12 12:25:21
e8odml,"Failure Modes in Machine Learning: ""as these systems become more pervasive, the need to understand how they fail, whether by the hand of an adversary or due to the inherent design of a system, will only become more pressing""",N/A,2019-12-10 09:16:45
cbg28o,"Goodbye floats, hello posits?",N/A,2019-07-10 12:24:06
9tfmiq,Identifiable Images of Bystanders Extracted from Corneal Reflections,N/A,2018-11-02 01:22:25
8mjbvm,Want to learn about Quantum Computing?,"Hello!

If you're reading this, you're most likely interested in learning about quantum computing; however, you might not be sure how to get started because of a lack of people to work with, lack of direction, and maybe even a lack of a bit of background knowledge.

I've created a subreddit, /r/MikeAndIke, which will enable people with the desire to learn about quantum computing to come together and learn, generally directed (though not entirely restricted) by the book Quantum Computation and Quantum Information by Michael A. Nielsen and Isaac L. Chuang (hence the name, Mike & Ike).

I'm very new to reddit in general, as you can see by my karma scores, and so I'm extremely new to running a subreddit. But, I hope that together we can make this a great learning experience for each other! There is also a discord chat going, which may possibly be more helpful than my subreddit will end up being, but I think only time will tell that for us.

Let me know if you have any questions or any other comments, feel free to spread the word to people you think may be interested, and I'll continue to look forward to your arrival (and also continue to make my subreddit look less ugly).

-Foobanana (the real one)

Edit: Yes, I know that this isn't exactly computer science; I just wanted to try to reach out to anyone possible who may be interested, just because quantum computing is so very interdisciplinary.",2018-05-27 17:37:57
5xet27,GitLab’s Secret to Managing Employees in 160 Locations: Write Everything Down,N/A,2017-03-04 02:55:11
3b7otq,What are the best youtube lectures on computer science?,N/A,2015-06-26 17:11:36
pakdp,"Udacity, new way of learning computer science.",N/A,2012-02-04 12:14:24
kb3sa,What every computer science major should know,N/A,2011-09-10 13:22:51
yiuvmo,What are some compsci topics and algorithms that more people should know about?,"Mine is Timsort, a fast sorting algo used by default in Python",2022-11-01 01:22:06
txm96b,Why are Turing machines more famous than other universal computers like cellular automata?,"There are other simple theoretical systems, such as cellular automata, that
can implement arbitrary computations. And there are also other conceptions
entirely, lambda calculus and general recursive functions, that are
equivalent to thinking in terms of Turing machines.

So why is it that out of all of these, Turing machines became the most
commonly used concept to talk about computability? Is the specific idea of a writing 1s and 0s to a tape very convenient in proofs?",2022-04-06 13:31:26
s75pgk,What books do you recommend to a person who is interested in theoretical computer science?,"I would like to know more about theoretical part of computers. So are there any resources, books would be greatly benefited cause I am more like a Book guy, but other sources like YouTube and etc, would even be great. 

Thx...",2022-01-18 19:32:38
nmj5c2,Cambridge Quantum Develops Algorithm to Accelerate Monte Carlo Integration on Quantum Computers,N/A,2021-05-27 22:16:38
mzyy33,Uncomputable Numbers,N/A,2021-04-27 21:20:50
cx4zil,AI Creates Fashion Models With Custom Outfits and Poses,N/A,2019-08-29 18:41:23
96o9pm,RStudio Chief Scientist Hadley Wickham recommends five books for data scientists learning computer science,N/A,2018-08-12 10:21:45
41fg9e,Why is security missing from computer science curriculums?,"We integrate testing into our computer science curriculums, why is security not integrated as well. Most students end up going into a job where data security is a factor in some way. The most we ever talked about security in my curriculum was just that you shouldn't use gets() in c because of a vulnerability, but that vulnerability was never really even explained. Shouldn't there be a larger focus on at least informing students of the OWASP top 10. 

I understand that cryptography is usually a course but that's such a small sect of data security. What would you focus on for creating a curriculum that included some focus in creating secure software?",2016-01-17 21:10:01
18234a,The Base64 encoder has a fixed point.,N/A,2013-02-07 09:39:40
13zo4y,10 Free online resources for learning Algorithms and Data Structures,N/A,2012-11-29 12:36:38
ued3jz,Can someone explain Knuth's hunch that P = NP?,"I was left with the impression that most computer scientists believed that it is very, very unlikely that P = NP. Whenever P vs NP is mentioned in popular writings, it's always presented like ""Well, technically there's no proof that P ≠ NP, but common sense tells us that they aren't the same. Or else the universe actually behaves radically differently than we currently think!""

But then there's a section of the [wikipedia article](https://en.wikipedia.org/wiki/P_versus_NP_problem#P_=_NP) that mention's Donald Knuth's different take on this issue:

&#x200B;

>\[...\] if you imagine a number M that's finite but incredibly large—like  say the number 10↑↑↑↑3 discussed in my paper on ""coping with  finiteness""—then there's a humongous number of possible algorithms that  do n\^M bitwise or addition or shift operations on n given  bits, and it's really hard to believe that all of those algorithms fail. My main point, however, is that I don't believe that the equality P = NP  will turn out to be helpful even if it is proved, because such a proof will almost surely be nonconstructive.

&#x200B;

I get the idea that an algorithm would technically be polynomial time if it ran in n\^M operations, but what is the basis for believing that there ought to be at least one that succeeds? It sounds like he's arguing based on probabilities. Is that even valid? And can someone ELI5 the last sentence of this paragraph? Donald Knuth is a smart guy, so I'm not surprised that I'm struggling to see from his point of view on this.",2022-04-29 03:43:26
fqrci3,Intro To General Purpose Hash Functions,N/A,2020-03-28 20:02:29
65sdjw,How to write a simple operating system in assembly language,N/A,2017-04-17 00:18:39
27q72d,An incomplete list of classic papers every Software Architect should read,N/A,2014-06-09 20:33:50
uxm1k,"Qbit kept ""alive"" for 3 minutes - a huge step-up from mere seconds. ",N/A,2012-06-12 07:23:20
uq6o5,Crypto breakthrough shows Flame was designed by world-class scientists,N/A,2012-06-07 18:44:38
10maqac,"What is a zip tree, and how does it work?",N/A,2023-01-27 03:19:32
odhvtw,"If P=NP, what would mean for non-researchers and academic folks? How would change, if any at all, the way we write softwares?",EDIT: Thanks everybody for your answers!,2021-07-04 10:35:43
lf0dnm,Subway Station Hazard Detection,N/A,2021-02-08 01:05:20
bq3fby,Art of the Problem explores the key insight behind Deep Learning,N/A,2019-05-18 12:21:57
6bg7hx,Ten 2D Cellular Automata Posters I made,N/A,2017-05-16 08:13:43
5865ea,Microsoft researchers claim to reach human parity in conversational speech recognition,N/A,2016-10-18 20:28:32
4o4ylb,Entertaining CS YouTube channels?,Are there any CS YouTube channels out there that are entertaining but still a good learning resource like Vsauce for example?,2016-06-15 01:48:28
2o73rv,Are you a robot? Introducing “No CAPTCHA reCAPTCHA”,N/A,2014-12-03 22:09:34
vm1thg,Is anyone interested in taking MIT's Intro to Algorithms course?,You can reply here,2022-06-27 18:06:57
gk9x6g,"Collatz conjecture news: Recently, I managed to verify all numbers below 2^68. The results confirm that the highest number occurring in the Collatz sequence starting at n grows to ca. n^2.",N/A,2020-05-15 14:17:22
fenaqi,"I just released PypTeX, a preprocessor for writing math/CS papers with Python and LaTeX, and I would love to get your feedback.",N/A,2020-03-07 00:40:31
68zwrh,How to program quantum games: Is this something you'd be interested in?,"I had an idea for a thing I'd like to do. But I thought I'd ask you guys whether anyone would actually like me to do it.

We are finally entering an era where programmers can start thinking about how to program quantum devices: Small scale quantum devices are starting to become available (like the IBM Quantum Experience), and APIs and SDKs for quantum computing are being released.

The trouble is, known quantum algorithms are usually quite large and precise. So there's not much scope for playing around with simple little ""Hello World"" like programs. To solve this, I am thinking of developing games for quantum computers. These games would be simple ones, like Battleships or Hunt the Wumpus, but they would use quantum effects to implement the game mechanics. 

The games wouldn't really be made for playing. Instead they would be aimed at giving an accessible introduction to programming a quantum device. Each game would be accompanied by a line-by-line tutorial to explain how it's made. As well as a release of the source code, of course.

By doing this I'd hope to give any interested programmers the info they need to start playing around with quantum programming, seeing what's possible and how things are done, and hopefully making their own quantum games.

Of course there's no game you can make on a small scale quantum device that a normal computer couldn't do. But I would hope that such tutorials could prepare programmers to really profit from the larger scale devices that will come in the next few years.

By the way, I am a scientist that does research in the field of quantum computation. So I do have some idea of what I'm talking about. If you want to see some simple quantum games that I made as tests, check out:

https://medium.com/@decodoku/introducing-the-worlds-first-game-for-a-quantum-computer-50640e3c22e4

https://medium.com/@decodoku/quantum-battleships-the-first-multiplayer-game-for-a-quantum-computer-e4d600ccb3f3

I give simple explanations of what is going on in the games, but these are by no means the tutorials I would hope to make in future.",2017-05-03 12:05:10
1q4ruq,"What are the ""must-read"" computer science books?","I mean basic computer books. So:
Introduction to Algorithms: CRL

I am not sure about putting Discrete Math or Probability books in here.

Some concepts of basic CS is best understood using some language:
Java: Bruce Eckel book + any other secondary book + Java site should suffice.
C: Donald knuth book

Any other ideas? Then we can put them on the side bar hopefully. Not just any book but more definitive ones, rather than subjective details about a book that helped in particular stage of learning CS or programming.

Edit: Nice list! I should have mentioned this is more beginner to advanced level rather than kid stuff. Honestly, I was expecting some core, basic CS books + maybe main books/sites from the major languages in the backend (since frontend is relatively easy to pickup/learn just like the DB or OS layer in enterprise arena)",2013-11-07 22:04:58
nwtu0x,Is database knowledge actually one of THE core competencies for people working with data in any way?,"I have seen a lot of comments of the form:

""You only need the absolute basics of SQL. You will learn all the things along your job""

And there was an professor who said something like this:

""To have a profound knowledge about (scalable) databases with their architecture/design is very high on the list of core competencies every cs major should have. It will not only help you working with databases but basically in every other field.""",2021-06-10 17:50:52
72xnlx,AI boom has seen countless companies scrambling to jump on the bandwagon — even if their products have little to do with AI.,N/A,2017-09-28 03:51:08
3sni2a,"TIL about Gene Amdahl (1922-2015) lead designer of IBM’s mainframe computers in the 1950s, which became the central nervous system for businesses throughout the world. If an IBM salesman saw a coffee cup with the Amdahl Logo at a customers site, they cut one million dollars of their price offer. RIP",N/A,2015-11-13 11:45:51
2mg43g,The Man Who Made the UK Say “I’m Sorry For What We Did To Turing.”,N/A,2014-11-16 06:18:58
toe8f,Non-textbooks worth reading that will make you a better computer scientist,"I'm entering a PhD program in the fall (scientific computing/bioinformatics) and am taking the summer off to travel. As such, I feel like I'm going to have a lot of free time for reading. I'm looking for suggestions for books that I should read that will make me a better computer scientist. I'm not interested in textbooks, since I'll be reading enough of those in the Fall and would prefer topics that I likely wouldn't get exposed to in a class. Also, everything I plan on reading I'm going to have to carry with me for the whole summer, so lighter and smaller is better. 

So far I've compiled the following list based off of previous similar discussions:

* The Soul of A New Machine - Tracy Kidder
* COMPLEXITY: THE EMERGING SCIENCE AT THE EDGE OF ORDER AND CHAOS - M. Mitchell Waldrop
* The Society of Mind - Marvin Minsky
* Gödel, Escher, Bach: An Eternal Golden Braid - Douglas R. Hofstadter
* Computer Power and Human Reason - Joseph Weizenbaum

What else is there anything else that I definitely should add?


EDIT: Thank you all for your suggestions. I'm definitely going to have a lot of good choices this summer.",2012-05-15 16:30:08
bqtlki,"How to make algorithms fair when you don't know what they're doing: using ""counterfactual explanations"" to reveal how algorithms come to their decisions – without breaking into their black box.",N/A,2019-05-20 10:04:01
6q0czt,"Just finished reading CODE by Charles Petzold, my first real introduction to how computers work. I'm hooked. Suggestions for what to read next?",N/A,2017-07-28 00:46:05
228hvj,Using logic gates to build a 4 bit adder... entirely out of dominoes!,N/A,2014-04-05 00:15:34
vm3cc,Google constructs massive neural network and feeds it YouTube images. Network teaches itself to recognize cats.,N/A,2012-06-26 04:27:40
pvodbc,"I made a program to randomly generate 2d turing machines, and found one that counts in binary!",[https://www.youtube.com/watch?v=f95ohEemxwI&ab\_channel=omputerfan](https://www.youtube.com/watch?v=f95ohEemxwI&ab_channel=omputerfan),2021-09-26 06:29:09
d0m7h3,"Charity Engine supercomputer solves the answer to life, the universe and everything","**“SUM-OF-THREE-CUBES FOR 42 FINALLY SOLVED - USING REAL-LIFE PLANETARY COMPUTER”**

Hot on the heels of the groundbreaking Sum-Of-Three-Cubes solution for the number 33i, a team led by Andrew Booker of Bristol University and Andrew Sutherland of MIT has solved the final piece of the famous 65-year old maths puzzle with an answer for the most elusive number of all; 42.

The original problem, set in 1954 at Cambridge University, looked for *Solutions of the Diophantine Equation x\^3+y\^3+z\^3=k,* with k being all the numbers from 1 to 100. Beyond the easily found small solutions, the problem soon became intractable as the more interesting answers – if indeed they existed – could not possibly be calculated, so vast were the numbers required. But slowly, over many years, each value of k was eventually solved for (or proved unsolvable), thanks to sophisticated techniques and modern computers - except the last two, the most difficult of all; 33 and 42.

Fast forward to 2019; Booker’s mathematical ingenuity plus weeks on a University supercomputer finally found an answer for 33, meaning that the last number outstanding in this decades-old conundrum, the toughest nut to crack, was that firm favourite of Douglas Adams fans everywhere.

However, solving 42 was another level of complexity. Booker turned to MIT math professor Andrew Sutherland, a world record breaker with massively parallel computationsii, and - as if by further cosmic coincidence – secured the services of a planetary computing platform reminiscent of “Deep Thought”, the giant machine which gives the answer 42 in *Hitchhiker’s Guide to the Galaxy*.

Booker and Sutherland’s solution for 42 would be found by using Charity Engine; a ‘worldwidecomputer’ that harnesses idle, unused computing power from over 500,000 home PCs to create a crowd-sourced, super-green platform made entirely from otherwise wasted capacity. The answer, which took over a million hours of calculating to prove, is as follows;

**X = -80538738812075974 Y = 80435758145817515 Z = 12602123297335631**

And with these almost infinitely improbable numbers, the famous *Solutions of the Diophantine Equation (1954)* may finally be laid to rest for EVERY value of k from 1 to 100 - even 42!

[*https://www.quantamagazine.org/sum-of-three-cubes-problem-solved-for-stubborn-number-33-20190326/*](https://www.quantamagazine.org/sum-of-three-cubes-problem-solved-for-stubborn-number-33-20190326/)

[https://www.charityengine.com](https://www.charityengine.com)",2019-09-06 20:35:41
6tutu5,"The traveling salesperson algorithm routing 260,000 grocery deliveries a week",N/A,2017-08-15 15:28:08
3tun6n,The Implementation of Functional Programming Languages (out of print book offered online for free by the author),N/A,2015-11-22 20:19:45
2m8g4q,Google Lifts the Turing Award Into Nobel Territory,N/A,2014-11-14 00:19:49
ve31r6,Continuous Unix commit history from 1970 until today,N/A,2022-06-17 03:03:19
86jj7n,The Declining Value of a CS Master's Degree,N/A,2018-03-23 10:12:41
7s63d6,Are there CS related podcast to listen to?,N/A,2018-01-22 14:30:40
766olv,"The Department of Energy seeks to make the U.S. the clear winner in supercomputing by creating a computer capable of exaFLOPS-level calculation by 2020. However, say, computer scientists, it takes more than speed to make real discoveries.",N/A,2017-10-13 18:19:29
5bv3y5,"What is the ""secret handshake"" of computer science?",What's something you can do or say to instantly prove to someone that you're are also a computer scientist? ,2016-11-08 18:50:50
4x9txw,The Joy of Cryptography (textbook),"Hi there. I've been writing a free undergraduate textbook in cryptography. It is still very much in draft form, but I have used it successfully as the primary reference in my courses. So I invite you to [**check it out**](http://web.engr.oregonstate.edu/~rosulekm/crypto/) and give any feedback you care to. But please keep in mind there is a lot left to add and I know it.

You'll find that the text has a theoretical flavor, being heavily grounded in formal security definitions & proofs, understanding sound ways of combining cryptographic primitives. My ultimate dream is to demystify this whole business of security proofs. To that end, the text uses a paradigm (known in the research literature as ""game-based"") for stating security definitions and giving security proofs that I think is much more accessible than other resources I've seen.",2016-08-11 19:31:29
4jq8hb,PDF collection,N/A,2016-05-17 10:27:51
2sqahh,Pixar's research papers on graphics and simulation.,N/A,2015-01-17 13:01:48
15vkit,Super Resolution From a Single Image,N/A,2013-01-03 06:54:27
myawz2,Is it always better to build your own sorting algorithms?,"In school, our professors always pushed sorting algorithms in the curriculum, but some languages, such as Python, have their own built-in sorting function. Are there any advantages to building your own sorting algorithms? Or is it more of a teaching tool.",2021-04-25 15:46:32
5nlznl,Computer Science ∩ Mathematics (Type Theory) - by Computerphile,N/A,2017-01-12 21:01:37
258r9l,15 Sorting Algorithms in 6 Minutes,N/A,2014-05-10 23:34:33
urju9d,Finding Binary & Decimal Palindromes,N/A,2022-05-17 10:59:00
mbcebe,Does studying CS in the US revolve a lot around programming?,"I've been curious for a while now, as when I see Americans discuss CS education, it very often revolves around programming - and overall I get the impression that a lot of classes depend heavily on programming, and that many people find this to be ""hard part""/ what holds them back. But this can very well just be confirmation bias.

I'm curious because for me (I'm a graduate student in Denmark) programming is of course a part of a lot of what I do, but mainly as a tool, and you can be a poor programmer, and still do very well in almost every class.",2021-03-23 11:15:20
la8yuk,Awesome blog I read on Scaling Software. Its a little old but its brilliant: Scaling with common sense - Zerodha Tech Blog,N/A,2021-02-01 17:39:17
ivvx3w,Awesome non-popular source for systems design & backends,"[Hussein Nasser](https://www.youtube.com/c/HusseinNasser-software-engineering/) on YouTube, brilliant channel",2020-09-19 16:40:01
hl8vwe,How do you do independent research as a CS undergrad? How do you start? What should you know? Are there any prerequisites?,"Hi iam a computer science sophomore from a state sponsored college in India. Iam interested in a career in academia, mainly research. But no productive research happens here in India, and there is no suitable environment for it. I wish to do independent research for the sake of it and to pursue a PhD in any European or US universities as the people there seems to care about it. Any bit of information you have , tips, experiences, all are welcome.",2020-07-04 19:14:36
f1suow,Top 10 Machine Learning Methods Explained in Layman Terms,N/A,2020-02-10 16:37:51
cpdgts,The Nature of Machine learning (Evolution vs. Reinforcement vs. Abstract),N/A,2019-08-12 14:56:39
6ust0j,What's next in programming language design?,N/A,2017-08-20 00:50:20
4qlpy3,"While Shannon was a contemporary of people such as Alan Turing, and also worked on cryptography during World War II, he hasn’t been nearly as well known. But that started to change this year when groups like Bell Labs, where he worked from 1941 to 1958, held events honoring his accomplishments.",N/A,2016-06-30 13:42:15
25i0xk,SIGGRAPH 2014 : Technical Papers Preview Trailer,N/A,2014-05-14 01:21:36
1rbkwa,Data Structures/Algorithms in major open source projects,N/A,2013-11-24 01:14:08
kkzn3r,"The lexical grammars of Python and Haskell are not regular. What does that mean, and why aren’t they?",N/A,2020-12-27 07:36:16
bpckhp,The Y combinator or how to implement recursion in a language that doesn't support it.,N/A,2019-05-16 13:29:50
86ui24,I would like to share 500 Data Structure and Algorithms problems,N/A,2018-03-24 17:26:35
5ulkl6,The Mathematics of Quantum Computers | Infinite Series (x-post r/physics) - [12:35],N/A,2017-02-17 11:08:16
4udkpj,/r/compsci hits 100K subscribers,N/A,2016-07-24 15:33:56
4h55t8,In honor of Claude Shannon's 100th birthday. Claude Shannon Demonstrates Machine Learning at AT&T Bell Labs,N/A,2016-04-30 16:46:45
464uxb,A.I. Playing NES games does surprisingly well and terribly bad.,"http://youtu.be/xOCurBYI_gY

This guy created an algorithm for an A.I. to play different NES games. The program did really well playing games like Super Mario Brothers and ""Hudson's Adventure Island"". But it did really bad playing Tetris and Pac-Man. What really caught my eye, was that when the program was just about to lose a Tetris game, it paused. Forever. The only way to not lose, would be to not play the game. Which if you think about it, it's true, and kind of creepy. I thought it was hard to believe that the program did that. Incredible experiment that I wanted to share.",2016-02-16 22:01:48
23okst,IamA 4th year PhD student in Computer Science. AMA,"Hi all,

20-something days ago [1], /u/wibbly-wobbly posed the question of whether a grad student AMA would be welcome in the community. The answer seemed to be a resounding yes, but no one followed up and started the AMA.

So I'll do it. I'm a 4th year (almost 5th O_o) grad student in CS. My specialty is Artificial Intelligence, in particular, Natural Language Processing. I'm an American citizen at a high ranking American university, so I cannot answer any immigration questions. (Important detail to many here, I'm sure; hopefully we'll have plenty non-Americans to help with answer as well).

AMA. Hopefully other grad students (and maybe former grad students) can also chime in replies.

[1] /r/compsci/comments/21vpz4/rmath_is_having_a_graduate_student_panel_would/",2014-04-22 14:53:24
1efufy,What every programmer should know about memory,N/A,2013-05-16 08:00:53
11olst,Happy Ada Lovelace Day - Celebrating important women in CS,N/A,2012-10-18 10:35:34
jg1s5x,"I spoke with some AI Expert friends of mine to discuss their thoughts on the potential for another AI Winter. Included are viewpoints from employees of DeepMind, OpenAI, Google & more. Who has the closest viewpoint to your own?",N/A,2020-10-22 15:29:50
iyxxy4,Limits of Computability,"I have written a little paper:

[Limits of Computability in Lambda Calculus](https://hbr.github.io/Lambda-Calculus/computability/index.html)

It explores the limits of computability avoiding a lot of math but without loss of precision. The lambda calculus presented is not annotated with math symbols. It is presented like a programming language. It addresses programmers who are interested in computer science.

The paper is a follow up on the introductory paper:

[Programming in Lambda Calculus](https://hbr.github.io/Lambda-Calculus/lambda2/lambda.html)",2020-09-24 14:09:24
hr3ku7,"This ""Ship City"" programming challenge seems pretty hard. I can't think of a simple way to do it.",N/A,2020-07-14 15:29:05
hlys6j,Is it recursion if a function calls a function that calls the original function?,Title,2020-07-06 01:53:08
gukmle,My computer science degree doesn't involve the theory of computation,"I was looking at a university for computer science and I saw that theory of computation wasn't listed as a class. Are there other cs universities that do not have the theory of computation as a class?

Edit: Thank you all for your help. I am going to get more information on the university. If it doesn't have it as a subject, I will look for another university. Once again thank you for the help",2020-06-01 13:27:28
gaz8cp,How to emulate hand-drawn shapes / Algorithms behind RoughJS,N/A,2020-04-30 16:43:04
aaxg6x,History of Computer Science Podcast,N/A,2018-12-30 16:53:30
9zawxd,"""Although Bitcoin was intended to be a decentralized digital currency, in practice, mining power is quite concentrated ... [O]ur work further motivates the study of protocols that minimize 'orphaned' blocks, proof-of-stake protocols, and incentive compatible protocols."" [abstract + link to PDF]",N/A,2018-11-22 04:49:38
95y3ka,Step by step introduction to lambda calculus,N/A,2018-08-09 16:43:49
8r1lm9,Want to learn Quantum Computing?,"Hello!

If you're reading this, you're most likely interested in learning about quantum computing; however, you might not be sure how to get started because of a lack of people to work with, lack of direction, and maybe even a lack of a bit of background knowledge.

I've created a subreddit, /r/MikeAndIke, which will enable people with the desire to learn about quantum computing to come together and learn, generally directed (though not entirely restricted) by the book Quantum Computation and Quantum Information by Michael A. Nielsen and Isaac L. Chuang (hence the name, Mike & Ike).

I'm very new to reddit in general, and so I'm extremely new to running a subreddit. But, I hope that together we can make this a great learning experience for each other! Let me know if you have any questions or any other comments, feel free to spread the word to people you think may be interested, and I'll continue to look forward to your arrival! :D

-Foobanana (the real one)

P.S. - I've posted this a couple times, and so I leave it to the moderators to determine whether or not I'm spamming the sub, and to remove my post if they deem this to be the case! My only wish in doing so is to leave no one behind who wishes to learn with us in our community!
",2018-06-14 12:52:53
8q07jm,I wrote about Priority Scheduling concepts used on the Apollo Guidance Computer,N/A,2018-06-10 11:27:03
7xht78,The real-world version of the famous “traveling salesman problem” finally gets a good-enough solution,N/A,2018-02-14 12:59:52
7czo5i,"No, it is not a compiler error. It is never a compiler error.",N/A,2017-11-14 23:09:40
1wqj78,Traveling Salesman Problem Visualization,N/A,2014-02-01 17:11:36
yxl34,"Pascal's Apology, or why computer science is complicated.",N/A,2012-08-28 00:07:34
mfvc7,"Stanford Online offering more classes [NLP, Game theory, Probabilistic Graphical Models]",N/A,2011-11-17 17:40:29
104wzy8,The Biggest Discoveries in Computer Science in 2022,N/A,2023-01-06 15:30:06
rydd0x,What is overfitting? A 2-minute visual guide. [OC],"&#x200B;

https://preview.redd.it/ze8n0vjn0ba81.png?width=2048&format=png&auto=webp&s=3f9c76662f91bf526e93932965a0a21a29f59343

https://preview.redd.it/ryngq6kn0ba81.png?width=2048&format=png&auto=webp&s=487dd856c24df9883a24c19b457c22cd06dd8b29

https://preview.redd.it/e6dt23kn0ba81.png?width=2048&format=png&auto=webp&s=20fe3cf2a3c854cda98013e2361549aca522fbd7

🔵 Overfitting 🔵

🧐 Overfitting is a common phenomenon the machine learning community tries to avoid like the plague. This is because when a model overfits it performs extremely well on the training data that it is provided but performs poorly and fails to generalize on unseen data.

💾 You can imagine overfitting with an analogy. When one assumes that the questions in the exercise session of a lecture are exactly what will be asked in the exam and end up memorizing them. During the exam, they realize that this rote-learning would not be of any help in answering unseen questions.

😮 Overfitting can be avoided in many ways. 5 common ways to do so is by (1) regularization of the model parameters using L1 or L2 norm for example (see previous posts for more details), (2) gathering more training data to let the model cut through the noise, (3) early stopping by monitoring the training and validation error curves, (4) reducing the number of features by selecting better features and (5) by performing data augmentation.

\---------------------------------------------------------------------------------

I have been studying and practicing Machine Learning and Computer Vision for 7+ years. As time has passed I have realized more and more the power of data-driven decision-making. Seeing firsthand what ML is capable of I have personally felt that it can be a great inter-disciplinary tool to automate workflows. I will bring up different topics of ML in the form of short notes which can be of interest to existing practitioners and fresh enthusiasts alike.

The posts will cover topics like statistics, linear algebra, probability, data representation, modeling, computer vision among other things. I want this to be an incremental journey, starting from the basics and building up to more complex ideas.

If you like such content and would like to steer the topics I cover, feel free to suggest topics you would like to know more about in the comments.",2022-01-07 17:53:51
2qofc4,Curated list of awesome university courses for learning CS,N/A,2014-12-29 03:49:24
19337d,"""River"" detection in text",N/A,2013-02-23 17:12:31
znzkp,"CS Professor says ""Learn by copying""",N/A,2012-09-10 19:02:21
ypgog0,Algorithm that runs faster on big input but runs slower on smaller input,"In computer science, we know that there are several algorithms that performs faster on smaller inputs but performs slower on large inputs (O(logn), O(n) and so on)

I have two fairly basic questions:

1. Is there any algorithm which performs poorly on a smaller input but runs faster on a large inputs?

2. How do we measure asymptotic complexity of such algorithm?",2022-11-08 09:20:09
wt3xxq,"Melvyn Bragg and guests (his expert biographer Andrew Hodges, Simon Schaffer and Leslie Ann Goldberg) discuss Alan Turing (1912-1954) whose 1936 paper 'On Computable Numbers' effectively founded computer science. (Links and reading material available).",N/A,2022-08-20 10:33:05
lsabpe,Not being able to do CS unless I'm working on it?,"anyone else feel like they don't know how to code unless:

A) they sit down and starting working/going over code or

B) they are helping someone else with code

wanted to see if this is normal. If someone asked me today at this moment what my code does I wouldn't be able to tell them unless I'm actively working on anything coding related",2021-02-25 16:22:47
gnn6qj,C++ proposal dismisses backward compatibility,N/A,2020-05-21 01:05:00
8jt3sp,"Smarter People Don’t Have Better Passwords, Study Finds",N/A,2018-05-16 07:39:12
74iazm,I just posted a new Art of the Problem video on P vs. NP (Complexity Theory),N/A,2017-10-05 19:25:51
4wn9qz,"Science and IT students struggle to get jobs upon graduation, study finds. Grattan Institute reports only half of those graduating with degrees in science found work within four months, 17% below the average for all graduates. [x-post from r/worldnews]",N/A,2016-08-07 23:13:41
2wzufl,"Proving that Android’s, Java’s and Python’s sorting algorithm is broken (and showing how to fix it)",N/A,2015-02-24 15:15:46
267u74,Millons of lines of code: An very interesting info graphic. (x-post from programming),N/A,2014-05-22 15:48:04
1epk8w,Obfuscating my proprietary code to appear independently-written so as to publish open source? (thought experiment),"*This isn't an ethical question (though ethics are important to think about). This is a technical question to get people thinking about 1) computational stylometry of code, and 2) legal issues in gray areas which will become more important once such obfuscators exist.*

Hypothetical situation: I am a programmer working on proprietary algorithms for a big software company. I love my code so much, I want it to be free and open source, so that the world can benefit from it and so that other hackers may freely develop upon it. But, I am contractually obligated never to share anything I've written for my company. Many programmers are in a position like this. Many programmers also independently discover algorithms similar to proprietary ones, to which they are free to attach GPL licenses. 

I am looking for a way to publish my code without getting in contractual or legal trouble. I wish to obfuscate code such that it raises reasonable doubt that code came from me and not some other hacker working on the same problem. I could re-write it from scratch. OR (my main point here) I could write an algorithm which mutates code, retains the same basic functionality on the outside, and obfuscates any tell-tale signs of my authorship. How could we do that? It needs to appear as if it were written independently from scratch.

There are algorithms for determining (to a degree of confidence) the authorship of pieces of writing using n-gram maximum entropy models. A similar approach could be used to figure out the author of code. If we all have unique styles of coding, it could work decently.  First question: how do we write the best code-authorship algorithms, so we can detect breach of contract? Second question: how do we fool them? Third question: how do you compensate for that fooling? etc

Where are the legal boundaries here? When does my code become so different that I can publish it with a different license? **When am I no longer plagiarizing myself?** Do I even need to obfuscate my authorship? Is it fine so long as it looks like I wrote it from scratch? 

How does one fake a clean room design? How confidently can one test a clean room design for authenticity?

**TLDR; How do we write an algorithm which can mutate code to look like it was written independently from scratch?**

[edit]
*This hypothetical has nothing to do with me personally, I work for a non-profit education platform making javascript games for teaching kids music theory. This isn't an ethical question. We assume the hypothetical programmer has already made up his mind. This is a technical question, which both asks 1) how do you pull it off, and 2) how do you defend against it (know thy enemy)*",2013-05-20 18:44:31
1ealvv,Odd Goldbach conjecture (every odd n > 5 is the sum of 3 primes) proven by H. A. Helfgott [x-post r/math],N/A,2013-05-14 04:01:34
nlt5nf,Richard Feynman’s Advice to a Young Stephen Wolfram (1985),N/A,2021-05-26 22:25:39
nf16en,Python library for simulating finite automata,"Hello everyone, am a computer science student, actually I'm working on a python library for simulating finite automata, on this library implemented DFA and NFA, and also is able to visualize the automata, convert NFA to DFA, and also implemented the product and union of DFA.

Here is my repo: [https://github.com/rohaquinlop/automathon](https://github.com/rohaquinlop/automathon)

and the PyPI page: [https://pypi.org/project/automathon/](https://pypi.org/project/automathon/)

On the documentation you can see my email and my other media where you can contact me if you want, I'm making this library because I think that automata are really fun, and I want to help others when they are starting to learn about them.",2021-05-18 04:31:08
mj0n5x,Ever wondered what a CS degree looks like in Canada?," Hello guys,

I am a recent CS graduate from the University of Alberta, one of the top universities in Canada. I wanted to share with you what a CS degree looks like here, all the way up north, and more specifically show what sort of courses a student interested in the Systems side of things might take. This might be quite insightful to some of you, and I hope that it might help some of you decide on what courses you might want to take in the future.

If you look at my post history, you will I actually posted my video on computer architecture on here and on /r/computerscience a while back, and some of you guys liked it. So, please enjoy the video I made, and feel free to provide some feedback so that I can improve on my future videos :)

Here is the link to the video: [https://youtu.be/WiVujkjU0Ns](https://youtu.be/WiVujkjU0Ns)

\~ArseniyKD.",2021-04-03 03:42:25
x3fpe,Interesting blog post by a tenured computer science professor on why he is leaving academia for Google.,N/A,2012-07-24 21:33:24
exxnx,IAMA - reviewing graduate applications at a Top 5 CS department AMAA.,"Pretty self explanatory, I posted this here instead of /r/IAMA because the /r/compsci group likely cares more about this topic than a general audience.

Update: We've made our decisions for this year. We turned down folks with 4.0 GPAs and first author publications... Its a tough year for prospective students. Good luck to you all.


",2011-01-07 15:36:36
ggr87h,How did you guys overcome difficult Algorithms Class Coding Projects? I am Struggling,"Throughout my computer science career, I have struggled the most with code-heavy projects in algorithms classes. I spend 90% of the time bug hunting. And almost always it consumes way too much time. I always end up submitting the project many days late.

On June 1st I will start my advanced algorithms class. I have already dropped out of the last two semesters due to spending too much time finding and resolving bugs on projects. I am very tired of this roadblock. This is my last course before graduating.

I have a decent grasp of data structures, sorting, and searching algorithms. The projects are in Java and I have a good grasp on OOP and java JDK.

Recently last semester I started to code in small chunks and test in small chunks,  instead of writing hundreds of lines and then weeding out errors in one big leap.

I use [stackoverflow.com](https://stackoverflow.com) whenever I am stuck. 

I also recently discovered eclipse debugger which was oddly never mentioned in any of my courses.

Anyways I would appreciate if anyone who had this problem in the past and overcame can share some of that knowledge with me.",2020-05-10 00:29:35
ejo65o,ELI5: Why is NoSQL more scalable than SQL?,"One of the main advantages I often hear of NoSQL is it's scalability.

Can someone give an ELI5 explanation for why NoSQL is more scalable than SQL? Is it because NoSQL has no schema?",2020-01-03 23:59:12
d952m2,Alibaba’s New AI Chip Can Process Nearly 80K Images Per Second,N/A,2019-09-25 15:43:10
bnbubd,Machine learning algorithms explained,N/A,2019-05-11 13:04:26
76yeo7,Boolr: a digital logic simulator,N/A,2017-10-17 13:07:04
4a95im,RIP Hilary Putnam,N/A,2016-03-13 17:38:05
ug1bgy,what can x86 do while ARM cannot?,"i have seen a lot of praise for ARM, if its so efficient then why don't the pc market shift towards ARM?

why do we still use x86? also why haven't intel and amd moved towards it?",2022-05-01 14:41:54
jclssi,"Weird question but, what are easy to digest topics I can study while sleep deprieved?","Hey so basically I'm studying computer science subjects on my own, and while I practice the basics I was wondering what are some easy to digest topics that I can do while very sleep deprived? Basically I have really bad chronic insomnia that somedays make doing stuff like programming or calculus very difficult and stressful to do while that tired, so was looking to instead of just doing nothing that day to study something that doesn't require a focused mind.

I know it's weird question, but thanks.",2020-10-17 00:45:05
houetl,"I make interesting applications on ML papers, and make short videos about them","Hey guys, shameless self-plug here.

I never really seen any short demonstrative or fun videos around the latest ML papers and other cool AI techs. So I decided to make a YouTube channel focusing on the new/cool ML papers along with easily understandable explanations and display my own fascinating results, aiming to be enjoyable to watch while not being time-consuming to the viewers. 

I hope that I can appeal to a wider audience other than just in the comp sci community,  so I include some anime, gaming, or even just general stuff into my contents, which also aims to be entertaining too.

It would be awesome if you could give any suggestions about my [channel](https://www.youtube.com/c/bycloudAI)

I also have some shitty installation tutorials for some of the ML papers I've made contents on, so more people can easily play around the AI. 

I hope through this I can help to raise awareness of these cool techs and give people that publish free researches more credits and support on their projects.

&#x200B;

oh and I admit I overuse the term ""AI"", but in a way not to confuse the audience that doesn't fully understand what ML, DL, ANN are, I just want to keep it in 1 easily understandable and general term as I want to aim for a more general audience. So even when they actually are interested and dig into this field, my usage of the word AI wouldn't cause too much confusion when they learn about the new terminologies. I would love to hear what you guys think about this.",2020-07-10 18:35:10
ennt4k,"How relevant are groups, rings, and fields to computer science?","At first I thought these were topics relevant only to pure math, but there's one thing that stands out: since linear algebra can operate over any field (e.g. real numbers or complex numbers), and linear algebra is hugely relevant to both theoretical and applied computer science, maybe representing a problem by choosing an appropriate field makes the problem much easier? Does this happen anywhere in computer science? 

And are there any other parts of compsci that rely on algebraic structures?",2020-01-12 14:04:41
cs1jgi,"Experienced programmers and debugging gurus, what are your powerful methods\tools for debugging huge code bases?",N/A,2019-08-18 14:01:57
avqstp,The Philosophy of Computer Science,"Hey guys,

Where do you think that philosophy and compsci converge in the most significant/fundamental way?

What areas of philosophy (metaphysics, ontology, epistemology) do you think are the foundation of compsci? What do you think are the most interesting philosophical questions/problems that it rises?

I'm interested in philosophy but my knowledge is very limited and I want to expand it.

Do you have any recommendations on topics/books/authors?

Thanks in advance.",2019-02-28 12:53:23
8umgoo,Programmer's Health and Well-Being Subreddit,"Hi all!

I created a subreddit /r/programmerhealth to discuss all things well-being with programmers and developers. It's pretty difficult to watch your own health in any field as we get busy, but Computer Scientists don't only face debugging issues; we also have to deal with mental and physical health issues as well. Feel free to join and share any health issues you are having as well as find help too! Thank you all.

**Link:** https://www.reddit.com/r/programmerhealth/


*The subreddit is mainly geared towards developers, programmers, and Computer Science students, but anyone can join and contribute here as well.* 



**Discord Server:** https://discord.gg/uG8aRrt",2018-06-28 19:11:17
8gxtz4,"Hey reddit, what is your favorite cs problem that uses multiple data structures and algorithms to solve it?","Bonus points if you feel like describing it too, or you have a link to a site describing it.
",2018-05-04 08:59:28
84cmph,My friend and I are producing a podcast about computational chemistry! This week we talk to an expert at Harvard University about what quantum computers are and how they work! We'd love to know what you think!,N/A,2018-03-14 11:25:56
416e1a,The QuickSort,N/A,2016-01-16 02:16:34
1c3hyz,"The long term trends for the top 10 programming languages, measured by hits in Google & Wikipedia (and others)",N/A,2013-04-10 23:05:14
12yjk2,vintage u.s. navy mechanical computation porn [video][sfw],N/A,2012-11-10 10:40:04
x5mwsd,"In your opinion, what's the most advanced topic or sub-field in computer science?",N/A,2022-09-04 13:23:57
dez30k,Information Theory: a short introduction,N/A,2019-10-08 12:11:55
den10w,Reduction from 3 SAT to SUBSET SUM. I cannot understand how the entries of bottom right box are decided and how t is decided,N/A,2019-10-07 17:53:40
a8l7xh,An Amoeba-Based Computer Calculated Approximate Solutions to a Very Hard Math Problem,N/A,2018-12-22 14:32:10
8v8zzp,Timsort — the fastest sorting algorithm you’ve never heard of,N/A,2018-07-01 10:12:31
2saf4l,Wolfram|Alpha Can't: examples of queries that Wolfram|Alpha currently fails to answer correctly,N/A,2015-01-13 15:43:25
1ttiqs,Chicago Makes Computer Science a Core Subject,N/A,2013-12-27 18:11:34
1e8ab4,Math ∩ Programming - Primers,N/A,2013-05-13 05:42:26
sa3y32,People who are doing/did a PhD - How did you find your topic?,"Title pretty much says it.

I have a Master's in CompSci and play with the thought of doing a PhD, but have absolutely no idea which topic I want to research or focus on.

Any tips on how to figure that out?",2022-01-22 14:43:20
er05hn,Help me wrap my head around Dynamic Programming,"I’ve been trying to understand Dynamic Programming, but I just can’t seem to “get” it. I feel like the most common Fibonacci example with memoization, while easy to understand, does not really help demonstrate to me the very essence of the technique (at least not entirely). Somehow my brain just won’t absorb it. So far I’ve watched the MIT 6.006 lectures on it, and few more videos I could find on YouTube, and still nothing.

Sometimes all it takes is the right person with a compatible teaching approach to help me understand. Can anyone here help explain and/or point me to resources that could help me understand.

Thanks!",2020-01-19 18:35:16
ebdugk,What are the current trends in Theoretical CS research?,N/A,2019-12-16 11:14:01
cwhj4v,Microsoft: Your Pa$$word doesn't matter,N/A,2019-08-28 07:41:09
xxza5,A New Way To Solve Linear Equations,N/A,2012-08-09 15:46:41
k2nyuj,Understanding Backtracking by solving the N-Queens Problem And Knight's tour,"Recently I have been working on algorithms that I should have really learned in my Algorithms class. For this week and did backtracking, which is one of the fundamental algorithms of problem solving and AI. 

To practice I solved 2 problems. The n-queens and knight's tour.   


Here is the video where I go over the solution if you'd like to take a look at it: [https://youtu.be/CQ3nDMcchdA](https://youtu.be/CQ3nDMcchdA)

Here is the code if you want to skip the video and go straight to it:   
[https://github.com/challengingLuck/youtube/tree/master/backtracking](https://github.com/challengingLuck/youtube/tree/master/backtracking) 

Let me know what you think! All feedback is appreciated!",2020-11-28 13:51:06
ic5miy,Set theory condensed in 100 symbols,N/A,2020-08-18 17:36:28
dzl03w,A Practical Guide to State Machines,N/A,2019-11-21 15:38:08
cn7171,Chinese Video Streaming Giant Introduces Anime Facial ID Dataset,N/A,2019-08-07 15:12:39
aa87ow,Amoeba finds approximate solutions to NP-hard problem in linear time,N/A,2018-12-28 07:33:21
9jbkoq,"Leslie Lamport Thinks Your Code Is Bad: ""Lamport says we should describe our algorithms not with code – real or pseudo – but with mathematics.""",N/A,2018-09-27 10:09:42
5poqu6,How do you take notes in lectures?,"Im a first year Comp Sci student at uni and im sturggling to take notes, The problem is I don't know what to note down (everyone seems to be copying everything but I dont see the point since the lecture and slides are uploaded online). 
Also, any recommendations for note taking software/tools? Is pen and paper better? Thank you",2017-01-23 13:38:47
2cyx5g,What books have you learned the most from?,"The sidebar link to /r/csbooks is for open, free books; what books (free or not) concerning computer science have you benefited the most from personally?",2014-08-08 10:50:10
drybk1,Can anyone help me find some useful books about cryptography and its algorithms?,N/A,2019-11-05 12:15:26
boisl4,Old one-page paper on recursion,"I have heard rumours of a one-page paper ""On recursion"" (or similar title) that only contains a citation to itself. Is anyone aware of such a paper?",2019-05-14 13:15:46
8s7la3,How does Tor really work?,N/A,2018-06-19 09:44:58
6q5nr6,"Chinese scientists create biggest virtual universe with world’s fastest computer, beating European record",N/A,2017-07-28 18:16:20
4ofs75,A Visual Guide to Graph Traversal Algorithms,N/A,2016-06-16 21:28:58
3ncqo8,What's the most difficult concept you've encountered in computer science?,"(I posted this in /r/computerscience a few days ago, but since discovered that /r/compsci is more suitable.)

I'd like to know what concept you've found especially hard to wrap your mind around.

This is a fun question to ask anyone with expertise in a subject you find interesting. I was thinking about it myself and realised there is little that I've learned over the years that is particularly difficult, rather there is just a lot of it. I'm in the mood for a challenge, so please tell me of the most mind-bending concepts you know of in computer science.",2015-10-03 15:59:33
2y31lx,Quantum Computing Explained,N/A,2015-03-06 00:27:40
bdan6,Maggie Sort Algorithm [video],N/A,2010-03-14 18:29:15
911h7,150 Computer science books for free,N/A,2009-07-14 12:11:19
13qcw86,"Maximal Entropy Random Walk (MERW) - often more optimal than naive RW, lots of applications",N/A,2023-05-24 05:53:33
ruxhg6,Best Paper Awards in Computer Science over the past 25 years,N/A,2022-01-03 09:07:18
jp21i9,"""Hardware lottery describes when a research idea wins because it is suited to the available software and hardware and not because the idea is superior to alternative research directions. Examples from early computer science history illustrate how hardware lotteries can delay research progress...""","In a [recent discussion](https://crossminds.ai/video/5fa2f7e126cd723d6a05f0cb/?playlist_id=5f07c51e2de531fe96279ccb), Sara Hooker from Google Brain discussed her [Hardware Lottery paper](https://arxiv.org/abs/2009.06489) and a few other related issues in machine learning research. Here are some interesting parts from the conversation:

* [Elevator pitch on hardware lottery](https://crossminds.ai/video/5fa2f7e126cd723d6a05f0cb/?timecode=885.2759151659393)
* [From GPU to TPU](https://crossminds.ai/video/5fa2f7e126cd723d6a05f0cb/?timecode=1258.4904389141693)
* [What does a model forget as you prune](https://crossminds.ai/video/5fa2f7e126cd723d6a05f0cb/?timecode=2146.279590032425)
* [Cultural divide in ML (Max Welling vs. Rich Sutton)](https://crossminds.ai/video/5fa2f7e126cd723d6a05f0cb/?timecode=2354.5244068264315)
* [Characterizing & mitigating bias in compact models](https://crossminds.ai/video/5fa2f7e126cd723d6a05f0cb/?timecode=4129.490065998093)
* [Are sparse networks more interpretable](https://crossminds.ai/video/5fa2f7e126cd723d6a05f0cb/?timecode=4614.422944131607)",2020-11-06 09:16:09
9fywtc,"Google launches ""What-if"" tool to analyze ML Models without writing any code",N/A,2018-09-15 04:51:32
1tjmd4,High Schools Not Meeting STEM Demand: Only 9 states recognize CompSci as credit for graduation,N/A,2013-12-23 18:21:21
r1ra7u,Resources to learn OS programming in C,"Heyy im a second year college student with OS as one of the courses. I felt pretty okay about the entire subject until very recently where i had a lab exam that went pretty pretty bad.

&#x200B;

So right now, I just dont feel confident at all about the programming part. Everything feels so foreign and complicated. Is there some resource/ website where i can do a lot of c programming and hope to improve myself before stuff like the final exams?  


I would really like problems that go from the introductory level up. Idk if its the panic but i really feel like i dunno anything about OS programming. Maybe an online course or something would work? then again idk which ones are good...  


Help on the matter would be amazing! Thank you",2021-11-25 07:45:01
n8y59i,"Implementation of a LL(1) parser using C++ made to parse a C like language. It has the support of Lexer, Symbol Table, Left Recursion Removal and Left factoring. On successful parsing, a Json output is produced which is visualized with TreantJs,","The repo link : [JuCC](https://github.com/TheSYNcoder/JuCC)

Feel free to check out the repo and make a pull request for further changes.

[The AST can be visualized on localhost:8080.](https://preview.redd.it/20jfvhssq8y61.png?width=1100&format=png&auto=webp&s=faa40b56b29b7d57f38e9179c353b82fcc3b5b69)",2021-05-10 06:58:54
mpl8ja,Cambridge Quantum Computing Appoints Former DeepMind Senior Research Scientist as Head of Artificial Intelligence,N/A,2021-04-12 19:23:37
bk1j56,7 Essential Algorithms that Power the Modern World,N/A,2019-05-02 23:15:04
45gecc,What is your favorite book on the history of Computer Science?,"The history of CS (pre-modern computing) as well as the development of it mathematically, to be more specific.",2016-02-12 19:32:27
2a990e,Prof Andy Tanenbaum is retiring. Everyone is invited to his farewell lecture.,N/A,2014-07-09 17:45:12
24pdun,I wrote a program that attempts to fit minimal Steiner Trees to a set of points. Here are some of the results.,N/A,2014-05-04 17:18:18
1idhap,"Computer Science Professor uses forensic linguistics to analyze ""The Cuckoo’s Calling"" and unmasked the authour as J.K. Rowling who wanted to write under a fake name",N/A,2013-07-15 23:19:15
ovxr1,The soviet computer that calculated partial differential equations with water ,N/A,2012-01-25 11:21:25
ehzox,Today one of my CS professors was getting rid of old textbooks.  I think I made out pretty well.,N/A,2010-12-08 01:08:51
b54og0,The Definitive Guide to Approaching Tough Coding Interview Problems When Blanking Out or Stuck,N/A,2019-03-25 01:56:09
axjz2i,How does TOR really work?,N/A,2019-03-05 11:07:39
aecmgy,"“Those with CS or engineering degrees, compared with those who do not, rate all AI governance challenges as less important”",N/A,2019-01-09 23:09:36
8dqkag,How can I appreciate the “beauty” in computer science?,"I’m doing a computer science/physics joint major. It’s easy for me to like physics because it describes the laws of nature which I intrinsically find interesting and mysterious. I’ve never been into technology but I like some math, science, and philosophy of science. I know computer science is also theoretically deep but so far I’ve just learned about some graph theory, time complexity, algorithms, Chomsky Hierarchy, etc. At first glance these things spiked my interest but they became dryer the more I learnt about them. To me it’s just about organizing information which is extremely useful but not awe inspiring. I’m wondering why I have an affinity for physics, but not for computer science. Anyway, my main goal with computer science is to become computationally literate because I know that will carry over into physics research and industry if I decide to go that route. I know there’s people out there that are seriously interested in computer science and the deeper nature of it, so I’m wondering how they view the discipline. As with most people, it’s a lot more fulfilling when you’re interested in what you’re studying.",2018-04-20 20:04:52
5sgmon,The Quantum Computer FAQ,N/A,2017-02-06 20:18:35
4u2gwo,Writing good code: how to reduce the cognitive load of your code,N/A,2016-07-22 12:17:23
4b8e64,Face2Face: Real-time Face Capture and Reenactment of RGB Videos (CVPR 2016 Oral),N/A,2016-03-20 17:27:28
30mb0g,Maze Algorithms (visual),N/A,2015-03-28 18:06:15
1m5sz3,Demo combines Image Processing and 3D modelling to extract and edit objects in a single photograph!,N/A,2013-09-11 06:34:43
jmpj1,Markets are Efficient if and Only if P = NP,N/A,2011-08-18 13:22:02
zz5bgd,2022 Top AI Papers — A Year of Generative Models,N/A,2022-12-30 16:53:42
61ehmk,Programming Languages Influence Network,N/A,2017-03-25 07:37:00
2mkm64,Modern Microprocessors A 90 Minute Guide - a good overview of modern processor design,N/A,2014-11-17 16:50:35
l8ro1,Up and Down the Ladder of Abstraction,N/A,2011-10-11 21:37:28
jeawy,"A free college level AI class taught by Stanford professors. The course will have Stanford and web-using students competing on the same grounds, listening to the same lectures, and doing the same homework(on which they will be graded); more info on the website.",N/A,2011-08-10 05:33:44
sbp32u,What is the highest level programming language?,"I'm learning the difference between high and low level languages and it seems like more of a spectrum, with binary being on one end and English being on the other.

However, I'm curious if anyone knows of any languages lower level than English but higher than say, Python.",2022-01-24 15:46:18
m5zo26,Would a math undergrad degree prepare you for a graduate program in Computer Science?,"Apologies in advance but I don’t know where else to ask this question.  I am currently in my last year of my first undergrad and I want to take a second undergrad in Computer Science after I finish the first one.  I intend to stay in the same university but I don’t mind switching to a different one.  The issue here is that the university I am currently attending has a highly competitive CS program with limited enrollment, so I have to have a plan B in case I don’t get in.  Would a Math degree be a good substitute/preparation for a future graduate program (masters or PhD) in Computer Science?  I already know I want to focus on AI, if that helps.

For sure I know I could just apply to a different university where it’s easier to get accepted, but I would still like to know if there’s anybody who went the Math route leading to CS and if this path is a viable option.",2021-03-16 03:12:00
h0167g,DeepFaceDrawing system allows users with little training in drawing to produce high-quality face images,N/A,2020-06-10 01:37:15
g9qiqc,Pluralsight Azure courses are free,"Pluralsight has an offer together with Microsoft to offer the Azure courses for free. You can access them  [here](https://www.pluralsight.com/partners/microsoft/azure).

Enjoy.",2020-04-28 16:35:19
edg61v,"If Data is the New Oil, How to Determine Its Value?",N/A,2019-12-20 21:13:42
c0brnz,Google TensorNetwork Library Dramatically Accelerates Machine Learning & Physics Tasks,N/A,2019-06-13 21:36:42
4c2irw,What was your favorite CS class as an undergraduate?,N/A,2016-03-26 19:33:40
31812v,"XKCD inspired passwords: ""How to Memorize a Random 60-Bit String""",N/A,2015-04-02 19:03:14
25n78q,American college students aren’t flocking to computer science,N/A,2014-05-15 18:08:17
vtfahz,The NIST post-quantum crypto algorithm selection has concluded,N/A,2022-07-07 10:17:38
r4od88,Denigma is an AI that explains code in understandable English. Test it for yourself and tell me what you think,N/A,2021-11-29 05:22:23
gktzbk,New integer multiplication algorithm related to Collatz conjecture,N/A,2020-05-16 12:37:25
ey060l,How much have Computer Science Programs changed over the past 20 and 30 years?,"So my dad got his BS in Computer Science from Stanford in 1991, and it got me thinking. How much have Computer Science programs changed over the past few decades? What's different today compared to back than. What things would a Computer Scientist know today that a Computer Scientist not know back then? Same vice versa",2020-02-03 02:54:34
33hgid,40 Key Computer Science Concepts Explained In Layman’s Terms,N/A,2015-04-22 15:36:48
1byszk,What are some clever algorithms that have resulted in O(1) solutions for seemingly complex problems?,N/A,2013-04-09 03:19:24
18nyfq2,The lost compression algorithm,"Hi i am really sorry for my bad English

in 2014 when i was a kid i heard a story about someone went to  Philips company in 90s and he had a crazy algorithm to encrypt the files for really high compress level i can't remember the numbers but i believe it was from 1gb to 1mb something like that anyways the end of the story he died and left  Philips with half of the code.

&#x200B;

now i can't find that story can anybody help i am very interested

thank you",2023-12-21 21:55:02
rr4cy4,"Looking back on what you know now, what concepts took you a surprising amount of effort and time to truly understand?",N/A,2021-12-29 09:39:15
iq1cba,Databases and SQL Cheat Sheet for Interviews,N/A,2020-09-10 11:14:47
gu4iay,Evolving Machine Learning Algorithms From Primitive Mathematical Operations,N/A,2020-05-31 18:48:05
gdttih,Feels like knowing nothing,"I have taken operating system, computer network and database class, but I still feel like knowing absolute nothing about them except for the fact the now I have a bunch of keywords floating in my head (page table, semaphore, functional dependency, routing...you name it). And this makes me feel not capable enough to be a good software engineer in the future.

Is there any CS students here who feel the same?",2020-05-05 08:22:04
aebcgw,A computer scientist is directing her research toward aiding adults with autism.,N/A,2019-01-09 21:05:17
79fpax,One pixel attack for fooling deep neural networks,N/A,2017-10-29 09:53:38
241ul7,"Classic interview question: one number is removed from an unsorted array with numbers 1, 2, ..., 100. How can you find the missing number efficiently? What if TWO numbers are missing? (x-post from /math)",N/A,2014-04-26 19:41:23
18cup5v,Why do x86 processors take up so much energy compared to ARM?,"I understand they have CISC and RISC ISAs and all that.

But what happens down there inside the processor that makes it consume so much power?

Context: 
my Intel Core i7 MacBook Pro runs out of battery within 6 hours.

My M2 Pro Macbook runs for over 48 hours.",2023-12-07 12:37:26
w4yzj3,How do you see computer science changing in the next 50 years?,"From whatever specialization you’re in or in general. What will the languages be like? The jobs? How will the future world around computer science affect the field and how will computer science affect the world in 50 years? Just speculation is fine, I just want opinions from people who live in these spheres",2022-07-22 02:30:26
hcq2sq,"How are unique links or strings like Bitcoin wallet address generated? At one point it seems that checking if that string is taken seems not efficient, is it just taking the chance and hoping such string will never be generated again ?",N/A,2020-06-20 17:23:05
1ecs6e,Announcing Online Masters Degree in Computer Science in Collaboration with Georgia Tech,N/A,2013-05-15 01:29:54
15h9oy,"Computers: It's Time to Start Over: Computer scientist Robert Watson, putting security first, wants to design with a “clean slate”",N/A,2012-12-26 19:18:46
vrwm19,Mark Braverman wins 2022 Abacus Medal: expands on Shannon's Information Theory,N/A,2022-07-05 12:24:03
k9zaw3,Distributed systems lecture series by Martin Kleppmann,[https://www.youtube.com/playlist?list=PLeKd45zvjcDFUEv\_ohr\_HdUFe97RItdiB](https://www.youtube.com/playlist?list=PLeKd45zvjcDFUEv_ohr_HdUFe97RItdiB),2020-12-09 19:58:01
ii6lxb,Vulkan as an alternative to CUDA in scientific simulation software,"This is a continuation post to the [VkFFT announcement](https://www.reddit.com/r/compsci/comments/i5z26r/new_vulkan_fft_library_vkfft_opensource/). In it I promised an example of scientific application, that outperforms its CUDA counterpart, has no proprietary code behind it and is crossplatform. Here I present [Vulkan Spirit](https://github.com/DTolm/spirit), fully GPU version of the computational magnetism package Spirit, developed at FZ Jülich. I hope this post can motivate other scientists to explore the world of Vulkan for scientific GPU computing, as right now it is heavily dominated by CUDA.

From mathematical point of view, simulation of a magnetic system in micromagnetics can be described as a system of differential equations ([LLG](https://en.wikipedia.org/wiki/Landau%E2%80%93Lifshitz%E2%80%93Gilbert_equation)) on a finite-difference mesh. Each cell's position is influenced by positions of its neighbors, material parameters, external effects and many other things. Successful iterative integration of the LLG system can yield time dynamics, resembling experimentally observed evolutuon of magnetics.

From the programming point of view, simulation software is simpler than the one that has to communicate with the user during runtime. There are no calculations performed on the CPU during the execution, so it is only used to create a command buffer before launch, which is not modified afterwards. Combining multiple iterations in a single command buffer significantly reduces initialization overhead and is one of the main benefits of using Vulkan due to its low-level nature.

The Vulkan Spirit includes many algorithms written in SPIR-V shaders, such as LBFGS, VP and CG energy minimizers, RK4 and Depondt integrators of differential equations. The VkFFT library was primarily developed to compute the Dipole-Dipole interaction part of the gradient, which is one of the most time consuming parts of the iteration. It was possible to optimize every single part of the command buffer to reduce memory transfers to the minimum due to the explicit memory handling of Vulkan. This allowed to get up to 3x performance increase in comparison to CUDA based micromagnetics code mumax3. More information can be found on the github repository: [https://github.com/DTolm/spirit](https://github.com/DTolm/spirit)

Thanks for the read!

As a side note, the [VkFFT](https://github.com/DTolm/VkFFT) has been improved in the past month - it supports WHDCN layout, 8k sequences and Intel iGPUs. There is also a benchmark uploaded that can be used to compare the performance to the cuFFT.",2020-08-28 13:01:58
dv4r2c,"AskCS: To those who weren't great in CS at first but got better with time, how did you do it?","Hi CompSci, I'm asking here because I find that the people here are generous with their guidance.

I'm currently in the first year of my Computer Science degree and I'm coming to terms that I may just be completely inept at this major. For some context, I'm decent but not great at math but I am committed to sticking it through with CS.

I'm finding that despite putting in 45-55 hours a week into my course load, I feel like I'm learning at a snail's pace, finishing assignments slower than my classmates and overall just lagging behind my work and my peers. For instance, the second I get a shallow understanding of some topic in discrete structures, we've moved on the next topic. And I wish I had the time to delve deeper and solve more problems, but the work assignments and projects already consume my entire week. I keep reading about how the early courses build up a foundation for future courses and are important for any software engineer's(or another cs-related) career but I feel as though my foundation is riddled with gaps and structurally unstable. 

If any of yall could shed light on your journey as a Computer Scientist/CS student and how you managed to overcome, work around, or accept your limitations, I would sincerely appreciate it. I'm open to unconventional or even drastic measures.",2019-11-12 04:18:36
de6w7f,"Was able to compile and execute a lost game on unreleased hardware in part with suggestions I heard on here, so thanks for that!","https://m.youtube.com/watch?v=7SKqGCPR4fo

It’s appreciated. Some good ideas on decompiling PowerPC code to get a better look at what was going on “under the hood”

Cheers! and if anyone ever needs arcade hardware help/repair/encryption work around, hit me up :)",2019-10-06 18:08:58
b11ff3,New Google Program Applies Technical Writers to Open Source Documentation,N/A,2019-03-14 15:08:18
61yme8,"Why are some programming languages ""faster"" or ""slower"" than others?",N/A,2017-03-28 10:52:16
558iw1,What are some must-read scientific papers of the recent years?,"What are the most important papers in CS (you know, the stuff with hundreds/thousands of citations on google scholar) that have been published in the recent years?

I am a student in Computer Networks and Distributed Systems interested in developing efficient, concurrent servers for data mining and other services. I am also an Android part-time Junior dev and Security enthusiast.

Can you provide me with something interesting to read?",2016-09-30 15:47:53
446tnl,Computer Science Field Guide For High School Students,N/A,2016-02-04 19:18:22
2wj9te,"Carnegie Mellon Accepts, Then Awkwardly Un-Accepts, 800 Applicants For Its Comp-Sci Program",N/A,2015-02-20 10:24:34
2chwrb,What's your favorite data structure?,N/A,2014-08-03 12:15:24
nqjbhs,JWTs done right: Quebec's proof of vaccination,N/A,2021-06-02 11:09:10
hz55x0,"Among computer scientists, is the Sloot Digital Coding System actually considered a lost invention?","I came across the Sloot Digital Coding System on a list of ""lost inventions."" What I read indicated that in the late-90s, it was able to play multiple movies at once using much less memory then we could compress such files even today, 20 years later. The former CTO put out something saying it isn't about compression; it was a whole different way of thinking. But it sounds like this wasn't widely demonstrated; I only find a reference to a demonstration to a Phillips exec, the company they were ""just about to"" sign a deal with when the inventor died. Afterward, a floppy disk was missing, so the whole thing is lost. Which all, frankly, seems like BS to me. An invention back then so much better than anything today, like saying you could build a 747 that only weighed 1/5 of the weight. One disk of code lost, but nothing left in terms of the underlying theory or other info to sketch out how it was done? No partner knowing how it worked? Not enough for others to try to ""solve"" this lost mystery, given how great the performance was? And no one really sees it working? It all sounds like it was going to be a scam... makes me think Theranos and the like. But, there may be something I'm missing to this. So, wanted to ask a community of people who think of this stuff more than I, is this considered a real invention that was lost among the computer community? Is there evidence of it existing/working beyond what I mentioned?

&#x200B;

EDIT: Thank you all for the replies. I like to ask the experts because not only do you know they ""yes or no"" of my question, but help fill in more details, so thank you.",2020-07-28 01:14:29
hbt2oz,Books like SICP?,"Are there any other books like SICP for theoretical comp sci out there? 

I've heard *Types and Programming Languages (The MIT Press)*, and *Introduction to the Theory of Computation by Michael Sipser (2012-06-27)* are good ones.",2020-06-19 03:18:28
cnyad4,A nature paper describes an AI system that can predict acute kidney injury up to 48 hours before it occurs. The approach could help identify patients who are at risk & enable earlier treatment.,N/A,2019-08-09 06:11:11
2cn1f0,The Visual Microphone: Passive Recovery of Sound from Video,N/A,2014-08-05 00:05:29
1jubb7,Are there any good computer science related documentaries and/or movies that you really enjoy?,Any good documentaries or films out there worth checking out?,2013-08-06 22:12:44
txzbt8,Researchers Identify ‘Master Problem’ Underlying All Cryptography,N/A,2022-04-06 23:30:25
l3lov2,CondensationDB: bridging the gap between mutable and immutable data [Open-source],N/A,2021-01-23 22:02:39
dsh6fu,Clear and Creepy Danger of Machine Learning: Hacking Passwords,N/A,2019-11-06 14:39:16
c7awl5,I just finished reading Weaving the Web by Tim Berners Lee in which he described the process of creating his world wide web and explained his various decisions along the way. Are there any similar books/autobiographies for other technology?,"I love reading about technology from a historical perspective so I understand why something is the way it is. Any technology is welcome, though I'd be most interested in web technology. Earlier history of the Internet that preceded Tim Berners Lee would be interesting. History of Javascript or the progression of websites would be good, as well as Java. Maybe some microsoft/windows and unix history. Thanks!",2019-06-30 08:32:33
5vb6nb,Computer Science related movies,"Hi! If you have the opportunity to show a movie to interested students in computer science, what movie should it be?

I am teaching introduction to computer science, a pre-university course and I want them to get exited about CS. For example last year, we watched The Imitation Game and talked about Alan Turing, but this year I want to try something new.

Cheers!",2017-02-21 12:21:16
4ybn3q,Procedural Generation of Water Sounds,N/A,2016-08-18 10:59:27
3mecup,ELI5: what is functional programming and how is it different from OOP,There is this huge craze and debate about Haskell and Scala being better than java and Python and people split between functional and object-oriented programming. I for one am in the object-oriented camp for a simple reason that I don't know what functional programming is. I tried to grasp it from stackoverflow but was too complicated for me to comprehend,2015-09-25 23:14:40
2mucvh,How To Criticize Computer Scientists,N/A,2014-11-20 03:45:18
zyg62j,I created a tool to visualize/edit graphs and graphs algorithms,"I created a tool to create/edit a graph and to visualize graph algorithms (like Dijkstra,kruskal etc).

The project was made entirely using js (p5js,ts).

I think the most interesting part about this project is the fact that you can change the graph (delete edge, move a vertex, set the graph to be weighted or directed etc etc) and the algorithm visualization changes in real time. Give it a try and i'd love to hear some feedback :D

demo: [https://giggiox.github.io/graphTheory-Visualizer/](https://giggiox.github.io/graphTheory-Visualizer/) (better on pc {zoom using mouse wheel})

code: [https://github.com/giggiox/graphTheory-Visualizer](https://github.com/giggiox/graphTheory-Visualizer)

&#x200B;

&#x200B;

https://preview.redd.it/958snc48mw8a1.png?width=1366&format=png&auto=webp&s=e5c6ad0ccb240be9774d2f3cd3dcef306305a84b",2022-12-29 20:55:35
j33ws5,If anyone wants to come contribute any of these algorithms you can in the github repo shared below. [Hacktoberfest],N/A,2020-10-01 07:18:17
fnzj38,What's the deal with JavaScript's reputation?,"Seriously. I don't understand why it's seen as the ""worst programming language."" I see posts all the time about this on r/programmerhumor but I don't get what the deal is. I'm 13 with experience in only HTML, CSS, and JS, so maybe it's because I don't have much to compare it to? Please don't downvote. I need answers.",2020-03-24 05:16:28
cz6iez,Clone a Voice in Five Seconds With This AI Toolbox,N/A,2019-09-03 15:38:39
bgvtf9,"Now You See Me, Now You Don’t: Fooling a Person Detector",N/A,2019-04-24 15:14:24
azupk6,UC Cuts Elsevier Subscriptions as ML Community Pushes Open Access,N/A,2019-03-11 15:25:45
93g3ay,"Syllabus for Introduction to Machine Language Programming, University of Pittsburgh, Spring 1970",N/A,2018-07-31 16:41:52
2hs5vi,Programming language theory StackExchange in last phase of creation; needs 200 people to commit to activate,N/A,2014-09-29 12:19:55
1zxra6,Fourier transform for dummies,N/A,2014-03-09 02:29:39
141d58,Timelapse Writing of a CS Research Paper,N/A,2012-11-30 04:57:13
10mhmp,"""I wish there were general literacy in computer science,"" Jaron Lanier says, ""Which is different from learning to program.""",N/A,2012-09-28 16:24:31
yynqms,Negative-Weight Single-Source Shortest Paths in Near-linear Time,N/A,2022-11-18 16:10:12
lea3qj,Foundational CS / Programming Reading Group,"Hi all,

Recently, I have had success doing an online study of Algorithms by Robert Sedgewick. Inspired by this experience, I would like to start a new reading group / book club that focuses on the fundamentals of programming and computer science.


**About me**: I have a master's degree in math and theoretical CS (graphs, logic, optimization etc) from France. I have been coding since my youth, but I've recently come to realize how much knowledge I am lacking in the fundamentals of programming languages and computer systems. I have coded in Java and Python, I have some experience in front-end, and I love math and algorithms. I am also very serious about improving my skills as a software engineer.


**The books**: having just completed the aforementioned Algorithms book, I have a short list of books that I am interested in studying next. I am also open to suggestions.

*Database Internals* by Alex Petrov

*Effective Java* by Joshua Bloch

*The Elements Of Computing Systems* by Noam Nisan

*Designing Data-intensive Applications* by Martin Kleppmann


**The group**: the book list and concept for the group are very tentative. If several people are interested by this idea, we could discuss time commitment and availabilities, and assign reading assignments to be discussed in online meetings.


Please write a comment or send me a message if you are interested by this idea !


Update: I'm glad people are interested !  I have sent out PMs to start figuring out the organization. Feel free to PM me if you want in.

Update2: I will be running the online sessions on a meetup group where I am an event organizer. The group also has sessions for leetcode problems, algo exercises, and some other topics. It is open to everyone. Check out International Algorithms Study Group: https://meetu.ps/c/4L89y/CdHtR/d",2021-02-06 23:46:48
h8cqch,What are some interesting stories and/or facts related to Computer Science that the general public would find really interesting?,"I have an Arabic youtube channel and I live discussing things related to CS. I do not want to get too technical into CS with videos explaining some core CS concepts, rather, some fun stories or interesting things so that it makes a bystander who knows nothing about CS, interested in CS. 

The way I like to do videos is that if lets say I wanted to explain what an algorithm is. It would be extremely boring for a person who isn’t interested in CS to watch a video titled “what is an algorithm”. However, if I figure out a problem that everyone is facing, think of a very relatable story so as to attract the average person. Then I would sneak in the importance of algorithms, what they are etc at the end of the video. 

This is a great way to share CS related topics with everyone at all ages. 

My problem is: I want so titles and stories that I can link up to some core concepts as a hook intro into those type of videos. Would you guys mind sharing some of the most interesting CS stories you know?",2020-06-13 18:23:07
e621q7,Personal Invisibility Cloak Stymies People Detectors,N/A,2019-12-04 16:52:53
d82pkr,"Software Architecture is Overrated, Clear and Simple Design is Underrated",N/A,2019-09-23 06:29:45
ardfts,Solve LeetCode problems in VS Code,N/A,2019-02-16 21:44:49
9c9t3g,Getting started with Competitive Programming - Build your algorithm skills,N/A,2018-09-02 05:25:10
6hl6u6,Google DeepMinds paper on how computers are starting to reason like humans,N/A,2017-06-16 08:06:12
43b3n3,"IT researchers have developed a machine-learning system that can comb through repairs to open-source computer programs and learn their general properties, in order to produce new repairs for a different set of programs. [X-post from r/programming]",N/A,2016-01-29 21:57:55
30b2zq,Michael Stonebraker wins $1 million Turing Award. This year marks the first time that the Turing Award comes with a Google-funded $1 million prize.,N/A,2015-03-25 22:46:49
2vfpqo,Snowblowing is NP-complete,N/A,2015-02-10 17:32:19
24nnln,Can someone explain to me the beauty of Computer Science?,"I would like to study Computer Science, but I am having a hard time grasping and understanding the sheer beauty and importance of this field and what is enjoyable about it. I like computers in general, but if I am to study Computer Science I would like to get an understanding of the magnitude of knowledge this field emits.

EDIT: Thanks for all the helpful replies I appreciate it!",2014-05-03 23:40:16
1gck04,"Boolean logic gates using ""water""",N/A,2013-06-14 17:06:20
rvqhks,How useful is First-Order Logic in Computer Science?,"I apologize if my question is a little broad. I recently took a philosophy class on propositional and FOL and various systems within each and the metalogic behind them. 

I was wondering in what ways what I learned can be useful for computer science?",2022-01-04 09:33:12
cdwyni,A Systems Design Interview Primer For New Engineers,N/A,2019-07-16 13:20:57
c7sjap,"When it comes to large numbers, is it possible to store a number using less bits if it is first factorised to the product of its primes?",For example for 12=2^2*3 it probably isn't worth it but for astronomically large numbers would it take less space to store them just as products and exponentiations of their prime factors?,2019-07-01 13:25:02
bhck7p,Being bored gets results,"A few months ago I was bored and started fooling around with edge detection in some programming language. Looking through a tutorial I saw an example of isolating the notes from a notes bar and that started me thinking. Would it be possible to distinguish a picture taken outside in the countryside from a picture taken in a city? In a city there are lots of vertical and horizontal lines (buildings, windows, streetlights, etc.) whereas in the countryside there are just a few (horizon, tree). So I wrote a small program to read through a directory of random pictures I ripped from the net and calculated the number and the length of all horizontal and vertical lines in those pictures. Then put all the data in excel and with the help of some coffee trying to find a correlation between those numbers and the fact that the picture showed either a city, open landscape, forest or coastline. And indeed, I found a correlation I could qualify a picture with 80% success rate.  And that started me thinking again, when I’m 80% sure the picture was taken in a city (or park, coastline, landscape) what else could I presumably detect?  The sky is blue, so seeing the color blue in the top of the picture is most likely the sky. Seeing green in the bottom part (landscape, park) is probably grass, seeing brown in the middle part (forest) is probably a tree. Etc.etc.

Next step was to write a program to divide the picture in sectors and calculate the most dominant color in that sector. And with the aid of that color, determine the probability of what is in that sector. The result was quite accurate in its prediction. Of course not 100% but good enough to give the impression that it actually was detecting objects.

https://preview.redd.it/qrnajqvrlgu21.jpg?width=528&format=pjpg&auto=webp&s=6eeca7f14d0a742fa39e1bad7e8afd83e675690f

And then the psychology part stepped in.  If, for instance, the program saw the color brown somewhere at the right and predicted it was a tree, whereas it was actually a mountain, but there was a tree somewhere else in the picture, the human observer (me) still thought the program had it right because it said it saw a tree and there was a tree. So in the eyes of the observer, the program was more right than it actually was.

And that led me to another thought, if I was detecting those colors, what else could I do with them? The psychology of color! Each color represents a kind of emotion. One thing led to another and the result is an android app where the user feeds a picture to the app and it tells the user wat it sees, but also how he/she feels. [https://habs.page.link/qbvQ](https://habs.page.link/qbvQ)",2019-04-25 19:10:29
8w1t3a,Recommendation for a beginner's book on maths for computer science?,I've done a bit of research and found MIT's mathematics for computer science course and plan on following that but I have always prefared to have a textbook to learn from so I was considering getting the book to go along with the course but I had a look online first and found that discrete mathematics with applications is highly recommended. Can anyone help me choose between the two or suggest other books? Any help would be greatly appreciated.,2018-07-04 13:55:19
67xp85,"Is there any reason why Calculus is often a required subject in the roadmap of a CS degree other than ""why not?""","I know math is good for critical thinking, but isn't it more practical and applicable to strengthen those skills through courses similar to Discrete Math?",2017-04-27 18:50:53
49rj06,MIT Creates Algorithm That Speeds Up Page Load Time By 34%,N/A,2016-03-10 02:30:47
380q72,What are your favorite blogs for staying fresh on algorithms/theory?,I work in software engineering now and I feel that my theory knowledge is lapsing. I'd love to do a daily read of a blog that talks about interesting algorithms or features engaging theory problems. Anyone know of something like this?,2015-06-01 00:17:10
2bc9lc,The Imitation Game - trailer for upcoming movie about Alan Turing and the Enigma machine.,N/A,2014-07-21 22:48:52
1hmug8,Play with light in your browser by drawing barriers and mirrors - Zen Photon Garden,N/A,2013-07-04 14:21:51
k6lzg,TIL Microsoft Research has released videos of most of the talks that take place there!,N/A,2011-09-06 17:39:54
mdnovw,Speculating the entire x86-64 Instruction Set In Seconds with This One Weird Trick,N/A,2021-03-26 12:38:29
m1nev4,[N] Attention Is Not All You Need: Google & EPFL Study Reveals Huge Inductive Biases in Self-Attention Architectures,"A research team from Google and EPFL proposes a novel approach that sheds light on the operation and inductive biases of self-attention networks, and finds that pure attention decays in rank doubly exponentially with respect to depth.

Here is a quick read: [Google & EPFL Study Reveals Huge Inductive Biases in Self-Attention Architectures](https://syncedreview.com/2021/03/09/attention-is-not-all-you-need-google-epfl-study-reveals-huge-inductive-biases-in-self-attention-architectures/)

The paper *Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth* is on [arXiv](https://arxiv.org/pdf/2103.03404.pdf).",2021-03-10 02:45:13
dk27zf,How Does BitTorrent Work? a Plain English Guide,N/A,2019-10-19 10:56:17
cw3rnw,Common Systems Programming Optimizations & Tricks,N/A,2019-08-27 12:29:43
ahlu6v,How do banks log know that certain characters of my password are correct?,"I understand the idea of hashing to enable computer systems to check that my password is correct without ever storing my actual password (hash password, store hash, check hash of entered password against stored hash). However, I'm not clear how this works when systems ask me for certain characters from my password. 

For example, how does a bank know that the 2nd, 5th and 10th character of my password is correct? I assume they don't store the unhashed password, and storing hashes of individual characters or even certain combinations of characters would surely be inherently less secure?

Edit : I wonder if this may be more of a UK thing than elsewhere - my HSBC, Nationwide and Halifax accounts all use this ""enter these three specific characters"" approach. My MBNA account asks for the whole password.",2019-01-19 12:53:12
4ukh1d,A Compiler for 3D Machine Knitting,N/A,2016-07-25 19:35:46
492fst,ELI5: Why is log₂ common in computer science?,"Hi everyone, I'm fairly experienced in programming (specifically java) and throughout my years I have realized that a lot of algorithms in computer science are log base 2. For example, some of the best sorting algorithms are some form of log₂n (merge sort, quicksort, heapsort). Also, binary search, one of the most efficient searching algorithms, takes approx log₂n steps to complete. Why is it this way? 

Edit: Wow this blew up bigger than I thought. Thanks for the replies everyone!",2016-03-05 13:40:30
32qkme,"Very cool paper showing that certain problems encountered in Pokemon, Legend of Zelda and more are NP-Hard",N/A,2015-04-15 22:31:09
mpy3t,This man deserves a pardon.,N/A,2011-11-26 16:29:43
lnl657,[N] Apple Reveals Design of Its On-Device ML System for Federated Evaluation and Tuning,"Apple has laid out the design characteristics of a new generic system that enables federated evaluation and tuning (FE&T) systems on end-user devices.

Here is a quick read: [Apple Reveals Design of Its On-Device ML System for Federated Evaluation and Tuning](https://syncedreview.com/2021/02/19/apple-reveals-design-of-its-on-device-ml-system-for-federated-evaluation-and-tuning/)

The paper *Federated Evaluation and Tuning for On-Device Personalization: System Design & Applications* is on [arXiv](https://arxiv.org/pdf/2102.08503.pdf).",2021-02-19 17:17:09
j9mf4v,Are fields other than machine/deep learning (CV + NLP + RL) seeing an explosion of research papers?,"I'm curious as to what is the state of research in other fields of computer science such as algorithms, databases, operating systems, networks, compilers, cryptography, etc.

I'd be interested to know what groundbreaking research is happening in these fields!",2020-10-12 07:26:43
hyc62q,"[Algorithms] How can I solve a ""stable roommates problem"" where new participants are being added in real time and every participant has a deadline in which they must be matched by? [originally asked on r/learnprogramming]","I originally posted this on r/learnprogramming but received only one response. I think this may be a better place to ask this because this is specifically an algorithm question rather than a programming question

Context: As a Covid-19 summer side project, I'm working on an app that first prompts users to take a personality test. When they are done, they receive multiple scores corresponding to different personality traits. The purpose is to meet new friends who have similar personality scores as you. To generate user engagement, users have to press a button to be added to a list of people waiting to get matched (so that there is a level of intentionality when finding a match to avoid inactive users). From the moment the button is pressed, they should receive a match within 24 hours

In general, what is the best algorithm for this type of live matchmaking? From my preliminary research, this seems to fall into a class of problems called the ""stable roommates problem"". However, I'm struggling to find resources for a variation of the problem where: 1) New participants are frequently being added to the set of participants waiting to be matched 2) From the time when new participants are added to the set, there is a maximum time that they wait to be matched. This means that at any given moment, every user has a unique amount of time left to find their match

Given those two constraints, what is the optimal way for me to match users based on similar personality scores?",2020-07-26 18:40:43
eageep,"As a soon to be graduate of CS, whats some online courses I can take that will put me ahead of the pack?","So long story short, im coming up on my graduation. I've had two internships with a large engineering company, have done well in school. I had a couple chances at internships in the big companies (Google,amazon, twitter) that I lost to what I feel was mainly poor technical interview performance\[  i get nervous :(  \] but other than that I am by all means set up to be pretty competitive in the job market.

&#x200B;

Its my first day of winter break and I want to make the best of it! I'm thinking of taking an online Data Structures and Algorithms class to get a refresher on that stuff, but I was curious if anyone has any recommendations of online courses that I could take that would have a big impact on how i can perform out of the gate in a new job?  Perhaps any skill you notice is consistently lacking in new hires or maybe a useful subject to get some info on (first thing that comes to mind is maybe Tensor Flow)  


Thanks for your input all!",2019-12-14 06:35:15
anf17k,Public Key Cryptography Simply Explained,N/A,2019-02-05 15:15:07
7umm5y,Quantum Computers Struggle Against Classical Algorithms,N/A,2018-02-01 22:26:42
1j802r,Bayesian modeling detects cheating at Don Cup 2010 International chess tournament,N/A,2013-07-28 16:51:30
ucj9t,Favorite CS related quotes from professors (or coworkers)?,"There are plenty of quotes from big names that have been floating around the internet forever, but I'm curious what little bits of hilarity or wisdom have been dropped in your presence that the world should know about.

> The biggest issue you'll face in security, and in life, is your own stupidity.

-- Jonathan Walpole teaching Operating Systems

> What happens in the left subtree, stays in the left subtree. (Discussing parsing)

> Java does its best to keep us from shooting ourselves in the foot, whereas C tells us that knives and guns are fun! (Discussing type systems)

-- both Andrew Tolmach teaching Compilers

Both from Portland State University.

What are yours?",2012-05-30 19:21:08
pl1cv,Markets are efficient if and only if P = NP,N/A,2012-02-11 19:12:45
i78s1,Remembering Alan Turing on his 99th birthday,N/A,2011-06-23 15:53:45
xhckof,I visualized the Idea behind the Master Theorem,"Here the Video: [https://youtu.be/d-gIGFxewW4](https://youtu.be/d-gIGFxewW4)

The math behind it can be found in ""Introduction by Algorithms"" by Cormen et al.

I simplified the third case a bit for clarity.",2022-09-18 09:53:45
nnchhp,Adjacency Matrices,Can someone please explain conceptually why adjacency matrices work for graph representation and why they have special properties like raising them to power k which gives you all possible walks between vertices of k length? Because to me it all seems rather arbitrary but yet adjacency matrices have such powerful applications and give correct answers. Thank you!,2021-05-29 01:25:50
nek6bf,Algorithmic Comic Book Lettering - A Surprisingly Hard Optimization Problem,"Word wrapping - choosing how to partition a paragraph of text into lines - is a classic computer science problem, with a well-known solution due to Donald Knuth and Michael Plass.

While their algorithm can quite flexibly handle a wide variety of scenarios, I believe I've found a variation of this problem that it cannot deal with. I can't find any relevant literature, and I've been having a hard time trying to solve it myself, so I'm hoping to find some new insight here.

To recap, we consider a paragraph of text to be a heterogeneous sequence of glyphs (each having a fixed width) and spaces (having a ""natural"" width, though they may be stretched or squashed), and we want to find a subsequence of only spaces, which will be replaced by line breaks.

We can immediately see that, for a sequence containing *n* spaces, there are 2*^(n)* ways to break it up, most of which are nonsensical, violate some external constraints, or both. From the rest, we want to choose the one that's most aesthetically pleasing, or at least close enough to be inoffensive.

For most prose text, we want each line to be shorter than some maximum width `l`, or more generally, we want line `i` to be shorter than `l[i]` (e.g. to fit text around an illustration). Subject to this constraint, we want to minimize both the total white space to the right of each line (i.e. `sum(i in 0..N) l[i] - L[i]`) and the raggedness of the paragraph (i.e. `sum(i in 1..N) |L[i] - L[i - 1]|`), and we can use dynamic programming to do it. In practice, you want to sum squared differences and add some other penalties, but that's the gist of it.

Comic book typography is an entirely different beast, however. Specifically, I'm referring to dialogue, laid out in word balloons; I'm disregarding sound effects here. Sure, for a given balloon, you could construct a sequence of desired line lengths, use the DP algorithm, and be done with it, but even that's tricky when you could fit the same text into a variable number of lines. Really, though, you want to fit the balloon to the text it contains, not the other way around.

And with that, the concept of a *desired* line length as input goes out the window. We're still subject to the constraint of a *maximum* line length (the width of the panel/page), but we don't really care about using any specific portion of it. Rather, we want the overall contour of the layout to conform to an oval shape, and we don't want that oval to be too eccentric. You can look at [this infographic by Nate Piekos](https://cdn.shopify.com/s/files/1/0152/5779/6662/files/bl005.jpg?1883) to see what I mean.

We'll need a new metric to optimize, and, at least intuitively, it seems clear we'll also need a different algorithm to do it - I'm not so sure it's even possible to solve this with dynamic programming *at all*, but more on that later.

So, given a sequence of *n* line lengths *L* (which we can easily derive from a proposed sequence of breakpoints), and assuming a constant line height *h*, we can easily construct a sequence of vertically adjacent rectangles, centered around the origin, here given as a sequence of 4-tuples of corner points:

    Y := nh/2,
    R[i] := (
        (-L[i]/2, ih - Y),
        ( L[i]/2, ih - Y),
        (-L[i]/2, (i + 1)h - Y),
        ( L[i]/2, (i + 1)h - Y)
    )

We can find the superellipse, also centered at the origin, with minimal area, that fully encloses these rectangles - I'll sketch out an algorithm for this further down, if you're interested, but I don't think it's all that relevant to the discussion. We can then calculate its area, and subtract the total area of the rectangles to obtain a measure of negative space.

(We use a superellipse, i.e. the set of points defined by `|x/a|^m + |y/b|^m = 1`, because a proper ellipse (where `m = 2`) just looks a bit too ""skinny""; we'll assume a fixed value of `m` that is greater than 2.)

Minimizing this quantity should naturally penalize asymmetric layouts, as well as those where a line closer to the center is shorter than one further away from it, and do so with appropriate weights. An additional penalty for high eccentricity is also required, something like `ab - (min {a,b})^2` with a configurable weight.

Hopefully, you can see my issue: there's no obvious way to decompose the line-breaking problem into sub-problems such that we can meaningfully reuse their solutions. How good a proposed solution for a subsequence is depends on what the rest of the sequence looks like, and that's going to hold whether you're going forwards, backward, or from the middle outwards. And I think this is intrinsic to the problem, rather than just an issue with this metric since every other metric I could think of was the same in this regard. (I am open to suggestions on how to improve this as well, though.)

I have an algorithm sketched out that can find a near-optimal placement for up to three line breaks in linear time, but I don't see how it would generalize. Maybe it could serve as the basis for some kind of recursive divide-and-conquer scheme, but again, I'm not sure how that would break down.

Anyway, it goes like this:

* In a linear pass through the sequence, find the breakpoint that is closest to the visual midpoint; let's call its index `j`. This is obviously the optimal point to break if it were the *only* line break, but we'll evaluate the metric anyway for later comparisons.
* In a second pass using two indices `i, k` going from the outside inwards:
   * evaluate the metric for both `[i, k]` and `[i, j, k]`\*, and remember the tuple/ triple if it scored better than the previous best,
   * advance `i` or `k` to the next breakpoint, whichever will leave the first and last line closer in length; terminate if either is longer than the line from `i` to `k`.
* Return one of `[]`, `[j]`, `[i, k]`, `[i, j, k]`, depending on which scores best.

\*: Once we've seen `[i, k]` perform better than `[i, j, k]`, it should be safe to assume we've already seen the optimal placement of three breaks, so we can stop evaluating the metric for that.

This doesn't account for the maximum line width, of course, but that's a straightforward extension.

Honestly, this seems just barely good enough for my use case, but it is pretty limiting. I'd like to find the optimum using any number of line breaks less than a configurable maximum, but I wouldn't be surprised to learn that's just not possible in polynomial time. In that case, I'd be happy with an approximate algorithm to do the same.

Any ideas on how to improve on this would be greatly appreciated!

**Side Note: Fitting a Superellipse Around a Stack of Rectangles**

Let `P` be the set of corner points of the rectangles. Iterate over all pairs of points in `P`, find the semi-axes of the superellipse going through them, and check if it contains all the other points. If it does, calculate its area, and remember only the smallest one seen so far.

This has cubic time complexity in the number of points, but we can use a set of points that is smaller by a factor of 4, by exploiting some symmetries:

* By definition, the corner points are symmetric about the y-axis (`forall (x, y) in P: (-x, y) in P`), so we can discard all points with `x < 0`.
* While the corner points need not be symmetric about the x-axis, their projection onto the y-axis is, i.e. `forall (x1, y) in P: (x2, -y) in P`. From each such pair of points, we need only keep the one where the x-coordinate has greater absolute value since a superellipse going through the other one will never include it.

We can shave this down further by throwing out points that aren't part of the convex hull of `P`.

That's only an improvement on the constant factors, but there's an approximate, linear-time algorithm we can fall back on for larger *n*, that also gives visually acceptable results:

* Pick any point in `P` and find the semi-axes of the superellipse with minimal area going through it (which will generally be of the form `a = k*x, b = k*y`, where `k` depends on the exponent `m` used to define the superellipse).
* Iterate over the remaining points; for each point `(p_x, p_y)` outside the superellipse, stretch one of its radii so that the point lies on the perimeter:
   * calculate the half-width `w` of the superellipse at `y = p_y`,
   * calculate the half-height `h` of the superellipse at `x = p_x`,
   * if `|p_y|/h < |p_x|/w` set `b := b * |p_y|/h`, otherwise set `a := a * |p_x|/w`.",2021-05-17 16:05:32
ju2eo7,Beyond CUDA: GPU Accelerated Python on Cross-Vendor Graphics Cards Made Simple,N/A,2020-11-14 14:04:44
hxfz2l,Is machine learning from Stanford/Coursera build a good idea on data science?,"First, sorry if this is the wrong subreddit. 

I’m interested in learning both machine learning and data science and I wanted to find out if this course builds a good foundation on both of those?

Also, are there any math prereqs like calculus or anything?

Thanks",2020-07-25 03:32:30
u2dbcq,Is General Intelligence really possible in the next 50 years?,"Note I'm not a machine learning expert, my last ML course was from 10 years ago, so please do point out to me any additional material I should read or watch.

I understand that generally making a machine that peruses through data or scenarios to arrive at an optimal solution is easy. But as we add more 'questions', the system becomes exponentially complex. Therefore, creating a machine to sort pictures is easy, but expanding that to include videos becomes exponentially complex. Making a robot that navigates terrain is easy, but adding say, jumping abilities, makes it alot more complex.

With this in mind, and with computational power leaps like quantum processors still a long way off, how can anyone reasonably say that we'll achieve true general intelligence in the next 50 years?",2022-04-13 00:17:00
602fqu,Controversial areas of research in computer science?,"I have an English assignment that requires analyzing research on a topic in my major (computer engineering) and determining whether it is worth pursuing. My immediate thoughts were to analyze the ethics of AI, however I feel off track with the assignment. Any help would be appreciated!!",2017-03-18 04:32:18
4djdqw,'Fulfilling' or 'Meaningful' CS jobs,"Hey everyone. I was curious about the job opportunities in the CS field. I'm currently a junior studying CS and I'm kinda having an existential crisis over whether I'm in the right field or not. 

I enjoy programming and learning all things computers. However my perception of the ""tech world"" kind of rubs me the wrong way. I don't have much interest in working for the likes of Apple or Google, for example. Regardless of what I'm studying, I've come to realize that whatever I want to do I want to be able to make a difference, help people, or have some sort of meaningful career in that sense. 

I was wondering if anything like this exists in the field of computer science? In my mind, computer science is a strong field as its utilized in virtually every industry. Am I wrong in thinking this type of meaning or fulfillment can be filled in the world of computer science? And if this is possible, what advice would you give to me or what direction should I be heading? I'm definitely interested in information security as keeping information private seems meaningful to me. But outside of that are there any real world applications (not necessarily in the tech field) that would achieve this goal while still involving technology?",2016-04-06 00:32:28
17wm6pf,Why does no one talk about systems programming.,"I've heard people mentioning about things like fullstack development, AIML, data science, cybersecurity etc. But no one ever talks about systems programming. I've never heard someone say that they're learning to build an operating system or trying to build their own framework. Why is this? Is is simply because it's hard to do these things? I'm pretty sure that there can be huge innovations in this field. Is it simply because there are not a lot of jobs?",2023-11-16 12:54:39
1733lw9,"My 8 Bit Processor Development Project on Breadboard. I explain how to increase the speed of processor clock, which can be adjusted from 10 Hz to 10,000 Hz.",N/A,2023-10-08 16:38:26
twzq0p,ELI5: How is passwordless (biometrics) supposed to provide better security than passwords?,"I’ve been hearing that using Face ID and fingerprints provide better security than using a password. This makes no sense to me. Your face and fingerprints are publically available so if you are actually a target, these seem inevitably doomed to failure. Even if you make the argument that duplicating a face and fingerprint to fool recognition systems is hard, this certainly will not be the case in the long term, or medium term TBH.",2022-04-05 17:06:01
122eokf,Is there such a thing as non-asymptotic analysis of algorithms for small n cases?,"I am reading lecture notes on a data structures and analysis of algorithms course and I find it interesting but I find two things annoying: 

1.  Compiler implementations and hardware specific details and runtimes are omitted.

2.  All run time analysis is asymptotic, even though no computer can run infinitely long.  Nothing in the course worries about real world usage and real world optimization in finite time for everyday usage.

I'm concerned about realistic scenarios like the efficiency in the first hour of use, for example.  I'd rather reduce area under the run time curve at finite times far less than infinity, than worry about what the worst possible case is.  Worst possible case is not good enough for me, I want to also optimize better than worst possible cases I want to optimize in good conditions so that it is even better and perfectly synced up to the hardware it is using.",2023-03-26 07:37:34
9e1miy,Is there a solution to the Travelling Salesman problem I haven't heard of? This is from a textbook for 16-17 year old students.,N/A,2018-09-08 04:30:31
274git,"The ""Weissman Score""","So, I, like i am sure many of you, have gotten into the HBO show Silicon Valley. In the show they continually reference the ""weissman score"" a fictitious compression metric that serves as a sort of reference for the shows viewers to track the development of the software on the show. I was wondering if there is anything out there in the real world that is comparable to this? How is compression measured, and how are algorithms compared?

the weissman score algorithm can be found here - http://si.wsj.net/public/resources/images/BN-CF445_valley_G_20140403194508.jpg

Note - I have little experience in this area, I took an image processing class in college that briefly dealt in this topic but that's about it.",2014-06-02 16:47:49
y79zd,Is there a resource that teaches math through programming?,"Some quick background: I am a programmer that works primarily on enterprise systems, and my math knowledge is very weak.  I'd like to learn more about math, but every text I try to read confuses me and I get frustrated quickly.  I was reading a blog post today about ""[the myth of superprogrammers](http://simpleprogrammer.com/2012/08/12/the-myth-of-the-super-programmer/)"" where the author gave an example of [a math equation and used a simple `for` loop to illustrate what was happening with the math notation](http://f.cl.ly/items/131k1x3N041q113Q0s1I/Screen%20Shot%202012-08-14%20at%208.28.13%20AM.png).  I had an ""ah-ha!"" moment and realized that this would be an excellent way for me to become familiar with math concepts, by referencing a field with which I am pretty familiar.  I know a lot of programmers already have a math background, but since I'm approaching this from the other direction, I was wondering if there are any texts, websites, or videos out there that take this approach.  Any suggestions would be most welcome!",2012-08-14 13:46:29
18hkdmp,"Christos Papadimitriou is a famous theoretical computer scientist. In 2014, he said about modern CS education that “the courses have become so complicated that I doubt I could pass them!”",N/A,2023-12-13 16:16:07
129z7yc,Patching Python's regex AST for confusable homoglyphs to create a better automoderator (solving the Scunthorpe problem *and* retaining homoglyph filtering),N/A,2023-04-02 21:42:05
13e5cza,Xerox PARC Files Released!,"Explore *The Office of the Future*

The Xerox PARC archive is open to the public and ready for you to explore.

Beginning in 1970, researchers at Xerox’s revolutionary Palo Alto Research Center (PARC) worked to develop computer hardware and software for the “office of the future.” Luckily, they took care to back up their work and migrate data over time to more updated storage formats.   

With help from CHM, a tremendous digital archive of this historic work has been preserved.

The archive contains nearly 150,000 unique files—around four gigabytes of information—and covers an astonishing landscape: programming languages; graphics; printing and typography; mathematics; networking; databases; file systems; electronic mail; servers; voice; artificial intelligence; hardware design; integrated circuit design tools and simulators; and additions to the Alto archive.

Explore: [https://computerhistory.org/blog/a-backup-of-historical-proportions/?](https://computerhistory.org/blog/a-backup-of-historical-proportions/?utm_campaign=PARC%20Archive%20Release&utm_medium=email&_hsmi=257598549&_hsenc=p2ANqtz-984tj9L_YJmjgtXuRxS2-JNUhEuC9LGEPSY9yAx3Yzn2_Oc1_lkWPSPt2KNweqyoN9HWgSbrNHomTsW470yD0UObcQhqfPy3pRBXF75Dh4ZDnuxYg&utm_content=257598549&utm_source=hs_email)

Dag Spicer  
Senior Curator  
Computer History Museum",2023-05-10 22:25:31
11cnxfk,Cache Oblivious Algorithms,N/A,2023-02-26 17:58:22
138eatb,A tiny Turing machine in C for 2-symbols busy beavers. Program is kept on input string. Position of program index holds the state.,N/A,2023-05-05 07:37:46
144bkwk,Searching for points within a sphere using a 3D KD-Tree / 3D-Tree in Unity,N/A,2023-06-08 15:00:05
11vg2w1,Similar probabilistic algorithms like Hyperloglog?,"Just recently learned about the Hyperloglog and I was wondering if you have any other cool probabilistic algorithms that I should look into. Also, if you have ever used them, I'd love to know in which scenarios.

For those who doesn't knew HyperLogLog, I wrote very basic notes to myself here  -> https://adriacabeza.github.io/2023/03/15/hyperloglog.html",2023-03-19 08:54:00
11e4fkz,"A Trie Variant Balancing between Time, Space, and Simplicity; And a C Implementation of the Aho-Corasick Algorithm Based on It","I think this sub is a suitable place to share my work.

* Implementation of the trie variant: <https://github.com/dongyx/chtrie>
* Paper of the analysis and proof: [https://arxiv.org/abs/2302.03690](https://arxiv.org/abs/2302.03690)
* Application in the A.-C. algorithm: [https://github.com/dongyx/libaca](https://github.com/dongyx/libaca)

The approach is called *coordinate hash trie*.

The idea is very simple.
We use a global hash table to store all edges in a Trie. Each edge is stored as a dictionary item `(from, symb)->to`.

We use a special hash function:

    h(from, symb) = (from*m + symb) mod H

, where `m` is the size of the alphabet, and `H` is the number of slots in the hash table. For a trie with `n` states(nodes), we take `H = (n-1)/alpha` where `alpha` is the constant load factor. **No rehashing, resizing, or reallocation is required.**

We could prove that **the time complexity of transition from one state to another, is O(1) for the average case and O(m) for the worst case**. **The space complexity is O(n), unrelated to** `m`.

Comparing to other compressed trie variants like *double array trie*, or using `n` hash tables each for a state, this variant provides stable space consumption and is very easy to implement.",2023-02-28 12:06:51
134b2tg,Big vs Little Endian: Does it even matter today?,"Hey y'all,

I'm a fairly early career SWE at an AI Accelerator company. I've written some driver code, cloud stuff, python, rust, C, go, Racket/lisp, and I'm learning Haskell. I feel like I've at least touched on concepts all the way from Arduino hardware to RPi to beefy servers and massive distributed systems. 

Seeing all this has meant that basically everything I learned in school was at least mentioned, if not an important part of my work. In fact, I would say that 95% of my CS schooling came in handy. There is one thing, however, that was covered in three separate classes (intro to systems, compilers, and operating systems), that has never, not even once, come up in conversation, let alone my duties: Little vs Big Endian systems.

Having to worry about it in classes made me think it was lurking around every corner, waiting to make things explode violently. I figured I would need to be writing code that checked for the current scheme and adjusted accordingly. Needless to say, I've never had to worry about it. My question is, what happened to it? It was obviously on every professors mind, so what gives?",2023-05-01 03:10:01
12nxj1l,There are a lot of sources on how genetic algorithms work but barely any about WHY they work,"Do these algorithms have rigorous mathematical reasoning (i dont mean proof, i mean reasoning) or its just something we tried after seeing it in biology and it happened to work out? 

 Theres so much randomness in genetic algorithms, especially when you want to maximize genetic variation, that it kinda seems like magic that they end up working out (most times at least). Thats why im curious if its something that was found out purely through experimentation, theres no shortage of things like that in computer science anyway",2023-04-16 05:59:00
136re43,"Are there NP COMPLETE problems that are ""easy"" in practice?",N/A,2023-05-03 16:00:00
12y4m4y,Tolerating Malicious Majorities - Advances in Distributed Consensus,N/A,2023-04-25 02:01:03
14jxa9r,Can the n-th row of Pascal's triangle be computed in polynomial time?,"Hi! I was looking into computing Pascal's triangle and I wanted to know if it can be done in polynomial time. I think that this is the case because computing the n-th row seems to take at most n^2 steps. However, I know that n isn't the  bit lenght representation of the row number which makes me doubt myself which also leads me to the ask myself the question: Can the n-th row of Pascal's triangle be computed in polynomial time?",2023-06-26 23:45:42
156l0ro,Snowflake Simulation with Cellular Automata (CA),N/A,2023-07-22 14:05:10
182btac,What kind of algorithm would you design to create a map like this? To me this looks like a very interesting graph theory question.,N/A,2023-11-23 21:47:27
14zx42z,What are some 'must read' or 'esstiental' books covering computer science?,Looking to expand my knowledge of CS in my free time and wondered if there are any books which have been really impactful for your learning and maybe some newer stuff that's good. Lemme know :),2023-07-15 00:33:57
15dn0cv,"100x Faster Than Wi-Fi: Li-Fi, Light-Based Networking Standard Released",N/A,2023-07-30 14:30:44
11f1whf,The Implementation of the Coordinate Hash Trie,N/A,2023-03-01 11:57:10
17qqq45,Must read books for any cs student?,I just started my computer science studies at college so I'd like to immerse myself in the field by reading books that will help me grow as a cs professional. I know CS world is too broad so I'd like to point out that my goal is to work as a software/web developer.,2023-11-08 17:27:50
14ykqj9,Microscopic Traffic Simulation utilizing the Intelligent Driver Model (IDM),N/A,2023-07-13 13:21:16
13wl6wi,A Divide and Conquer Approach to Maximize Deep Learning Mammography Classification Accuracies (my first published research article),"Hello r/compsci redditors! As a long-time lurker who has been following this subreddit since I was a CS student in university, I am excited to share my first research paper entitled “*A Divide and Conquer Approach to Maximize Deep Learning Mammography Classification Accuracies*” that was recently published in PLOS (Public Library Of Sciences) ONE.

In this study, we explored a divide and conquer approach that aims to enhance the accuracy of deep learning algorithms for mammography classification (figure below). We hope that our results can act as a starting point for future DL-based breast cancer detection pipelines with the goal of improving early detection and diagnosis of breast cancer, ultimately leading to better patient outcomes.

You can read the paper here: [https://doi.org/10.1371/journal.pone.0280841](https://doi.org/10.1371/journal.pone.0280841)

We also created a repository to encourage code reproducibility (PRs and Issues are welcomed): [https://github.com/Adamouization/Breast-Cancer-Detection-Mammogram-Deep-Learning-Publication](https://github.com/Adamouization/Breast-Cancer-Detection-Mammogram-Deep-Learning-Publication)

Here is the final results figure that summarizes the divide and  conquer approach (bar chart comparing the results achieved using various deep learning techniques relative to a baseline model):

[final results figure](https://preview.redd.it/tj7izx9yd73b1.png?width=2083&format=png&auto=webp&s=7eedbded40a91fdd99a50b08ef0e0449378215de)

where:

* \*: Histogram equalisation + Gaussian filtering.
* α: All layers instantiated with pre-trained weights from a binarised mini-MIAS dataset.
* β: Base CNN layers instantiated with ImageNet weights; fully-connected layers instantiated with pre-trained weights from a binarised mini-MIAS dataset.
* γ: Base CNN layers instantiated with ImageNet weights; fully-connected layers instantiated with random weights.
* δ: Balanced class weights (0.907 for majority benign class, 1.113 for minority malignant class).
* ϵ: +50% class weight for minority class (1.0 for majority class, 1.5 for minority class).
* ζ: Two sets of convolutional layers before base CNN.
* η: Convolutional layers before fully-connected layers.",2023-05-31 12:40:55
13y2kgp,Is there a provably optimal algorithm for the game '2048'?,"The game's placement of blocks may at first appear to be random, but is not fully so. To further clarify, when I say ""optimal"" I specifically mean ""the shortest possible path to get to 2048 regardless of the initial starting conditions""

Edit: Is it just me or are there a lot of karma farming bots on this post!? Too many duplicate comments. Quite a shame as the question was interesting...",2023-06-02 04:07:30
15o28ux,Can someone tell if my idea for computer will work? I'm wanting to build a computer without abstraction.,N/A,2023-08-11 07:43:28
169wugt,What are some underrated research work or tech advancements that has the potential to eventually make an insane breakthrough?,N/A,2023-09-04 16:38:23
13k4kih,Huijia Lin proved that a master tool of cryptography is possible,N/A,2023-05-17 15:13:19
17lomek,Gen Z and the advancement in technology,"I am currently undergoing an internship at a university in their robotics research lab and I recently had a conversation with one of the compsci professors about the advancements in technology and Gen Z ( to preface I am a Gen Z-er) and I thought what he had to say was interesting and wanted to share. Bare with the long post. 

He complained that our generations consistent use of software that made accessing technology much easier were making us technologically illiterate. We could get into programming/technologhy much easier than our predecessors but we understood the technology much less. He says that many of the CompSci students he taught lacked many fundamental principles of computer science and was baffled about their inability to code relatively simple algorithms (data retrieval/ creating files).

He argued thats these software were good in the fact that it closed the gap between the technologically illiterate and the technologically literate but it made the TL lazy and slowed the learning process and thus progress. He said that AI wasn't making this issue any better and was making people more reliant on technology we ourselves don't even properly understand, creating a sorta ""blind leading the blind"" situation.  AI algorithms trained on data that's cannot be properly understood by the engineers would not be good for society.

With CompSci becoming a more saught out career path by Gen Z (he thinks many people go into Tech/CompSci that shouldn't due to not being suited for it), he thinks that the overall technological advancements are going to slow drastically over the next 100 years.

I just wanted to see what other people thought? Do you agree with him or nah? He is 40+ I don't know his age exactly.",2023-11-01 22:48:38
165p9oi,Why is array shuffle algorithm not implemented like this?,"The array shuffle algorithm (fisher-yates) is implemented like this:

    void shuffle(int *array, int size) {
        for (int i = size - 1; i >= 0; --i) {
            int a = randint(0, i);
            swap(&array[i], &array[a]);
        }
    }

Where as I would imagine it would be implemented like this:

    void shuffle(int *array, int size) {
        for (int i = 0; i != size; ++i) {
            int a = randint(0, size);
            int b = randint(0, size);
            swap(&array[a], &array[b]);
        }
    }

So I have a few questions. Assuming both algorithms operate under true random generators, is one's quality better? Is mine flawed? 

I also understand I double the calls to `randint` but in my defense `randint` is probably just a couple of CPU instructions where I always range-reduce to the same `[0, size)` range so I can just precompute the montogomery multiplication values ahead of time and avoid using modulos which is kinda slow in the `randint`.

Anyway, would mine be okay? Is one faster or better than the other? Reason second one is litteraly not mentioned anywhere?",2023-08-30 20:10:24
13i63nx,What language for creating mathematical modeling program?,"Hey all, I'm looking to start building a tool for visualizing high level mathematical concepts/examples. Past 2nd year in math there's really not many tools to help see what's actually happening within the math you study, and I want to build something that would visually display the concepts we study. What would you guys recommend as a language to work in this with? I'd want to have 2D visuals at the very least for things like differential equations, real/complex analysis, etc,  maybe 3D if it's feasible. I transferred from physics/math to comp sci/math so I'm still a bit newer to programming. Any suggestions would be appreciated :)",2023-05-15 11:56:08
1ah0qoe,Reflective Analogue Processing Could a type of “Analogue Algorithm” be encoded as geometry on a reflective surface to process data on a light beam?,N/A,2024-02-02 10:34:43
15zggiv,USSR Computing?,"Does anyone know a good, all-encompassing, and more technical-leaning resource on USSR computing? I'm not seeking a novel, nor do I seek a 'pop' account. I need a technical listing, something like a catalogue. I am just interested in how far they had went. I made a post comparing US computing to EU computing, but I completely forgot that USSR once had a burgeoning computing field. One thing I am interested in is their hardware. Someone once posted an IC made in USSR which really invoked my interest. I'm interested to know if they had their own architectures, compilers, languages, algorithms, etc. I realize they were not moonmen and they indeed copied much of their shit from the US and Europe. But I know they had an 'internet' and I'm wondering if they used Bereckly Sockets? Had they ported UNIX to their architecture? It's just very interesting.

Thanks for your help.

NOTE: no Tetris  pls. Tetris was made waaaay down the line into the life of USSR, and it, as I believe, was originally written for a Western architecture. Also there's a movie starring Johnny Arbuckle. I'm more interested in developments between 1950s-late 1970s.",2023-08-23 20:57:50
14uu69n,A report on the Collatz problem,"As of July 9, 2023, the project [Convergence verification of the Collatz problem](https://pcbarina.fit.vutbr.cz/) was able to verify the validity of the Collatz conjecture for all numbers less than 2^(70). The project started its operations on September 4, 2019. On May 7, 2020, it verified the convergence of all numbers below 2^(68), while on December 10, 2021, it verified all numbers up to 2^(69). The project consumed 7053 CPU-years of computing time (of which 6928 years using the CPU and 125 years using the GPU). The project uses work units of 2^(40) numbers. Verifying one such unit takes, on average, 5:59 minutes on the CPU and 8 seconds on the GPU.",2023-07-09 09:30:19
17bgj90,The Great Explainers of Computer Science,Who would be considered the great explainers in the world of programming and Computer Science? Who is the best person you've found on YouTube or any other medium who can break down a complex concept and make it make sense?,2023-10-19 11:04:58
14icpzl,What do people with a degree in computer science do at work?,"What do y'all do at work? I guess more specifically what problems y'all solve, what you work on, and how you built your skills that made you able to do your job.",2023-06-25 04:27:05
13tiaol,That Computer Scientist - Why Sorting has n(logn) Lower Bound?,N/A,2023-05-27 21:09:32
11ayrc0,Gradient Boosting with Regression Trees,"Hi guys,

I have made a video on YouTube [here](https://youtu.be/lOwsMpdjxog) where I explain what gradient boosting is and how it works.

I hope it may be of use to some of you out there. As always, feedback is more than welcomed! :)",2023-02-24 18:47:22
1803qzg,What started the generative AI frenzy?,"I understand there have been genAI products before 2022 (like DALL-E in 2021), but nothing gained traction. Then came chatGPT, the biggest hit in genAI on 30 Nov 2022. After which, within a few months, several other genAI products like MidJourney, Dall-E, Stable Diffusion were popularised and more LLM-applications like Bard were created.

What kickstarted the genAI frenzy? Did people think for the longest time genAI was too farfetched, until they saw it done with chatGPT and saw it was possible, then got to work? Was it a breakthrough in research for genAI technology or a release of a whitepaper? Was it a particular class of hardware that revolutionalised compute? I'm really curious, but nobody talks about this stuff.",2023-11-21 00:26:02
12zjlzd,How many abstract interpretations exist for a given function?,"Given some function `f: u -> v`, we're interested in approximations of it `f' : u' -> v'` along with the functions `a: u -> u'` and `b: v -> v'`. where `f(x) = y --> f'(a(x)) = b(y)`. How many exist, how to find/derive them, etc.

Edit: I'm thinking of finite sets for `u'` and `v'` and that `|u'| < |u|`. `u` and `v` are also likely finite or practically finite where we're working with machine integers, strings with upper bound on length, etc.

# Examples

For the function, `sort: List[T] -> List[T]`, we can approximate it with `identity: u32 -> u32` where we take the length of the input and output (ie. the lengths don't change)

For the function `capitalize_first_letter: str -> str`, we can approximate it with `capitalize_char: char -> char` where we take the first letter of the input and output.

For the function `u32_plus: (u32, u32) -> u32`, we can approximate it with `u1_plus: (u1, u1) -> u1` where we take the inputs and outputs modulo 2. We can also do this with `u2_plus` and modulo 4, etc.

For any function `f: u -> v`, we can trivially approximate it with `TypeUToTypeV: unit -> unit` (or maybe clearer with the mapping `{TypeIsU -> TypeIsV}`) where we take the type of the input and output, where `type(x: u) = TypeIsU` and `type(y: v) = TypeIsV`. This is restating the viewpoint of type systems as abstract interpretations. And this is a unique approximation since it is a mapping from one element to one element.

# Thoughts

The mapping `f'` isn't (necessarily) that interesting because given the functions `a` and `b`, we can just write down a lookup table of `{a(x) -> b(f(x))}`.

I'm most interested in approximations of varying sizes of `u'` and `v'` that lie along the spectrum from `#1 -> #1` (which is the type system judgement) and `#u -> #v` (which is the original function `f`).

I'm also interested in ranking approximations of equal size, where one approximation is better than another if it more evenly covers the codomain `v'`. In the `u32_plus` example above, modulo 2 is perfectly balanced because it sends half the inputs to 0 and half to 1. There could (maybe not for `u32_plus` but in general) exist another approximation of equal size, `#4 -> #2`, but with an imbalance, like the mapping `{0->0, 1->0, 2->0, 3->1}` since 0 is mapped-to three times and 1 is mapped-to only once.

If you are okay giving up 100% accuracy, we can extend these questions to ML and seek to learn approximations for a given embedding dimension. Can we use a regularizing term that helps balance (equi-distributes) the output of an encoder decoder network? Is this just a different way of looking at clustering?

# Closing

I'd be interested in hearing thoughts, discussion, related papers, related ideas etc. Thanks in advance",2023-04-26 14:41:46
1458xkt,Any resources on experiments simulated environments?,"Does anyone have any interesting papers, researches, books, etc with helpful resources regarding behavioral experiments with simulated environments? I've come across some insteresting ideas on a couple videos on the [Primer YouTube channel](https://youtube.com/@PrimerBlobs) (although they're inclined more towards explaining concepts rather than studying them), or [that one paper](https://arxiv.org/abs/2304.03442) where some researchers from Stanford university and Google ran a the-sims-like simulation and observed the interactions between simulated characters that were simulated using a natural language model, and was wondering where I could find some related work.",2023-06-09 15:54:25
16goqid,"Interesting research paper on whether Computer Science falls into the category of science, engineering, or mathematics."," I find the Reddit debates about whether Computer Science belongs to the realms of science, engineering, or mathematics quite fascinating. Recently, I came across a research paper that I believe  provides a very good summary of this topic. I'm curious to hear your thoughts and opinions on this matter, so please feel free to share your perspective. What are your views on this topic?   


  

""We conclude that distinct positions taken in regard to these questions  emanate from distinct sets of received beliefs or paradigms within the  discipline:        


\-  The rationalist paradigm, which was common among theoretical  computer scientists, defines computer science as a branch of  mathematics, treats programs on a par with mathematical objects, and  seeks certain, a priori knowledge about their ‘correctness’ by means of  deductive reasoning.  


 \- The technocratic paradigm, promulgated mainly by software engineers  and has come to dominate much of the discipline, defines computer  science as an engineering discipline, treats programs as mere data, and  seeks probable, a posteriori knowledge about their reliability  empirically using testing suites.        


\- The scientific paradigm, prevalent in the branches of artificial  intelligence, defines computer science as a natural (empirical) science,  takes programs to be entities on a par with mental processes, and seeks  a priori and a posteriori knowledge about them by combining formal  deduction and scientific experimentation.    


We demonstrate evidence corroborating the tenets of the scientific  paradigm, in particular the claim that program-processes are on a par  with mental processes. We conclude with a discussion in the influence  that the technocratic paradigm has been having over computer science.""  


References

Amnon H. Eden. (2007). *Three Paradigms of Computer Science*. [https://link.springer.com/article/10.1007/s11023-007-9060-8](https://link.springer.com/article/10.1007/s11023-007-9060-8) ",2023-09-12 11:24:00
14fhbu3,"Sharing: How to Write an Object Model That Doesn't Suck - we recently went through developing the object model for our startup, here's some of the lessons and tips we learned. Enjoy!",N/A,2023-06-21 19:45:39
12hhfos,#29 - Can PL Theory Make you a better software engineer? feat. Jimmy Koppel,N/A,2023-04-10 12:32:31
1anbb1b,The most beautiful computer science paper I have ever read,"A mathematical algorithm, greek politics and a bunch of priests…this  is what you need for the most beautiful paper I have ever read.

This week I am bringing you a paper about the Paxos distributed  consensus algorithm. It got its name from an island in the aegean sea,  or more accurate: From a way how the parliament of that island conducted  legislation. The paper is long (33 pages), but beautifully written and  explains the algorithm in a nice way. You got to check it out.

**In order to receive ALL articles, subscribe to the email based newsletter:** [**https://www.weeklycspaper.com/**](https://www.weeklycspaper.com/)**. Here on Reddit I only share some of the articles.** 

Here is the first paragraph:  


>**1.1 The Island of Paxos**  
Early in this millennium,  the Aegean island of Paxos was a thriving mercantile center. Wealth led  to political sophistication, and the Paxons replaced their ancient  theocracy with a parliamentary form of government. But trade came before  civic duty, and no one in Paxos was willingto devote his life to  Parliament. The Paxon Parliament had to function even though legislators  continually wandered in and out  
of the parliamentary Chamber. The  problem of governing with a part-time parliament bears a remarkable  correspondence to the problem faced by today’s fault-tolerant  distributed systems, where legislators correspond to processes and  leaving the Chamber corresponds to failing. The Paxons’ solution may  therefore be of some interest to computer scientists. I present here a  short history of the Paxos Parliament’s protocol, followed by an even  shorter discussion of its relevance for distributed systems. Paxon  civilization was destroyed by a foreign invasion, and archeologists have  just recently begun to unearth its history. Our knowledge of the Paxon  Parliament is therefore fragmentary. Although the basic protocols are  known, we are ignorant of many details. Where such details are of  interest, I will take the liberty of speculating on what the Paxons  might have done  
 “The Part-Time Parliament” – Leslie Lamport

**Abstract:**

Recent archaeological discoveries on the island of Paxos reveal that  the parliament functioned despite the peripatetic propensity of its  part-time legislators. The legislators maintained consistent copies of  the parliamentary record, despite their frequent forays from the chamber  and the forgetfulness of their messengers. The Paxon parliament’s  protocol provides a new way of implementing the state-machine approach  to the design of distributed systems

**Download Link:** 

[http://lamport.azurewebsites.net/pubs/lamport-paxos.pdf](http://lamport.azurewebsites.net/pubs/lamport-paxos.pdf)

**Additional Links:**

* None this time",2024-02-10 07:59:44
14u1wkj,Does everything in computer run on an event loop?,"I was thinking of something today.

In video games you have a main god while loop (Event loop) which runs, this while loop checks for things like keypresses and other events to run the game logic.

As a web developer, I can make a button with an onclick handler.

On the web layer, this is not a while loop that checks the state of the website every millisecond to see if the button is clicked, its just an event based system that triggers something when the button is clicked.

But I was thinking... Maybe its not an event loop on the web layer. But maybe somewhere down the rabbit hole, whether it be Google Chrome or the OS itself. There might be a secret event loop running 24/7. One that underpins everything. One that checks my keypresses and mouseclicks whenever I open up Excel or something.

Is this true? ",2023-07-08 11:39:00
11mgfpu,Lang based on Computability Logic? What might this look like?,N/A,2023-03-09 02:44:33
1912ffl,Which recently discovered algorithms have made the biggest impact in standard libraries - or at least in close to one-to-one drop-ins?,"Examples of the kind of thing I'm thinking of:

* [Timsort](https://news.ycombinator.com/item?id=21196555) as a standard part of Python and Java
* [Swiss hashing](https://abseil.io/blog/20180927-swisstables) - third-party C++ library)
* [Faster Remainder By Direct Computation](https://arxiv.org/pdf/1902.01961.pdf) - not sure if it's implemented in libraries yet but that is fairly directly what the paper is intending

These three address some very common and general algorithms-and-data-structures use cases.  What are some other recent discoveries or developments that would affect the performance of some of our most common uses?",2024-01-07 21:01:23
16u5c4d,Why does nobody talk about TCS and CS research?,"I feel like there’s a big lack of media coverage for these fields, and it’s a bit saddening because I think I’m interested in them, but have no public figures that I can follow.

I think I keep going back and forth between physics and CS in my mind because of this. I like both subjects, but nobody talks about CS research which makes me feel like I wouldn’t have a good career path if I took that route.",2023-09-28 03:35:48
1328gqe,Is Bernstein's hash congruential? Is (a * C + b) % 1 an LGC?,"I read somewhere that Bernstein's hash aka DJB2 hash that is basically, `(hash * 33) + byte`, a congruential algorithm. Like an LGC. But since I'm new to this I do not understand where the modular arithmetic happens? Did the person who said this meant it's ""like-like congruential"" or is there some magic I am unaware of? Of course the hash can be redefined as an LGC -> `(((32 * hash) + hash) + byte) % 1`. But is a modulo of 1 even considered in LGCs?

btw please read this regarding the beginner-level of my question(s):
https://pastebin.com/Y7rPKDRz

Thanks.",2023-04-28 20:13:22
18gaetx,What are some relatively unknown CS books which are gems?,N/A,2023-12-12 01:44:42
17d868n,How do Computer Science Professors come up with projects for the classes they teach?,"On the one hand, you have to make sure the project is actually doable for students at that level, whether it's an introductory computer science course or a more advanced course. On the other hand you don't want students to just be able to find the project on somebody's GitHub/GitLab/SourceHut and be able to easily figure out what to do. So how exactly do CS professors come up with the projects they assign to their students? ",2023-10-21 17:49:00
150c1fl,How do you decide which data structure to use?,"As someone preparing for Fresher Interviews and OA rounds, I'm really curious what are the details of a problem (both in competitive coding and Development work) that trigger your mind to use a certain data structure over another?

How do you know a Stack is more a appropriate than an array or a graph in a certain situation, and so on?",2023-07-15 13:26:31
14ns4li,How are cross-platform libraries implemented ?,"There is a concept that I didn't understand when I first learned programming: how are library functions in high-level languages implemented? Functions that deal with graphics, networking, file storage, and access to devices—what is their code like?

I've come to understand the concept of an operating system API. If your program wants to interact with these devices, it will call an OS API. These APIs are mostly written in C, which means that high-level languages like Java and Python actually call C code (how does that even work ?) to interact with devices and the operating system. But I have two questions:

1. If a high-level language library is cross-platform, does that mean it checks which OS it is currently running on and then uses the appropriate OS API? Is this how cross-platform technologies work in general?
2. How do OS APIs work internally? How do they relate to system calls? Are they just wrappers for system calls? And where do device drivers fit into this?",2023-07-01 10:52:42
1354n5h,Nerd sniping: Optimal one shot sorting algorithm (request),"There's a game going around on TikTok which a player has 20 slots. Each turn a random number from 0 - 999 is drawn and the player must put the number in a slot in ascending order.

For example if the first number drawn is 500 you might place that at spot #10. The next number could be 505 which then #11 might be a good spot for it. If on your next draw you get 503, you lose.

The player wins if you can sort all 20 numbers.

What's the optimal strategy? If played perfectly what's the probability of winning?

Bonus points for generalizing to a list of n numbers from 0-m where m>n",2023-05-01 23:20:02
1am2q3u,Why are the values of bit numbers of different lengths different?,"Why does 0.01 give a value of 1/4 and 0.010 gives a value of 2/8? I understand that they are the same numbers in the end, but I don't understand why their values are written differently.

I calculated the decimal places like this:
01 = 0 * 2^-1 + 1 * 2^-2 = 0 + 1/4 = 1/4

010 = 0 * 2^-1 + 1 * 2^-2 + 0 * 2^-3 = 0 + 1/4 + 0 = 1/4

Where did the 2/8 come from?",2024-02-08 18:37:48
15xxsfc,First paper introducing the hashtable?,"Hello, just for fun does anyone know any old cs papers which might be the first to discuss the hashtable / hashmap data structure as an alternate container?  Or would this type of thing be developed so early on before there were even papers being written in the field?",2023-08-22 07:02:15
14iyb3s,Debugging: A Competitive Programmer Approach,N/A,2023-06-25 21:45:19
15gosna,"FYI: there is indeed a new version of Tannebaum's OS book, except it has no code","A few days ago, someone has posted here complaining that AST's seminal MINIX3 book has not seen a new edition since 2006. Well there IS a new version, it's just released under a different title ('Modern Operating Systems') and most of the text is either the same, or reworked from the MINIX3 book. And it has no code attached to it. But see MINIX3 itself has seen some updates and there's not really a need to release this book along with code because people can just use the MINIX3 wiki to stay up to date. 

Anyways this edition is a very good book, highly recommend it. By the same publisher, even has the same Tannenbaum cover shenanigans. The cover has a BLUE tint, if you're in the book store, if it has a green tint, it's the old book.",2023-08-03 00:22:06
16y32zf,How do webservers listen for new requests and also process requests at the same time?,"When I run a webserver, how does the webserver listen for requests and also serve them at the same time?   
Lets assume the webserver uses one acceptor thread and has a worker thread pool of some size N. Lets also assume that the OS is only able to schedule a single thread each time, either an acceptor thread or a worker thread and no two threads ever run in parallel, which is one of the possible cases. 

My question is, what happens when a worker thread gets scheduled and a new request comes in? Is the request just lost? Does the new request lead to some kind of interrupt being raised, making sure that the acceptor thread gets scheduled? Or does the NIC generate some sort of interrupt when a new request comes in and this request is stored in a buffer somewhere in memory and then processed when the acceptor thread gets scheduled again? 

If someone could shed some light on this for me, that would be helpful.  
Thank you.",2023-10-02 17:43:18
166jcph,Generating Chess Puzzles with Genetic Algorithms,N/A,2023-08-31 18:45:51
153ugnm,"Typed Design Patterns for the Functional Era. ""I present four concrete examples embodying this idea: the Witness, the State Machine, the Parallel Lists, and the Registry. Each pattern is implemented in Rust"" [abstract + link to PDF, 9pp]",N/A,2023-07-19 13:03:07
14hnvju,Introduction to Dependency Graph Analysis,N/A,2023-06-24 08:53:17
18z0c2w,Best YouTube channels to casually learn Operating Systems,"I’m going through a class on Operating Systems and it’s phenomenal (specifically CS 162 from Berkeley by John Kubiatowicz).

Though the lectures are 1.5 hours long and sometimes I lack the attention span.

I want to keep up this knowledge and sometimes dive deeper into parts of operating systems less covered or just more fun to learn about tbh. Anything low level in general is also fun to learn about.

I personally found [Low Level Learning](https://youtube.com/@LowLevelLearning) and [Ben Eater](https://youtube.com/@BenEater) to be very fun channels to watch. Do y’all have any other YouTube channel recommendations?",2024-01-05 06:38:45
18tscx8,Best paper awards in computer science over the past 28 years (1996-2023),N/A,2023-12-29 17:27:26
18pneyn,Parsers and CAS (Computer Algebra System),N/A,2023-12-24 04:28:04
17de56l,What are some recommendations for computer science and philosophy books?,"I'm interested in reading books about computer science which are told from a philosophical perspective. I saw a post here but it was posted a decade ago, so any more recent recommendations would be great :)",2023-10-21 22:22:01
12tu2vh,Merge Sort And It's Early History,N/A,2023-04-21 07:36:33
12rwbiu,Back to the Future with Time Series Continuous Validation,N/A,2023-04-19 15:07:20
17zmslh,Recommend me some fields in CS that you find interesting!,"I just wanna know what sub fields in computer science are you guys learning, or doing research. What fields are worth learning about currently?",2023-11-20 11:49:36
15j5uwy,How to Mathematically Prove that a Neural Network is Converging Faster,"Hello r/compsci!

I'm working on understanding how a neural network converges faster and wish to approach this mathematically. Can anyone recommend resources, papers, or tools that could assist me in proving this?

Thank you in advance for your help!  


Edit: Removed converges faster to remove ambiguity",2023-08-05 20:30:18
15gv6x4,Introducing PokerKit: An Open-source Library for Poker Games and Hand Evaluations,"Hello everyone,

We're excited to announce the launch of our project: PokerKit, a comprehensive open-source Python library for simulating poker games and evaluating hands. This is a project developed by the University of Toronto Computer Poker Research Group.

PokerKit offers a wide range of poker variants, supports extensive game logic, and facilitates swift hand evaluations, all with an intuitive interface. It provides not only a diverse set of hand types and game variants, but also fine-grained controls over game states, making it highly flexible for a variety of tasks and applications.

This library can be an excellent tool for AI development, poker tool creation, and even for the infrastructure of online poker casinos. We're excited to see the innovative ways you will use PokerKit, whether it's for research, game development, or just for fun!

To get started, you can install PokerKit by running ""pip install pokerkit"". You can find more details, including usage examples, on our GitHub repository at [https://github.com/uoftcprg/pokerkit](https://github.com/uoftcprg/pokerkit). We encourage you to contribute to this project and we appreciate your feedback!

We hope that PokerKit will serve as a valuable tool for researchers, developers, and poker enthusiasts alike!",2023-08-03 05:35:52
1afge1t,Bottom-up vs Top-down CS Education,"Bottom-up:

  \- Mathematics --> CS theories --> Programming/Frameworks etc.

Top-down:

  \- Programming/Frameworks etc. --> CS theories --> Mathematics  


Obviously everyone learns differently, but personally for you, which one do you think is the best path to learn CS, and why?",2024-01-31 12:08:43
163x3hq,"Understanding Topology-Based Data Architectures: Data architectures can be classified based on their operational mode or topology, including data fabric, data hub, and data mesh. Here's the distinctions.",N/A,2023-08-28 20:30:06
1418wpy,Why We Don't Use the Mean Squared Error Loss in Classification,"Hi there,

I have made a video [here](https://youtu.be/bNwI3IUOKyg) where I explain why we don't use the mean squared error (MSE) loss for classification problems.

I hope it may be of use to some of you out there. Feedback is more than welcomed! :)",2023-06-05 09:39:07
193n8qi,80s BASIC vs Modern languages (in the context of coding education),"How do you compare the coding tools available for young students today with microcomputers from the 80s, such as the ZX Spectrum, BBC Micro, Commodore 64, etc.?

  
Despite their limited specifications, many people considered those early machines excellent for coding education. They provided a built-in language (BASIC), a built-in code editor, and a graphical-based API for printing and drawing on the screen.

  
Do you agree, or do you think that Scratch and Python offers more advantages?

&#x200B;

https://preview.redd.it/wyn1ng4tapbc1.jpg?width=1420&format=pjpg&auto=webp&s=3c7474c8e4fc6be688f141f7e5c7a8bb062b86d9",2024-01-10 23:54:34
169lt3f,"what are your favourite computer science, maths or tech related books? (not textbooks)","What are your favorite books on those topics? I don't mean textbooks for learning (like Introduction to Algorithms). I've been reading a wide range of literature, from Kafka to philosophy like Nietzsche, and science (such as Gödel, Escher, Bach). So, I'm hoping there are some book enthusiasts here who can recommend interesting books in the fields of computer science, math, and technology. They can be novels, biographies, or non-fiction books. 

Thank you!",2023-09-04 07:54:42
17ydn18,An example needed where OOP has clear advantage over functional (-like) paradigm,"Quick background: quasi self-taught CS hobbyist who has been doing computational research with Python using numpy, cupy etc. Have done an OOP-heavy base course with Scala that introduced also functional stuff. During my research, I took a deep dive to learn about history of compsci and different paradigms and philosophy. Out of curiosity I found Haskell and functional way of thinking. 

The more I have coded and studied the foundations, the more I'm disliking the fact how OOP is the way of programming most people face first. So let's set our basis: let's have OOP and all it's flavors with duck typing, interfaces, inheritance, multiple dispatch at our disposal. Then we'll have functional-like way say using Python where we create dataclass objects i.e. they are just classes but no methods, only fields. We'll have functions that are strictly typed and they can take functions as their inputs.

Please, give some pseudocode example or a scenario (can be some large-scale project) where the modern OOP has a clear advantage over the functional-like approach. Advantage can be conceptual (easier to understand), scalability, maintainability, flexibility etc. 

I'd like to have a friendly debate on this as I really think that functional or functional-like approach leads to more sane code than modern OOP especially with ""design patterns"" where some of them solve non-issues. I'm still naive and don't have the expertise. Also if there is a better subreddit, please inform!  ",2023-11-18 19:14:33
17rncs0,"Tip of my tongue: A theorem that my professor described as ""The best step we have taken towards P ?= NP""","Hey! I recently visited my prof's office for a seminar project and, like everyone at my faculty, he had something scribbled on the whiteboard behind his desk. I was interested and asked him what it was and he gave me a name and description so I could look it up, but I forgot already :( I don't want to annoy him by emailing and hoped one of you could help me out.

I think it was named for two people, perhaps one was Eastern European? Not quite sure. He said it was a good approach to gathering evidence towards an answer to P ?= NP. Googling has only led me to the usual entry level descriptions, TV interviews, Quora questions and so on. I would guess it was something of current research interest because he was clearly working on, or at least playing around with it. If any one of you has an idea what theorem or algorithm it could be, that would be greatly appreciated!",2023-11-09 21:20:30
162qvwc,Detecting errors in LLM responses," We just released as study where we show that a ""diversity measure"" (e.g., entropy, Gini, etc.) can be used as a proxy for probability of failure in the response of an LLM prompt; we also show how this can be used to improve prompting as well as for prediction of errors.

We found this to hold across three datasets and five temperature settings, tests conducted on ChatGPT.

Preprint: [https://arxiv.org/abs/2308.11189](https://arxiv.org/abs/2308.11189)

Source code: [https://github.com/lab-v2/diversity\_measures](https://github.com/lab-v2/diversity_measures)

Video: [https://www.youtube.com/watch?v=BekDOLm6qBI&t=10s](https://www.youtube.com/watch?v=BekDOLm6qBI&t=10s)

&#x200B;

[Example result showing correlation of entropy with failure probability](https://preview.redd.it/9hs68ouhqnkb1.png?width=392&format=png&auto=webp&s=196e0e6bf7e494b36c9f50e9116dd8b2ae526015)

&#x200B;",2023-08-27 13:47:47
151g51m,What are some computer science topics where intensive research is going on ?,N/A,2023-07-16 20:08:56
14xuu1o,"""typeof"" operator in a formal theoretical framework with lambda calculus?","In practice, many language support some kind of typeof. For instance, \`typeof\` in C, \`decltype\` in C++, \`type()\` in python, \`typeOf\` in Haskell.

**How would you understand typeof in terms of formal lambda calculus?**

In particular, in what sort of formal language, the \`typeof\` is **part of the language itself**?

(I have learnt some lambda calculus, but I have not found any first-class ""typeof"" in any of the theory I have seen.)

*(Mathematically, when analysing a formal language, we always have a notation of some form representing the type of a value. But often, that notation is* ***not*** *in the language* ***itself***\*, and that's\* ***not*** *what I am asking about.)*

**In each of the following situation, does there exist a typed lambda calculus framework which has the behaviour described?**

1. In python, \`type\` is just a function (class constructor), which is a first-class citizen, and types are also **first-class** citizens. Interestingly, you can apply \`type()\` 1000 times to a variable.
2. In C/C++, things are uninteresting, because \`decltype\` or \`typeof\` can almost always be avoided. Does that mean the existence of \`typeof\` does not make much of a difference in terms of the formal structure of the lambda calculus (if we have such a structure)?
3. In Haskell, types are also first-class citizens. Is it different from python?

Please do not mention that python fits into untyped lambda calculus. That is not the point. The point is to have a clear concept of types in the language itself, and have a function in the language itself mapping a term to its type.

Does any expert know the connection between theory and practice in this regard?",2023-07-12 17:22:27
1990dyy,Cognitive Load In Software Development,N/A,2024-01-17 16:18:38
18t21a0,I created a collision detection algorithm for arbitrary polygons. Im wondering if the method i used is already in existence somewhere.,"So i thought of a way to detect if two arbitrary polygons, including concave ones, are colliding. Its really simple, way simpler than Separating Axis Theorem and per my tests seems even faster for higher edge counts.

The idea goes like this:

Step 1 (optional): I perform area checks, as a break-early condition. I calculate negative space on both polygons by subtracting polygonal area from bounding box area, then if intersectional bounding box area is greater than the negative space of both polygons, i declare a collision has occured. I also do this with bounding circles to gracefully handle many-sided regular polygons.

Step 2: I pick a single vertex on the smaller of the two polygons, preferably the one closest to the midpoint of the other polygon, and i perform a Point-In-Polygon / raycasting test on the other polygon. If true i declare a collision.

Step 3: I calculate the sides of each polygon derived from its points, filter them based on the bounding box of the opposing polygon, then compare the sides of Polygon A to Polygon B. Between the two previous break early conditions and filtering the sides its usually efficient even with many-sided polygons, but in theory (i think), this could degenerate to exponential operations.

The rationale is that comparing sides will necessarily detect all edge collisions, then to handle the circumstance of one polygon being inside of the other with no intersecting sides, a single point in polygon test using any vertex will prove the entire shape is not in that polygon.

I tested this against an implementation of SAT against 2 2000-sided polygons, my runtime was \~3 ms while SAT was \~50 ms.

So my question is, is the method im using well known somewhere, and if so, whats the actual advantage of separating axis theorem? Isnt SAT more linear in theory? But does linear in theory matter if in practice its the opposite?",2023-12-28 19:18:40
15vgadq,Gaussian Mixture Models Explained,"Hi there,

I've created a video [here](https://youtu.be/wT2yLNUfyoM) where I explain the main ideas and mathematics behind the Gaussian Mixture Models.

I hope it may be of use to some of you out there. Feedback is more than welcomed! :)",2023-08-19 13:27:18
15ah3bl,Sublinear Time Shortest Path in Expander Graphs,N/A,2023-07-26 20:39:35
12y6ago,Using Neuro-Fuzzy Systems to Model the Human Thinking,N/A,2023-04-25 03:08:48
18fasl1,Scrambling eggs for Spotify with Knuth's Fibonacci hashing,N/A,2023-12-10 19:10:36
15l1d5o,This guy has taken his time to implement all the string searching (strstr(3)) algorithms. Amazing.,N/A,2023-08-07 23:51:39
14lioym,Protein-Protein Interaction Prediction is Achievable with Large Language Models,N/A,2023-06-28 19:30:19
17nsesr,How large is the zoo of Turing-complete models of computation?,"There are many formally equivalent ways to do computation; lambda calculus, turing machines, cellular automata, cyclic tag systems, differential equations, langton's ant, neural networks, etc. 

Is the number of possible computational models known? Is it finite? Infinite? Uncountably infinite?",2023-11-04 18:51:05
17cev89,"How well is Drepper's ""memory"" paper holding up?","I was recently made aware of Ulrich Drepper's paper [What Every Programmer Should Know About Memory](http://people.redhat.com/drepper/cpumemory.pdf), written in 2007.  Since then, the interaction between processing units and memory has become significantly more complex.  

My questions as a dilettante are:

1. Is this paper still worth reading, and if so what are the caveats?
2. Are there any more modern papers of its kind worth checking out?",2023-10-20 16:08:18
15jqugn,Turing's Maze - From Mouse to Mandelbrot,N/A,2023-08-06 14:22:04
15e7pan,What are some fun activities to teach computer architecture concepts to middle schoolers?,Basically I get to teach 6-8th graders about low level computer concepts but I want to do it in an interactive engaging way where I’m able to teach them both theory and demonstrate how to assemble electrical components using breadboards. Any ideas on ways to make the class fun?,2023-07-31 06:05:12
143wh6u,Understanding Alpha Dev Sorting Algorithm,"I'm having trouble understanding the AlphaDev sorting algorithm improvement that was announced today. But my issues begin with the original sort3 algorithm they provide. I have some familiarity with assembly instructions, but this algorithm is unintuitive for me. I thought I had it until the last three line, and their comments. I don't see why/how Memory\[2\] can never be assigned the value B. I think of the adverse case where M\[0\] = 0, M\[1\] = 100 and M\[2\] = 0. I, this case, surely B would have to be assigned to M\[2\] after sorting? But this is not possible by getting the max(A,C). Some clarification on this would be appreciated, and I think would enable me to understand the AlphaDev solution. I run into a similar problem understanding why in that solution C can never be the smallest value/be assigned to M\[0\]. I am sure I am misunderstanding some part of the code, or the meaning of the comments. Any insight is appretiated!

[https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms](https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms)

&#x200B;

https://preview.redd.it/09n005yddp4b1.png?width=1280&format=png&auto=webp&s=5ea9f95eb6582c5fbec6d2c233159f9686d3d4e2",2023-06-08 02:17:43
17qdybi,What is your favorite non-realistic/wacky sorting algorithm?,"We were having a discussion on sorting algorithms at my ACM club at my college and someone brought up the gnome sort. Gnome sort is a pretty wacky name for a sorting algorithm, but I wanted to post here to see if anyone else has any other sorting algorithms, or algorithms in general that they think are cool or funny. I think the >!brainfuck !<programming language is pretty wacky.",2023-11-08 04:38:20
150zwf6,The Hungarian Algorithm for Object Tracking,"Hi there,

I've created a video [here](https://youtu.be/oo-H_ZY2TGA) where I explain how the hungarian algorithm works and how it can be applied in object tracking.

I hope it may be of use to some of you out there. Feedback is more than welcomed! :)",2023-07-16 07:36:25
14s5nhp,A modified version of the Halting Problem?,"We know that the Halting Problem is undecidable. But what if we take a modified version where we swap the logical quantifiers around. The original Halting Problem says that there doesn't exist a general algorithm/procedure such that for any given computer program and input pair, following the procedure will tell us whether the program will halt.

But is the following distinct but similar question also undecidable: For any computer program and input pair, does there exist an algorithm that can determine whether the program halts.

Could someone provide me of a proof or a counterexample?",2023-07-06 10:55:36
192m2x6,"We can solve 3-SAT ""quickly"" by applying it to superposed booleans on interaction nets",N/A,2024-01-09 18:45:22
18z1bdp,How important is Discrete Structures in Computer Science?,"
I have the option to take discrete mathematics to cover my discrete credit for both my math and cs major. If i take discrete structures, i’ll have to take discrete mathematics anyway. Discrete structures focuses more on trees and heaps, and discrete mathematics focuses more on the math side of things. would it be worth just to take discrete mathematics or both discrete mathematics and discrete structures?

Discrete structures covers “set algebra including mappings and relations; algebraic structures; elements of the theory of directed and undirected graphs; Boolean algebra and propositional logic; these structures applied to various areas of computer science”


and discrete mathematics involves “formal logic, set theory, counting, discrete probability, graph theory, and number theory. Emphasis on reading and writing rigorous mathematics”",2024-01-05 07:41:00
15cqzr0,Merge Strategies: from Merge Sort to TimSort [pdf],N/A,2023-07-29 12:21:46
159pnvw,Is there a good datastructure for scope based maps?,"Suppose we have a partial function mapping `String -> val`. Suppose we are in a given scope or context that has an existing mapping. We may add items to the mapping, and some of them will be duplicates that overwrite values in the mapping, then we can pop them all off in an operation. I'm wondering if there's an efficient data structure that can give me a good runtime for lookups and popping off a stack frame.

Here's an example usage of what the data structure may look like
```
stack.put(""key1"", a)
stack.put(""key2"", b)
statck.pushState()
   stack.put(""key2"", c)
   stack.get(""key2"") // c
stack.popState()
stack.get(""key2"") // a
```
One option is to just use a list of maps, and we just traverse backwards to find the most recent item. Lookup may be in `O(n)` where `n` is the number of stackframes, but popping off the state is `O(1)`

Can we do better than this?",2023-07-26 00:01:21
146xqkc,Is the following language decidable?,"L = {w ∈ Σ∗ | 2 ≤ |T (Mw)| ≤ 4}.

I thnik it is not decidable. 

We can reduce H to L, since in order to have 2 <-> 4 Elements in T(Mw) we would need to solve Halting problem which is not possible (Because we are talking about all TMs). 

Is this correct? 

If so, is there any function that reduces from H to L?",2023-06-11 16:06:50
1823aip,How to start with Kernel Development,"I have good experience of C/C++/Go and am experienced in Systems Programming. Done academic projects on Concurrent Data structures, Concurrent Runtime, Garbage Collection, Network programming etc.

But never touched Kernel Programming.
I have the following questions.

1. How to start with Kernel programming?
2. I will be graduating in 2024. Any project that can be done within 2/3 months to show kernel  programming experience?

Thanks.",2023-11-23 15:13:17
15xnzlh,WTH are 'regex derivatives'?,Can someone pls explain these to me? I don't understand how it could be applicable to more complex patterns. Thanks.,2023-08-21 23:30:24
195kb4a,Why is mkdir slower as we get deeper into the directory hierarchy?,"Consider the following program in C:

    #include <stdio.h>
    #include <unistd.h>
    #include <sys/stat.h>
    
    int main(){
        size_t const N = 10000000;
        for(size_t i = 0; i<N; i++){
            printf(""%zu\n"", i);
            mkdir(""1"", 0700);
            chdir(""1"");
        }
        return 0;
    }

On my filesystem, the program gets slower and slower as `i` increases, after making tens of thousands of directories.

I do not understand this. Isn't creating a directory just

1. Allocating a little space on disk,
2. Write a link from the current directory to the allocated space,
3. Write links for . and ..

NONE of these operations have anything to do with directory hierarchy depth. Basically, we start with the file descriptor of the current directory, and there is no need to traverse the entire hierarchy. The permission info of the current directory should already be cached. So why is it slowing down?

\[Also posted here: [https://www.reddit.com/r/filesystems/comments/1958e7y/why\_is\_mkdir\_slower\_as\_we\_get\_deeper\_into\_the/](https://www.reddit.com/r/filesystems/comments/1958e7y/why_is_mkdir_slower_as_we_get_deeper_into_the/?utm_source=share&utm_medium=web2x&context=3)\]",2024-01-13 09:30:48
18unlmp,🏆 Most read articles across engineering blogs in 2023,"I've recently compiled a list of the most read articles across engineering blogs in 2023.

I considered the engagement across **Hackernews**, **Reddit**, and **X**. With some help of Python and Jupyter, I’m excited to share the final list!

1. 🥇 [**""How Meta built the infrastructure for Threads""**](https://engineering.fb.com/2023/12/19/core-infra/how-meta-built-the-infrastructure-for-threads/) *by Laine Campbell, Chunqiang (CQ) Tang ⸱ Meta ⸱ 9 min read ⸱ 19 Dec 2023*\- Discusses the successful launch of Meta's Threads and the infrastructure behind- Describes the use of ZippyDB, a distributed key/value database, and how it was optimized for the Threads launch- Explores the role of Async, a serverless function platform, in scaling workload execution for Threads
2. 🥈 [**""Slack’s Migration to a Cellular Architecture""**](https://slack.engineering/slacks-migration-to-a-cellular-architecture/) *by Cooper Bethea ⸱ Slack ⸱ 9 min read ⸱ 22 Aug 2023*\- Tells a story about migration from monolithic to cell-based architecture at Slack- Introduces the concept of gray failure in distributed systems- Explains how Availability Zones can be drained- Covers the implementation of siloing and traffic-shifting in cellular architecture
3. 🥉 [**""Migrating Netflix to GraphQL Safely""**](https://netflixtechblog.com/migrating-netflix-to-graphql-safely-8e1e4d4f1e72) *by Jennifer Shin, Tejas Shikhare, Will Emmanuel ⸱ Netflix ⸱ 8 min read ⸱ 14 Jun 2023*\- Describes the migration of Netflix's iOS and Android apps to GraphQL with zero downtime- Explores the use of three key testing strategies: AB Testing, Replay Testing, and Sticky Canaries, to ensure a safe and smooth migration- Covers the phased approach to migration, including the creation of a GraphQL Shim Service and the subsequent transition to GraphQL services owned by domain teams- Discusses the challenges and wins of each testing strategy- Shares insights into the tools developed, such as the Replay Testing framework and Sticky Canaries, to validate functional correctness, performance, and business metrics during the migration
4. [**""What is an inverted index, and why should you care?""**](https://www.cockroachlabs.com/blog/inverted-indexes/) *by Charlie Custer ⸱ Cockroach Labs ⸱ 7 min read ⸱ 17 Aug 2023*\- Describes how inverted indexes work and their impact on database performance- Explores the downsides of using inverted indexes, specifically the minimal impact on write performance- Covers how to use inverted indexes, including when and how to create them- Shares examples and best practices for using inverted indexes in relational databases
5. [**""Scaling the Instagram Explore recommendations system""**](https://engineering.fb.com/2023/08/09/ml-applications/scaling-instagram-explore-recommendations-system/) *by Vladislav Vorotilov, Ilnur Shugaepov ⸱ Meta ⸱ 11 min read ⸱ 9 Aug 2023*\- Discusses the use of Machine Learning in the Explore recommendation system on Instagram- Describes the use of Two Towers neural networks to make the recommendation system more scalable and flexible- Explores the use of task-specific DSL and a multi-stage approach to ranking in the system- Covers the use of caching and pre-computation with Two Towers neural network to build a more flexible and scalable ranking system- Introduces techniques such as Two Tower NN and user interactions history in the retrieval stage, and the use of Bayesian optimization and offline tuning for parameters tuning.
6. [**""Understanding Real-Time Application Monitoring""**](https://medium.com/expedia-group-tech/essential-application-monitoring-metrics-a08519ecab9d) *by Ritesh Kapoor ⸱ Expedia Group ⸱ 7 min read ⸱ 13 Jun 2023*\- Covers the performance indicators and SLI/SLO/SLA concepts for application monitoring- Shares different categories of metrics, including application VM, API, database response, infrastructure, and more- Explores the importance of monitoring distributed tracing for troubleshooting requests with high latency or errors- Gives an overview of the challenges of improving operational performance and the benefits of monitoring applications with the right metrics and tools
7. [**""Improving Performance with HTTP Streaming""**](https://medium.com/airbnb-engineering/improving-performance-with-http-streaming-ba9e72c66408) *by Victor ⸱ Airbnb ⸱ 7 min read ⸱ 17 May 2023*\- Describes how HTTP Streaming can improve page performance and how Airbnb enabled it on an existing codebase
8. [**""How does B-tree make your queries fast?""**](https://blog.allegro.tech/2023/11/how-does-btree-make-your-queries-fast.html) *by Mateusz Kuźmik ⸱ Allegro ⸱ 12 min read ⸱ 27 Nov 2023*\- Introduces B-Tree as a data structure and clarifies B-Trees vs. BSTs- Explains B-Tree organization and search queries- Explores the practical implications of using B-trees on hardware, including CPU caches, RAM, and disk storage- Explains how packing multiple values into a single node reduces random access and enhances query performance- Addresses balancing in a B-Tree
9. [**""Meta developer tools: Working at scale""**](https://engineering.fb.com/2023/06/27/developer-tools/meta-developer-tools-open-source/) *by Neil Mitchell ⸱ Meta ⸱ 4 min read ⸱ 27 Jun 2023*\- Describes Sapling, an open-source version control system designed for extreme scale- Covers Buck2, a build system supporting remote caching and execution for large-scale development- Explores testing and static analysis tools used at Meta, including Infer, RacerD, and Jest- Presents Sapienz, a tool for automatically testing mobile app
10. [**""How Gradle Reduced Build Scan Storage Costs on AWS by 75%""**](https://gradle.com/blog/how-gradle-reduced-build-scan-storage-costs-on-aws-by-75/)  *by Oliver White ⸱ Gradle ⸱ 4 min read ⸱ 23 Jun 2023*\- Describes the challenge faced with inefficient cloud storage using Amazon RDS- Presents the decision to migrate to Amazon S3 as the solution- Shares the immediate 75% reduction in cloud expenses as a result of the migration- Explains the added benefit of enabling automatic deletion for unactivated scans after the migration
11. [**""Real-time Messaging""**](https://slack.engineering/real-time-messaging/) *by Sameera Thangudu ⸱ Slack ⸱ 7 min read ⸱ 11 Apr 2023*\- Describes the architecture used to send real-time messages at scale- Discusses the setup of the Slack client, including the use of Webapp, Envoy, and GS to establish a websocket connection- Explains the process of broadcasting a message to all online clients following the journey of the message through the stack- Covers the different types of events, including regular traffic spikes for reminders, scheduled messages, and calendar events
12. [**""How Discord Stores Trillions of Messages""**](https://discord.com/blog/how-discord-stores-trillions-of-messages) *by Bo Ingram ⸱ Discord ⸱ 3 min read ⸱ 6 Mar 2023*\- Describes problems with a Cassandra database storing billions of messagesCovers the impact of hot partitions on latency and end-user experience- Shares the challenges of cluster maintenance tasks and compactions- Discusses the frequent tuning of JVM's garbage collector and heap settings to address latency spikes

I hope you enjoyed it!

**I'm building a 📬 newsletter called** [**Big Tech Digest**](http://bigtechdigest.substack.com) **where I send the latest articles  found across 300+ Big Tech and startup engineering blogs like Uber, Meta, Airbnb, Netflix, ... every two weeks.  I think you might find it useful.**

**I'd also highly appreciate if you retweeted or liked** [**this X thread**](https://twitter.com/bigtechdigest/status/1740321118672838915)**.**",2023-12-30 19:32:48
15c5vu9,How to interpret physical memory addresses,"So I'm taking a course in Operating Systems and I've come across diagrams of main memory (including the memory addresses), and I'm not sure how to interpret them for available memory space. For example in this diagram:

https://preview.redd.it/ij5yhztw5reb1.png?width=333&format=png&auto=webp&s=fce7878b570e7c12166e9498d23ce9eedd9c4c9e

The lecturer says that at the bottom, 4MB are not in use. I'm not fully sure why the space between 0x0 and 0x400000 represents 4MB. Let's even simplify it to 0x100000. This represents 16\^5 or 2\^20 bits. 1 Mebibyte is 2\^20 BYTES, though. Not bits. So then, does each memory location refer to 1 byte of space? Is the word size then, 1 byte?",2023-07-28 18:55:16
143max1,Interview with Andrew Ng and Chris Manning: Natural Language Processing,N/A,2023-06-07 19:22:45
13p4065,A question about reaching definition analysis,N/A,2023-05-22 21:29:25
1852b98,In which situation should a Segmented Tree should be used instead of Fenwick Tree / Binary Indexed Tree?,"I was going through some theory on ST (Segmented Tree) and BIT (Binary Indexed Tree), and I came to know that BIT is more memory efficient, has smaller constant (In context of time complexity), has same complexity as ST, and is faster in construction from a given array.

So my question is, In which situation should a Segmented Tree should be used instead of Fenwick Tree / Binary Indexed Tree?",2023-11-27 12:54:15
175d9o9,Hegel 2.0. The imaginary history of ternary computing,N/A,2023-10-11 12:50:25
16l8unr,The first complete and open source implementation of Alan Turing's famous paper,N/A,2023-09-17 18:54:49
14sw2ep,Computer Science research papers related to chess?,"I am a pretty avid chess player, and also a CS major potentially interested in Research (rising sophomore rn). I know there's plenty of overlap with the two topics, but for some reason I can't find much material on Computer Science research topics relating to Chess. Surely I'm searching the wrong stuff as there has to be a decent amount of papers published relating to chess in the CS realm right? If y'all know any good papers or could help me find some good ones I'd really appreciate that, thanks!",2023-07-07 04:08:46
13vaazj,Cryptographic Ghost Proofs (CGPs) are Merkle Multiproofs for Sparsely Activated Tensors that enable the generation of cryptographically verifiable neural outputs. CGPs open up a new paradigm for peer-to-peer AI systems.,N/A,2023-05-29 23:42:18
18qeu53,Books or articles on Nice algorithms for doing Linear Algebra Operations,"I am trying to find books or surveys on algorithms which involves doing computational linear algebra.
I found one book [Linear Algebra Methods in Combinatorics](https://people.cs.uchicago.edu/~laci/babai-frankl-book2022.pdf) which involve this but i wanna find more of these.",2023-12-25 08:40:12
17s7cu5,[Question ]encrypted computation is this a thing?,"Bear(bare?)with me, i have an idea , however I think it is either impossible or it is already being done but has a different name.

The idea is that the actual instructions/data a CPU carries out are already ""encrypted"" in some way. 

So you want A  processed into B, but you don't want to give the CPU A.

So run A is masked with a public key beforehand to be C and then processed to create to D, you then use the a private key to to turn D into the B you wanted.

&#x200B;

&#x200B;

&#x200B;

&#x200B;

&#x200B;",2023-11-10 16:12:14
1594yar,"Demonstrating Rob Pike's LL(1) lexer which he used in Go templates, but in C, also applicable in general Finite State Machine implementations (e.g. embedded/bare metal context)",N/A,2023-07-25 10:48:51
18m2y94,"Is the problem of ""finding the output given the algorithm halts"" not computable?","Originally posted here [https://cs.stackexchange.com/q/164611](https://cs.stackexchange.com/q/164611)

For simplicity, let's assume all Turing machines print 0 or 1 on the tape. Consider an algorithm $A$ (which is guaranteed to halt), which, given any Turing machine $T$ as the input, always outputs a single digit $x\in \{0,1\}$, such that x satisfies the condition that if $T$ halts, then the last symbol printed by $T$ is $x.$ 
When $T$ does not halt, it does not matter what the output of $A$ is, as long as it halts and outputs 0 or 1.

Is it the case that algorithm $A$ does not exist (and thus the problem is undecidable)?

EDIT: assume that the input of T is bundled with T, so we do not need to care about input.

CLARIFICATION: I have clearly stated that A must halt even when T does not.",2023-12-19 14:19:04
16rlkms,Can a regular language have more than one pumping length?,"Also if we can't prove that a language is not regular using the pumping lemma, does it mean that it's a regular language? could it still be a non-regular language? Do all non-regular languages contradict the pumping lemma?",2023-09-25 07:37:50
16nhkdd,Documentaries that give historical context on Operating Systems,"
I’m taking my first course on operating systems and I’m quite interested in knowing how we went from a bunch of engineers tinkering at Bell labs to where we are today. I’d love to know more about the people involved and the stages of development and changes that OS technology went through over time.",2023-09-20 10:15:16
151otjl,"Harvard, Von Neumann, and... What else?","What other major types of processor architectures are there? I want to have a basic idea of all of them.

So far I have heard of :

- Harvard

- Modified Harvard

- Von Neumann


If you know of more please let me know.",2023-07-17 02:13:13
14mx78a,Is this language decidable or not? Why?,"Assume we have a language called ""A"" which only includes string ""s"" such as:
s = 0, if God does not exist
s = 1, if God exists
Is this language (A) decidable or not? Why?
(A language is decidable if and only if some Turing machine decides it.)
(The answer to this question has nothing to do with religious beliefs.)",2023-06-30 10:59:07
135jt86,Simulating Turing Machines with Wang tiles,"Here is a Python program that demonstrates how to compute with Wang tiles in practice, ie:

* encode any Turing machine into a set of Wang tiles
* deterministically generate a tiling for any input
* exhibit the computation result in the last row

Source code is available on [https://github.com/nst/WangTilesTuringMachines/](https://github.com/nst/WangTilesTuringMachines/).

*Processing img 17atm191jlxa1...*",2023-05-02 12:30:33
11b4pvh,Techniques for Scaling Applications with a Database,N/A,2023-02-24 22:55:51
19bb8rk,Why was CP/M so much more expensive than MSDOS?,"Gary Kidall's OS was priced by IBM at $240, while Bill Gates OS was priced at $40. Why did IBM do this? Was it more expensive to make Gary's? Really interesting story",2024-01-20 12:59:46
194mr7u,Books recommendation of computer history,"Hi. I'm here to ask for one or more books that you would recommend about computer history. I need some which explain from a architecture perspective. I hope the book tell about the IBM mainframes, CPUs architectures like Motorola 6800, Intel 8086, etc. The evolution from CISC to RISC, The birth of OS, UNIX, Linux and GNU. Also programming languages historical perspective punch cards, assembly, BASIC, C language, Java, Python, etc. 

I appreciate any suggestion and thanks for reading so far. ",2024-01-12 04:58:09
15wyx30,Two-way quantum computers (2WQC) adding CPT analog of state preparation - enhancement in theory allowing to attack NP,N/A,2023-08-21 06:04:33
158vwcd,what platform do you use to write a cs research paper,N/A,2023-07-25 03:07:04
14cy1rq,Finding the most discriminative sub graphs,N/A,2023-06-18 23:07:39
1adw47s,Can a simple functional sieve be fast? Optimizing Tromp's algorithm on HVM.,N/A,2024-01-29 14:07:07
16nluoc,How to build a computer using origami,N/A,2023-09-20 13:52:00
13mcnyz,Can PAC-learning be classified as an NP-Complete problem?,"I apologize if this is comparing apples to oranges, but generally, PAC, as an optimization problem, can it be considered NP-Complete? Thanks for your helpful replies.",2023-05-20 00:24:28
183kpz3,Packrat Parsing and Parsing Expression Grammars,N/A,2023-11-25 14:19:12
196i70i,easy to criticize papers for undergrads," i'm TAing an intro to research class. i want to teach students how to critically review a paper (consider experimental design, results, etc) by having them walk through some examples. do y'all know of any easy to read papers that have some obvious flaws/shortcomings? Particularly papers from areas that feel more approachable like HCI or CS Ethics? Or some fundamental papers in systems/architecture? Or just papers that are easy for students to analyze?

For context, these students are 2nd semester freshmen with limited research experience. The goal is to teach them how to read papers critically.",2024-01-14 15:21:25
17z2ul4,Recommendations for unique/fun classroom project?,"*apologies if this is not the right sub to post this but I'm not sure where else this would fit best*

I teach a c++ beginner course. I have multiple Labs associated with the course. I'm thinking of doing something unique that somehow exploits the presence of the Labs, some sort of tournament that pits the Labs vs each other in a fun competition. I'm trying to draw inspiration from something fun, like video games that would incentivize students. 

Tbh I'm not happy with the current structure of the Labs, in which students just have to show up for attendance purposes. I want to give students purpose for why they should attend the lab to make the most out of their time, because currently they just gpt their way out of the exercises and call it a day.

I was thinking throughout the term, students in their respective lab would embark on ""quests"". The nature of those quests...unknown right now and thats where im seeking your brain power to help me with fun ideas!

By the end of the term, I want to dedicate 1-2 days where those students demo their findings/results/(whatever the objective was).

Also there's a cloud club that I think would be really fun to include in this but keeping it optional. Like maybe if students go to one of the club's workshops, they pickup a hint or some keyword that benefits their success in the proposed tournament...but I'm not sure what I could tie c++ to something within say AWS or Azure etc...especially since students are very beginner and they don't know even what cloud I'd at this point. 

If yall could propose ideas 💡 I'd appreciate it :) I'm just a humble teacher trying to evolve my teaching style in the era where students have no incentive to solve problems with the existence of AI chatbots, so I want to do something that the chatbot would not be useful for them.",2023-11-19 18:00:59
17twgc4,Log-Structured Merge Tree implementation,"Hey everyone,  
I wanted to share a project I've dedicated some time to - my Java  implementation of a Log-Structured Merge Tree. The repository includes a  skip list implementation and an SSTable built entirely from scratch. The tree performs background flushing to disk and table compaction.

If you're keen to dive into the details, I've also written a Medium article about the project.  
\- **GitHub Repository:** [Link](https://github.com/tomfran/LSM-Tree)  
\- **Medium Article**: [Link](https://medium.com/@tomfran/log-structured-merge-tree-a79241c959e3)

I'm open to any questions or discussions, so feel free to reach out!",2023-11-12 23:04:19
17joi9y,Best resources for kernel level exploits?,"There is a lot of material on cyber security out there, but very few when it comes to system security.

There are so many critical bugs being fixed in the linux kernel, android etc. on a daily basis.

Which is a good place to start learning about these assuming I'm still a beginner in system security?",2023-10-30 08:16:55
18ibf4k,Undecidable problems for cryptography?,"I wonder if it's possible to build cryptographic protocols based on security provided by undecidable problems such as the halting problem, which are uncomputable from definition. 
If there's a way we are able to do this(probably build one way functions from an uncomputable function), wouldn't it imply ultimate security even in the PQC era? 

Please excuse my naivety if this seems absurd
Thanks",2023-12-14 15:43:00
16cm02z,Can Super-Resolution be used to accelerate MRI acquisition?,"Hi fellow computer scientists,

&#x200B;

After some research I came to the conclusion that both Super-Resolution (SR) and Compressed Sensing (CS) are used for MRI reconstruction. However, I'm questioning whether super-resolution is suited for MRI reconstruction when the goal is to accelerate image acquisition or reduce scan time while maintaining image quality?

I've seen some really good papers that support super-resolution as a technique for MRI acceleration, but I have not yet found a general opinion about this. Is it possible/practical to leverage MRI images reconstructed from undersampled k-space data, and then use super-resolution algorithms to enhance the spatial resolution and generate higher-resolution MRI images?

Won't that imply acquisition acceleration, since we deliberately collect fewer data points in k-space than what would be required for a fully sampled image?

&#x200B;

Thank you!",2023-09-07 17:46:15
14yh306,Learning Materials,"Hello i'm gonna be a compsci student this upcoming school year, i don't have any knowledge related to this field of study so i'll appreciate it if you recommend me some beginner learning materials (preferrably books). Thanks a lot!",2023-07-13 10:26:43
14ayzeo,Is there a viable alternative to Reddit for r/compsci to migrate to?,"The open web has largely died since this subreddit was created and Reddit exists awkwardly with a foot in the old world (where some reddits feel like old-school community forums or even Usenet), and the new world (a large gated centralized tech company product).   


Given the unfortunate direction that the website seems to be heading in (eg [https://www.businessinsider.com/reddit-ceo-will-change-rules-to-make-mods-less-powerful-2023-6](https://www.businessinsider.com/reddit-ceo-will-change-rules-to-make-mods-less-powerful-2023-6)), it might be desirable to migrate this community somewhere else. But: is it feasible? Would simply hosting a forum actually getting any visitors? Is there an alternative to Reddit with an active community and better management?",2023-06-16 14:55:35
140og58,Subsets of a 64 bit mask which are divisible by a certain number.,N/A,2023-06-04 20:00:12
18r6cdk,Contraction Clustering (RASTER): A very fast and parallelizable clustering algorithm · Issue #27848 · scikit-learn/scikit-learn,N/A,2023-12-26 11:38:46
18a61e8,"The First Law of Complexodynamics (Scott Aaronson, 2011)",N/A,2023-12-03 23:04:09
16bgvwl,Bloom Filters and Beyond: An Illustrated Introduction and Implementation,N/A,2023-09-06 10:43:35
167533p,Iteration protocols supporting optional parallel iteration,"My favorite programming language (Julia) has a standard iteration protocol that must be satisfied by iterators (if you satisfy the protocol, you are an iterator). Sadly, the protocol seems to have been designed without due care (there seems to have been a hurry to redesign it before the v1 release) so it has some issues (affecting the performance of composed iterators, in particular, in some cases). Thus I want to provide a separate and improved interface for iterators (call it *IteratorsV2* if you will) as a user package.

One thing in particular that crossed my mind is this: I suppose it would be good to think about **supporting different execution policies** upfront. For example, a user should be able to choose whether the iteration will be **executed in parallel** or **sequentially**. ""In parallel"" should presumably be further subdivided into *threaded* execution, *GPU* execution, etc.

Could someone point me to any possible existing languages that have/support something like this? If there are no examples, why is that?

C++, for example, has support for something similar, its [execution policies](https://en.cppreference.com/w/cpp/algorithm/execution_policy_tag_t). They're however limited (user-created execution policies are not allowed) and, it seems to me, unwieldy (the execution policy needs to be provided explicitly to each function that does iteration).

I think it would be preferable to:

1. somehow enable users to provide their own custom execution policies

2. have the execution policy as part of the type of the iterator, so it wouldn't be necessary to pass the execution policy explicitly to every single `foreach` or `mapreduce` call. I'm not sure that this idea of mine is good, though.

I'd also appreciate references to relevant papers or books.",2023-09-01 11:56:34
1608k45,The MAD Turing's Maze,N/A,2023-08-24 17:34:28
14ui7ic,Complexity class NP ∩ co-NP is closed under concatenation,"I was browsing through some materials about complexity theory, and I stumbled upon a question they left for the readers to prove:

""Prove that the complexity class NP ∩ co-NP is closed under concatenation.""

So my idea was that I know that a language L∈ (NP ∩ co-NP) iff both L and L(not) belong to NP. So I know that I need to find a non-deterministic turing machines that runs in polynomial time and is solvable for L1L2 an L1L2(not).

For L1L2 I have an idea, using the machines that are given to me already by knowing that L1 and L2 are in NP, I can build a Turing machine that accepts when both of their machines accept, and declines otherwise.

My problem now is with L1L2(not), I thought about two approaches:

\* If I do the same idea which I did with L1L2, and use the turing machines that given to me by L1(not) and L2(not) but I don't feel it's right - since I don't think that complement of concatenation is concatenation of complements.

\* Taking the TM I built in the first step, and basically swapping the accept and decline, which seems right but doesn't it prove that NP = co-NP? Because then I could take every problem in NP and swap the accept/decline and and make it decidable.

&#x200B;

I would be glad to hear of ideas or help to fix my understanding of the things I proposed.

Thank you!

&#x200B;",2023-07-08 23:02:58
18y7vw8,Eigendecomposition Explained,"Hi there,

I've created a video [here](https://youtu.be/ihUr2LbdYlE) where I explain how we can factorize a square matrix using eigendecomposition and why this transformation can be useful in solving machine learning problems.

I hope it may be of use to some of you out there. Feedback is more than welcomed! :)",2024-01-04 08:04:12
188ysbh,What numeral system would work well with a Trenary computer,"Hello. Just daydreaming about science fiction. I have only a tiny background in CompSci so I know about some concepts without necessarily understanding it.


With a Trenary computer, what would be a good numeral system to use with it? (Eg. Base10, Base16/Hex)

I read that Hex is easy for human recognition as well, appreciate if someone could ease my curiosity by giving 2 answers -

1. Easy for human usage as well as Trenary computers,
2. Disregarding humans, just for use in Trenary computers. (AI programming themselves?)",2023-12-02 07:52:12
17p9i8y,"I have written an article about machine code, assembly and high level languages. Would like some feedback.",N/A,2023-11-06 18:32:57
16qm5iw,is ant colony optimization viable for finding efficient road networks?,"its for science fair, and im planning on doing something like an ant colony optimization simulation to find efficient road networks.

&#x200B;

im planning of having different ""species"" that have traits like ""studious"" or ""athletic"", for example, a student species thats studious and a tourist species thats exploratory, then having buildings with those traits, like a library is a place to ""study"", and a museum is ""exploratory"" or something like that

&#x200B;

ill have each species start in neighborhoods, then when im simulating the ants, whats considered ""food"" is determanant on the ants traits, and the food/buildings (if they match or not), and maybe weight it by how often they visit, example, if they visit it, itll be weighted lower, and itll incease as time goes on until they visit it again. the point of this is to create a bunch of cycles that are tailored for each specefic species (type of person), then the road network is just all of the paths they made combined.

&#x200B;

im thinking of having every ant have a certain bit of randomness in a set ammount of interests for its type, and doing a second pass to make sure every building is able to be traveled too. im also thinking the ammount of ""road"" they make can be controlled by their trail evaporation / number of ants. im also thinking about having the food locations be known at all times, and also creating barricades to make it more realistic, and maybe copy real world citys for buildings, and to test against to see if it did better or worse, and maybe making it 3d aswell

&#x200B;

ive also done something similar to this before, but with slime molds and tsp and i have more time this time, so im pretty confident ill be able to do it

&#x200B;

my questions are, is this idea viable? is this how something like this would be done? would the resulting simulation be usefull to anyone? are there better methods for this? is there anything im overlooking? what would make it more realistic / accurate? any advice from people who actually know how stuff like this works would be very apreciated!",2023-09-24 02:28:40
168kvsf,Solving N-queens and NP-complete problems with constructive search,N/A,2023-09-03 02:17:03
15den16,How are waits in semaphores made atomic in nature?,"I was going through the book Operating Systems by Galvin. First they explain Semaphores acting like a mutex.

While talking about semaphores as mutex, they mention that the wait operation of semaphores are always atomic in nature.

This is how a simple snippet of wait would look.

```
wait()
{
    while(s<=0);
    s-=1;
}
```

where the value of shared variable s is initially 1.

As we know that a thread or process can be context switched anytime irrespective of anything else. So in the above what if a thread1 context switches after line3 and another thread comes in, it would also find the value of s to be 1. So it wouldn't be waiting in the while condition.

Now to tackle the above situation Galvin says that `wait` is an atomic operation.

What I don't understand here is how can wait be atomic and how the same is implemented internally? The OS also must be using some similar operation to make a function atomic and if we already have that algorithm which is used by OS then why use semaphores at all?

What are the ways in which a system ensures atomicity?",2023-07-30 06:46:59
116dv7e,Odd Sketches,N/A,2023-02-19 15:12:54
197ca4e,Crashing As A Kind of Failure vs. Crashing As A Separate Concept From Failure,"Succeed/fail semantics can be supported with a code library or directly in a programming language. In succeed/fail languages and techniques, predicate operators (e. g. comparisons, such as `<=`) do not typically return a Boolean value, but rather, they fail the current execution context if the condition is not met. It's possible to code a conjunction of operations and the conjunction succeeds if and only if all the operations succeed. It's possible to code a list of alternatives and the semantics here is that the computer must try alternatives until encountering one that succeeds.

All this can be done in imperative programming, pure functional programming, or logic-based programming (for example, committed-choice concurrent-constraint logic programming, like ToonTalk).

I coded a library that supports succeed/fail semantics in an imperative language and the client code can also be imperative. I decided that if the underlying programming system detects a condition that would usually only arise from a programmer error, I would not treat a case like that as failure, but rather, as a separate concept called a ""crash"". I provide a slot where a reference to a callback function can be lodged, so that if a run in the library crashes, the outer code that is invoking the library can recover control and deal with the error. I felt that by providing this concept and hook, I was mimicking Erlang's support for having one process supervise one or more other processes and deal with their possibly crashing.

I now feel that separating crashing from failure was an engineering error, that it leads to requiring more programming effort than should be necessary in building, for example, a web server.

Do you have any strong case to make for separating, conceptually, crashing from failure in a technique (or language) supporting succeed/fail semantics?",2024-01-15 16:06:47
1933g9x,Non-Functional Software Requirements - Guide,"While functional requirements define the “what” of software, non-functional requirements define how well it accomplishes its tasks. The following guide explains how these qualities ensures your software meets user expectations: [Why are Non-Functional Requirements Important - Guide](https://www.codium.ai/blog/why-are-non-functional-requirements-important/)

* Scalability
* Performance
* Security
* Usablity
* Reliability",2024-01-10 08:21:58
18klgt8,Indexing and searching for a polygon regardless of it's orientation / scale,"It's been a while since I've worked on a real compsci problem, but since I've been enjoying the Advent of Code so much this year I came up with my own problem which I've been trying to tackle this weekend.

Given any polygon (as a set of vertices) I want to be able to query a collection of previously indexed polygons for the most similar match, in a way that does not depend on the polygon being in a specific orientation or scale. 

[Here's my current approach](https://github.com/Timmoth/PolyMatcher)   
Identification:  
\- Sort the vertices in ascending order by their distance to the centroid. This order will be the same for any orientation / scale.

\- Calculate the angle between each pair of points and the centroid. (If there are an odd number of vertices, pair the last vertex with the first)

\- Return an array of floating point angles in radians.

Comparison:

\- Calculate the Euclidean distance between two arrays of floating point angles in radians.

\- The lower the Euclidean distance the better the match (between 0.0 and 1.0)  


I'm still unsure if my solution works for all scenarios, and am currently trying to think of edge cases and add tests for them. At the moment its all in memory, but I hope to learn a bit more about databases by integrating it into one.  


I'd love to know if there are any algorithms or areas of computer science you think I should research that might be applicable to this problem.  
Or if you have any feedback for my solution i'd really like to hear it! ",2023-12-17 16:50:06
17120ui,Best Way to Approximate an Algorithm,"I want to use a computationally-heavy algorithm (e.g. minmax), but the device I need to run it on has limited resources. What would be the best way to approximate an algorithm? I figured one way would be to train a neural network to predict the output of my algorithm. Does anyone have any other possible solutions? Or any clues on what further reading I could do?

Thank you!",2023-10-06 03:28:04
14qq1bl,Visualizing the Impossible - Numerically Approximating the Time Dependent Schrödinger Equation for Computer Visualization,N/A,2023-07-04 20:28:29
1abv6t0,Suggestions to tame complexity in hierarchical state machine?,"I'm working with a hierarchical state machine which seems very large to me — 15 leaf nodes, and 5 parent nodes (example of hierarchy included below). The number of states makes it difficult to understand all the interactions, and putting all the state transitions into a single diagram is a nightmare. I suspect that the state machine could be simplified, possibly through:  


1. reducing the number of states.
2. restricting the kinds of transitions that are allowed.

&#x200B;

https://preview.redd.it/n7vpf2ja4vec1.png?width=1762&format=png&auto=webp&s=e2e2fb4b426ebafdc36d41ce68348ac4139676b6

I'm hoping for advice on how to do either of these, or more suggestions for how to tame the complexity in the state machine.  
I've searched for suggestions regarding ideas (1) and (2) a bit already. I expected there would be some heuristic to determine when states should be combined to reduce the number of states, but I haven't found anything about this. I also haven't found definitive agreement on idea (2) — I think I'd prefer if leaf nodes only only handle transitions to direct siblings, and anything more complex needs to be handled through an ancestor state, like what is described here ([https://stackoverflow.com/questions/50182913/what-are-the-principles-involved-for-an-hierarchical-state-machine-and-how-to-i](https://stackoverflow.com/questions/50182913/what-are-the-principles-involved-for-an-hierarchical-state-machine-and-how-to-i)). But many of the guides describing hierarchical state machines violate this kind of restriction in their examples.  
 ",2024-01-26 22:41:24
18lyl3f,is Diffie-Hellman symmetric or asymmetric?," [Difference Between Diffie-Hellman and RSA - GeeksforGeeks](https://www.geeksforgeeks.org/difference-between-diffie-hellman-and-rsa/) 

>Symmetric vs. Asymmetric: Diffie-Hellman is a symmetric-key algorithm, while RSA is an asymmetric-key algorithm. This means that Diffie-Hellman uses the same key for encryption and decryption, while RSA uses different keys for encryption and decryption.

according to this\^ it is symmetric? but i'm pretty sure it is not. So is this page just wrong or am i just stupid?",2023-12-19 10:12:52
1811o1q,How do you people stay updated?,Do y'all follow any newsletters or use any apps that focus on tech news?,2023-11-22 05:22:21
180qzs9,Publishing a paper on a package,"
To clarify I am a mechatronics engineering researcher, I didn't study software engineering or computer science so I am not very familiar with the conventions.

Anyways, I made a python package that has to do with analysing neural networks. My supervisor suggested publishing a paper. He doesn't want me to make the repo public in fear of having the idea be plagiarised, and to make sure we don't lose the citations in case the package is used by other researchers. (this might seem awful but the reality of the matter is that these things do happen and the citations count basically helps us keep our jobs).

Does anyone have any experience with writing a paper about a software or a package? Dol only make the repo public after publish it? Is there a way I can get some feedback on the work before publishing or is the peer review process enough?",2023-11-21 20:46:34
16xeeuj,Is Gödel's speed-up theorem an instance of Blum's speedup theorem?,N/A,2023-10-01 22:04:06
15rx4kp,Packing Scale Invariant Rectangles into a Square: Exploring Optimal Algorithms,N/A,2023-08-15 16:16:06
14hqdv3,Integer Map Data Structure,"A data structure for storing ordered integer maps. The data structure is a compressive, cache-friendly, radix tree that attempts to: (1) minimize the number of memory accesses required to manage the data structure, and (2) minimize the amount of memory storage required to store data. It has performance comparable to an unordered map (`std::unordered_map`) and is an order of magnitude faster than an ordered map (`std::map`).

https://github.com/billziss-gh/imap",2023-06-24 11:15:36
13rcs24,CS25: Tranformers United!,N/A,2023-05-25 09:19:36
13ejyd2,Graphs vs Hypergraphs for Pathfinding,"I'm participating in a directed reading program that has taken a recent turn toward pathfinding approaches. I've been interested in multi-agent and dynamic pathfinding for a while, so we're spending a bit more time on this.

My mentor is a graph theory/combinatorics Ph.D. without a lot of computer science experience. However, he mentioned that a friend in industry works with hypergraphs for their company's recommendation algorithm. From my mentor's description, it seems like they're more amenable to vectorization? However, there are vectorized algorithms for graphs as well.

What are the advantages and disadvantages of hypergraphs in this context (pathfinding, recommendation engines, etc.)? Does anyone have book or paper recommendations on the topic?",2023-05-11 11:00:50
17pr9w0,A Linear Algebra Trick for Computing Fibonacci Numbers Fast,N/A,2023-11-07 10:25:40
17mdkkp,How does hole punching in file systems work out?,"If you punch a hole in the  middle of a file, the pages in the hole would be freed for other use.

So would those pages/blocks on disk be used for other files? If so would the size of original file decrease by hole size? (My guess is the logical size would remain same to keep the offsets same while the physical size decreases) and offsets in the original file after the hole change? 

How does this work out?",2023-11-02 20:57:04
179r4zi,About a New Computer Architecture.,"I'm developing a processor designing/simulation game with a new paradigm. But I don't know if its really new. Does the following algorithm belong to any known class?

\- control unit is not central

&#x200B;

\- every module works on its own by generating requests and responses

&#x200B;

\- control unit requests new instruction opcode from decoder

&#x200B;

\- decoder requests data from cache on its own

&#x200B;

\- cache requests data from RAM

&#x200B;

\- responses follow the opposite order

&#x200B;

\- control unit sends square root opcode to fpu

&#x200B;

\- fpu requests data from cache

&#x200B;

\- ... same pattern until control unit gets answer

\- if an instruction is independent from last one, control unit sends it to another control unit as a load-balance

\- even in fpu, if square root needs an extra iteration, it generates another request like ""newton raphson step"" and any other fpu can take it or itself can take it if pipeline is not over-allocated

\- all independently and concurrently

\- even bus nodes are concurrent to each other, by sharing data with their n-way unified ring-channels. So each module can i/o freely with bus network.

&#x200B;

Is this a possible way of making a totally modular cpu design? Even cache banks and cache controllers will work on their own, by trading requests/responses.

&#x200B;

Aim of game is not to get the best performance but only relatively better performances between human players and NPCs. With some hypothetical skill based adjustments on the inner latencies of modules like newton raphson taking 2 cycles instead of 4 with a high electronics skill, etc. Name of game is advanced macro devices: deadlock tycoon. Rpg/rts hybrid with simulation of cpu & software. Skills will make modules wider, faster and more technologically superior but the depth will be decided by players by simply placing modules on a grid and connecting with bus modules.

Imo, hardest thing to implement will be cache snooping bus. Because snooping has to be instant but bus is a ring of rotating channels with their own latencies and cache banks will be connected to cache controller through a bus which will have latency. Then branch prediction will be very hard. Lastly, maintaining instruction retire order with multiple control units will be a nightmare.",2023-10-17 05:35:25
1568o6h,"Static regional allocation based on a grant system, as per A. Tannenbaum's paper (except in the user-space)",N/A,2023-07-22 03:17:53
14yp7pg,Google’s New Quantum Computer is a Game-Changer for Data Science,N/A,2023-07-13 16:20:43
14ebx2z,Optimal Subset Selection in C++ with OR-Tools Constraint Solvers,N/A,2023-06-20 13:59:31
13rl3ff,"Origin Stories: Plantations, Computers, and Industrial Control",N/A,2023-05-25 15:41:58
1an4agl,optical computing,does this field actually exist? is this field the future? how does this work? how does it differ from quantum computing? how to get started as an undergrad?,2024-02-10 01:19:41
19edpz6,Random Graph Generation Algorithm,"While a seemingly simple looking task, when you dive deeper for an optimal algorithm, we discover various intricacies of this task.

Textbook algorithm is fairly simple, if we need a graph with N nodes and M edges, just keep generating random edges and add if not already present till we get M edges, while this may work great for sparse graphs it becomes inefficient really quick as graph becomes denser.

The problem becomes even harder if we want the graph to be connected, the base step is to generate a random spanning tree amd add remaining edges randomly such that they don't repeat.

This problem is essentially to sample some edges from complement of a set where the universal set is the set of all possible edges, in a way that they don't repeat, we use Floyd's Sampling algorithm for it, the end result is a mathematically random graph which is optimal in worst case, you can check out the implementation.

[Implementation](https://gist.github.com/theabbie/0be86edab481af581c450a4cfeef6d69)",2024-01-24 10:04:20
19d23mv,Best way to simulate Low-Field MRI from High-Field MRI,"Hi fellow computer scientists,

&#x200B;

I'm trying to trivially simulate Low-Field MRI from High-Field MRI. I'm wondering if any of this options is valid. If so which one is the best?

&#x200B;

A) Let's consider we have a 3D High-Field MRI image:

1. Apply FFT to obtain k-space -> Undersample k-space with mask -> Apply IFFT
2. Apply FFT to obtain k-space -> Downsample k-space with bicubic interpolation -> Apply IFFT
3. Apply FFT to obtain k-space -> Center crop k-space -> Apply IFFT

&#x200B;

B) Also, in case of low SNR in Low-Field, I can consider larger voxels during acquisiton. We want the same FOV (is this okay, right?). In such case what will happen to k-space when compared to an acquisition with smaller voxels? Let's consider we have a 3D High-Field MRI image with size 512x512x512:

1. The new k-space, with size 256x256x256, will look like a downsample version of the k-space acquired with smaller voxels. Similar to option 2.
2. The new k-space, with size 256x256x256, will look like a center cropped version of the k-space acquired with smaller voxels. Similar to option 3.

&#x200B;

Thank you :)",2024-01-22 18:11:12
181a3ay,Confused: Is data transfered quicker when using Programmed I/O compared to Interrupt-Driven?,"TLDR: Correct me if I'm wrong, but this is what I understand: There is a trade-off between the drawbacks of programmed I/O and interrupt-driven. Either waste processor time but transfer data at a higher rate with programmed I/O, or let the processor be busy with other tasks until the I/O is done but the transfer rate from I/O to memory is slower. Thus, data can be transfered quicker when programmed I/O is quicker.

&#x200B;

Ok, so I am reading William Stalling's book: ""Computer Organization and Architecture"", and right now I am reading about DMA. To introduce the concept, he was describing the drawbacks of programmed I/O and interrupt-driven.

I am going to quote the passage and tell you what I interpret and why so that maybe you can help clarify some things? Here is a the passage:

`""Interrupt-driven I/O, though more efficeint than simple programmed I/O, still requires active intervention on the processor to transfer data between memory and an I/O module, and any data transfer mist traverse a path through the processor. Thus, both these forms of I/O suffer from two inherent drawbacks:`

`- the I/O transfer rate is limited by the speed with which the processor can test and service a device.`

`- the processor is tied up in managing an I/O transfer; a number of intructions must be executed for each I/O transfer`

`There is somewhat of a trade-off between these two drawbacks. Consider the transfer of a block of data. Using simple programmed I/O, the processor is dedicated to the task of I/O and can move data at a rather high rate, at the cost of doing nothing else. Interrupt I/O frees up the processor to some extent at the expense of the I/O transfer rate.""` 

I'm sure I must have misunderstood something but I just can't see it. This is what I interepret:

There is a trade-off. Either waste processor time but transfer data at a higher rate with programmed I/O, or let the processor be busy with other tasks until the I/O is done but the transfer rate from I/O to memory is slower. Thus, data can be transfered quicker when programmed I/O is quicker.

I'm confused. I thought that is what the I/O data buffer is for: so that data can be transfered at different speeds (ie. transfer in Ghz when the processor is transferring data even if the I/O device was transfering the same data in Mhz).

Thank you for reading until the end, and thank you for your help in advance :)",2023-11-22 14:15:00
17wv25o,How do you conceptualize the difference between ‘Imperative’ vs ‘Declarative’ Programming?,"
This is something I’ve been turning over in my head a bit today, and I’m curious how other programmers orient to these concepts.

As I understand it and often see it used, “imperative programming” basically means “you explicitly write a linear sequence of function calls/primitive language operations which achieve some goal”. And “declarative programming” means “You ‘delcare’ your goal via some interface, and let the details of how it is achieved live in the abstraction layers below you”.

The thing that gets me twisted…there really is no fundamental difference here as far as I can tell? In imperative/procedural code, you write functions to abstract away repeated functionality, so is that suddenly “declarative”? And vice-versa, as soon as you start “declaring” multiple pieces of desired state via an interface, aren’t you just defining a series of “imperative” steps in terms of that more abstract interface?

As far as I see it, the only thing that is real is abstraction; either you rely on abstractions or you do something yourself. But that is just what programming is…nested abstraction. So it’s hard for me to see the utility in these roundabout labels for something so ubiquitous, which make them sound like totally incommensurate programming styles. Actually, I often *do* see the terms tossed around in the way that makes them sound at odds, IE “I’m writing code in an imperative style” or “I’m writing a declarative API”, and that makes me wonder if I’m missing some important distinction beyond just the abstraction layer someone is choosing to emphasize? What are all your thoughts?",2023-11-16 19:21:40
17lpuf5,Serious game to teach finite automata,"I'm thinking of making a serious game to teach concepts like dfa, nfa, Turing Machines for a research project. I want to have like interactive mini-games but idk how to craft it so that the mini-games are analogous to solving real world problems. Can someone help me brainstorm ideas so I can get started",2023-11-01 23:43:18
17incss,What is point of calling syscalls in the kernel?,"If syscalls are meant to transition into kernel mode from user mode, what is the point of calling syscalls in the kernel?

Reference: [https://stackoverflow.com/questions/15841327/can-we-call-system-call-in-kernel-space](https://stackoverflow.com/questions/15841327/can-we-call-system-call-in-kernel-space)",2023-10-28 21:17:40
17c0ro1,Solving NxN sudokus with CSPs,"I've built a site that lets you play around with solving [NxN sudokus](https://dawnofthe.dad/ndoku), up to 36x36, backed by a Constraint Satisfaction Problem (CSP) solver. The site exposes a bunch of parameters that influence how this problem is solved, including how the cells are selected, what values are attempted first, how the problem is modeled, and how quickly the solver attempts to eliminate impossible states after each run. Each of these comes with a set of trade-offs, like a more thorough elimination algorithm takes longer to run between each step, so each step takes longer, and it can be interesting to try out different combinations to see which result in faster solutions, fewest backtracks, and so on.

This is definitely not the fastest sudoku solver out there, but the visualizations tend to be fun to watch and should give you an idea of how search incrementally builds up the solution, eliminates uninteresting parts, backtracks on failure, and how the various parameters affect its behavior. You can expand the ""?"" to see the FAQ about what the colors represent and a bit more details on the parameters.

I also have a bunch of the technical details about how this all comes together in my blog (e.g., [this post gives an overview of the solver](https://blog.dawnofthe.dad/posts/solver-basics/)), and if you want to see another application of this same solver, check out the [crossword builder](https://dawnofthe.dad/crossword). The model for crosswords is of course very different, but the underlying engine is the same. The only thing that crosswords share with sudoku is one all-different constraint: while sudokus are basically just one giant glob of all-different constraints, the crossword only has the one, to ensure no word is used twice. This all-different constraint is the ""Sparse"" one (in the UX), and being tailored for the crossword use-case, unsurprisingly tends to perform poorly for sudokus (because while it's very fast, it's also very simple).

In any event, it's been a fun project to nerd out on, and I hope you enjoy poking at it. I'll be happy to take any questions about it.",2023-10-20 02:38:58
161xot7,Lower bound of the channel capacity,"How do I calculate lower bound of the channel capacity with source X and output Y if I have given joint probability distribution? I know how to calculate the mutual information I(X,Y), but how do I take its maximum over all possible P_X?

For example this joint probability distribution: 


X // Y | a  | b  | c  | d
-------|----|----|----|----
p      |1/8 |1/16|1/32|1/32
q      |1/16|1/8 |1/32|1/32
r      |1/16|1/16|1/16|0
s      |1/4 |0   |0   |0",2023-08-26 15:08:20
14ts7ge,"Breaking down { w | Len(w) <= N } to Log2(N) subclasses { Wn | n = Log2(Len(w)) }, does it make any improvements in verifying w in terms of polinomiality?","Note: If what I am saying does not make sense, that is because I am stupid. I will give you the context in the thread's first post. I don't want you guys to think I am doing 'AH' (ac\*d\*mic d\*sh\*nsty). Also I want this to be as theoretical as possible.

If we have a class of strings W, which max length is N, and I need to verify that W is either the same as S or is somehow close to S, if I break down that class of string based on their length into n subclass where n is Log2(MAX(Len(W)), have I done anything worthwhile to make this NP problem more quickly verifiable? So for example, if MAX(Len(W)) is 256, I have 8 subclasses. So if I one of these subclasses each a machine, is what I have done anything smart or worthwhile? What if I sort each Wn inside each of the 8 subclasses? If then, what strategies can I use to make the verifiability faster, or improve its polinomiality?

&#x200B;",2023-07-08 03:19:50
14igw7z,Super simple 1-bit 6502 microprocessor,"For those interested in minimalist computing,  
you may want to take a look at this IEEE article and the associated youtube series.  
[https://spectrum.ieee.org/turing-meets-pacman](https://spectrum.ieee.org/turing-meets-pacman)",2023-06-25 08:27:29
144xet0,The Equivalent of FSM in the Theory of Recursive Functions,"Hi Everyone,

I wasn't sure where to ask my question since it could fit either in the math subreddit or in the CS subreddit, but since I come from CS background I thought I'd ask here.

I was looking at results involving Regular Automatas and found the following result: Simply Typed Lambda Calculus is equivlent to FSMs. In other words, the class of languages recognized by ST lambda calculus is strictly equivalent to Regular Languages.

You can find more about this result in this post: https://mathoverflow.net/a/296879 as well as in this paper http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.23.8845&rep=rep1&type=pdf

I was wondering if there was a similar result in Recursive Function Theory. I'm no expert in it, in fact, I know very little about it. I am nonetheless interested in learning more, especially about how those ""regular"" recursive function might look like.

Thanks in advance!",2023-06-09 06:30:15
13hu6k5,"How Much Partiality Is Needed for a Theory of Computability? ""In this paper we consider function classes which besides the total functions only contain finite functions whose domain of definition is an initial segment of the natural numbers."" [abstract + link to PDF, 52pp]",N/A,2023-05-15 01:55:49
1apkys0,Just how dependent are p2p networks on permanent nodes?,"When I torrent, I usually open up by BitTorrent client, download a file, and the app will close when I shut down my computer. When I use my computer again, the torrent client would stay closed (therefore not seeding).

I believe this is how most people torrent. However, I find it hard to believe that the BitTorrent network would be able to reliably provide most files this way. So is it true that a vast majority of torrent downloads still come from some permenant node hosted on servers? The fact that to host something reliably on ipfs seems to support this?

For a computer to get onto a p2p network, they would need to be bootstrapped on. For BitTorrent, this is usually done by being bundled into your client, or being obtained after torrenting for the first time using a torrent file. You would also need to bootstrap to get onto the i2p network. Doesn’t this also heavily rely on more or less permenant and nodes?

Does this mean that p2p networks are mostly networks of interconnected servers, that can just enlist the help of some pcs when they pop on?",2024-02-13 04:38:10
1adnkyq,Question about Big-Oh(Log n),"Was doing some readings and found out that the binary search algorithm was O(Log n). If my understanding is correct, that’s because every iteration we are cutting the numbers we have to search through in half, so the worst case scenario is log ₂ N. So in the case that N = 8, then it would take 3 iterations before we can’t divide by 2 any longer? Should we always try to get algorithms to take this amount of time assuming our algorithm isnt O(1)?",2024-01-29 05:22:42
1ad0y93,Deep Reinforcement Learning,"A Survey Analyzing Generalization in Deep Reinforcement Learning 

 [https://github.com/EzgiKorkmaz/generalization-reinforcement-learning](https://github.com/EzgiKorkmaz/generalization-reinforcement-learning) ",2024-01-28 11:46:48
19f9zcn,Understanding Mesh Allocator,N/A,2024-01-25 14:00:27
16ltfwy,The fedora-tipping ADT (article's not mine),N/A,2023-09-18 11:52:49
16g4ovr,Adversarial Reinforcement Learning," A curated reading list for the adversarial perspective in deep reinforcement learning.

[https://github.com/EzgiKorkmaz/adversarial-reinforcement-learning](https://github.com/EzgiKorkmaz/adversarial-reinforcement-learning)",2023-09-11 19:29:16
15psd2k,Roast my first Open Source project! (or maybe you'll like it :D),"I am currently working on a [path shortcut manager CLI](https://github.com/noahpy/navtag), which enables users to abbreviate paths with short labels. I am always doing stuff on my terminal and I felt that typing out long paths take some time / effort, especially if your file system gets more complex.  
As this my first serious Open Source project and want it to be a real useful tool, I want to gather any feedback possible. So feel free to try things out, give me some suggestions or roast me if needed. Any feedback in any aspect is welcome :)  


Here are some details on the project:

* The shortcut manager, navtag, is written is C. It is capable of adding, removing, listing and resolving shortcuts, which consist of one unique label and a path. 
* When resolving, the input can be a label, a path or a label proceeded with a subpath.
* On top of navtag, I implemented some shell commands for managing your shortcuts in bash or zsh.
* Additionally, I overroad many basic built-in commands so that they would support shortcut labels.
* To ensure fast and efficient use, I implemented tab-completion for labels, paths and subpaths after labels.

I am curious how this will go. Thanks!",2023-08-13 07:22:14
14ktyy6,Interlaced Mantissa and Exponent 3:1,"Interlaced Significand and Exponent (ISE) is a rational number format based on standard floating point, designed to be resizable with no additional computation. Though, the format doesn't inherit NaNs and infinity. All values are arithmetic.

The format is a sequence of contiguous chunks composed of 3 significand bits followed by 1 exponent bit. The significand is the reversed concatenated significand bits, and the exponent is the unreversed concatenated exponent bits. All bits beyond the number default to 0.

The mantissa is obtained as 0.*s* (where *s* is the significand).

The significand and the exponent can independently be signed. The signs are the least significant bits of their respective parts. A sign of 0 denotes positivity.

Here's a comparison of a fully signed number (with both a signed significand and exponent) formatted in both 64-bit floating-point and 64-bit IME. Bold bits are part of the exponent, and italicized ones are signs. The least significant bits are to the right.

Format               |Value
---------------------|-----
64-bit Floating point|*0*​***1*1111011011**0000001011110000100010111100010101110001001001000010
64-bit IME           |**0**010**0**000**0**100**0**100**0**100**1**110**1**101**1**010**1**001**0**111**1**010**1**001**0**000**1**011**1**110***1***10*1*

Please provide feedback disregarding hardware and software compatibility.

EDIT: The mantissa is now stored in reverse to minimize its precision loss after resizing down, with feedback from u/gct.

EDIT: The mantissa is obtained as 0.*m* (where *m* is the mantissa).

EDIT: A sign of 0 denotes positivity.

EDIT: I renamed it to Interlaced **Significand** and Exponent because the format doesn't store the leading bit (just like floating point, except the leading bit here is 0)",2023-06-28 00:03:35
1adeoth,Uncomputable functions via undecidable table?,"Around the 24:30 mark of this [UC Davis lecture from 2011][0], Dan Gusfield sets up a diagonalization argument around a table *T* whose rows are computer programs. See also “Gödel for Goldilocks: A Rigorous, Streamlined Proof of (a variant of) Gödel's First Incompleteness Theorem,” [arXiv:1409.5944 \[math.LO\]][1] from 2014.

He set out to prove the existence of a non-computable function in

*Q* = { *f* | *f* : ℤ+&nbsp;→&nbsp;{0,1} }

He defines *A* ⊆ *Q* as the set of computable functions: “given *any* positive
integer *x*, the program finishes in finite time and correctly spits out the value *f*(*x*).”

Back to table *T*. Its rows are computer programs that compute some function in *A* and columns their values at all ℤ+, but *f̅* defined as

*f̅*(*i*) = 1 - *fᵢ*(*i*)

appears nowhere in *T*.

Cantor’s diagonalization proofs deny the existence of the analogous *T*s for infinite sets or ℝ. However, Gusfield asserts

> (Remember that lists *L* and *T* are only conceptual; we don’t actually build them—we only have to imagine them for the sake of the proof).

Imaginability is one thing; existence is another. I’m stuck on the claim that a function is non-computable because it depends on a table that no oracle can furnish. No matter what *T* we get, we can construct its *f̅*.

What am I failing to understand?

[0]: https://podcasts.apple.com/us/podcast/theory-of-computation-fall-2011/id585297167?i=1000411462836
[1]: https://arxiv.org/abs/1409.5944",2024-01-28 22:11:38
19f6pyz,Framing Frames: Bypassing Wi-Fi Encryption by Manipulating Transmit Queues,N/A,2024-01-25 10:55:16
18ygwc4,Recommendations of open academic profile(like google scholar) database or API,"Hey, I'm developing a platform that allows for scientists to publish analysis and opinions on public policy in my country.

I'd like to integrate the users' profiles with something akin to google scholar for keywords, citations, main topics, h-index, etc.

That way, users reading a post may judge how relevant the poster's analysis is considering his scientific work.

The problem with google scholar is that it doesn't have an API. There is a 3rd party one called SerpAPI, but I'm not sure about its stability/longevity and adherence to google ToS really.

So, do you know any other tools I might use for this that are legal and don't require webscraping? Thank you in advance!",2024-01-04 16:17:29
1859gnl,Np hardness and Np completeness,"Hey, i read a lot about the Definition of these two things but i dont get it. Can someone explain with extremely simple english and slowly what np hard and np complete is?",2023-11-27 18:12:44
16beuw8,An explanation on how to enumerate the vertices of a convex polytope in 3D,N/A,2023-09-06 08:41:54
15onrq1,Heap's Algorithm for partial k-permutations?,"[Heap's Algorithm](https://en.wikipedia.org/wiki/Heap%27s_algorithm) generates all permutations of items in a list. For example, for the group \[A, B, C\], it generates \[ABC, ACB, BAC, BCA, CAB, CBA\].

You can also do a [k-permutation](https://en.wikipedia.org/wiki/Partial_permutation) where you obtain a list of K item selections out of a list of N items. For example, for the N=3 list \[A, B, C\] and K = 2, the permutations are \[AB, AC, BA, BC, CA, CC\].

How can I modify Heap's algorithm so that it generates not permutations for the entire list, but *k-permutations*?

&#x200B;",2023-08-11 23:04:58
14i2qom,Algorithmically Speaking - #7: Dependency Graph Analysis,"&#x200B;

# Dependencies and Graphs

In software development, it is common to have multiple teams working on different applications and modules that will be assembled somehow to build the “final product”.

That final product can be anything. Examples go from a web application to a car to a recommendation system.

For the final product to be released it has to be tested first. For it to be tested, it usually has to be assembled, which means putting all the pieces together and running your tests.

Once again, testing a web application and a car will be different, but they must be tested.

In a dream world, all these different modules and applications that constitute the final product don’t depend on each other. This means that a team can make as many changes as they want to the module they are working on, which will not affect any other team.

But let’s be real. This is unimaginable.

Even the simplest web applications will struggle with not adjusting their “client“ side every time a major change is introduced on the “server“ side. It is also difficult to imagine that changes on, let’s say, a module that controls the energy distribution system of a car will not affect the module that controls the temperature.

The interesting part of this dependency system is that it can be modeled as a graph. Software developers can then find information on that graph that will help them on making better structural changes to their dependencies and improve aspects such as the time it takes to build the “final product“ just for testing purposes.

Let’s see some common analyses that we can do to dependency graphs.

# Structural Analysis

Every team works on a different module or application as we said before. This is what one single module looks like in a dependency graph:

https://preview.redd.it/1nh4bh0xg48b1.png?width=6480&format=png&auto=webp&s=26d3aee3f53e56ca406c8ba14963388d364e701b

This module can have explicit modules depending on it. Which we will call “explicit downstream dependencies”:

https://preview.redd.it/2lnya62yg48b1.png?width=6480&format=png&auto=webp&s=4ecb386f45137c3c342b689f5ce6e82a6e69876a

However, other modules can also depend on the rightmost modules shown in the image above. These modules will also depend on our initial module. All modules that depend on the initial module are part of the so-called “transitive downstream dependencies”:

https://preview.redd.it/gf7qi4uyg48b1.png?width=6480&format=png&auto=webp&s=6e66a8b6045ddab7efcd463e71937488dc7b90de

Knowing the number of transitive downstream dependencies for a module will allow the developers to know how many modules will somehow be affected every time changes are made to that module.

This is a useful metric to have because it allows us to understand the impact that apparently harmless changes can have on an organizational level. Changes to modules mean that people will be assigned to make those changes and time that could be used for something else now will be allocated to make those changes.

You sure want to make as few of these changes as possible the more modules, people, and time you will affect.

On a side note, the dependency graphs should always be Directed Acyclic Graphs. This means that the direction of the dependencies is well defined, in the sense that no two modules can depend on each other. Also, it cannot have a cycle of dependencies, because the order of prerequisites would not be well defined.

https://preview.redd.it/ytt4goh1h48b1.png?width=6480&format=png&auto=webp&s=ad59b8e42640fc6ddabbdd5ca60843b154c2dcfc

Another important metric to look at is the depth of the dependency chain. This will give a sense of how many “layers” of modules will be affected by changes made to a single module.

This metric is crucial to identify opportunities to adjust the dependency graph and make it “wider” instead of “deep”.

https://preview.redd.it/pkluz6b2h48b1.png?width=6480&format=png&auto=webp&s=1ee624efc34b8cfaf95dffa0bfa5c95adb6df239

We can do several other structural analyses on dependency graphs, and we will discuss them in future posts.

For now, let’s focus on what information can we extract from these graphs if we include a bit of “behavioral analysis”.

*Comment below if you are curious about a specific application of data structures and algorithms in modern software development. I will try to cover the most popular topics in future editions of the newsletter.*

# Behavioral Analysis

Let’s broadly define behavioral analysis as metrics that we can measure over time. These metrics will give us a sense of how things behave, and we can begin to notice patterns by analyzing those metrics over a sufficiently large period

As long as the patterns we identify are positive, we keep doing what we are doing so far. If the pattern is starting to affect the development process which can mean that build times have gotten slower, then we take action to correct those behaviors.

Let’s take, for example, the number of changes that have been made to a particular module in the past month.

If you use Github, Gitlab, or any other alternative, this should be easy to calculate by requesting information about the commits made to specific repositories in a period.

Take that number and multiply it by the number of transitive downstream dependencies of the module and you get a value for a metric usually called “Rebuilt Targets“.

https://preview.redd.it/twdnv3q3h48b1.png?width=6480&format=png&auto=webp&s=59ac5c05cf0835425206c241e73ae469626b20b8

This metric can give a score for every module showing how much the changes made to every module have affected others in the past month.

But we can take this idea even further.

In reality, this module that we have been analyzing all the time can also depend on other modules. We will call those “transitive upstream dependencies“.

https://preview.redd.it/xskeqai4h48b1.png?width=6480&format=png&auto=webp&s=d0fcba127fd28d4e3d34516569dbc66132d94858

As we can see in the image above, every change made to any of the modules on the left will affect the modules on the right.

This leads us to define a related metric, which is called “Rebuilt Targets by Transitive Dependencies“.

The metric is calculated by multiplying all the changes made to the transitive upstream dependencies of a module in the past month by the amount of transitive downstream dependencies of that module.

https://preview.redd.it/0qch3785h48b1.png?width=6480&format=png&auto=webp&s=c7fd148b6d693f7d6534de4681edd9bfe86e68f3

The score we assign to each module based on this metric can give a sense of which modules have been the bottlenecks of our dependency graph in the last 30 days or so.

# Last Words

I hope you enjoyed this introduction to dependency graph analysis as much as I did when I was first diving into these topics a few weeks ago.

In future posts, we will discover new structural analysis metrics and we will be diving into the world of centrality algorithms in graphs.

Also, I want to start sharing a bit of my experience with data visualization so I might have an entire article showing how to create a dashboard to display all the metrics we gather from a dependency graph.

Feel free to read a little bit about those topics in the upcoming weeks and let me know if you find them as interesting as I do.

*As always, if you think this post provides value for someone you know, share it with them. Nothing will make me happier.*

[Refer a friend](https://albexl.substack.com/leaderboard?utm_source=post)

See you next week,

Alberto",2023-06-24 20:27:58
146y7lx,YOLO Model Explained,"Hi there,

I have made a video [here](https://youtu.be/J__DmmGBcdU) where I explain the YOLO model which is mostly used for object detection in computer vision.

I hope it may be of use to some of you out there. Feedback is more than welcomed! :)",2023-06-11 16:26:27
13tnep3,Coin flips and most significant bits,N/A,2023-05-28 00:59:53
12vah40,"Drawing Trees Functionally: Reingold and Tilford, 1981 (with pretty animations!)",N/A,2023-04-22 16:04:49
1aiykbk,Could resistance-based memory somehow make its way into actual products?,"To give more context:

I need to do a little 5 minutes presentation in a course for learning how to present, not Informatics.

Now  I choose the topic analog In-Memory Computing for deep-learning models,  because just prior I saw a video from veritassium talking about analog  computing.

I started to actually read the papers I found to the topic and the current situation seems pretty dire to me.

[http://knowen-production.s3.amazonaws.com/uploads/attachment/file/5270/10.1038\_s41565-020-0655-z.pdf](http://knowen-production.s3.amazonaws.com/uploads/attachment/file/5270/10.1038_s41565-020-0655-z.pdf) this paper from 2020 talks about it and especially the different types of resistance-based memory.

RRAM  lacks a lot of research till you could even think about realizing an  actual piece of usuable hardware. MRAM and PCM don't seem to be that far  either.

Now my main idea was that  you could be able to implement solutions with resistance-based memory  into real-time systems. Like a camera analyzing input in real-time with a  deep learning modell.

But it  seems that the only real application would be only for training the  model, not running it locally, with lower consumption and a big  deep-learning model in a small device?

The  markting guys from veritassium talked about using it to analyze body  movements ""like for the metaverse"", but how realistic is that?

To  me its really hard to put the piece together. One article in 2008 says  its impossible, Wikipedia meanwhile says IBM already has a PCM In-Memory  Computing chip, but refers to a paper from a institute. ChatGPT says  its already commercially used (?), meanwhile no products show up when I  search for any actual product.

If anybody has actual knowledge about the field, just give your input.",2024-02-04 21:06:22
1ah6ab7,Whom do you think will win Turing Award this year?,"Since the announcement of the award is approaching, whom do you think will win Turing Award?",2024-02-02 15:27:02
1aczvg2,"Security and Privacy Failures in Popular 2FA Apps -- ""We identified all general purpose Android TOTP apps in the Google Play Store with at least 100k installs that implemented a backup mechanism (n = 22).""",N/A,2024-01-28 10:34:02
198sspq,"Can Rice's theorem be applied to decision problems that might allow ""fuzzy"" answers?","This question is based on the post [https://www.reddit.com/r/compsci/comments/18m2y94/](https://www.reddit.com/r/compsci/comments/18m2y94/is_the_problem_of_finding_the_output_given_the/?utm_source=share&utm_medium=web2x&context=3).

In that post, the following question was asked: is there a Turing machine `A`, accepting **any** Turing machine `T` as an input, which is guaranteed to **halt on all inputs**, and outputs the last symbol printed by `T` if `T` halts (and when `T` does not halt, simply print anything)?

People mentioned that this is closely related to Rice's theorem.

For simplicity, let's say `T` can only output 0 and 1. The property that ""the last character printed by `T` is 1"" is undecidable by Rice's theorem. However, `A` is **not** required to **decide** this property. It may freely output anything if `T` does not halt. So **can Rice's theorem really be applied to determine that such machine** `A` **does NOT exist?** Are there any subtleties there?

&#x200B;",2024-01-17 09:38:06
18ya5ve,SAT Solving for Instruction Count in Game of Life,"I have what I think is an interesting problem for SAT solving and was wondering if I could maybe receive some help to fully solve my problem! In particular, a friend an I have been looking at a problem of optimizing the code in a hot-loop for a fast game-of-life simulator.

We know that the minimum number of instructions in this hot-loop is bound from below by 8 and above by 10, which we found by applying some assumptions. The hot-loop computes the next iteration of a cell, given its state and the state of its `n` neighbors.  The table below shows whether this step can be computed using `m` [lop3](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#logic-and-shift-instructions-lop3) instructions.

|n/m|2|3|4|5|6|7|8|9|10|
|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|
|3|**UNSAT**|**SAT**|SAT|SAT|SAT|SAT|SAT|SAT|SAT|
|4|UNSAT|**UNSAT**|**SAT**|SAT|SAT|SAT|SAT|SAT|SAT|
|5|UNSAT|UNSAT|UNSAT|**UNSAT**|**SAT**|SAT|SAT|SAT|SAT|
|6|UNSAT|UNSAT|UNSAT|UNSAT|**UNSAT**|**SAT**|SAT|SAT|SAT|
|7|UNSAT|UNSAT|UNSAT|UNSAT|UNSAT|**UNSAT**|**SAT**|SAT|SAT|
|8|UNSAT|UNSAT|UNSAT|UNSAT|UNSAT|UNSAT|???|???|SAT|

This table was made by first encoding the problem in DIMACS CNF, after which we ran various SAT solvers including Kissat, ParKissat and PRS both locally and on the high performance cluster at our university.

Sadly, however, the most interesting row is incomplete for the standard implementation of game of life on a rectangular grid - `n = 8`. Our solvers received a time-out after 7 days with 128 cores on the high performance cluster.

We have attempted to exploit as much symmetry as possible in order to reduce the search space, such as ordering of inputs and instructions. We also enforced the requirement that each input and instruction output must be used. Additionally, we have tried to encode the problem in Z3 to little success (most likely due to inexperience using it).

We would be very interested in hearing if you've got any ideas on how to fill in these last two entries in the table. If needed, we can also provide more of the gory details of our encoding as well!

Relevant:

* [CNF Encoding](https://github.com/binary-banter/sat-generator/tree/new-attempt/src) (note that `n` in our encoding includes the center cell)
* [Terrible Z3 Attempt](https://gist.github.com/Vlamonster/0d91fd2a633f5ea26c155f0a7ca464a9)
* [Blogpost on Method](https://binary-banter.github.io/game-of-life/)
* [Implemenation of Best Hot-Loop](https://github.com/binary-banter/fast-game-of-life/blob/4732749f8a550e43baadf2c6d0b32d3f6a2dc694/src/kernels/gol.cu#L11) (see `sub_step`)",2024-01-04 10:37:44
18szqml,I have some queries as I want to write a process scheduler for atmega328p,"I am planning to write a simple process scheduler for an atmega328p micro-controller. I want to write a process scheduler because my interest lies towards operating systems and computer architecture, and I thought that writing a simple process scheduler for an actual hardware would be a good hands on experience.

So I understand that there are different process scheduling algorithms and all that but I have some doubts regarding the actual implementation of process schedulers - 

First, what are the things I need to actually keep track of in my schedule table? Do I need to store the value of every register, program counter, direction of data register bus, etc? I found some process scheduling programs on github, but I can only see objects like function, whether task is active or not and, priority - in the structure of processes (or maybe I was looking at something wrong), and not individual register values, etc.

Second, does the process states only depends upon the processor internal memory units(like registers, program counter, etc)? If yes, then what if a program which is dependent on memory and makes several memory store and memory fetch calls, does the scheduler also have to store a copy of whole memory block(which is simply impractical) and if it doesn't then isn't there a chance of data hazard(for example process 1 and process 2 can both depend and alter a memory location because of which corruption can occur after process switch). ",2023-12-28 17:43:31
18g0opr,"Could GDB's ""checkpoint"" functionality be used to add Universal Undo to any program?","Hey everyone. I have this crazy idea and I'm wondering if it has any chance.

Could GDB's (or any decent debugger) ""checkpoint"" feature be used to effectively add an ""undo"" feature to literally any program?

This could be implemented as a wrapper around the program, and every minute or so, it runs GDB to attach to the process and save a checkpoint, plus a screenshot of the UI. The user might also be able to save a checkpoint on demand with a hotkey, let's say.

At any point, the user can check the available checkpoints, and visually decide which state of the application to ""undo"" or ""check back"" into.

For simplicity, let's assume that we only care about programs with no network access and with only a single process. But if this works well enough, some FAANG could through a few million dollars at it and figure out the rest. And only Linux support because let's face it, these sort of crazy ideas like containers and stuff are done there first.

Naturally, a problem would be external files used or created by the program. These could be copied and associated to a checkpoint to be restored (maybe only storing diff information on successive checkpoints).

This would include a generic GUI for the ""restore checkpoint"" feature, which would work on any program.

Indeed, this is similar to checkpoints in video game emulators.

Has something like this been done? Is it feasible? I understand that this is doable on virtual machines, but then the performance cost and storage of checkpoints could be huge.

Edit: Looks like [CRIU](https://en.wikipedia.org/wiki/CRIU) already implements part of this?",2023-12-11 18:42:58
17zq03j,how does an algorithm that tries to match as many people with their preferred choice work?,"hi everyone! I have no computer science background at all but I am applying to my clinical for nursing. for our last clinical, we are supposed rank our top 20 choices and then a computer tries to allocate as many people towards their preferred location as possible. any idea how this algorithm works or if there's a way I can kinda cheat my way into getting some of my top choices? ",2023-11-20 14:41:06
17qtyww,Meaning of stack and program counter of a process with multiple threads," I am studying the book ""Modern Operating Systems"". It talks about the concepts of stacks and program counters (PCs) in both processes and threads.

I understand the meaning of stack and PC in the context of threads. As I can understand they both are specific to each thread.

While I understand the meaning of stacks and PCs within the context of threads, as they appear to be specific to each individual thread. I find it challenging to grasp their meanings when applied to processes (especially processes with multiple threads).

For example, thread is a stream of instructions and PC points to the memory address of the next instruction to be fetched to the processing unit. I maked sense to have PC for each thread. Now I'm unclear about the meaning of a process's PC when each thread possesses its own PC.

One explanation I encountered on Stack Overflow suggests that the process PC represents the PC of the currently executing thread at a given moment. However, I'm puzzled about how this works when multiple cores are in play, and multiple threads from the same process are running concurrently.

I have same problem with the meaning of stack in the context of process.

Or are they just logical implications, where processes does not actually have stacks or PCs ??",2023-11-08 19:52:03
16k71eh,How CPython Implements and Uses Bloom Filters for String Processing,N/A,2023-09-16 13:01:46
15zpcca,A Simple Proof of Sybil-Proof,"Happy to be able to share this paper, which formally proves the existence of a sybil-proof reward mechanism for fully PERMISSIONLESS routing networks, something that has been widely considered unachievable since the publication of the ""On Bitcoin and Red Balloons"" paper in 2011/12.

[https://github.com/SaitoTech/papers/blob/main/sybil/A\_Simple\_Proof\_of\_Sybil\_Proof\_Lancashire-Parris\_2023.pdf](https://github.com/SaitoTech/papers/blob/main/sybil/A_Simple_Proof_of_Sybil_Proof_Lancashire-Parris_2023.pdf)

Of interest to the economists in the crowd, the mechanism works by creating a collective action problem that incentivizes openness rather than closure. While early-hop nodes are collectively better if none of them share, each is individually better off ""defecting"" from this hoarding equilibrium and sharing with their peers. This strategy transfers income from hoarders to sharers and thus pressures other participants to share themselves as a loss-minimization strategy.

Self-cloning is meanwhile eliminated as it lowers the probability of producing a block (and the expected income from doing so) by more than it increases the node's expected income from the inclusion of an additional routing hop.",2023-08-24 02:51:25
15syr3g,Generating Chess Puzzles with Genetic Algorithms (using the geneticalgorithm Python library),N/A,2023-08-16 19:02:22
15ovsux,Game Theory Egoist: Don't be Outcome Oriented,N/A,2023-08-12 05:27:05
18wi6ww,Need some help finding some articles or other scholarly sources for writing a paper,"I'm in my last semester as a Computer Science student and we have to write a persuasive ethics paper for my capstone class. The topic that I was assigned is ""Social media apps reduce isolation and are, on balance, a good thing"". We have to have 3 sources for the pro and 3 for the against. I have found papers easily for the against, but can not find anything for the pro. I have tried Google Scholar, ieeexplore and Researchgate, but I haven't been really successful. Are there any articles out there that any of you know of that support a statement like this: ""technology brings us closer together and makes us more social by allowing us to make and maintain relationships without respect to geographic location."" Any help would be greatly appreciated.",2024-01-02 05:58:52
18fwr9y,Optimal Splitting of Feature-Target Pairs within Input Size Constraints," 

Hi there, I'm dealing with two lists, one comprising features and the other containing targets. The task at hand involves processing all possible feature-target pairs. Ideally, I'd combine these two lists into a single input for processing. However, due to an input size constraint, I'm required to split them and merge the outputs afterward. I experimented with taking all the features in all the chunks and adding as many unprocessed targets as possible to each chunk. Unfortunately, this approach doesn't accommodate scenarios where the features alone surpass the input size constraint.

Is there an algorithm or an optimized approach that can intelligently split these feature-target pairs, ensuring eventual processing of all pairs while minimizing the number of required calls?",2023-12-11 15:13:41
17yi63l,Why doesn't x86 have 8 bit SIMD bit shift or multiplication instructions?,"ARM and PPC off the top of my head both have instructions for shifting each element of a 16 byte vector by either a constant or by the number of bits specified in the corresponding byte of a second vector. x86 only added that second form in the AVX2 extension, but from what I can tell, there's still no efficient way to shift multiple 8 bit ints.

Since a left shift by N is semantically identical to multiplication by 2^N, I figured *that* would be the solution until I realized there is no 8 bit multiply either. Not even one that would e.g. compute eight 16 bit products by multiplying the corresponding 8 bit integers in the lower half of two 128 bit vectors.


Is multiplying or shifting 8 bit integers really not that useful? Is there some other way to accomplish these operations efficiently that I'm not aware of? I've lost count of the number of times something is done differently and I eventually come to support the change but in this case I continue to be at a loss.",2023-11-18 22:41:36
16k7n8z,How does a hypervisor isolate the hard disk from two virtual machines?,N/A,2023-09-16 13:30:11
15pysg1,Spaces of Flaws of Flows: COBOL and the back-back-ends of development,N/A,2023-08-13 13:21:48
14s6nqv,"If you have a minute, could you take a quick survey for my Science Project?","“Hello fellow Developers!

We need your input for a research project! If you have a few minutes to spare, we would love for you to fill out a short survey about your coding experience with certain languages. This survey is part of my High School Research project.

Here's the link to the survey:https://forms.fillout.com/t/btJ5G6QDjcus

Thank you in advance for your help. Your feedback is much appreciated and will be used to further our research!”",2023-07-06 11:41:02
146rago,Compare ranked lists with RBO,"Have you encountered the problem where you have ranked lists, but no ground truth to compare which of the 2 lists are most correct? Then check out [this article](https://medium.com/@oieivind/find-similarity-of-ranked-lists-with-rbo-4f8c2c90b9e) to learn how to compare the 2 lists!",2023-06-11 11:13:30
144cq0k,How common is programming using (undelimited and delimited) continuations these days?,"I am interested in programming language theory, and I have been able to gather from reading around that first-class continuations are useful for all sorts of control-flow reasons.

I understand that when implementing a toy language it can be nice to simply implement first-class continuations (and/or delimited continuations) to have it be as expressive as possible for all sorts of control-flow things one might want to do, and that this would be a better time-saver than implementing various kinds of loops and breaks and all that. But aside from theoretical/toy languages, do programmers tend to use things like `call/cc` and `shift`/`reset` much? They seem hard to reason about, and so I wonder if they are used only in very demanding conditions where one has a very specific flow of control they want and this is the only way to do it.

As an aside, how do people generally certify correctness of code using first-class continuations?",2023-06-08 15:45:07
12xz6xq,Abstract Machine Models - Also: what Rust got particularly right,N/A,2023-04-24 22:38:00
193gnql,Increasing confidence in your software with formal verification,N/A,2024-01-10 19:25:09
18g4cgy,Technical Considerations for GUI Toolkits [Discussion],"I  didn't find popular enough sub to talk about gui's, so ill just talk here. A while ago i make myself a list of possible ways to make a GUI  (reddit-specific markdown fucked up the formatting, but its still  readable enough):

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

Types of tools for creating a gui (and how those tools approximately work):

1)Utilize the native *graphical interface API*, and depending on the platform, they have specific layers to interface:

* Wayland, X11, for Linux
* [GDI](https://learn.microsoft.com/en-us/windows/win32/gdi/windows-gdi) for windows
* [Quartz](https://en.wikipedia.org/wiki/Quartz_(graphics_layer)) for macOS  
Example - GTK uses [wayland](https://gitlab.gnome.org/GNOME/gtk/-/blob/main/docs/reference/gdk/wayland.md) ([source code](https://gitlab.gnome.org/GNOME/gtk/-/tree/main/gdk/win32)) [X11](https://gitlab.gnome.org/GNOME/gtk/-/blob/main/docs/reference/gdk/x11.md) ([source code](https://gitlab.gnome.org/GNOME/gtk/-/tree/main/gdk/x11)) GDI ([source code](https://gitlab.gnome.org/GNOME/gtk/-/tree/main/gdk/win32)) Quartz ([source code](https://gitlab.gnome.org/GNOME/gtk/-/tree/main/gdk/macos)) [How to use wayland display server](https://bugaevc.gitbooks.io/writing-wayland-clients/content/black-square/the-wayland-client-library.html) (TODO missing ""animation"" section)

2)Utilize opengl *or other low level graphics api's* with window context, use GPU to render widgets

* Window context manager - [glfw](https://github.com/glfw/glfw), [sdl](https://www.libsdl.org/)  

   * contexts and surfaces, reading input, handling events  
Example: ImGui, NanoVG, Nuklear, raylib Why? Mainly used for game development, but also good for gui's. *(i haven't seen any examples that uses this method that are used for developing general-use graphical user interfaces.)*

3)Utilize multiple established gui toolkit libraries to make one common gui toolkit library  
Example: [iup](https://www.tecgraf.puc-rio.br/iup/)  (need more examples) Why? Mainly for styling. Previously mentioned  examples like GTK might support multiple graphical interface API's to  support all platforms, but it still follows single style rule set. [GTK uses gnome rule set](https://developer.gnome.org/hig/guidelines.html), windows uses its own rule set, etc.

4)Enslaved web pages

* Electron Why? html and css is easier to use

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

Currently I'm confused, where is downside of option **2** over option **1**?  is it performance loss? I tried raylib and i found it easier, simpler  for creating gui's than any of compile-to-native gui toolkits, like gtk,  qt. I could just learn tools like opengl and/or option **1** libraries (like raylib), that way, not only do i have a tool for game dev, but also for gui dev.  
I'm considering using opengl/raylib for custom-made text/code editor, is that a bad idea?  
People  who are experienced in gui dev, i want to hear your thoughts on this  question, and also on correctness of the list above. Thank you.",2023-12-11 21:11:28
1891d9i,Kabsch-Umeyama Algorithm - How to Align Point Patterns,"Hi there,

I've created a video [here](https://youtu.be/nCs_e6fP7Jo) where I explain how the Kabsch-Umeyama algorithm can be used to align point patterns.

I hope it may be of use to some of you out there. Feedback is more than welcomed! :)",2023-12-02 10:58:52
17tyqz0,Password Managers in Digital Forensics: Creating a Process to Extract Relevant Artefacts from Bitwarden and KeePass,N/A,2023-11-13 00:54:00
17pq3ji,"Emergence, patterns in small Turing machines","
I've noticed something about busy beavers (or Turing machines in general).

* 2-state BB has 2 ""patterns"" of going left. 
* 3-state busy beaver has 3-4 patterns of going left. Where a ""pattern"" is defined as the exact sequence of ""pixels"" (a ""pixel"" is a head state + cell value). [Image](https://i.imgur.com/IMXNyMH.png).
* 4-state busy beaver has 4-5 patterns of going left. [Image](https://i.imgur.com/6lamZRR.png). [Source](https://mathworld.wolfram.com/BusyBeaver.html) of the original images.
* 5-state BB contender seems to have 5 patterns (so far) of going right. Here a ""pattern"" is a sequence of ""pixels"" — but pixels repeated one after another don't matter — e.g. *ABC* and *ABBBC* and *ABBBBBC* are all identical patterns. [Imagine 1](https://i.imgur.com/c51AL7J.png) (200 steps). [Image 2](https://i.imgur.com/5w2UyqF.png) (4792 steps, **huge image**). [Source 1](https://www.wolframalpha.com/input/?i=busy+beaver+5-state+2-color), [source 2](https://commons.wikimedia.org/wiki/File:Busy_Beaver_5-state_2-symbol_best_contender_Run_prefix.gif) of the original images.
* 6-state BB contender seems to have 4 patterns (so far) of going right. Here a ""pattern"" is a sequence of ""pixels"" — but repeated alterations of pixels don't matter (e.g *ABAB* and *ABABABAB* are the same pattern) — and it doesn't matter how the pattern behaves when going through a dense massive of 1s, in other words we ignore all the *B1F1C1* and *C1B1F1* stuff. [Imagine](https://imgur.com/a/E8mtEDk) (2350 steps, **huge image**). [Source](https://commons.wikimedia.org/wiki/File:Busy_Beaver_6-state_2-symbol_best_contender_Run_prefix.gif) of the original image. 

Has anybody tried to ""color"" patterns of busy beavers like this? I think it could be interesting to see how the colors alternate. Could you write a program which colors such patterns? 

Can we prove that the amount of patterns should be very small? I guess the amount of patterns should be ""directly"" encoded in the Turing machine's instructions, so it can't be big. But that's just a layman's guess.   


## Context 

Why did I look into busy beavers in the first place? I wanted to get some intuitive understanding of how long-lasting irregular behavior (halting or not) arises from a very small set of instructions and a completely empty tape. I'm fascinated by it. You can create so much stuff from just a couple of instructions and emptiness? Wow!  

I know that many researchers study busy beavers. I don't want to imply there are any important low-hanging mathematical results about busy beavers we could prove. No. 

But I guess not many researchers want to ""explain"", in a more philosophical/everyday sense, how Turing machines give rise to irregularity. (I could be wrong though. I've tried asking about it, but got no response.) That's why I think it makes sense for anyone, professional or not, to take a look into emergence in TMs. To come up with their own ""philosophical"" take. 

And wouldn't it be just fun to turn the run of a Turing machine into some kind of rainbow/spectrum?",2023-11-07 08:56:27
16wj42q,Quantinuum’s H1 quantum computer successfully executes a fully fault-tolerant algorithm with three logically-encoded qubits,N/A,2023-09-30 21:55:50
16la14v,Survey on Fourier Transform and series in Theoretical Computer Science,I need a survey or any other reference to learn how to use Fourier transform and series in different theoretical computer science topics from basic to advanced. For example in coding theory ε-biased code sometimes going to Fourier basis is helpful in many occasions. So I want a survey or any other reference on this topic does there exist any?,2023-09-17 19:41:05
15a83iw,Generating Orthogonal Set Partitions,N/A,2023-07-26 14:57:44
1591egf,[Operative Systems] A modern reference Book,"Hi All !  


I just found my old Modern Operating System (from Andrew S.Tanenbaum 2ºEd, 2001) and I wonder if there is a more modern reference book for operative systems nowadays  > 2020  
Cause it's been almost 20 years from this ....  
Do you know if they still teach Operative Systems with this Book ?  
Thanks",2023-07-25 07:46:53
150pg42,"mfw Alfred Aho (of The Dragon Book fame) has another book, about algorithms and data structures. I honestly did not know this. Follow link.",N/A,2023-07-15 22:46:04
14yyo29,“Low-Resource” Text Classification: A Parameter-Free Classification Method with Compressors,N/A,2023-07-13 22:33:11
14v4wpg,Capsule Networks Explained,"Hi there,

I've created a video [here](https://youtu.be/sGK5mhJSzVg) where I explain how capsule networks work and what problem they are trying to solve.

I hope it may be of use to some of you out there. Feedback is more than welcomed! :)",2023-07-09 17:52:09
14s1qxh,Is it correct to say the big O of an algorithm imprecisely (But still upper bound)?,"Binary search is O(log(n))

Now here is the schtick... According to Khan academy you can TECHNICALLY say its also O(n\^2), because since its ""upper bound"", technically the binary search algo will never grow faster than n\^2, it might grow slower but never faster than n\^2,

hence why technically its also O(n\^2) and O(n\^k) for every k >= 1",2023-07-06 07:41:22
14fb15w,Guiding Language Models of Code with Global Context using Monitors,N/A,2023-06-21 15:38:06
1amkc67,Spearman Correlation Explained,"Hi there,

I've created a video [here](https://youtu.be/cHIJjZFfMYo) where I explain how the Spearman correlation works and what it tries to measure.

I hope it may be of use to some of you out there. Feedback is more than welcomed! :)",2024-02-09 09:27:25
19ahrbw,"Temperature, Top-k and Top-p Explained","Hi there,

I've created a video [here](https://youtu.be/-BBulGM6xF0) where I explain how the temperature, top-k and top-p sampling affect the LLM text generation.

I hope it may be of use to some of you out there. Feedback is more than welcomed! :)",2024-01-19 12:14:22
196d6o1,KL Divergence Mathematics Explained,"Hi there,

I've created a video [here](https://youtu.be/MXcsW613msA) where I explain the mathematical intuition behind the KL divergence.

I hope it may be of use to some of you out there. Feedback is more than welcomed! :)",2024-01-14 10:42:32
190ma5c,Essential Languages/Projects to Practice?,"Hey everyone! Im a sophomore in university and I am beginning to practice CS more seriously for my career once I graduate. Im currently thinking SWE, DevOps and FullStack. Also interested in cybersecurity but I don’t think thats a lot of coding. 

What are some essential languages I should practice? Also, what are some projects you recommend to create for learning and experience? Currently doing my first project, it’s a diophantine equation calculator for 2 distinct integers (in Java)!",2024-01-07 06:58:33
18id6ap,Prime Distribution Conjecture,"Hi all, I would like to test - and learn from your responses to a conjecture on prime distribution I came up with:

**Sequence Definition**

1. **Starting Point**: *a*\_0 ​= *n*, for any integer *n* \> 3.
2. **For each subsequent element** *a*\_*i*\+1**​:**

* **If** ***a***\_***i***​ **is a prime number**: *a*\_*i+1​ = a*\_*i* ​− *p*, where *p* is the maximum prime number less than *a*\_*i*​.
* **If** ***a***\_***i***​ **is not a prime number**: *a*\_*i+1 ​= a*\_*i* ​+ *n*(*A*), where *A* is the set of prime numbers less than *a*\_*i*​, and *n*(*A*) is the number of elements in *A*.

**Conjecture**

For every initial *a*\_0​, there exists some *N* in N(atural Numbers) such that a\_*N* ​= 2.

Looking forward to your comments!

Thanks!",2023-12-14 17:02:07
17s5ggx,Feedback on my matrix multiplication algorithm,"Ever since I started learning about matrices and trying to implement something in code, I've heard that fast matrix multiplication is a big deal and people are always trying to optimize the operation. I know the ""vanilla"" method generally uses 3 for-loops and is considered to have a complexity of O(n\^3). I started wondering if there is a way to implement the operation using only 2 for-loops for multiplying the elements. This is what I've done:

    public Matrix2D multiply(Matrix2D b) {
            if (nColumns == b.nRows) {
                Matrix2D bT = b.transpose();
    
                double[] numbers = new double[nRows * b.nColumns];
    
                for (int i = 0; i < numbers.length; i++) {
                    int rowIndex = i / b.nColumns;
                    int colIndex = i % b.nColumns;
    
                    double sum = 0;
                    for (int currentDotProduct = 0; currentDotProduct < b.nRows; currentDotProduct++) {
                        sum += getElement(rowIndex, currentDotProduct) * bT.getElement(colIndex, currentDotProduct);
                    }
    
                    numbers[i] += sum;
                }
    
                return new Matrix2D(numbers, nRows, b.nColumns);
            } else {
                throw new IllegalArgumentException(""Number of columns of A must be equal to the number of rows of B"");
            }

By the way, here are the methods ""transpose"" and ""getElement"":

    public double getElement(int rowIndex, int columnIndex) {
     return flatMatrix[rowIndex * nColumns + columnIndex]; 
    }
    
    public Matrix2D transpose() {
            double[] numbers = new double[flatMatrix.length];
            for (int i = 0; i < numbers.length; i++) {
                int rowIndex = i / nRows;
                int colIndex = i % nRows;
                numbers[i] = getElement(colIndex, rowIndex);
            }
    
            return new Matrix2D(numbers, nColumns, nRows);
        }

From the tests I've done it was about 50% faster than the vanilla multiplication algorithm. However I didn't find a similar approach out there. Is this a decent method, could it be improved somehow? Thank you.",2023-11-10 14:43:35
16yd2zt,[PDF] How to Read a Paper -- S. Keshav,N/A,2023-10-03 00:10:20
15pub3z,Data-driven decision making: Case studies,"I am constructing an IT architecture for a startup and I have come across a lot of interesting information about data-driven decision making. I want to share my insights and findings with you.

P.S. Feel free to write your thoughts in comments.

**Data-driven decision making: Case studies**

Data-driven decision-making is all about using relevant data to support important choices. It's about seeking valuable insights rather than getting lost in a sea of information. Let's take a look at two cases, where organizations have successfully implemented this concept.

**1. Google’s Approach**

Google’s mission is to organize world’s info and make it useful and accessible. They use data to inform decisions at every step.

* **Objective Definition:** Google begins with clear questions. For example, they questioned, ""Do managers matter?"" within their HR function, leading to some fascinating discoveries.
* **Data Collection:** Google’s people analytics team collected data on managerial effectiveness, finding that teams with better managers performed better and were happier.
* **Data Analysis:** They further analyzed the data to identify the top traits of high-scoring managers and factors causing a manager to struggle.
* **Information Presentation:** Google shared these insights with their managers through detailed reports.
* **Data-Driven Decisions:** Actions based on the analysis were implemented. For example, Google introduced a new bi-annual feedback survey to track manager performance.

In addition to its internal practices, Google also used data-driven insights to develop AI tools like Hire, which screens resumes and matches them with job descriptions.

Google also applied machine learning to reduce energy consumption in its data centers, which led to a significant reduction in cooling energy usage.

**2. Service Hotel's Implementation**

Service Hotel, a boutique hotel chain, was collecting conventional performance metrics but wasn’t using the data effectively. They wanted to foster a data-driven decision-making culture.

* **Objective Definition:** The leadership team established key questions related to their strategic plan.
* **Data Collection:** They evaluated existing data and introduced new data collection methods, like incorporating external data, or more frequent and precise customer and employee satisfaction surveys.
* **Data Analysis:** The team onboarded an analyst and provided training to existing employees. They found strong correlations between customer satisfaction, employee satisfaction, and organizational performance.
* **Information Presentation:** The hotel introduced a set of dashboards for each of their key questions, which included a headline, visual, data chart, and a narrative comment.
* **Data-Driven Decisions:** The team used machine learning to analyze extensive data, predict occupancy rates, and optimize pricing.

Check out the full article in my blog: [https://ainsys.com/blog/2023/06/26/data-decision/?utm\_source=linkedin&utm\_medium=social&utm\_campaign=hfs\_research&utm\_content=data\_decision&utm\_term=datamanagement](https://ainsys.com/blog/2023/06/26/data-decision/?utm_source=linkedin&utm_medium=social&utm_campaign=hfs_research&utm_content=data_decision&utm_term=datamanagement)",2023-08-13 09:20:54
14jn6z3,Ax=b of huge matrices in Py3,"I am trying to do Ax=b on Py3, where size of A is (50000,50000) and size of b is (50000,9). Both A and b are CSC matrices (as a result of previous operations), and spsolve is giving memory issues. Do you have any suggestions on how to solve this in Python 3?

Note: np.linalg.solve could not do these operations, nor any of the previous ones, which is why I'm working with scipy. Scipy functionalities managed to solve upto this point, where I am stuck right now.",2023-06-26 17:14:47
14jabz3,A Collaborative Approach to Problem-Solving,N/A,2023-06-26 07:26:22
147h3ml,How is Apache APISIX Fast? Hint: Data Structures,N/A,2023-06-12 06:41:50
141p7oj,"The only definitive way to establish that software is correct and bug-free is through mathematics, using the formal methods",N/A,2023-06-05 19:37:01
1ao4v9m,Balanced Ternary Algebra,N/A,2024-02-11 10:16:47
1ahab80,Incremental Database Computations | Feldera,N/A,2024-02-02 18:18:14
1aeos3c,Time series segmentation paper reading list repository,N/A,2024-01-30 13:46:27
1983fk9,Relationship between symbol (data type) and debug symbol (symbol table)?,"I'm reading Wiki page on [debug symbols](https://en.wikipedia.org/wiki/Debug_symbol), where it says the following:
>A debug symbol is a special kind of symbol 

Reading linked page on [symbols (primitive data type)](https://en.wikipedia.org/wiki/Symbol_(programming)), I think this connection is incorrect. ""Symbol"" in the context of [symbol tables](https://en.wikipedia.org/wiki/Symbol_(programming)) refers to key-value pairs, and debug symbol is just special type of information used for debugging, and does not have anything to do with the primitive data type.

Wikipedia page for [symbol (data type)](https://en.wikipedia.org/wiki/Symbol_(programming)) says:
>Uniqueness is enforced by holding them in a symbol table.

This refers that these primitive data types are made in some sense ""constant"" by the way they're stored in symbol tables. 

Please correct me if I understood this incorrectly.",2024-01-16 13:55:55
191i3so,Complexity class for constant number of NP oracle calls,"So I‘ve been looking a bit at the polynomial hierarchy and was wondering whether there exists some papers on algorithms that run in polytime, when giving access to a constant number of NP oracle calls",2024-01-08 10:21:12
18u8n4j,How Neural Networks Work,"I made a video explaining how neural networks work and function. If you get a chance, I would really appreciate it if you checked it out:  [https://youtu.be/WRSNrVH0wg8](https://youtu.be/WRSNrVH0wg8) ",2023-12-30 06:05:34
182suwp,Cyber-physical decentralized planning for communizing,N/A,2023-11-24 14:06:19
17zn87m,Knuth Airgaps & Knuth Buffers,N/A,2023-11-20 12:16:07
17rvma0,How do hypervisors accommodate more than 65536 virtual machines?,"In ARMv8-A, VTCR\_EL2.VS bit when set allows 16-bit VMID's to be stored in the TLB entries for 2-stage address translations. But what if we have more virtual machines? For example large cloud computers.",2023-11-10 03:58:55
17m2pbd,How to pass information from VM to hypervisor?,"I am writing a hypercall interface which helps the guest to talk to the hypervisor, but I need to pass some arguments which I don’t know how to pass to the hypervisor because the OS runs in a completely different address space and while switching to the hypervisor, we switch context and all general purpose registers are lost/saved elsewhere.

I can always access the VM’s pt_regs but is there a better way to do this?


Running on Raspi3b Armv8-A",2023-11-02 12:46:44
17cgvqq,Can both preemptive and non-preemptive scheduling be present in the same OS?,N/A,2023-10-20 17:37:57
17c8fas,Computer networks learning material,"Computer networks learning material.

Hey guys, I’m a UG student on my second year of CS. Ive got computer networks subject this year, it’s mostly theoretical basic stuff. Internet, routers, protocols, waves, cables etc. we go through a lot of material and at this point I’m completely lost. Can somebody recommend me good computer networks material so I can catch up from scratch?

Thanks",2023-10-20 10:52:35
1770fre,Open Source Schema Registry with Schema Checks for Federated GraphQL,N/A,2023-10-13 14:47:22
173db5q,Mealy Machine practice,"I want to design a 5 bit combination lock using a Mealy Machine.

So far I created these variables to use

Inputs:

– R: to reset the lock to the initial state.

– Z: for a zero input

– I: for a one input

Outputs:

– L: 0 = off, and 1 = on.

&#x200B;

I was able to draw the state Transition Diagram; however I am completely confused on what the State Transition Table.  Any help would be appreciate, maybe my diagram is wrong?

https://preview.redd.it/lnclut38e2tb1.jpg?width=1154&format=pjpg&auto=webp&s=97e105e784e70020254193f2602ff640543ea34e",2023-10-08 23:31:42
16kdjos,Are there any highly successful theoretical computer scientists who were not amazing at high school and/or university math contests?,N/A,2023-09-16 17:49:24
15erj1m,Blog Post: Sliding in a Type Checker,N/A,2023-07-31 20:44:39
14yb6q0,How can I decode this string?,"A little info, this is the data from a qr made in the ""Nothing X"" app which has an advanced eq that allows exporting & importing eq profiles in qrcodes. You can only change some parameters by 0.5 and I'd like to be more precise. My idea is I can extract the data from an exported qr change it repackage it into a qr and then scan it back into the app as a new profile hopefuly keeping the modified numbers.

Data that should be in there is the numbers 1815, 1.6 and -1.5. There is garaunteed more data in there I'm just not sure what.

Here's the string: 
H4sIAAAAAAAAAGNIYACDGCcGhgZ7CPsOEjvGGUkcyj6wn+HBI5ezZ85AxB38XOFqHM4hsf3cQGxGdpfUtMTSnBIA5pwLVGsAAAA=",2023-07-13 04:58:04
14ldj7q,On the Precision of Static Analyzers,N/A,2023-06-28 16:07:34
14icw44,Why does Sipser's say (1∪0)0* = 32? Is it not n ∈ 2^n?,"I apologize if this question is rather stupid. I asked the AskMaths subreddit but I got no replies. Also, I hope you are not seeing two question blocks in the title. If you are, the first question block is the union symbol, the second question block is the 'belongs to' symbol. Now my main question:

Sipser's, chapter 1, in introduction to regex, says that `(1∪0)0*` is the number 32. But is it not every positive integer (and negative two's complement integer) where the corresponding decimal number would be 2 to the power of n, where n ∈ Z? So basically 0, 2, 4, 8 (and their two's complement) etc etc? Why would it specifically be 32? 32 has 5 zeros in front of it. But where does this regular expression say 5? I am really confused. Again apologies for stupid question.

Thanks.",2023-06-25 04:36:13
14i00yo,Negative integer handling in programming languages,N/A,2023-06-24 18:31:23
14duxpf,"How do ```dynamic dispatching``` of a method, and the ```late binding``` if it, differ?","Edit: god. I screwed up the title. Here: How do dynamic dispatching of a method, and the late binding of it, differ?

They both operate on the virtual methods table right? How do they differ exactly?",2023-06-19 23:54:20
1akojgt,Achieving Consensus in Go: A Raft Implementation,https://github.com/jmsadair/raft,2024-02-06 23:45:06
19d4d9f,Extension of fuzzing for Linux disk encryption,N/A,2024-01-22 19:44:30
1999672,Debating the Transition from Monolith to Microservices: Where's the Line?,"I'm diving deep into the complexities of evolving from a monolithic architecture to a microservices model and I'm intrigued by the nuances of this transition. I’d appreciate your insights and personal experiences on this topic.

The journey from a monolithic application to a microservices architecture is rarely straightforward. It often involves segmenting a large, integrated system into smaller, independent components. But the big question is: when do these changes signify a genuine shift from a monolith to microservices?

**Example for Discussion**:

* Imagine a system where the UI is a React-based Node.js application, and the backend is a separate Django service.
* Additionally, there are distinct SQL and NoSQL databases, each functioning as separate services.
* The front end and back end are developed and deployed independently.

With this setup in mind, here are my queries:

* Does breaking down a monolithic service into distinct components like this mean we're no longer dealing with a monolith, or is it too soon to call it a microservices architecture?
* Considering key microservices attributes (independent deployment, loosely coupled services, individual data management), what are the definitive signs that we've transitioned to a microservices model?
* In the spectrum between monolithic and microservices structures, we encounter terms like ""modular monolith,"" ""hybrid architecture,"" and ""distributed monolith."" How do you differentiate between these in real-world scenarios?

This transformation seems to be more of a gradual evolution rather than a distinct jump. I’m curious about how others identify this shift in their projects. At what stage would you classify an architecture like the example above as microservices? Are there particular indicators or benchmarks that you look out for?",2024-01-17 22:03:46
18wlwr9,Multi-Head/Multi-Query/Grouped-Query Attentions Explained,"Hi there,

I've created a video [here](https://youtu.be/o68RRGxAtDo) where I explain how the Multi-Head Attention (MHA), Multi-Query Attention (MQA) and Grouped-Query Attention (GQA) work, and what are the pros and cons in using each one of them

I hope it may be of use to some of you out there. Feedback is more than welcomed! :",2024-01-02 09:59:11
18d1zi2,Open Automation project,"Hey fellow scientists, I thought some of yall may find this interesting. Its a little project I started for a sort of modular automation system. Feel free to branch it, fork it or send pull requests :D

At the moment all automation is based on image/script pairs. The first big addition I'd like to make is to add schedule/script state/script automation as well.",2023-12-07 18:30:26
184army,Adaptive Sampling For a Grid With Rough Estimates?,"Let's say you have a function that returns a response for a given X,Y coordinate, a grid of coordinates, and there are some known points that are roughly where you want to focus a search. What techniques would you use to create an adaptively-sampled grid? 

This could either be coarse-to-fine and increase accuracy as you get closer to the points, or it could just be generating ""outward"" from the known points with a kind of falloff for the precision (e.g. one step away from the point, it's still relatively accurate, but as the cartesian distance from each point of interest increases, the estimates become more coarse)?

I've tried quad-trees, but in this particular case, the regions of interests may fall near the edge of the trees and I don't want the heatmap to have any ""cutoffs"" when it crosses into another quadrant. I'm thinking there may be some kind of ""breadth-first"" approach where you start out from the gridpoint closest to the estimated X,Y coordinate and slowly increase the size of the region as you take more steps away from the initial estimate, but I forsee that being relatively complex, trying to group together gridpoints as the estimate gets more coarse.

Any suggestions?",2023-11-26 13:30:59
17x02mw,Constant time income tax algorithm— Part 2,N/A,2023-11-16 22:56:25
17gzm53,Seeking a Community Focused on Elevating Computer Science and Its Practitioners,"Hi fellow computer scientists,

I'm not entirely sure if this is the right subreddit to ask this, so if it's not, I sincerely apologize! Could anyone kindly direct me to a more suitable place for this query?

I would like to know if there is any **community dedicated to spread enthusiasm for Computer Science**. I believe in the power of bringing together computer scientists and enthusiasts to foster a deeper appreciation for our field in society.

To clarify, I'm not seeking an exclusive group that elevates us above others. Rather, I'm interested in a platform where we can collectively work towards **highlighting the positive impacts of computer science**, support each other's growth, and **inspire a new generation of computer scientists**.

I envision this as a space where we can share resources, collaborate on projects, and advocate for the value and importance of our discipline in solving real-world problems. I think by uplifting each other and showcasing the diverse, inclusive, and innovative nature of computer science, **we can enhance our collective success and contribute positively to society.**

Does anyone know of such groups, online communities, or organizations that align with these goals? I’m eager to contribute and learn from others who share this vision. Your suggestions and insights would be incredibly valuable.

Thank you!",2023-10-26 15:53:21
17ccdfd,Questions on the Edmonds-Karp algorithm (Network Flow),N/A,2023-10-20 14:18:24
172w8w1,I want to know about data analytics My question is 1. I'm from non it background this profile is good for me? 2. How to get job in this field 3. Which topic I do cover for this field? Thnkuuu .....anyone give me some suggestion.,N/A,2023-10-08 10:50:39
16x6h50,"Thrilling update for all! The eagerly-awaited Curve token distribution has officially kicked off. Check your qualification and collect your free CRV tokens via their primary site. I've secured 900 CRV worth $462, but your bonus might differ based on your blockchain activity.","Exciting news, crypto enthusiasts! Curve Finance is hosting an airdrop to reward our amazing community. Hold CRV tokens, stay active, and spread the word to get free tokens starting 10.01.23 for 10.10.23. Join us in supporting DeFi innovation and be part of this exciting opportunity! https://linktr.ee/curvelabs",2023-10-01 17:02:39
16wluzh,the new video about making I.A animation,N/A,2023-09-30 23:49:36
16lvc2i,MetaMask Unveils Coin and Community Distribution!,N/A,2023-09-18 13:18:06
16lv0dy,Lorinda Cherry & UNIX (one of the earliest women in CS),"I saw her [here](https://youtu.be/tc4ROCJYbm0?t=939) and I taught she might be a clerk or a secretary at Bell Labs but I was very wrong. She is very decorated. She worked on troff and GNU plotutils. She is one of the earliest people who had a degree in CS. Probably one of the earliest women in CS as well. Does anyone know a bit more about her besides what is written on the web? 

PS: One of the few women higher-ups at Bell Labs worked on troff, please don't blame me for thinking she was a secretary.",2023-09-18 13:04:36
1687pee,N-rooks completion puzzle,"I am interested in completion problem of non-attacking rooks on a chessboard. 

**Input:** Given a chessboard of size 𝑛×𝑛 with 𝑛−𝑘 rooks placed in non-attacking positions, and certain chessboard diagonals represented by multi-set of integer D= {j1,j2, ... , jk}

**Output:** Can we place additional 𝑘 rooks such all 𝑛 rooks are non-attacking and each new rook is placed on exactly one diagonal in 𝐷?

The multi-set of diagonals D defines parallel diagonals. For diagonal j, the sum of x and y coordinates of any cell on that diagonal is equal to j. This implies that there are no crossing diagonals. Only parallel diagonals (only diagonals, no anti-diagonals).


In the linked stackoverflow, find sample input and  its solution. The posted answer provides an exponential algorithm in the worst case.

I suspect that the problem is NP-complete. Is there an efficient (fast) algorithm?",2023-09-02 17:01:42
14v6htd,Comparing Queuing Strategies in Distributed Systems,N/A,2023-07-09 18:55:27
14jq6s4,The relation between Graphs and Boards,N/A,2023-06-26 19:08:58
14jehv6,Difficult Question: Effient Solution for finding the value D that is the Distance of a number X to 2/3 of the mean of all values. Finding D by just locking at all numbers once. So finding it in O(n).,"Imagine  you have a growing set of values, denoted as xᵢ. As more values are  added, keeping track of the median by calculating the sum and number of  values becomes an efficient way to determine it. However, the challenge  arises when you need to find the value x that is closest to the mean  multiplied by 2/3, without reevaluating all the numbers again. You need  that x to find the Value D that is the distance between this X and the  special Value of mean multiplied by 2/3.

​ So it looks like this: n is the numbers of values that have been added so far:

totalSum\_(n) = xᵢ + totalSum\_(n-1) totalSum\_(n)  / n = mean\_(n)

median\_(n) = totalSum\_(n)  / n specialValue = Median \* (2/3)

Distance D = min(|x₁ - specialValue|, |x₂ - specialValue|, ..., |xₙ - specialValue|)

It seems very difficult to do this without knowing all the values in advance. I don't want to go back and lock at the numbers.

I want to get D by just looking at all the numbers once.   
~~Or an idea why it is not possible.~~ ",2023-06-26 11:16:16
193v5yw,How related is compiler to a person interested in computer security?,"IE., is a compiler class crucial for people who want to pursue graduate studies in security?  
My gut is wrenching for not taking it but I didn't understand anything first-day at that course (front end compiler).",2024-01-11 06:34:22
193pkt7,"Pure, Mixed, and Entangled Quantum States (article + Jupyter notebook)",https://medium.com/@emilmarinov/pure-mixed-and-entangled-quantum-states-84e8a4a8dd16,2024-01-11 01:41:11
18yy40w,[D] Setting up a small HPC for orchestrating a small teams AI research,N/A,2024-01-05 04:37:10
17yicsj,faulTPM: Exposing AMD fTPMs' Deepest Secrets,N/A,2023-11-18 22:50:18
17wmd3j,Is my understanding of Dependency Inversion correct?,"This principle states that a high level module should not depend of on a low level module, both should depend on abstraction.

So instead of having this code were a class called Laptop declare and instantiated a field of SDRam:

    class Laptop{  SDRam ram = new SDRam; } 

We could make laptop class have a instance field of abstract and and assign an object of SDRam class at run time. Assuming SDRam class implementing or extending Ram interface/abstract class.

    class Laptop{  Ram ram;  Laptop(Ram ram){                this.ram= ram;      }      public static void main(String args[]){            Laptop laptop = new Laptop(new SDRam());     } 

}

Is my understanding correct?

What does ""abstractions should not depend on details. Details should depend upon abstractions'"" mean?",2023-11-16 13:03:39
17op31z,Technical Dimensions of Programming Systems,N/A,2023-11-05 23:35:23
17jpsog,Any resources that compiles different notions in computer science?,"Hello guys, I just finished this repo and it has so much notions in computer science and I would like to know if you guys have any other resources to learn how things work and improve my knowledge in computer science

https://github.com/ByteByteGoHq/system-design-101",2023-10-30 09:53:48
17e29xo,An instance variable concept for pointfree interpreters,N/A,2023-10-22 20:20:02
16zyvr9,Aho Corasick For Efficient String Matching (Python & Golang Code Examples),N/A,2023-10-04 21:15:31
159i686,Constraints on valid CFG production rules,"Not every collection of production rules represents a valid context-free grammar. Apart from conventions such as only having one start symbol, or avoiding null and unit rules, there are other constraints for a usable grammar. For example:

* every non-terminal and terminal symbol must be reachable (eventually generated by expanding) from a start rule
* avoid unproductive cycles: `A -> B`; `B -> A`

are pretty obvious . Excluding duplicate production rules is another obvious one. There is also:

* Every terminal symbol must occur on the RHS of at least one rule all of whose RHS symbols are terminals.

which is perhaps not so immediately obvious.

What are some other, perhaps less obvious, constraints on when a set of production rules make a valid, non-redundant or ""reasonable"" CFG?",2023-07-25 19:22:49
145ezq4,Interview with Andrew Ng and Chelsea Finn: AI & Robotics,N/A,2023-06-09 19:53:26
144icfj,EnrichedCS Guest Speaker and Competition,"Hey guys! We are a student-run organization called EnrichedCS. We are hosting a free **USACO** training session with MIT graduates from VPlanet. This seminar will provide attendees information regarding tips, practice resources, and advice in preparation for this competition. Plus, if you attend this event, you can earn a chance to win a free **Discord Nitro** one-month subscription. This event will occur on June 9th from 6-7PM.   Hope you will be there! You can become a member of our organization by clicking the link below! [https://discord.gg/enrichedcs](https://discord.gg/enrichedcs) 

And check out VPlanet at [https://www.vplanetcoding.com/](https://www.vplanetcoding.com/)

We are also hosting a USACO-style competition right now with **$300** in **cash** prizes which you can join by going to our announcements channel in our discord server ([https://discord.gg/enrichedcs](https://discord.gg/enrichedcs)) that contains all instructions for signing up. Competitors will have 4 hours to compete with a maximum team size of 4 people. There are two divisions, a beginner division, and an advanced division. There is one question in each division. Join quickly because this competition ends on June 11th (3 days)! 

Thanks!",2023-06-08 19:20:25
1aneidu,Inject memory safety check into executable binaries to get rid of MMUs?,"Let's say there's a binary with content:

    void main() {/*...*/}
    int swap(int *a, int *b) {
        int tmp = &a;
        &a = &b;
        &b = tmp;
    }

If we insert some memory safety check before every pointer operation into the binary, we'll have:

    void main() {/*...*/}
    int swap(int *a, int *b) {
        validate_ptr(a);
        validate_ptr(b);
        int tmp = &a;
        &a = &b;
        &b = tmp;
    }
    
    inline void validate_ptr(void *p) {
        if (STACK_BOTTOM <= p && p < STACK_TOP) {
            return;    
        }
        if (is_allocted_on_heap(p)) {
            return;
        }
        exit(ILLEGAL_MEM_ACCESS);
    }

It's 100% safe to execute this binary under real mode because it will never access illegal addresses.

Now, if our OS has a ""compiler"" that ""compiles"" every executable binaries into such ""safe binaries"" before executing them, we can get rid of the MMU and let everything run under the same address space. This can reduce a lot of overhead.

My question is: is there any research or project that explored similar ideas? [Language-based system](https://en.m.wikipedia.org/wiki/Language-based_system) is the closest I can find but I'd like to see some binary-level approach. Rewrite everything in a particular managed language seems a very impractical idea to me.",2024-02-10 11:42:44
180eiz6,Introduction to Code Coverage Testing - Guide,Here is a guide on how code coverage testing helps to improve the quality and reliability of software. It helps to identify and resolve bugs before they become problems in production: [Introduction to Code Coverage Testing](https://www.codium.ai/blog/introduction-to-code-coverage-testing/),2023-11-21 11:06:36
17e8yy5,Polymers | Free Full-Text | Knot Formation on DNA Pushed Inside Chiral Nanochannels,N/A,2023-10-23 01:35:32
165fwq7,How Code Integrity Supercharges Code Generation,"The article explores how code generation and integrity tools, working together, suggest a powerful combination to stay ahead and exploit AI coding assistant tools smartly: [Code Integrity Supercharges Code Generation](https://www.codium.ai/blog/code-integrity-supercharges-code-generation/)

* Code generation tools enable you to code faster. However, they can also create new problems for development teams, like introducing hidden bugs and reducing familiarity, understanding, and responsibility of the code.

* Code integrity tools verifying that the code fits the intent or spec, improving code coverage, improving code quality, and helping developers get familiar with the code.",2023-08-30 14:14:03
150ooi6,"I have an idea for a novel, non-Von-Neumann architecture I'd like to possibly research . . . . .",". . . . . but *anyone* can say that.

I can't do it alone-- how can I get someone to take me/my idea seriously?

I have a Master's degree in Computer Science, but all of my experience is in software development.

Who can I approach, and how?

Many thanks for any advice!

&#x200B;

&#x200B;

edit:

Guys/gals-- What is going on with all of the harsh replies?  

I never advertised or claimed that my idea is anything more than just an idea.

Some of you seem to think that I'm making claims of creating revolutionary technology.

That is simply not the case!

If you understand English, and if you read my original post carefully, you will notice that my question is not about my idea, but where/who can I go to to receive constructive feedback on it.

All the scientists out there will understand that theories and concepts need to be formally investigated before they can be confirmed or refuted; simple desires and/or doubts are not proof.

Not only might my idea not work as desired, it might even be physically impossible to implement in the first place; hence the possibile need for research.

I'm very sorry if I offended or insulted anyone.

Thank you to all of you who actually did take the time to read my original post and did give constructive feedback.

&#x200B;

&#x200B;",2023-07-15 22:13:40
14iqkl7,I need critique on my IBA cache idea,"The CPU would use a single cache memory paired with an idempotence bit array (IBA).

When writing to a memory address inside the cache's coverage, the data would be written to the cache and the corresponding IBA bit would be set.

When reading from a memory address inside the cache's coverage, if the corresponding IBA bit is set, the cache's output would be yielded. Otherwise, the main memory's output would be yielded. And of course, reading from a memory address outside the cache's coverage would yield from main memory.",2023-06-25 16:32:46
195qspy,How You Can Hide Files Inside Images: The Art of Steganography,https://medium.com/@jizoskasa/how-you-can-hide-files-inside-images-the-art-of-steganography-e5c2200a5671,2024-01-13 15:45:02
18oghgj,Sending addresses via the address bus,"If we had an address bus that was 8 bits wide, then you'd assume it would be able to access 2^8 (256) memory locations, but the average person would want to access more locations than this. How do we get around this? A couple of obvious ways I can think of would be sending the address over multiple clock cycles or sending a ""row"" and a ""column"" address to access 256×256 locations. I was wondering what the standard way of accessing more locations is and if there are any more cool ways to do it.

Thanks in advance!",2023-12-22 14:43:56
18ed4zb,The N×log(N) Limit of Multi-Factor Authentication,N/A,2023-12-09 13:01:20
180po5z,Ready Worker One? High-Res VR for the Home Office | Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology,N/A,2023-11-21 19:50:17
16lulhv,Breaking: MetaMask Unveils Coin and Community Distribution!,N/A,2023-09-18 12:46:05
15svwdq,Prove in NC^1 formulas and circuits are equivalent,"NC^1 is the class of boolean circuits with depth logn and size polynomial of n. Then prove that circuits and formulas are equivalent.


My try: https://imgur.com/a/VcNPGV4",2023-08-16 17:15:34
15o3220,Why the world still runs on C or C++,"We know that almoat every Operating system is either C or C++ at its core. I understand that C or C++ is the language can run on bare metal hardware but after all this growth and development. Can't we re write all these systems on something new that has better capabilities and efficiency. We are progressing into better hardwares and new programming languages but we are somewhar creating a pile of updates on top of the old system.

What do you think about it, Can we rewrite the whole system with current and latest technologies?

Or it will be just reinventing the wheel?",2023-08-11 08:30:35
14v3qhx,Beyond Undecidable,N/A,2023-07-09 17:04:08
14smwqx,Preparing for the basics,"I'm an engineering major and I'm taking an intro to algorithm design and programming class. Are there any ways to prepare myself for this course over July?

Edit: the course description is ""This course provides experience in developing algorithms, designing, implementing programs. Topics include syntax/semantics, flow control, loops, recursion, I/O, arrays, strings and pointers.""",2023-07-06 21:46:30
14hwu3f,Which are the websites or contests to showcase cyber security talent,"I am a beginner. Is there a website where I can solve challenges and showcase the world that I am worthy?
Similar to what happens in competi",2023-06-24 16:13:26
14hbaqc,How close are computers to proving of disproving mathematical propositions?,"I started reading a book by Michael Spiser called ""Introduction to theory of Computation"". I got it as part of a class at uni, but never actually read it page to page. In the book it says that a long time ago mathematicians like Alan Turing and Alonzo Church proved that, computers cannot solve certain problems. An example is making true assertions about a mathematical proposition. It felt odd reading this knowing that with the recent development of AI we can prompt a problem and get the answer. Thinking from just the ChatGPT perspective which is a NLP model I understand that it learned pretty much everything and it can take its best guess at what the answer would be. But could an AI be trained to ""understand"" purely the logic thus making correct assertions about problems it never encountered?  
I am not very familiar with all this, so please feel free to correct me!

Thank you",2023-06-23 22:07:45
1aboca0,Towards modern development of cloud applications,N/A,2024-01-26 17:51:20
18wtu9p,How are applications patched?,"I was wondering about the details of how different programs are patched. For example when a game or a program like discord gets a patch whats actually happening under the hood? Its not like the entire application is redownloaded, only the parts that changed. 

I read about binary patching, is this the go to method, or are there different options?

Thanks!",2024-01-02 16:47:10
18gbfbc,Build a fantasy CPU emulator in JavaScript,N/A,2023-12-12 02:35:17
180vjue,"Would ""there exists a pair x,y in the subarray arr[left:right+1] that sums up to k."" be a good loop invariant for the code below which determines given a sorted array of integers if there is a a pair of integers, x and y, that sum to k.","The code: 

https://preview.redd.it/mvhp2recis1c1.png?width=317&format=png&auto=webp&s=f8f8b1cbb2b70ef1ced4aafd35a7d781ec5ec45a",2023-11-22 00:00:45
18x0xm6,Why does random access memory have a time complexity of O(1) and not O(log(n))?,"Say that I have an array of size n, therefore each memory address is comprised of log(n) digits, just reading the address will take the processor log(n) operations. So how is it O(1)?",2024-01-02 21:29:56
18x0vy2,Mag Amp Computer,"# I've studied the use of magamps to make computers and honestly think they'd be good for making less advanced but still working computers compared to vacuum tubes. But if not then I'd like to know why???

&#x200B;",2024-01-02 21:28:01
18ax538,Computer Science Major Experience [Survey],"Were you ever enrolled as a CS major at a college or university and decided to leave the major? We are four students from the Information Science Department at CU Boulder interested in learning about what leads students to leave a CS major.  
This survey will provide an opportunity to share your compliments and complaints through a fully anonymous system. The survey itself should only take 5-10 minutes to complete. Whether your experiences were positive, negative, or somewhere in-between, your experience is extremely valuable in allowing us to understand how we can improve the CS major and make it a more positive experience for others in the future.

[https://cuboulder.qualtrics.com/jfe/form/SV\_8qfDAR7ahmh9vvg](https://cuboulder.qualtrics.com/jfe/form/SV_8qfDAR7ahmh9vvg)",2023-12-04 23:07:36
17l2faf,Why can't data centers be decentralised?,"Ok, for context, I'm working as an architectural designer and engineer, and I have no idea how data centers work. I just work on maximising spaces for building occupation and use. However, our client raised this question in the middle of our meeting, and I would like to hear from a CS-perspective why this isn't feasible.  


So the question the client raised is why data centers can't be decentralised using blockchain technology. I always assumed you need data center space because it requires a lot of computing power and electricity to power and operate a data center. The client went on a rant about how much CO2 is being released from data centers and how data centers need to be decentralised like cryptocurrency in order for it to be sustainable. Obviously, this is beyond my scope, and no one is intervening or weighing into this discussion (we're all working in a non-cs background in architecture and engineering). Can someone explain why data centers aren't decentralised?",2023-11-01 02:44:08
165ps8b,A Deep Dive into low-code platforms,"The software development landscape is witnessing a paradigm shift. Developers, in their quest for innovation, often find themselves entangled in the web of routine operational tasks. Low-code platforms are emerging as a beacon of hope, offering a fresh perspective and a transformative approach to the challenges faced by developers. I've delved deep into this topic in my recent [article](https://www.ainsys.com/article/low-code) and here are some insights:

  
**Component abstraction in low-code:** One of the standout features of low-code platforms is their focus on component abstraction. It allows for a more straightforward expression of business logic, benefiting not just developers but also business analysts and managers. The platforms are designed to be easily understandable, bridging the knowledge gap between different stakeholders.

  
**Reusability and flexibility:** Low-code platforms emphasize the reusability of components. This means that developers can easily integrate new functionalities into existing systems without having to build from scratch. This is a significant departure from traditional platforms, where each new functionality often requires extensive coding.

  
**LCDP vs. Code-First Platforms:** It's essential to differentiate between Low-Code Development Platforms (LCDPs) like Mendix, AINSYS, Pega, and Appian, and more flexible systems such as WordPress. LCDPs are built around a core of builder elements and related functions, focusing on efficiency and reusability, rather than mere flexibility.

  
**Operational efficiency:** One of the most compelling promises of LCDPs is their potential to eliminate or significantly reduce routine tasks. It allows developers to channel their energy into more creative and complex tasks, thereby adding more value to the project.

  
**User-friendly interface:** LCDPs are designed to be so user-friendly that even non-developers can participate in the development process. This inclusivity ensures that the final product is of top quality, as flawed logic or insufficient naming can be quickly detected and corrected.

  
**Streamlining requirement collection:** Platforms like AINSYS have framework requirement management systems that facilitate better communication between developers, analysts, and stakeholders. It makes the process of requirements collection and documentation more efficient, ultimately improving the quality of the software.

  
For professionals in the IT sector, what are your thoughts on the rise of low-code platforms? Do you see them as a viable solution for the challenges currently facing the software development industry? I would appreciate your insights.",2023-08-30 20:30:01
1501015,"Open source licenses need to leave the 1980s and evolve to deal with AI: « Since many programming datasets, in particular, are based on free software and open source code, something must be done. »",N/A,2023-07-15 03:41:25
146w3zi,"You Are a Computer, and No, That’s Not a Metaphor",N/A,2023-06-11 15:00:49
18z7ouy,Do things in a Linux os book apply on Windows as well as Linux.,"I read a book called (os three easy pieces) (not the whole book though) but it only talks about Linux.
Can I use what I learn from this book to understand windows or do I have to read a different book which explains about windows?",2024-01-05 14:07:20
17vq059,Lebanese computer science history and achievements,"Hello, I am doing research and I'm trying to compile a list of the history of Computer Science and programming in general in lebanon or by lebanese people.

Can anyone help me by suggesting some key points in the history, for example: 

1. LAU  was the first university to offer an undergraduate in computer science in lebanon. (1976)
2. Pou the game was programmed by lebanese mobile programmer Paul Salameh (2012)",2023-11-15 09:30:11
14h74cz,GADDAG,N/A,2023-06-23 19:17:42
1acu5k1,Does multiplying with zero affect runtime Big O?,"ELI5 very new to this topic. If I'm multiplying two vectors (for regression), and there are n elements in them but in one vector, there are m non-zero elements (m<=n). Would my Big O of this operation be O(m) or O(n)?",2024-01-28 04:26:50
185fzdv,The largest number representable in 64 bits,N/A,2023-11-27 22:36:25
14wzbkw,The Possible Pathways to Proving P=NP are actually strongly constrained.,"People seem to think that resolving P=NP is some mysterious thing without a starting point but if you are trying to prove P=NP, you are basically forced into working with a small number of possibilities — ER proofs and parsing graph grammars. Obviously, there could be some other approach, but this is the most obvious one and largely unexplored.

There are several major proof systems in proof complexity. For our purposes, we can talk about just Resolution and Extended Resolution (ER). Frege proofs don’t appear to be much more powerful than ER and because Frege systems are a little more complex, unless you’ve tried and failed with ER there is no reason to use them.

Resolution proofs involve the simple combination of clauses with variables of different valences with no other variables shared between clauses of different valence. So, for instance $(a \\lor b \\lor c) \\land (\\lnot c \\lor d \\lor e) \\rightarrow (a \\lor b \\lor d \\lor e)$, but not $(a \\lor b) \\land (\\lnot a \\lor \\lnot b) \\rightarrow (a \\lor \\lnot a)$.

Known advanced SAT solvers such as CDCLs are equivalent in power to resolution which has known exponential lower bounds on proof complexity (see Pigeon Hole Proofs). Actually, basically any attempt to solve SAT runs aground on it only being as powerful as Resolution, so for any attempt to prove P=NP, you need a strong proof system.

Extended Resolution (ER) is just resolution, but you are allowed to define new variables from the existing variables. For instance, $q \\equiv (\\lnot a \\lor b)$ or $(\\lnot q \\lor \\lnot a \\lor b)\\land(q \\lor a)\\land (q \\lor \\lnot b)$. This is the same as using $(a \\implies b)$ in Frege proofs. No super-polynomial lower bounds are known for ER, so ER could potentially be used to prove P=NP.

If you assume that short ER proofs might exist for every unsatisfiable CNF, then you need a way to find them. Randomly searching for ER proofs won’t work because new ER variables can be defined from old ER variables (and it can be assumed that they have to be), so there are exponentially-many possible ER steps. To get around this problem, you need some way of finding short ER proofs. Since, ER proofs necessarily have some structure, the most natural approach to do that is parsing. CNFs are bipartite graphs, not strings so you need graph parsing.

There are a variety of different graph grammars and even the context-free HRGs (Hyperedge Replacement Grammar) and Node Replacement Grammars are known to be NP-complete. ER productions seem like they should be simple enough to be context-free, however they cannot be straightforwardly fit into an existing graph grammar scheme because proofs have to be free to reuse variables. So, the clauses have to be considered primary.

What could go wrong here? The grammar could be too big to be polynomial time. The grammar could have Right-hand Sides (RHSs) of productions with arbitrarily high treewidth. That would make the algorithm super-polynomial. Perhaps you could turn any failure of graph grammars to work into a new attempt to separate P from NP.

\--------------------------------------------------------------------------------

\_The Handbook of Satisfiability\_ mentions Resolution and Extended Resolution and is a good introduction to Satisfiability.

Robert Rechow’s thesis \_On the Length of Proofs in the Propositional Calculus\_ introduces Proof Complexity including Extended Resolution.

[https://www.cs.cmu.edu/\~mheule/publications/rat.pdf](https://www.cs.cmu.edu/~mheule/publications/rat.pdf) uses Extended Resolution.

[https://dl.acm.org/doi/pdf/10.1145/1008335.1008338](https://dl.acm.org/doi/pdf/10.1145/1008335.1008338) is a short paper that show that a well known SAT problem which is exponentially hard to refute with just Resolution can be refuted in polynomial time with Extended Resolution.

[https://www.cs.rochester.edu/u/gildea/2018\_Fall/hrg.pdf](https://www.cs.rochester.edu/u/gildea/2018_Fall/hrg.pdf) is an introduction to HRGs.

[https://www.researchgate.net/publication/220713349\_Node\_Replacement\_Graph\_Grammars](https://www.researchgate.net/publication/220713349_Node_Replacement_Graph_Grammars) is an introduction to Node Replacement Graph Grammars.

[https://aclanthology.org/P13-1091.pdf](https://aclanthology.org/P13-1091.pdf) clearly describes an algorithm for parsing HRGs intending for use on NLP problems. It can probably be adapted to other types of grammars.

\_The Handbook of Formal Languages: Volume 3 Beyond Words\_ Chapter 3 Context Free Graph Grammars discusses both types of graph grammars.

Edit: Added references for those interested.",2023-07-11 18:30:01
14s1o3x,💡 Calling all AI enthusiasts! Join us at VOICE & AI Conference - the ultimate event at the Intersection of Conversational and Generative AI!,"Hi all! Join us at VOICE & AI, the leading Conference at the Intersection of Conversational and Generative AI! Date: September 5-7, 2023, Location: Washington Hilton, Washington DC. 

🌟 VOICE & AI is all about exploring topics such as LLMs, Generative AI, Coding, Design, Marketing, and Conversational Interfaces. This event is a must-attend for anyone passionate about the future of AI! 

🎉 We have an impressive lineup of top brands participating, including Walmart, Microsoft, Veritone, GitHub, AWS, NVIDIA, GM, Capital One, and many more. And guess what? We keep adding new speakers and sessions every week, ensuring a diverse range of insights and expertise. 

✨ But wait, there's more! We're kicking things off with a pre-event workshop conducted by OpenAI on September 5. This workshop will cover essential concepts of data training, including data collection, preprocessing, feature engineering, and model evaluation. It's the perfect way to get things started! 

💡 And on September 6, we have something special for you. It's the Free #PromptNight, the largest AI Meetup on the East Coast! Join us for a night of networking, exchanging ideas, and connecting with fellow AI enthusiasts. 

🎟️ So, don't miss out on this fantastic opportunity! Visit our official event website at[ https://www.voiceand.ai/](https://www.voiceand.ai/) to secure your spot and get all the information you need. 

🚀 Let's come together and explore the exciting world of voice and AI at VOICE & AI Conference. See you there! ",2023-07-06 07:37:22
130srx0,The 2-MAXSAT Problem Can Be Solved in Polynomial Time,N/A,2023-04-27 15:46:28
14xtrgm,Free Compute Trial,We are are offering a free compute trial on our managed Kubernetes machine learning platform. We appreciate any input we can receive. Academic users are given preference and half of the free compute is dedicated for them. Please let us know if you're interested!,2023-07-12 16:42:35
14hk11a,"Why are the concept of ""quoting"" things and ""escaping"" thing so ubiquitous in computer programming ? Is this a universal of all things computing ?","Will quantum computers and light based computing still make such heavy use of quoting and escaping ? 

Is a language that talks to the outside world always going to require ""quoting and escaping"" ?

Does ""quoting and escaping"" have a more formal definition in computer science ? I feel like that could be it's entire sub field like boolean logic. 

What are the major ideas of that subfield, if it does exist ? 

Are languages without quoting and escaping that are still useful and able to interact with the outside world even possible ? 

[I asked it who shall not be named this question, here is what it said](https://chat.openai.com/share/88547cdc-4099-4c29-a8d4-d9c746119656)",2023-06-24 05:07:58
17qusll,I created exact convex decomposition algorithm. What are possible applications and monetization strategies?,"My algorithm is similar to CGAL's convex decomposition algorithm but creates significantly fewer convex pieces. Whereas CGAL's approach generates r\^2 convex pieces in the worst-case scenario, my algorithm produces at most r convex pieces, and on average r / 2  (where r represents reflex edges in CGAL terminology. I refer to them as concave pairs). It achieves such efficiency by avoiding the creation of new triangles and forming convex pieces solely from the initial mesh triangles. It works on any closed mesh (mesh without holes).

While I cannot share the implementation details, the algorithm broadly follows these steps:

1. Select a triangle and designate it as the initial element of the convex piece.
2. Find a triangle adjacent to the previous one and include it in the convex piece.
3. Determine whether the convex hull encompassing the updated convex piece extends beyond the initial mesh geometry.
4. If the convex hull does not extend beyond the initial mesh geometry, keep the triangle added in step 2 in the convex piece; otherwise, remove it.
5. Repeat step 2.
6. Once no more triangles can be added to the convex piece—since any additional triangle would cause the convex hull to extend beyond the initial mesh geometry—save the accumulated triangles as one convex piece and start again from step 1.

The time complexity of this new algorithm is nearly linear. It is challenging to specify the exact time complexity, as the amount of work the algorithm requires dynamically changes throughout its progression. The primary bottleneck for meshes with large convex pieces is the updating of the convex hull using an incremental convex hull algorithm, which operates in O(n\^2). If this algorithm is something important, I plan to implement a some clever data structure to improve performance. For meshes with large amount of the concave pairs, the bottleneck is in filtering which concave pairs can be skipped - this too could be accelerated with a smart space-partitioning data structure, likely an octree.

Currently the algorithm uses only basic data structures (arrays, lists, hash sets, hash maps), so there is a room for the improvement. Nevertheless, I think the algorithm already surpasses existing methods in performance. Although I have not found any other exact convex decomposition algorithms that do not generate new triangles, I have seen a few papers on approximate convex decomposition where the Armandillo mesh exact convex decomposition takes about 4 hours, whereas my algorithm completes the decomposition in 94 seconds, so roughly in 1.5 minutes (using 13th Gen Intel(R) Core(TM) i7-13700  2.10 GHz).

[Here is a link](https://drive.google.com/drive/folders/1_CFpcMjZJ-qtCrX2TZOufgb94XZauwm0?usp=sharing) with 3D models and their exact convex decompositions processed by my algorithm, along with statistics.

&#x200B;

https://i.redd.it/dswfd9mio6zb1.gif

Now, I have a few questions for the community:

* Who might be interested in this kind of algorithm, and what are its possible applications?
* I would like to monetize my work—what monetization strategies would you suggest? I am considering dual licensing, but I am sure there are more options.",2023-11-08 20:29:05
16n9gbu,can we call ada lovance and charles babbage as the creator of computer era ?,N/A,2023-09-20 02:19:51
151t856,"Why you shouldn’t use .index() in LeetCode, use .split() instead",N/A,2023-07-17 05:57:48
14sqmu4,Threads Web App and Twitter,"Full disclosure, I don't use Twitter, or Instagram, or Facebook. But I am hyped for Threads. Elon Musk said tech was bloated and fired 80 percent of the workforce. Threads rehired loads of them and is trying to replace Twitter. I am here for it. Economist and Wall St. Journal articles I read said that if Musk's gambit succeeds, it means more tech layoffs.  I'm wondering if [Threads.net](https://Threads.net) will be operational as a web app in its own right soon. I certainly don't use IOS apps for any day-to-day communication. Do you think I am being silly by suggesting people who work in the CS field have it in their interest to switch and support Threads wholeheartedly? Or any thoughts on this in general?",2023-07-07 00:09:37
18km00x,What typical beginners problems become obsolete with new programming languages?,"People advertising for new languages, especially ""functional"" ones often boast ""see how easy it is to write quicksort in it"" and show the version with two new arrays filtered out of original and then sorted recursively. True mammoths of programming despise this generally as the method is not exactly quicksort since it doesn't work ""in-place"".

I'm trying to collect what other problems become completely spoiled, e.g.:

* reversing string - in languages like C or Pascal you need to do it in-place, walking from both ends with two pointers and swapping characters - in most nowadays languages strings are immutable, reversing functions are often built-in (or it is `[::-1]` in case of Python) so it takes more time to explain to students it is a problem at all
* rotating string - again, in-place it could be done with whimsical applying of two reverts, but in modern languages it's just concatenation of two substring calls
* modular arithmetics - calculating long chain of additions and multiplications and taking modulo at the end (like [this](https://www.codeabbey.com/index/task_view/modular-calculator)) - normally this makes student to think about overflow and understand applying of modulo after every other operation - but in Python specifically numbers are silently switching to infinite arithmetics - other languages nowadays have built-in bigints and so on.
* rotating square matrix 90 degrees (useless for matrix but useful for images) is performed in-place by mirroring against main diagonal and then flipping horizontally or vertically (advanced version of rotate string, perhaps) - though again with modern languages people rarily understand the idea of doing anything ""in-place"" (and with modern garbage collectors and typical ram sizes it is not that bad, of course).

Thus I would be thankful if you can help adding more examples to this list.",2023-12-17 17:13:34
18472qc,An idea regarding solving Data Hazards,"At the software level, resolving data hazards by reordering instructions is a crucial optimization technique. In today's landscape, we benefit from chatbots that assist in solving programming challenges, offering convenience even if not always completely accurate. What if a similar approach were applied to instruction reordering?

Imagine implementing an Instruction Reordering Unit (IRU) within a processor, leveraging a feed-forward neural network (AI) to rearrange instructions intelligently. The primary goal? Ensuring simultaneous arrival of the rd and the Result, thus minimizing data hazards and enhancing result accuracy.

However, the challenge lies in effectively training and validating this neural network. It's a complex task that involves exposing the network to diverse instruction sequences and their dependencies to ensure it can reorder instructions accurately across various scenarios and workloads.

Now training the network to understand and predict these relationships as well as validating the neural network's performance across different processor architectures and workloads? That's another story.

However, regardless of the challenges I see potential in this idea if it has not been implemented yet.",2023-11-26 09:31:05
14t1ipz,Swift vs Python,N/A,2023-07-07 08:54:25
19bt5vk,Am I The Only One Interested In Committed-choice Concurrent Constraint Logic Programming For The Web?,N/A,2024-01-21 02:45:59
18r3f19,Cyclic Machine that could be useful for simulating some properties of elementary particle,"(Previous post was automatically deleted due to edit)

Here is a description:  

Machine consists of a list of instructions. Each instruction represents some direction in space: left, right, up, down, forward, back. Machine executes all it's states one after another and moves in corresponding direction of space the same discrete distance on each tick of time. After some state is executed, control is passed to the next state. It happens infinitely in a loop. After last state is executed, control is passed to the first state.  

So machine moves and moves until it's state is changed.  

https://youtu.be/yXSO_N2tL-0?si=RhrsZe26qwl19rlX

Properties and phenomena that this machine reproduces:  

\- E - total energy: total amount of states. Energy of one state is numerically equal to reduced Planck’s constant and is the reason why action is discrete

\- inertia (first newton's law): Machine keeps on moving infinitely until it's state is updated and the more states in machine the more states to be updated and the more particle ""resists to acceleration""  

https://youtu.be/sO9TgfWO5c4?si=XSxcvTIZP1w4hdgd

\- limited speed: you can not move faster than straight  

\- discrete action (interaction): change in energy equals energy of one state  

\- reduced wave length: contribution of one discrete piece in motion  

https://youtu.be/uaYC5s82iIE?si=8KSSpK-OtD9RljKt  

\- uncertainty and observer effect: interaction destroys the original particle so you can't know some properties of the particle after interaction. Because you can't control, which state will be taken from machine or passed to machine  

https://youtu.be/mNjKbEcswI4  

\- momentum and conservation of momentum: amount of states that represents motion  

https://youtu.be/IG7Rfsu4fK4?si=PDikrn45K26gsmoF  

\- rest mass: amount of states that represents cyclic motion. For example a pair of states left-right does not move machine anywhere, but takes ticks of time too be executed.  

\- speed: If you have particle RRRR, it moves with maximum possible speed right. If you have RRRRLLL, it moves right 1 moment of time out of 7. So it's average speed is 1/7 of maximum speed  

\- Photons generated by set of particles have more or less the same speed in any direction  

https://youtu.be/RVrPr4NvddU  

and more.  

Bell inequalities are not usable because of observer effect. Classical statistic can not be calculated because observation destroys the particle AND hidden variables. Therefor you can not use classical statistics in bell inequalities.  

https://youtu.be/OX\_0poP6\_tM  

Edit: some day we could test if it’s just simulation or the true nature of reality. It can be the next huge thing.",2023-12-26 08:16:56
1837ahk,"Is there room for significant innovations in computer science, or has it reached its peak?","While numerous advancements are happening in computer science, they don't seem to be inherently disruptive. Do you believe significant innovations, such as compilers, interpreters, and operating systems, are still feasible?",2023-11-25 00:54:42
18vqcf7,"Exploring the Intriguing World of Computer Science: Seeking Your Insights on ""A Computer Science Degree is (Mostly) A BAD Decision"" Video: https://www.youtube.com/watch?v=lcYTlAPhYrU"," **https://www.youtube.com/watch?v=lcYTlAPhYrU** 

&#x200B;",2024-01-01 06:00:35
189poph,Artificial intelligence is already in our hospitals. 5 questions people want answered,N/A,2023-12-03 09:02:34
1bq1xd8,How Netflix Uses Machine Learning To Decide What Content To Create Next For Its 260M Users: A 5-minute visual guide. 🎬,"TL;DR: ""Embeddings"" - capturing a show's essence to find similar hits & predict audiences across regions. This helps Netflix avoid duds and greenlight shows you'll love.

Here is a visual guide covering key technical details of Netflix's ML system: [How Netflix Uses ML](https://open.substack.com/pub/codecompass00/p/how-netflix-uses-machine-learning?r=rcorn&utm_campaign=post&utm_medium=web)

https://preview.redd.it/7ir84ag554rc1.png?width=1363&format=png&auto=webp&s=98b34ab4367383c22b8519081fcedc53b486ed87",2024-03-28 17:53:55
1bjwv4l,How do I break down Operating Systems: Three Easy Pieces into 14 weeks,N/A,2024-03-21 03:19:50
1b4ye8y,Nevalang: A Flow-Based Programming Language,"Hello, Reddit community!  
  
After three years of development, I'm ready to announce **\*\*Nevalang\*\***, a new general-purpose, flow-based programming language that I believe introduces a fresh perspective to software development. Nevalang is designed with static typing and compiles to both machine code and Go, offering an interpreter mode for flexibility.  
  
The essence of Nevalang lies in its flow-based paradigm, there's no control flow constructs like functions, loops, breaks, or returns. Instead, it embraces message-passing in a fully asynchronous environment, enabling effortless concurrent programming through implicit parallelism. This design choice not only simplifies concurrency but also makes Nevalang ideal for visual programming, representing programs as computational graphs of components interconnected by inputs and outputs.  
  
The syntax is clean and C-like, free of clutter. Down the road, I'm planning to add a visual node-based editor to make Nevalang a hybrid beast where you can switch between text and visual schematics seamlessly.  
  
So far, I've got the core language up and running, complete with a compiler, runtime, and the bare-bones of a standard library. I've even thrown together a basic LSP language server and a VSCode extension for syntax highlighting. There's also a package manager that works with git tags.  
We're at alpha now, and the next big step is building a community. I'm shooting for at least a hundred people to kick things off. If this sounds like something you'd be into, don't just scroll on by. Join the community. I really believe that together, we can make Nevalang a legit production-ready language that can go toe-to-toe with the traditional control-flow languages out there.  
Thank you for your time and interest. I'm looking forward to welcoming you to the Nevalang community!  

**Hello World**:

```
component Main(start) (stop) {
	nodes { Printer<any> }
	net {
		:start -> ('Hello, World!' -> printer:data)
		printer:sig -> :stop
	}
}
```

Will drop links in the comment, otherwise post is immediately banned",2024-03-02 20:51:26
1bbkdqq,Creating OS from Scratch,"Hello, 

I would like to know if is there any way I can create an OS from scratch. Any books, or classes I can take to understand how to create an OS from scratch as I am very interested in learning this side of the world. I look forward to your suggestions.  ",2024-03-10 20:37:28
1b5vlam,My favourite data structure: The trie,N/A,2024-03-03 23:28:15
1bpizfw,How do I program software to be updateable?,"When I started my Computer Science degree, we had some classes on the history of computing, and I presented a paper on Margaret Hamilton. She was the director of the software engineering department that developed the Apollo 11's onboard flight software. One of the important features of the software created by her team was its ability to be updated remotely. Reflecting on this today raised the following question:

&#x200B;

**How do I program software to be remotely updateable?**

&#x200B;

How do I write an update? How do I send it to a program? What protocol do I use? What requirements does my software need to accept updates? I've never heard anyone talk about this and have no idea how it works.

&#x200B;

If anyone can provide an example of a project that implements the concept of remote updating, I would be very interested, especially if it's an example I can include in academic software projects to learn the concept for educational purposes. I think it would be an interesting addition to future college projects.",2024-03-28 01:17:13
1blsvoz,What is it that got you more invested into CS?,"I’d say knowing about all the technological capabilities that are available today. That and research, that’s what gets me going in the morning.",2024-03-23 14:01:41
1bk4p7t,Alternatives to Von Neumann Architecture,"I read a bit about Harvard and Data Flow Architecture and I’m particularly curious why we didnt adopt harvard, given that we have the extra security benefit of preventing buffer overflow attacks and we also get 2 separate buses for data and instructions. It seems we could also preserve the abstraction of sequential execution for the compiler with harvard. 

Was it just a historical / simplicity reason we chose Von Neumann and just stuck with it? If anything, the harvard architecture seems even simpler?",2024-03-21 11:50:38
1bjw8b1,Behind in my comp sci degree,"I’m currently in my second semester of my sophomore year in university and currently in the third main class of CS (advanced algorithm design). I managed to pass the first two classes (data structures and algorithms 1-2) but I feel incompetent. I understand simple ideas but even things like pointers and function designs confuse me. Once I see a completed version of code I can begin to understand it much more but I wouldn’t have been able to make it on my own. I’ve been doing labs using the help of AI to get through them and know that I’m extremely behind on skill and knowledge. This is what I feel I  want to do in the future but I’m just super nervous for what’s ahead, especially internships. I’m holding off on taking the next core class and just wanted some input from you guys on what I should do and what would help me. Thanks.",2024-03-21 02:47:59
1bpnqhy,FizzBee: Python-like Formal Methods Language,"I was learning formal methods and tools like TLA+, Alloy and PRISM. I wanted to build a formal language that is easy for every programmer to use, so came up with a proof of concept. I would appreciate your feedback.

Introducing [Fizzbee](https://fizzbee.io), the Python-like formal methods language designed for most developers. This will be the most easy to use formal language ever. In addition to behavior modeling like TLA+, it also includes a performance/probabilistic modeling like PRISM.

Dive in with our online IDE/playground—no installation required.

The body of the methods are all python. So, any developer should be able to instantly get it. The introductory example for DieHard from the TLA+ course.

    always assertion NotFour:
      return big != 4
    
    
    action Init:
      big = 0
      small = 0
    
    atomic action FillSmall:
      small = 3
    
    atomic action FillBig:
      big = 5
    
    atomic action EmptySmall:
      small = 0
    
    atomic action EmptyBig:
      big = 0
    
    atomic action SmallToBig:
        if small + big <= 5:
            # There is enough space in the big jug
            big = big + small
            small = 0
        else:
            # There is not enough space in the big jug
            small = small - (5 - big)
            big = 5
    
    atomic action BigToSmall:
        if small + big <= 3:
            # There is enough space in the small jug
            small = big + small
            big = 0
        else:
            # There is not enough space in the small jug
            big = big - (3 - small)
            small = 3

Getting started guide: [https://fizzbee.io/tutorials/getting-started/](https://fizzbee.io/tutorials/getting-started/)

There are more examples are in the git repository.

# Probabilistic modelling:

&#x200B;

For example: Classic example from [PRISM](https://www.prismmodelchecker.org/tutorial/die.php). Dice from fair coin:

    invariants:
      always 'Roll' not in __returns__ or __returns__['Roll'] in [1, 2, 3, 4, 5, 6]
      always eventually 'Roll' in __returns__ and __returns__['Roll'] in [1, 2, 3, 4, 5, 6]
    
    atomic func Toss():
        oneof:
            `head` return 0
            `tail` return 1
    
    atomic action Roll:
      toss0 = Toss()
      while True:
        toss1 = Toss()
        toss2 = Toss()
    
        if (toss0 != toss1 or toss0 != toss2):
          return 4 * toss0 + 2 * toss1 + toss2

This will generate this Graph:

And you can find the mean time to completion, and the corresponding histogram.

    Metrics(mean={'toss': 3.6666666666660603}, histogram=[(0.75, {'toss': 3.25}), (0.9375, {'toss': 4.5}), (0.984375, {'toss': 5.75}), (0.99609375, {'toss': 7.0}), (0.9990234375, {'toss': 8.25}), (0.999755859375, {'toss': 9.5}), (0.99993896484375, {'toss': 10.75}), (0.9999847412109375, {'toss': 12.0}), (0.9999961853027344, {'toss': 13.25}), (0.9999990463256836, {'toss': 14.5}), (0.9999997615814209, {'toss': 15.75}), (0.9999999403953552, {'toss': 17.0}), (0.9999999850988388, {'toss': 18.25}), (0.9999999962747097, {'toss': 19.5}), (0.9999999990686774, {'toss': 20.75}), (0.9999999997671694, {'toss': 22.0}), (0.9999999999417923, {'toss': 23.25}), (0.9999999999854481, {'toss': 24.5}), (0.999999999996362, {'toss': 25.75}), (0.9999999999990905, {'toss': 27.0})])
       8: 0.16666667 state: {} / returns: {""Roll"":""1""}
       9: 0.16666667 state: {} / returns: {""Roll"":""2""}
      10: 0.16666667 state: {} / returns: {""Roll"":""3""}
      11: 0.16666667 state: {} / returns: {""Roll"":""4""}
      12: 0.16666667 state: {} / returns: {""Roll"":""5""}
      13: 0.16666667 state: {} / returns: {""Roll"":""6""}

&#x200B;

[https://github.com/fizzbee-io/fizzbee/blob/main/docs/fizzbee-quick-start-for-tlaplus-users.md#probabilisitic-evaluation](https://github.com/fizzbee-io/fizzbee/blob/main/docs/fizzbee-quick-start-for-tlaplus-users.md#probabilisitic-evaluation)

This is not fully integrated into the online IDE, and to use it, you would have to get the git repo and try. The instructions are in the [git repo](https://github.com/fizzbee-io/fizzbee).

Online playground: [https://fizzbee.io/play](https://fizzbee.io/play)  
Github: [https://github.com/fizzbee-io/fizzbee](https://github.com/fizzbee-io/fizzbee)  
Tutorials: [https://fizzbee.io/tutorials/getting-started/](https://fizzbee.io/tutorials/getting-started/)

&#x200B;",2024-03-28 05:22:40
1b9k14u,Books on architecture of 8 bits computer,"Hi, 

I've become interested in diving into how 8 bits computer work to hopefully build my own such as a Commodore 64. For this, I'm going through the learning process of computer architecture. I've found good books and references that explains extensively bits, microprocessors and memory but I'm lacking on sound and video chips. I'd like to also be able to understand the inner working of SID and VIC. A lot of good books on computer architecture (ex: Inside the Machine) are focused on microprocessor and I have a hard time finding a book that is more general purpose. I'm thinking maybe older books focused on 8bits computer architecture may give a tour on each component but havent been able to find one. 

Any suggestions of good resources ? ",2024-03-08 09:20:53
1bnszvo,Writing grammar for a mathematical expression evaluator,"I am trying to wrap my head around parsing and formal languages. But I am having a lot of difficulty in understanding these concepts well. I am writing a small mathematical expression evaluation program to begin with and build my understanding from there. The goal is to take a string of mathematical expression as input, and parse it to create a parse tree. Now I think, if I am able to write a grammar, then I will be able to implement an LL(1) parser for it.

But I am having difficulty in defining a grammar for the same. This is what I have tried as of yet, please check and let me know if it is correct or not. My goal is to create a parse tree for expressions like - `3+5*7-6+4`

This is the grammar I have came up with, where E stands for expression, T stands for terms, and N stands for numbers. 

E -> T + E | T - E | T \* E | T / E

T -> (E) |  N 

Apologies in advance for asking such a basic (and probably vague) question, I don't have any other help to clear this doubt that's why asking in this forum.

 ",2024-03-25 23:42:34
1brjiyd,Finite State Automaton Animator,"I built a web app called ""Finite State Automaton Animator"" for my project. It is nothing fancy, but I am still proud of it! It intends to help students learn about deterministic finite-state automata (DFAs). The tool supports building DFAs from a user interface and from regular expressions. Then, the user can provide a custom sequence and match it against the DFA.
DFA is created from a regular expression first by following [Thompson's Construction](https://en.wikipedia.org/wiki/Thompson%27s_construction) to create an ε-NFA and then it builds NFA transition table and DFA transition table using [Subset Construction](https://medium.com/@mmksajeeb/the-subset-construction-algorithm-nfa-ε-nfa-to-dfa-adf46dba31e3) I liked the visual aspect of this method. I thought this could be further improved if DFA was built step by step while simultaneously building up the DFA transition table, and so visualising the building of DFAs better.
It accepts basic RegEx made of Kleene star ""*"", union ""|"", parenthesis ""("" and "")"" and treats any other character as a matched character. I wish to extend it to support escaping and more fancy operators like ""."" or ""+"".

Other improvements I would like to make are:
* Animating NFAs and ε-NFAs, not only DFAs. 
* Add support for memory (e.g. stack) to allow animating pushdown automata (PDAs) etc.
* Improve docs and better explain algorithms involved.
* Improve the UI, which is currently not amazing
* Find a way to export these to GIF so they can be integrated into lectures.

Would you find such a tool useful as a teaching supplementary resource? I'm also interested in any suggestions on how to improve this.

[Deployed project](https://danielius5.github.io/algorithm-animator/), and [repository](https://github.com/Danielius5/algorithm-animator)",2024-03-30 14:45:06
1b6ked2,Aho & Ullman Proof for Lu to be RE but not Recursive,"&#x200B;

[ ](https://preview.redd.it/j8si7dyegdmc1.png?width=698&format=png&auto=webp&s=cf336300bd3f98e6ebfc2a97990e0c7c7d72bf0d)

In Hopcroft & Ullman's textbook, we prove that the universal language Lu is RE but not recursive by reducing an instance from the diagonalization language Ld \[= Strings in (0+1)\* where a string describing a TM does not accept the string itself\]. If we say Lu is recursive, then we can construct a Turing Machine for Ld, thus making it RE. Thus, by contradiction, we arise at the conclusion that Lu is not recursive.

Since Ld is undecidable we can also say that Lu is undecidable (as stated in the theorem).

But what I can't get my head around is Ld (P1) is a non-RE language but Lu is RE (P2). How does that work? Doesn't this violate Part B? 

&#x200B;",2024-03-04 19:54:45
1bkwqcl,Did CPU differences in the past matter for business as much as today's DL/LLM scene between NVDA and AMD?,"Hi everyone,

We know that today a lot of DL and LLM research and development rely on NVDA's CUDA, even if AMD is trying to catch up with its ROCm, but it seems that it's not there yet. It seems that there's a large gap between these two, so that people who want to do research or develop DL and/or LLM would usually buy NVDA's products instead of AMD's.

I thought of the following question: Altair 8800 used Intel 8080, and IBM PC used Intel 8088 (and PCs usually came with Intel CPUs until AMD caught up), whereas Apple I and II used MOS 6502, and the first Macintosh used Motorola 68000 (PowerPC era).

So I was wondering that for people who have experienced or studied that era, were there any productivity gap between Intel machines and non-Intel machines, as large as today's NVDA and AMD? Some (small) business seemed to hold up with Apple machines even before its cooperation with Intel, do you think this is or can be true today, e.g., for (small/medium) companies/studios or individuals that can only afford AMD GPUs, or it's more a bet for the future?

Thank you for your time.",2024-03-22 11:12:30
1beejp4,The Era of 1-bit LLMs - Paper Explained,"Hi there,

I've created a video [here](https://youtu.be/wCDGiys-nLA) where I talk about how we can build LLMs whose weights can be represented by 1.58 bits and what are the advantages of doing so, by analyzing the paper ""The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits"".

I hope it may be of use to some of you out there. Feedback is more than welcomed! :)",2024-03-14 06:18:14
1bgmk67,Kolmogorov Complexity of Graphs,"I've been thinking about the Kolmogorov Complexity of graphs on and off for a long time, though today I came up with a really simple way of thinking about it that is no different from the complexity of a string. Specifically, you define the Kolmogorov Complexity of a graph G as the length of the shortest binary string x for which E(G) = U(x), where E(G) is the edge set of the graph G. This is really simple, though apparently not the accepted definition in the literature, which uses a [conditional Kolmogorov Complexity] (https://arxiv.org/pdf/math/0110203.pdf). That said, I'm pretty sure someone else has thought of this before.

However, I unpacked this idea quite a bit, and show that we can take Kolmogorov Random strings, and directly translate them into graphs, which are therefore certain to be Kolmogorov Random. I also show, interestingly, that the Kolmogorov Complexity of a Kolmogorov Random graph is equal to the number of edges in a complete graph, for at least one infinite set of graphs.

Further, I talk at decent length about infinite sets of graphs, and the connections to complexity, showing that you can have non-computable sets of low-complexity graphs.

Thoughts are welcomed.

https://derivativedribble.wordpress.com/2024/03/16/on-the-complexity-of-a-graph/",2024-03-17 02:14:21
1bewvxm,"Theories and Applications of Boolean Algebras, Tau Net's breakthroughs on Software Development","Hi everyone, im really excited. After ten years of development Tau Net just disclosed their discoveries and developments. Their logic languages NSO and GSSOTC are huge, since NSO is capable of consistently referring to its own sentences, while GSSOTC has a new approach to temporal logic and they both come to solve long standing problems that have been plaguing the field ofr a while. There's also Ohad Asor's brilliant paper in the Theories and Applications of Boolean Algebras that is the basis for this discovery and the Github repo with all the data.

&#x200B;

&#x200B;

Tau Language:

[https://github.com/IDNI/tau-lang](https://github.com/IDNI/tau-lang)

&#x200B;

Article on the release:

[https://tau-software.medium.com/unveiling-the-future-of-ai-taus-logical-ai-evidences-a-new-era-4b0d092b8695?postPublishedType=initial](https://tau-software.medium.com/unveiling-the-future-of-ai-taus-logical-ai-evidences-a-new-era-4b0d092b8695?postPublishedType=initial)

&#x200B;

Research and Background Theory:

[https://tau.net/theories-and-applications-of-boolean-algebras.pdf](https://tau.net/theories-and-applications-of-boolean-algebras.pdf)",2024-03-14 21:40:37
1bdzjv1,Understanding linked list based file systems and Windows File Allocation Table (FAT),"I'm going through [this chapter on](https://pages.cs.wisc.edu/~remzi/OSTEP/file-implementation.pdf) file system implementation from the OSTep book. On page 9 they mention a linked list based version of file systems where each data block contains a pointer to the next block. Clearly, such an implementation comes with its own issues (linear access time to find a particular block). They mention an improvement on this scheme by introducing a table data structure which stores the link information.

>The table is indexed by the address of a data block D; the content of an entry is simply D’s next pointer, i.e., the address of the next block in a file which follows D

I'm unclear on how this table is structured and how it is used to improve access time.

1) How is a data block addressed in the first place?

Is the address simply the offset of the data block from a fixed point in the disk?

2) How do we figure out the address of the block to be accessed?

I assume that we only know the byte that we want to read. Is there a way to directly compute the address of the block from the byte that is being referred to.

For eg, to read byte 4000 in the file we wish to access the third block in the file (assuming 1KB blocks). How do we now know the address of the third block?

3) The FAT is said to be an ""in memory"" data structure? Does this mean that the FAT is present in the memory of every process running on the system?",2024-03-13 18:56:18
1bl23dl,Studying Parallel and Distributed Computing in C++,"I have good experience with multithreading C and C++(Mainly - fine grained locking, lock free and some threadpool) , message queue, shared memory and  socket programming. I have some experience in SIMD.   


but I have never used OpenMP or have worked per say on parallel and distributed programming.   
What all new things I need to learn to be able to practice. ",2024-03-22 15:33:20
1b8ldvs,Solving Algorithmic Problems in The Wild,N/A,2024-03-07 04:27:26
1blisz2,How well can shortest common supersequence over small alphabet size be approximated?,N/A,2024-03-23 03:42:10
1bijnsj,Untangling Non-Linearity: How the Linked List Changed Everything,N/A,2024-03-19 13:00:14
1bfnidi,Why don’t we have multiple levels of the Translation lookaside buffer?,"I just read this [paper](https://www.usenix.org/legacy/events/osdi02/tech/full_papers/navarro/navarro.pdf) on huge pages. The authors state that the motivation behind huge pages is that the address space coverage offered by the TLB is quite small relative to the memory and the working set of certain applications. 

I wanted to know if there have been solutions which involved the addition of additional TLB levels (similar to the cache). I realize that this would involve making major changes to the processor chip and it would probably not increase the memory coverage by too much. 

I’m just curious if this was ever tried out in a real chip. ",2024-03-15 20:22:36
1box1q3,Manual Model Checking of a FSM,"Recently got down the rabbit hole of modeling code as finite state machines and learning about formal verification.

Was wondering if there were simple methods to do manual model checking for a FSM and what are the current best methods for state minimization and partitioning to reduce state explosion so model checking can be done.",2024-03-27 08:40:06
1bjfai0,Best resources for neuroscientist wanting to learn to code ,"Hi, I’m a PhD in neuroscience who’s looking to get into coding as a distraction from my experimental work while still being useful. I’ve seen python or matlab are probably the best. Just wondering which would be more useful/beginner friendly and where to start self teaching coding. 

Any replies will be greatly appreciated. ",2024-03-20 14:50:32
1bhv4er,Data compression using Perlin noise or predetermined maps.,"Is there some kind of method or way to compress Strings or Arrays,  
Like trying to match an array of numbers, each seed of perlin noise.

and if it matches, it returns the seed, and index and length. which sounds kinda op.",2024-03-18 16:35:29
1b5k1ft,"""The best definition of complexity theory I can think of is that it’s quantitative theology: the mathematical study of hypothetical superintelligent beings such as gods."" — The Fable of the Chessmaster (Scott Aaronson, 2006)",N/A,2024-03-03 15:39:37
1bm5bz3,Book Recommendations ,"If I was to only get one book related to computer science ever, which should it be? ",2024-03-23 22:48:12
1b8y4sf,Reinforcement Learning,"Decision boundary similarities in deep reinforcement learning

[https://twitter.com/Mila\_Quebec/status/1636472805620428809](https://twitter.com/Mila_Quebec/status/1636472805620428809)",2024-03-07 15:56:20
1bjlofe,Undergrad research project ,"So I was given the opportunity to start undergrad research recently by a professor in the CS department, and I am making this my passion project.

Last semester, he let my class research a set of given topics, and I chose to focus on the advantages of disadvantages of AI simulation in the military. It was a super cool project and I did pretty well on it.

He wants me to do this so I can have research under my belt and on my resume. I want to focus in on AI and the military, and what issues there are, what’s the current consensus, and what needs to be solved.

With this, I really want to start it. I have some preliminary ideas, such that how can we get AI to have a way of mocking human instinct and intuition, and apply that to a real world scenario.

Thoughts on this?",2024-03-20 19:14:08
1bd4ojt,Is building our own proxy for cybersecurity course doable?,"Hello, as the title suggest, I want to build my own proxy server for educational purpose (uni course) where the proxy needs to catch the http traffic going out of a small network. But, the proxy should be controlled by me (as I have to analyze the traffic and manage the packets before sending them to other networks).

Any suggestions? Or is it not doable at all?

P.S.: If possible to do it for free or at least for cheap would be great!",2024-03-12 18:32:39
1bb7msh,k-Vertex Cover Complexity Class,"Can anyone provide an explanation on the following, given that the correct answer is D. 

&#x200B;

The k-Vertex-Cover problem is, given a graph G and an integer k, to decide whether G has a vertex cover of size at most k. Let k = 500. Then the k-Vertex-Cover problem is:

(A) coNP-complete

(B) NP-complete

(C) neither in P nor NP-complete

(D) solvable in polynomial time",2024-03-10 10:51:35
1bqzg4u,"Minimal Model of Monotone Formula is #P hard, references?","The minimal models of monotone forms is hard, requiring enumeration of models in an orderly manner. So, I have Minimal Model of Monotone Formula is #P hard. Does that agree with literature?",2024-03-29 21:10:37
1bo2jji,Want to know the best methods for continuous black-box optimization problems? I just got a paper out!,N/A,2024-03-26 08:13:18
1bfge2m,Consistent Hashing with Block Partitioning for faster lookup,"I implemented an addition to Consistent Hashing with Block Partitioning to make lookup faster. I would appreciate receiving your feedback  


[https://github.com/mbrostami/consistenthash?tab=readme-ov-file#addition-to-the-original-algorithm](https://github.com/mbrostami/consistenthash?tab=readme-ov-file#addition-to-the-original-algorithm)

  
",2024-03-15 15:17:53
1b4wufg,"Are there any other software issues or occasions like Year 2038, y2k or 42.zip ?","I'm a random noob guy who is into searching and learning these kind of things.
I have interest in issues like y2k and 42.zip. Do you know any other issues like this? Solved or unsolved doesn't matter. l'd like to read about them. Can you suggest me topics that unsolved in software world? Or solved but forgotten.",2024-03-02 19:45:05
1b4mgew,Calculating the Matrix Inverse,N/A,2024-03-02 11:45:12
1bkx9y6,Training LLMS to follow instructions with human feedback (RLHF) - paper explained,"Hi there,

I've created a video [here](https://youtu.be/iUZR0maBkOU) where I talk about how we can train LLMs to follow instructions with human feedback by looking at the OpenAI's RLHF paper that they used to train ChatGPT.

I hope it may be of use to some of you out there. Feedback is more than welcomed! :)",2024-03-22 11:45:03
1bqpupc,BART Model Explained,"Hi there,

I've created a video [here](https://youtu.be/jTvPJD81m8E) where I explain the architecture of the BART model and how it was pre-trained.

I hope it may be of use to some of you out there. Feedback is more than welcomed! :)",2024-03-29 13:54:01
1bp2wh0,Ask for help - Paper reproduce,"Any body had reproduced this paper **Structure-Revealing Low-Light Image Enhancement Via Robust Retinex Model - 2018TIP** ?  Met some trouble and can't solve for few days. 

The author does not provide the source code. I think I miss some detail in the implementation.",2024-03-27 14:13:58
1bihwgr,Multimethods,"Who is into multimethods and generic functions (e. g. as in Common Lisp or Dylan) as distinct from single-dispatch OO (e. g. as in Smalltalk or Ruby)?

For whatever crazy reason, I took it into my head to implement my own system for multimethods (on top of a language that doesn't have them natively). My current need doesn't even require multiple dispatch. I just thought the syntax of calls using generic functions might look better than that of single dispatch and might bode better for meeting future requirements.

Terminology: a programmer adds ""rules"" to a generic function. Each rule has a head and a tail. The head is a pattern over the arguments to a call. The tail is a ""method"" i. e. a function or a procedure that gets executed in case the head matches the arguments. Only one rule executes for a given call. Maybe some people would use the term ""method"" for the head and tail together, but Chat Gupta suggested to the contrary, say ""method"" for just the tail and ""rule"" for the whole.

At first, I thought I could make the system catch ""ambiguious"" combinations of rules and throw an error in that case. But I have given up on that and decided to just make sure the dispatch is deterministic (repeatable) based on, as a last resort, the order in which the programmer added the rules.

I use named parameters in the calls. Rules can specialize on parameter names (constraining their arguments to belong to classes or primitive types). I also want to allow in calls, parameters not mentioned in the rules. In effect, rules that don't mention a given parameter leave it unconstrained.

I am not trying to emulate Common Lisp's :BEFORE, :AFTER, :AROUND.",2024-03-19 11:23:51
1brt5ys,Why is the probability like this (petri net)?,"
If you look at the petri net, you can see that after I explored it till time instant 4, there are 2 transitions which can fire. One has a prob. of ca. 17% and the other 83%. 

The send transition has as stochastic properties: Type: Uniform, Earliest firing time: 1 and Latest firing time: 2.

The timeout transition has as stochastic properties: Type: Deterministic, Value: 5, Weight: 1, Priority: 0.


I am now at time instant 4. I thought at time instant 5 the timeout-transition should have a probability of near to 100% of firing, because it was enabled from the beginning. But how is send-Transition more likely to fire? I don't get it and I would really appreciate any help!",2024-03-30 21:40:33
1bbb48o,Are there application of zk outside of blockchain?,N/A,2024-03-10 14:05:46
1b4l5wv,Wizards and PPO,N/A,2024-03-02 10:21:21
1bjkry0,Template Metaprogramming C++,How to practice template metaprogramming in c++ ?,2024-03-20 18:37:08
1bii336,Looking to Connect with Fellow ML/DL and Data Science Enthusiasts,N/A,2024-03-19 11:34:47
1b9k1rr,TOC,Can anyone suggest some Good YouTube channels for learning Theory of computation?,2024-03-08 09:22:05
1bq3qfl,GAN with java,i have found like 30 pictures (copyright free) that i want to use to train my GAN to generate specific patterns. i haven’t really started yet but is 30 way too low (im afraid it is going to overfit the dataset),2024-03-28 19:04:59
1bkzbuf,Internet radio with web interface,"Hi everyone. I'm looking to build an internet radio with web interface for my work. I prefer a linux based OS on a thin client of whatever type. I'm no particular fan of a RasPI, and whatever software is for the PI should also work on any other debian based OS.

The hardware part isn't most difficult, but I can't find what software I should or can use for this. 

The reason for the web interface is that the device will be in an enclosed space. 

Anyone a suggestion where to go? thanks for all replies.",2024-03-22 13:32:47
1bifs5g,"Two theorems of monotone reason, about cardinality and propositional deciders","1. \#P=#Q: The number of Boolean models of a logical form equals the number of valid quantifications.  Knuth volume four.

The proof leads to a linear transformation from models to quantifications.  My program works well for modest sizes.  Monotone forms on n variables decide all 2\^n quantifications. 

2. Monotone reason is linearly decidable: Quantified monotone Boolean forms are linearly decidable by plugging one for existential and zero for universal.

Commonsense is monotone. RIP jmc by jdp.

Wisdom is monotone.  

Is cognition also linear?  Is there a reddit area more appropriate for these two theorems?

avoid negation and prosper in trees of truth, Joseph Daniel Pehoushek",2024-03-19 09:00:22
1bq2rf4,MSIT from Illinois IIT online on coursera,N/A,2024-03-28 18:26:14
1bq092r,Streamlit ,Can anyone suggest best YouTube channels for learning streamlit?,2024-03-28 16:46:43
1boyk0t,What are 1x1 convolutions and how do they make your model lighter? A 5-minute visual guide. [OC],"Building deeper models is an important part of solving the matching learning puzzle.

What if there is a way to (1) simultaneously reduce the parameters in your model AND (2) increase the model depth? 1×1 convolutions are your answer.

These help you build:  
\- faster (training and inference time),  
\- leaner (smaller memory footprint, smaller GPU to run them), and  
\- smarter machine learning models (equally performant if not better).

[Learn what are 1×1 convolutions and when to use them.](https://open.substack.com/pub/codecompass00/p/1x1-convolutions-supercharge--machine-learning?r=rcorn&utm_campaign=post&utm_medium=web)

https://preview.redd.it/2c322qivsuqc1.png?width=1659&format=png&auto=webp&s=f5820d2336d569b6d932351235c0326b7ec9813c",2024-03-27 10:27:50
1br13eo,Error function not converging to under 1,"does anyone know why the error function i made in python is not converging to a value that is under 1, if i plug in 3 its doing fine, but if i plug in a value around 175 it just keeps growing. i expanded the function using both maclaurin series and other formulations, both resulting in non convergence at that value.

    def ERF(z:float, n:int):
        """"""Evaluates the Error function up to z with macclaurin series of order 2n+1""""""
        return (2/sqrt(pi)) * sum([((-1)**p)*((z**(2*p+1))/(factorial(p)*(2*p+1))) for p in list(range(n))])

",2024-03-29 22:15:36
1bimu5r,PhD / Doctorate Programs,"I am planning to do a PhD / Doctorate program in either computer science or data science. I have a list of schools I have found so far where I can do this online. Anyone have any advice on good and/or bad experiences, schools, etc. before I commit to one?",2024-03-19 15:23:26
1bkruas,Why are LLMs bad at deductive reasoning?,"I know that LLMs are programmed for pattern recognition rather than ""true understanding"". 

But why aren't they given a component that can do sound logical reasoning, something like Kahnemann's ""slow thinking""??

Intuitively it seems to me that deductive inference should be easier to program compared to inductive reasoning, which involves complex learning algorithms requiring a lot of statistics and linear algebra.

&#x200B;",2024-03-22 05:27:49
1b8awia,I worked on P vs NP for 5 years and I want to share what I've found,"[https://medium.com/@white.garrick935/p-np-duh-part-1-of-4-405882ed1fb0](https://medium.com/@white.garrick935/p-np-duh-part-1-of-4-405882ed1fb0)

I genuinely hope my semi-formal proof can spark some interesting discussion, and I humbly ask for some constructive feedback on the ideas presented.

The concept that I would like to introduce in my blog post and paper is what I call a ""spoofer"". In the halting problem, there is a notion that for any proposed solver, there exists a machine that can be fed as input to break/spoof the solver. I theorize the existence of analogous spoofers for some NP-Complete problems that crop up at very large inputs.

In a similar manner to the Halting Problem, if any algorithm claims to be a polynomial-time solver of these problems, then there are spoofers that will exist as inputs to that problem that will prevent accurate, polynomial-time completion of the problem. The conditions that allow spoofing only exist so long as the solver claims to run in polynomial-time, so they can be avoided only by slow solvers. More detailed proof in the blog post.

Has this idea been proposed before for P vs NP and does it seem feasible? Let me know what you think!",2024-03-06 20:52:46
1bbl9uw,Which research is most productive in quantity? theory vs application?,"In computer science

which research is most productive in quantity? theory vs application?

&#x200B;

ps. Aside from if I'm sincerely devoted to academics, i have reason to produce as many papers as possible at shortest time for graduation and my age concern",2024-03-10 21:13:24
1bnqu9i,Are NFC tags (such as those found on clothing labels) Turing complete?,"Every time I see one of those NFC tags I wonder what hardware it has, and the capabilities of it. It is just a finite state automata or a very basic processor with instructions?",2024-03-25 22:14:59
1bcg0fb,"I know whata foreward porxy IS, but what is it used FOR?","Reverse proxies are immediately obvious to me as a programmer cause i've used NGINX. Foreward proxies are not. I get that the traffic cop (i.e. the proxy) stands on the junction between a LAN and the web, as opposed to the traffic cop standing on the junction between the web and a servers LAN. 

But practically, what does it look like, who does it serve, and which firms include it in their stack?",2024-03-11 22:09:33
1bhwubb,Why don't bank numbers contain some sort of check sum to check if they where copied correctly?,"Like in bar codes, QR codes, wired protocols ECT. ",2024-03-18 17:44:37
1boe1qu,symbolic mathematics on an infinitely powerful computer,"i have developed an algorithm which can iterate over all equations having symbols (+, \*, \^, integers, letters). every equation is having a complete domain and not defined values (like division by zero is invalid) are no possibility. power can have a integer exponent of value 2 or more.

this algorithm was not possible without infinitely powerful computer assumption. and we can use this concept to do a lot of things.

contribute to this project, because i see a lot of possibilities.

Edits for more details:

The code: [https://github.com/SwastikMajumder/book-transcendental/blob/main/part\_1/main.py](https://github.com/SwastikMajumder/book-transcendental/blob/main/part_1/main.py)

It will for example be able to generate equations like:

x+1, 1+x, 2+2, x+2, x+3, x+4, x\^2+1, x\^2+2, etc. iterate through all possible math,

The code given generates such equations and then it categories the equal ones together.",2024-03-26 17:46:21
1bh2nux,Why are we learning so much theoretical cs?,"I'm in my fourth year of high school, specializing in computer science.

Recently, we've been deeply focused on the Big O notation, covering over 60 slides of theory in a 4-hour lecture. This detailed exploration seems to emphasize concepts that appear both impractical and somewhat abstract, but I'm questioning the extensive emphasis on theory over practical application.

Since the beginning of the semester, we've had mostly theoretical tests, with only a single practical one. Topics like abstract classes, final and static keywords, lists, objects, and classes have been discussed at length, yet we haven't been tested on these concepts through practical exams.  
Instead, after spending months on theory, we're assigned repetitive, boring exercises that don't truly test our understanding or skills, but rather totally demotivate us.

Tomorrow, we face a test covering over 250 slides of theory, with no practical component. This approach seems to be dampening the enthusiasm for programming among most of my classmates, leading to demotivation due to the monotony of study and lack of hands-on experience.

I'm wondering about the necessity of this theoretical part. In the professional world, is theoretical knowledge prioritized over the ability to program and apply concepts in real-world situations? Why is there such an emphasis on theory, and how does it serve us in practical programming tasks?",2024-03-17 17:06:37
1ba6elh,"There's no way ASTAR is better than Greedy BFS, I have tested it out.","I don't know why the statement of astar being better than Greedy bfs exists, my simulation results and online simulator results prove that Greedy BFS is better.
I'm have simulated using both Euclidean distance and Manhatten for heuristics, GBFS was better. 

I have used both, a map with many barrier and a map without barriers, GBFS was better.

Execution time : gbfs was faster.

Number of nodes discovered : gbfs found less nodes(better).

Number of nodes undergone cost computation: gbfs computed less nodes(better).

Path length was the mostly same, in few maps Dijkstra found shorter paths. 
Rarely would astar find a shorter path, but when it did by a small margin.

I lost my mind, till I compared my sim results to online sim.

",2024-03-09 02:14:14
109ha3,Reminder: Don't vote up or respond to off-topic posts.,"Like most internet communities, we're always experiencing a slow but steady decline in quality. I'm sure that people who care about Computer Science will eventually leave this subreddit and migrate to /r/TrueTrueTrueCompsci. Until that dark day arrives, I'm asking everyone here to (1) restrain yourselves from upvoting or discussing posts which don't actually fit the sidebar criteria, and (2) if someone else posts something off-topic please politely direct them to a more appropriate subreddit. 

Thanks!",2012-09-21 19:28:03
e398q,CS Is My Life - University of Waterloo,N/A,2010-11-09 03:05:28
id370,"New study shows high anguish and anxiety with computer tech support due to long lag times, lack of ready resolution",N/A,2011-06-30 08:10:59
88uu3h,Blame the Computer/ Pein/ Baffler. longread critique of CS/ software engineering culture/ mentality,N/A,2018-04-01 23:05:52
1yiwym,"No Girls, Blacks, or Hispanics Take AP Computer Science Exam in Some States",N/A,2014-02-21 09:59:17
agrvjk,"Women here, what's the sexism like?","So I'm starting my computer science degree in about 2 weeks.

I'm really scared that Comp Sci is a bad fit for me in terms of the environment and people. I don't see myself being happy in a male-dominated field and I'm scared of creepy weird guys (things have happened to me before and I highly doubt it'll stop).

So women who studied comp sci/ work in the comp sci field, please tell me about your experiences with sexism? 
If you're not a woman, you can still give your opinion lol, I don't really mind.

Also I really don't want to be the diversity hire...",2019-01-17 00:23:47
7ye9yz,Why are loop invariants so rare in CompSci (and in code)? They can give you coding superpowers!,N/A,2018-02-18 13:39:41
3bt1od,More Universities Should Shut Down Their Computer Science Programs,N/A,2015-07-01 22:27:59
29d4nd,/r/theoreticalcs - a subreddit for theoretical Computer Science,N/A,2014-06-29 02:08:44
34m8gu,Try this Crossword for Programmers !,N/A,2015-05-02 12:34:27
uwrvq,Who wants to help me solve a 17th century code?,"[Edit 2: The Phrase ""Compsci Nerds"" was removed as it has been deemed insensitive to virgins.]

Gordon Code (Parts 1-3): http://imgur.com/a/isCoU 

Remember me, r/compsci? My name is Matthew Kaminski, and I'm a history student at the Masters Program at UMass Boston. The subject of my thesis is the role of John Rowe and the BSETC merchants in fomenting the Stamp Act riots, non-importation movement, and Tea Party. Several months ago I posted a low-quality photocopy of a Masonic Code on a letter located in the Massachusetts Historical Society to the /compsci subreddit. (Original Here: http://www.reddit.com/r/compsci/comments/twl6j/who_wants_to_help_me_crack_an_18th_century/).  You [Sterling examples of masculinity] did the whole proof of identity thing then, so don't question my existence or credentials. The letter was written by William Gordon, a semi-successful Author, Preacher and Freemason. The letter has a complex code written in the margins, which seems to have several possible solutions. I just got back from the MHA and, after getting permission, took some higher quality photographs for you to examine and perhaps solve. If anyone wants more information on Gordon or wants to read Gordon's book on algorithmic code creation (available online), I would be happy to come back in a few minutes and add some comments. The Gordon Code is available here: http://imgur.com/a/isCoU

[EDIT] TLDR: Help me solve this masonic code and win the respect of the Reddit Community! (Warning: Prize does not actually exist.)
[EDIT] Here are the original low quality scans, to help orient the viewer: http://imgur.com/a/rfLtk",2012-06-11 21:15:18
ek78w,I'm interviewing for an internship at a large social networking company what sort of interview questions should I expect.,"I'm expecting questions about C++ (Polymorphism, Inheritance, Operator Overloading) and Data Structures what other kind of questions should I expect? ",2010-12-11 20:28:46
awo5l,"Somewhat off topic, but I almost cried with disbelief when I read these comments. The iPad is not turing complete...",N/A,2010-02-01 13:38:39
bazvr,Ask Compsci: Best music to study CS?,"Im not very good at studying without music, specially since my earbuds are noise canceling and i like how they block out the surrounding ambient noise.

Anyways, what do you CS guys like to listen to when studying? Aside, something different while programming?

Currently I'm studying algorithms so I'm not at my keyboard but instead on pencil and paper, idk if people listen to different music during those two situations.",2010-03-09 06:12:28
ie6pk,Looking for some advice.,"I've just finished my first year of university, half of which was spent on Java.

Now, I'd like to actually create something but I've not really learnt enough to make anything complex, just the basics.

So would you recommend deciding on a project and just learning as I go?

Or should I spend my time gaining a broader understanding and *then* starting a project?

Thanks.",2011-07-01 13:29:49
532xul,"P vs NP - Since reverse-computing any finite n cycles is np-complete, whats the connection between np-complete and turing-complete?","Every digital circuit can be emulated by a forest of nand gates where some nand computes the next state of a specific bit var in the memory and registers.

Example: The recognizer function: Does any possible javascript code exist whose sha256 is 0 and within 1 googol cycles returns 42? This is an npcomplete recognizer function, given a precise definition of javascript at the nand level.

If we say ""infinity cycles"" instead of ""1 googol cycles"", its potentially a turing-complete recognizer function, if the constraint (example: javascript code exist whose sha256 is 0) is hard enough. If the answer is no, you may have to search all possible javascript code to verify it, so turing-complete. But if the answer is yes, it would return in finite time.

Or we might ask the same of quines or gliders in conways game of life or rule110.

Since reverse-computing any finite n cycles is np-complete, whats the connection between np-complete and turing-complete?",2016-09-16 17:08:01
t52c5,I'm going into compsci as a college freshman in the fall. This is my senior English Final.,N/A,2012-05-03 13:43:17
881s1,Ask Reddit: Im most likely going to double major in Math and CS. Is that (+ a decent GPA) enough to impress employers and secure a job?,N/A,2009-03-27 19:48:03
3ro7cw,Why Was 5 x 3 = 5 + 5 + 5 Marked Wrong,N/A,2015-11-05 20:14:56
1ub3zg,The NSA may be ahead of the rest of the world in the race to building a functional quantum computer,N/A,2014-01-03 12:55:08
e228f,So you want to get a PhD in theoretical computer science,N/A,2010-11-06 07:23:43
3deh8l,Opinion: CS in Universities Should Not Belong to Arts and Sciences,"It's common for most universities to assign Computer Science majors to their Arts and Sciences school, under the pretense that CS is closely related to the liberal arts and other humanist subjects thought there. To me, that always seemed like a very poor judgement call. Not only does it lump CS majors with students who are, for the most part, nontechnical (I've nothing against liberal arts majors, I just think CS students would benefit more if they were within their peer group), but it also limits their ability to network and socialize with students of closely-related fields, such as Computer Engineers, Software Developers, Mathematicians (who are typically either part of the Engineering or Math schools). Hence, I believe CS majors would be much better served, if they were assigned to a technical school. I am surprised I haven't seen anybody else raise this issue before.",2015-07-15 17:15:04
kwm4f,Doing 4 years of MIT CompSci in 12 months,N/A,2011-09-30 16:47:05
t9fnc1,"IDEA: Why don´t we use time difference while transferring data? Less energy, electricity consumption? Lower costs? Since time is free.","*Hello compsci redditors,*

Let us say we use something like UART. In short: when low voltage came: then transfering data is started....but instead of like how UART is working...

Why don´´ t we just use ""start bit"" and ""finish bit"" and measure time in between.

I will explain on example for easier understanding what I do mean:

Let  us say we use ""start bit""( from high to low voltage), then we do not do  anything for 12 s and then ""finish bit""(low to high voltage).

Now,  since every computer knows what time is (what 1 second is) and time is  free (we measure it on every device anyway).  Let us say we use base64.  From our example: difference in time is 12 seconds: that would mean that  we transferred letter ""M"". If we would like to transfer letter ""J"" we  would not do anything for 35 seconds (how much time is between ""start  bit"" and ""finish bit"").  Obviously, this is just example and we can use  in reality a 1/1000000 of a second or something like this for measuring  unit, but for better explanation I used seconds.

It  is a lot less electricity,energy consumption and since every single  thing that we use in computers are getting broken after some time (since  it is used), there is also less cost for buying new ones, since we  would be using ""high to low"" or ""low to high"" a lot less time for same  amount of data transfferred.

Why are we not transferring data like this?

*Thank you for possible reply. I will be very glad for every single reply.*",2022-03-08 12:21:52
3x1acz,HS Senior planning on pursuing a CS degree?,"I plan on pursuing a CS degree in college even though I do not know anything about programming or computer science. I know I love computers and I would like to understand how they process, etc.

 Once college applications are over, I plan on searching code academy and videos trying to get the feel of what computer science is.

If anyone has studied computer science, has a career related to this, or has been here before and has any advice, I would REALLY appreciate it!l

I'm lost because I don't know anyone who has done this before, so I'm looking for all the help I can get.",2015-12-16 03:58:08
2dwx2n,Could a newborn baby walk and run by wearing a powered exoskeleton with real-time brain scanner?,"If necessary, the real-time brain scanner could be used to allow movement based on neural activation patterns.

Perhaps such an exoskeleton could even accelerate a baby's brain development?",2014-08-18 19:54:09
4wdbdy,Build a Self Driving Car in 5 Minutes,N/A,2016-08-05 23:32:24
5utman,I Wanted To Learn Computer Science so I Created My Own Degree — Here’s My Curriculum,N/A,2017-02-18 17:51:29
i4026,Hey reddit. How do you choose your passwords?,"What length and character set should a password be which balances ease of use (easier to remember and type in) and strength (so it can't be compromised very easily)

Do you use completely different passwords for different accounts?

How do you remember all your passwords? Written down? A mnemonic device?

And does anyone have any good statistics on how long it takes top of the line computers to crack passwords with different levels of complexity these days?",2011-06-20 03:01:51
2skm2n,Proving P=NP is provable,"Has it been proven that P=NP can be proven, or that a solution exist to this question?

Edit: I apologize for the misleading title I understand this is a sensitive issue",2015-01-15 23:53:29
hfqp3,I think I'm going insane.  And I hate fortran. Anyone have any clue why some code would be doing this?,"So I'm trying to convert some old fortran code into c, and am just having an absolutely lovely time with it.  This is the first fortran code I've worked with, and well, I have no clue why this might be happening.  The code is reading a value entered by the user:

     99         print *,'What value of circulation parameter (A-Tilde) would you like to use?'
    100         read *,A
    101 
    102         print *,'A is',A
    103         A = 1.8
    104         print *,'A is',A

Then when I run the code:

    What value of circulation parameter (A-Tilde) would you like to use?
    1.8              <----i typed this in
    A is  1.79999995
    A is  1.79999995

What on earth is going on? I'm trying to compare the results to what I'm getting in c, and fortran reading this value incorrectly is messing everything up.

I've tried compiling it on both OS X using g77 and linux (64 bit) using gfortran.  Same error on both OSes.",2011-05-20 08:16:40
4ugq63,Real functional programmer don't need functional languages.,N/A,2016-07-25 04:07:49
b2t11x,Why a CS degree is better than teaching yourself how to code,N/A,2019-03-19 04:45:05
ie7m6,Narrowing down my college major. (Compsci/Physics),"Okay, so right now I'm going into my senior year of high school in Florida. I'm having kind of a hard time narrowing down what I want to major in. Just recently, I've become quite interested in the field of Computer Science. Clearly having the ability of computational thinking is invaluable, and I would most definitely love to pursue a career in Compsci. But, I am also interested in hard science. I would love to find something that is a good mix between Computing and Physics, and I wouldn't even mind doing something with computer graphics. Any help is appreciated because I figured this subreddit knows far more about Computer Science than I.",2011-07-01 14:08:46
82pazl,Less math intensive Computer Science research area,"I am a first year undergraduate looking to delve into research in the field of Computer Science. IoT, Machine Learning(though I have a paper currently in review) and Security are not fields I am interested in. Other fields like Programming Language theory seem too math heavy for me to understand. 
Would love to hear suggestions. Thanks!",2018-03-07 15:59:29
c5rdy,A Proof for P vs. NP Problem,N/A,2010-05-19 02:18:37
25dgya,Computer Science Book Reading List,N/A,2014-05-12 17:24:14
1ka5du,"Programming is a skill, not a profession.",N/A,2013-08-13 15:15:31
eaoy1d,Different ways to add 1 to a number 😲,N/A,2019-12-14 20:34:58
f5ajph,The CAP Theorem,N/A,2020-02-17 15:45:03
9v1khe,Easiest way to start coding?,"Hi, I am interested in coding, I have no idea is that what I wanna do in the future, but I wanna learn some basics. What would be the easiest way to make an algorithm that does something if a part of the screen is a specific color? I would maybe like to use Notepad++ as it seems nice to begin with.",2018-11-07 17:46:55
v2wnz,Why is git so unnecessarily complicated?,"ie.
git checkout command does different things depending on the arguments.
git pull is a redundant command

I'm sure there are more examples. Concatenating numerous commands into one by using arguments saves people from tying a few letters, but the adding complexity in remembering how all the commands work is not worth it.",2012-06-15 04:10:15
1efbz2,The Science in Computer Science: The Sixteen Character Traits of Science,N/A,2013-05-16 02:12:57
2oqicm,"A ""Modern"" Approach",N/A,2014-12-09 07:46:22
daa6v4,"Enthusiasit: As I learn to code, what is the true complexity of this algorithim?","Someone has mentioned it could be sub-exponential. But, I'm not familiar with sub-exponential time. My knowledge is limited to **O(n), 2\^n, O(n\^k)** definitions only. I think it could be O(n). 

So what's the running time for input bit-length?  Is it safe to say its O(n)? Or is it subexponential? (Not sure what that is)

    n = input('Enter integer so that you can factor_sum_of_digits:  ')
    strings_of_digits = list(map(int, str(n)))
    
    factor_sum_of_digits_input = sum(strings_of_digits)
    
    
    def getFactors(y):
        # Create an empty list for factors
        factors=[];
    
        # Loop over all factors
        for i in range(1, y + 1):
            if y % i == 0:
                factors.append(i)
    
        # Return the list of factors
    
        return factors
    
    y = factor_sum_of_digits_input
    
    X = int(input('Enter target integer for X: '))
    
    alist=getFactors(y)
    names = alist
    
    if names.count(int(X)) > 0:
    
      print(""yes"")
      print(names)
    else:
      print(""no"")",2019-09-28 02:21:06
85pnpy,why isn't Church also considered a founder of computer science?,"if lambda calculus is equivalent to a turing machine

shouldn't both of them be considered the founders of computer science, and not just Turing?",2018-03-20 03:19:56
6v9347,A Stronger Foundation for Computer Science and P=NP,N/A,2017-08-22 05:58:33
mj5hr,"I'm choosing a language to learn out of the following (in description).  I would love to hear what you guys think I should do, and why. Thanks!","* Fortran 
* Haskell 
* ML or SML
* OCaml 
* Ada 
* Pascal
* Modula 
* APL or J 
* Forth or PostScript
* F# 
* Go 
* Oberon
* Scratch 
* Scala 
* Squea",2011-11-20 17:52:32
acswoh,Computational complexity - Big O notation,N/A,2019-01-05 10:02:54
xcd37,Internships??,"Hi, I need some recommendations on potential companies to apply to intern for. I've made a pretty big list of companies, just curious what you guys think.

Here are companies I plan on sending an application -

Google,
Yahoo,
IBM,
Intel,
AMD,
Nvidia,
Blizzard,
EA,
Epic games,
Apple,
Microsoft,
Sony,
Lockheed Marti ,
Boeing 

Any other companies? The more I apply for the more likely I'll get one. 

Thanks ",2012-07-29 15:04:06
afwvw,Redditors wanted to participate in a survey that I am conducting as part of my dissertation.,"I am interested in knowing more about how you store, use, and maintain collections of web pages as part of on-going work on the Distributed Collection Manager. Your responses will help me to understand how you currently work with collections of web pages in order to better support the kinds of tasks that you would want in a collection management tool. Please help me to gain valuable insight in to the problem of web page collection management by taking the time to be interviewed by me.

If you are interested in participating, please visit:

http://www.csdl.tamu.edu/surveys/index.php?sid=51955

Thank you! ",2009-12-17 23:07:34
4ercdy,Paper claiming existence of one-way functions (and hence P != NP),"https://arxiv.org/ftp/arxiv/papers/1604/1604.03758.pdf

This was published this morning to arXiv. I haven't had a chance to read it closely yet but figured someone might find it interesting (even if it's false).",2016-04-14 14:21:16
21pqjw,Reverse Engineering Disassembled Programs,N/A,2014-03-30 01:21:35
14b4ir,Overall list of Computer Science ideas/subject/areas of interest? ,"I am looking for a complete list of computer science ideas and subjects. Ex. programming, computational complexity, etc. along with subtopics?",2012-12-05 05:40:31
t70kn,The undecidability of the halting problem is not very important,N/A,2012-05-04 16:17:31
igb9w,Dynamic Host Configuration Protocol (DHCP)/Domain Name System (DNS),N/A,2011-07-04 10:51:44
1sjyah,Why Johnny Can’t Write Multithreaded Programs,N/A,2013-12-10 16:02:13
205bbs,The JavaScript epidemic,"Ok so I tried to write something that people would open up. 

Like most people on here I have learned/used/taught a wide selection
of programming languages. I dont think that there is one language
that is right for everything.  But you can accomplish most things in 
any language, but it may take longer in one rather than another.

JavaScript is rapidly becoming the de facto language, not only for 
DOM manipulation, but consuming services, writing web servers, 
writing database code and a whole lot more. It seems every product announced lately uses JavaScript in some manner.

I dont particularly like that, but that is just a preference. 
What does concern me is that we might have a generation 
of developers for whom JavaScript is the first and only
programming language they have known. 

Its not an object oriented language, though it can be 
(tortured) into sort of behaving like one.   Its not a 
functional programming language though lately 
the blogosphere is filled with stories about how it is.
It can sort of behave like one in a limited capacity. 

Perhaps its my own hangup about learning the different 
ways OO, functional, logical, imperative etc, and then being
able to write better code, but I dont quite know what native
JavaScripters would end up with.

I feel like a luddite writing this though and it might just be
my age showing.",2014-03-11 16:10:33
ajdvmx,How can I pursue PhD in Programming Languages from non CS background ?,"I studied bachelor in Electrical and Electronics engineering with communication major from outside US. But I want to get a PhD in Programming languages. I know I don't have any formal background in Data Structure and Algorithm, Compiler Construction, Automata theory, Theory of Programming languages, Functional Programming, Database Programming, logic programming etc. I was just trying to learn those stuffs from internet.  My aim is to develop totally a different type of programming language where it will be easier for AI to write its own program. I feel that the current C,C++ stuffs are so hard for a machine to learn and write its own program. ",2019-01-24 16:05:56
5ciwid,What will personal computers be like in 50-100 years time?,"In your professional opinion as a computer scientist, what do you think personal computers will be like in 50-100 years time? Will it be like comparing today's fastest supercomputer to the ENIAC?

And will full quantum computers become a reality?",2016-11-12 04:38:26
7h0h4,"Ask Compsci: Please help me detect BitTorrent shaping, details in comments",N/A,2008-12-03 02:55:51
2zghcc,"If the halting problem says no program can determine if a program terminates, how can I know while(true){skip} doesn't terminate?",N/A,2015-03-18 11:38:55
dkryu,16-bit ALU built within Minecraft video game ,N/A,2010-09-30 01:03:34
1xbet8,Minesweeper is (probably) not NP,"Feel free to check me on this, but I'm pretty sure minesweeper is not NP. I haven't done the actual runtime analysis, but nothing would lead me to believe it is. A while back I posted a rough algorithm for a minesweeper player we were working on. I'm not sure WHY minesweeper is considered NP (according to wikipedia and google searches), but it's not (unless I don't understand what NP is). We coded up an algorithm I devised in Haskell, and were able to solve a 100 by 100 or 10000 square 1000 bomb minesweeper game if it were indeed *solvable without guessing* in... 3 minutes? Yes, I have a pretty fast computer, but that doesn't sound like NP run time along either the number of squares or the bombs. When we gave the demo at the ACM meeting a grad student who had been supervising the project said our algorithm was most likely **polynomial along the edge**. Here's how we did it, step by step.

The minesweeper playing AI is broken up into two phases, auto-expansion and searching for logic. For sake of simplicity we assume the top left square never has a bomb in it. If there were perhaps a bomb, it would still not change the validity of the algorithm.

To spoil it for you, here's the grid we'll be working with

    _ _ #
    _ _ _
    _ _ #
    # _ _

Underscores mean unknown and number signs mean bombs.
FIRST PHASE EXPAND:
So we open up the square. Since the algorithm automatically fails (requires guessing) if there is a bomb in any of the three surrounding squares, we will say it's a 0 (no bombs surrounding).  This gives us a grid that looks something like this.

    0 _ _
    _ _ _
    _ _ _
    _ _ _

The first thing we do is look for any squares that have been opened with a value of 0 (the number of bombs found subtracted from the number of found bombs). To do this, we traversed across all squares. When we find one, we open up all neighbors and continue traversing. This turns us into...

    0 1 _
    0 2 _
    _ _ _
    _ _ _

At this point, we return, recognizing that we've updated our located in an expansion. So we continue expanding until this is not true. The same algorithm is applied again and we get this.

    0 1 _
    0 2 _
    1 2 _
    _ _ _

We do one more sweep and find that nothing new has been opened. At this point we switch to our next phase.

SECOND PHASE SEARCH:

OK, now that we have a board it's time to start generating some logic! Let's do some quick labeling to make this easier.

    0 1 A
    0 2 B
    1 2 C
    F E D

We again do a search for squares, but this time we're looking for ones with a value of number found bombs subtracted from the total number of bombs > 0. The first hit is that ""1"" directly to the left of the A. Since it is a 1, we know the logic will be an XOR of simply the unopened squares around it. In this case, we have

    A XOR B

Well we have logic, but what does it mean? I came up with four ways of ruling out and determining the meaning of logic--none of which require exponential run time over the currently generated logic.

The first I named ""Confirmation"". This is a way of determining if a single XOR (in this case XOR A B) has an element that appears across all units. In this case, it does not. A is not in B and B is not in A. So we move on.

Since this is the only one of the four we can apply with only one logic unit, let's generate some more logic! But where do we get the logic from? Well, the only squares that contain relevant logic are the ones that touch the bombs in our current logic. So we take our logic list, find neighbors with values (as earlier) > 0 and add them to the list. In this case, A borders the one next to B and B borders both that one and the one next to C so we'll generate both logic. This generates some substantial logic.

    XOR: A, B (2 choose 1 generated)
    XOR: A and B, A and C, B and C (3 choose 2 generated)
    XOR: B and C, B and D, B and E, B and F, C and D, C and E....
    C and F, D and E, D and F, E and F (5 choose 2 generated)

I'm not going to re explain confirmation for our first XOR but looking at our logic, we see that in the second XOR, A is not in the third and, B is not in the 2nd, and C is not in the first. Similar problems exist with our third XOR.

So a second logic rule might be useful. That's where ""Contradiction"" comes in. We start taking entire XORs and comparing them with ANDs of another XOR. If every element of an XOR (assuming it is not length 1) is contained in the and of another XOR, we can add that and to a remove logic list. This does appear here. The first XOR contains A B so we can add A and B (appearing in the second XOR) to a remove logic list.

The remaining logic functions tell us nothing interesting (oh but they will) so we can skip over them and go back to confirmation (no point in first generating new logic, as the logic functions are still working--confirmation hasn't been run since the logic has changed. Looking at that second XOR we see.

    XOR A and C, B and C

C appears across all elements! We've found a bomb!

    0 1 A
    0 2 B
    1 2 #
    F E D

Great! We'll have to restart our logic (since the values have changed) so before we do we run PHASE 1 again and find nothing new. So let's skip ahead to our new generated logic.

    XOR A B
    XOR A B
    XOR B D E F
    XOR E F

Time to introduce our third logic rule, ""Reiteration"". Reiteration works by checking if all elements of an XOR are contained in another XOR, meaning that any other elements can be removed. This shows up for the fourth and the third. The fourth contains E F and the B D E F, meaning that it *cannot* be B or D. We'll add these to our closed logic list.

This brings us to our fourth and final logic rule. I couldn't think of a name for this one so we used the name a grad student came up with, which I can't remember at this exact moment. We check our removed logic list for any free standing squares. Both B and D were removed in the last run, which means we can open them. We find

    0 1 A
    0 2 2
    0 2 #
    F E 1

Of course this means we'll have to generate new logic, so time to do phase one again. This time we get a hit. That 1 in the bottom right has a bomb next to it, thus a value of zero and we can open things up.

    0 1 A
    0 2 2
    1 2 #
    F 2 1

First thing we do is start generating logic and we find...

XOR A.

Booya! Another confirmation hit.

    0 1 #
    0 2 2
    1 2 #
    F 2 1

Nothing new from Phase 1 so let's give the logic one last go...

   XOR F

Shows up first on the 1 above the unknown in the bottom left. That's a confirmation so we now have our solved game of.

    0 1 #
    0 2 2
    1 2 #
    # 2 1

What does this mean? I've gotten it down to three possibilities which I will state in order of likeliness.

1) Minesweeper is not NP. Nothing here seems to lend to the idea that it would take exponential time.Of course it is possible I missed something, and that it's exponential along the length? This would mean at minimum 2^100 operations in 3 minutes, which still doesn't seem likely on my laptop.

2) Minesweeper is NP and I don't understand what NP means. This is a possibility, but I think I learned something in my languages class where the concept was first introduced to me, so I have to wonder.

3) NP problems are solvable in polynomial time. This is the least likely, but hey it's still not proven that they can't be right? So I thought I'd throw it in here. This is by far the least likely option, but I thought put it in here for the titillation of people--maybe convince someone to do an actual runtime analysis?

Cheers and thanks for reading!
Ian Swift",2014-02-08 00:11:25
e4ooj9,6th grade me solved P=NP… i don’t know how y’all didn’t think of this 😌😌😌,N/A,2019-12-01 22:08:57
7idxg,"960 cores, 4 teraflops - on your desk!",N/A,2008-12-09 18:08:37
qziu8s,Algorithm quiz to check and make solid your knowledge,N/A,2021-11-22 10:51:54
cczwhg,Outperforming Rust With Functional Programming,N/A,2019-07-14 06:31:20
756gn,XML as a programming language syntax,N/A,2008-10-04 04:57:26
1lrzjc,Why does scientific computing today still use only technology of the last century?,"I am a programmer. It happens only occasionally that I have to deal with mathematical algorithms. I assume, most of you use math frameworks like R, Matlab and the like?  But I wonder, why none of them is actually able to give the same experience like modern software programming frameworks? Let's say: Visual Studio. I know it is for applications. But, hey, shouldn't programming applications be much more complicated than a single math script? But, obviously, Matlab & Co are simply not able to catch up with the convenience of Visual Studio!? Where are features like test integration, (working, fast) intellisense, refactoring, code versioning, team collaboration, remote debugging, profiling (yes, we are using multiple processes! And we do need to debug them!) ... ? Everything what gets really essential as soon as it comes to real (large) projects ??

This gets even more true, if you are trying to put an algorithm into a program! Correct me, if I am wrong, but so far, my experience with Matlab ""Compiler"" is best described by: ""PAIN"". The python experience is in no way any better... Which professional developer would really want to carve up his whole software development chain by starting with an *.m file, compiling it to a general purpose language (C) and have it afterwards corporated into a super modern enterprise .NET online portal ? Let's disregard the pollution of the project with dozens of additional dependencies to the Matlab runtime and also the licensing costs! Even worse: in order to fix a bug in the *.m file, I need to have all tools available and must repeat the whole process? C'mon ... !! Of course there will be bugs! Or do you know any good testing framework for ... ""Octave""? And what, if I measure and compare the results with something written in a GPL from scratch ? I still get only a tiny fraction of the speed which would obviously be possible ... 

Is there really no modern alternative out there? Which language/framework can you suggest which delivers an acceptable convenience and is really able to support us in getting large, professional projects done in time, reliably, and maintainable?",2013-09-05 11:02:26
775rcs,Natural Simulation Theory - computer science meets metaphysics in the inevitable synthesis of science and philosophy,N/A,2017-10-18 10:46:36
ipk6q,How to begin for CompSci?,"I'm an undergraduate student majoring Physics and Math. I knew that Math and CS both were suppliments to each others, but never tried to learn CompSci. Now I feel very bad about this. I'm good in math and want to learn Computer Science too. Please suggest me  what I should read to be a man like you all. Suppose that I don't know anything about Computer Science and Wikipedia articles were not helpful so much. Please provide links to some online available books or lecture notes.

EDIT: Thanks everyone for their valuable comments. My 'problem' is almost solved.",2011-07-14 16:44:08
gb75l,"They said I couldn't have a ham, tomato and cheese croissant; I say they need to review their logic statements",N/A,2011-03-25 11:25:21
cv3u6,Ask ComSci: How does one say they 'found' an optimal value for continuous functions?,"I'm working on an algorithm that finds the optima for continuous functions and want to begin writing up my results. From literature I've noticed a lot of papers will say they 'found' the optima 99% of the time for a given function f. What they dont say is if its within some epsilon, or how they measure that.

For example, I can't use relative error since some global minima are 0. Using the relative error would be divde by zero error. I can't offset by 1 and recalculate because that is just some arbitrary offset and depending on what offset you choose drastically can change relative error. Is it normal to just pick some epsilon and if the difference is less than that say you found it?

How does one normally say they 'found' the optima?",2010-07-29 15:25:31
adbh9t,Is there a University that proposes a master degree linking AI and Climate Change ? Or any organisation that searches someone in those domains ?,"It can be anywhere in the world ! I want to feel useful and put Computer Science to a great and important cause

Thanks !",2019-01-06 23:46:45
zxzt2f,"Technically and functionally speaking, are folders in filesystems relevant?","Hello everyone!

I hope I'm posting a good question in the right subreddit and I'm not violating any rules.

So, as the title is: Are folders relevant? I know it's tidy, easier, and makes life easier and safer. But are folders really essential for a computer to function? In an abstract sense, not necessarily on current filesystems/OSes. I googled a bit and all the answers I'm getting on how useful folders are, but not whether we can do away with folders or not for a computer to run even if it means having to create a new filesystem/OS.

I know we can set permissions on folders especially when we want to share them across networks, but we can potentially do the same on files levels and set some sort of flags on metadata for permissions and such. Maybe names could be a problem, but we can refer to files by some GUID or something and include the name in its metadata (And probably version too).

I personally dump most of my files in a single folder and look files up by name, type, size, date and get to needed files almost all the times without hiccups.

What do you think, are folders really important for a computer to run in terms of functionalities and technicalities? What would not having folders structure implies?",2022-12-29 08:06:12
inmkl,Do computer science majors tend to be poor programmers?,"I posted this yesterday out of curiousity and judging from the responses, the tendency is to believe that comp sci majors are poorer programmers than non-cs degree holders (obviously there may be a bias being in /r/learnprogramming):

http://www.reddit.com/r/learnprogramming/comments/ims39/how_many_noncs_majors_in/

If one is not going to pursue a master's degree after a obtaining a bachelor's in CS, what are the practical applications of the degree in the workforce if CS majors truly perform below average as coders (due to degree emphasis on theoretical computer science)?",2011-07-12 18:14:39
tpztb,I'm thinking of buying an Apple //e for a summer project. Any ideas what I should do with it?,"I'll be using the assembler, because 6502 machine code makes my head hurt.",2012-05-16 14:39:14
17rz2p,I'm a SoftEng with CS background intent on drawing manga of a new genre: CSPunk. I appreciate fellow redditors' ideas.,"I'm a software engineer and I work on compiler optimizations. On the side, I draw manga. I'm very interested in Cyberpunk (my favorite being GitS) and I'm inspired to further specialize the genre into one we all CS fellows would appreciate: CSPunk/CompsciPunk. The motivation is two-fold: I want to create something new, and I want to get people interested in Computer Science.


Now, with CS being such a specialized field, some may doubt the feasibility of it gaining mainstream attention. With this post, I hope to draw some ideas from the crowd, and see if it's possible to craft a believable fictional world with CS as its theme.


I have some [concept art](http://imgur.com/a/O6puQ). I imagine a near future where people can plug their brain into the Internet, directly manipulating virtual objects using their mind. The heroine is a data parsing/manipulation specialist, and I intend to dramatize and visualize exploits/information manipulation using actual CS knowledge. I hope to write a story that is grounded on true CS knowledge (nothing like the hacker movie), but is also comprehensible to a layman.


Examples of ideas I'm looking for: heroine infiltrates a process running in a server's userland, identifies the structure of the floating data (she gathers it's an acyclic graph of some sort), constructs a parser on the fly, and extracts information from it. Unbeknownst to her, the graph is really cyclic, and so the intelligence she obtains from the graph turns out to be wrong, and as a result she loses a comrade (who has made use of the intel).


She may also be a counter-intelligence agent, saving the world from a nuclear missile by means of a series of clever bitwise operations on positional data feeding to a ballistics computation process.
I'm unfortunately not nearly smart enough to come up with dramatized exploits like this. If this post sparks some ideas in you, feel free to share!
Also, I'm aware that this post is rather different from a regular /r/compsci post, but I also do not find this post violating any rules. If it does then please point me to the right direction.
Thank you! All inputs appreciated! If something comes out of this (hopefully a webcomic), I'll make sure to credit your name.


TL;DR have ideas for a dramatized CS exploit suitable for a manga medium? Share!

**edit** thank you all so much for the advice! I'm in the absorbing (the resources you all suggested) and planning (the pilot) stage. I'll keep people updated!",2013-02-02 23:03:29
1em3m4,Is floating-point obsolete? Is there a way to represent values better? Here is an alternative.,N/A,2013-05-19 03:36:03
yk0j2v,Is there a possibility that all the current knowledge about computer science turns useless?,"What happens when quantum computing advances? I'm currently studying a career in computer science and every time I think about it I get a little bit depressed. What if I'm learning all this for it turning into history? I love studying it and I'm certainly not doing it for money but the possibility of it being useless in the future and not having any application feels just depressing. Probably a very asked question but I just needed to post it, sorry",2022-11-02 09:31:38
jfh5f,Was Alan Turing wrong ? Jeff Hawkins thinks so...,"If you have read the book 'On Intelligence' by Jeff Hawkins you would know what I am talking about. If you have not read the book you should, provided you are interersted in AI. 

Hawkins argues that Turing could not draw an universal definition of intelligence and therefore, was compelled to explain intelligence through a comparative parameter like behavior - i.e. - 'something is intelligent because it is behaving intelligently'. Hawkins suggests that behavior is not the fundamental property of intelligence. Instead, the fundamental property is predicition - which make us behave in some way. 

Then.. and this coming from a person with mostly bio/hardware background.. he goes on to blast everything that software related AI has 'not' achieved in the last 50 years. 

Comments, fellow CS subredittors...",2011-08-11 07:10:27
k5ebl7,We put together a list of our Top 30 Women Aiding AI Advancement in 2020 - Some great recommendations from our community!,N/A,2020-12-02 17:54:06
1n4k0z,On viral misinformation around garbage collection,N/A,2013-09-25 19:58:32
77hbw7,BRCA1–BARD1 promotes RAD51-mediated v gvhomologous DNA pairing : Nature : Nature Researchg,N/A,2017-10-19 21:00:19
4ll0jt,If an algorithm doesn't contain recursion are its time and space complexity equal?,N/A,2016-05-29 16:16:19
4iuyb7,"Community Hangout 62 starts at 2pm EDT, 11am PDT, 8pm CET. We are discussing tech updates, community updates and our DAO proposal. #scala #etherum #bitcoin #blockchain","Link to the hangout https://www.youtube.com/watch?v=Mp-L4Puj8HI I would like to invite everyone to be apart of this community call.

The community leaders are working on a DAO proposal, our team will inform the community about the details of this proposal.

Our intention is to decentralize the Daohub.org project as soon as possible and raise $3,000000 USD or community related projects. $1,500000 in Ethereum with the possibility of Synereo backing $1,500000 in Amps.

http://www.synereo.com 
Facebook: http://www.facebook.com/groups/1013726192055203/ 
Slack channel: http://www.synereonet.slack.com 
Twitter: http://twitter.com/synereo 
White Paper: http://www.synereo.com/whitepapers/synereo.pdf

Synereo is an open source, decentralized social network. It is an attention economy that rewards popular content and participation with crypto-currency. Content is promoted or advertised in a way that fairly rewards the content's creator and those who choose to engage with that content. An automatic and transparent reputation economy assures that you experience content relevant to you. The privacy of your communications and contacts is baked-in to the structure of the network. Synereo is modeled in π-calculus and functionally programmed in Scala.",2016-05-11 13:42:38
1k0soo,Why is there not a Master degree in Computer Operating Systems?,"I have search internet for a Master Degree and no University offers it. Is it under other name? Any book that can teach me how to build an OS from scratch?

TIA for your answers",2013-08-09 12:33:03
bdeb0,"Does it annoy anyone else that compsci's reddit alien is saying, ""P=NP""? ","First, P=NP has never been proved, and second, it never will be.",2010-03-15 01:32:14
ahlci,/r/Compsci: what is an entry level networking tech job and how do I get it?,"I've stacked up some cash and can study for about 2 semesters at the local community college, which offers a certificate and an associates degree in network administration. I've got some of the courses knocked out already, but even the lighter of the two will take more than two semesters to complete, so I need something to hold me over. Is there a low-level job that someone just getting into the field could get and reasonably perform at, or do you have to wait until you've got an experience-filled resume to get a decent job in the field?",2009-12-22 20:39:20
8q8zk,The Death of Formalism. ,N/A,2009-06-06 06:25:15
rz3dp,What is LLVM and what are good resources to get started with it?,I've been trying to get hold of an introductory material on LLVMs. Please share if you some. Thanks!,2012-04-08 10:24:58
c90dr,Who killed Kurt Goedel's mentor? A University of Vienna Professor gives me an incredible explanation. From /r/PhilosophyofScience. ,N/A,2010-05-28 11:18:04
i80uc3,"A demonstration of how bad computers are at picking random numbers - each pixel is a random colour, with the random function seeded with the pixels x and y coordinates multiplied together before drawing each pixel. A pattern clearly emerges (other than the trivial diagonal line of symmetry)",N/A,2020-08-11 21:44:49
e82spm,"Come meet Steve Huffman, CEO of Reddit, at USC’s HackSC 2020!","Hi everyone! Just wanted to let you know that Steve Huffman will be the keynote speaker at HackSC 2020!

HackSC is the University of Southern California’s largest hackathon, and today is the LAST DAY TO APPLY!

If you are a student looking to network with amazing companies like Reddit, collaborate with other students, and have an unforgettable experience at USC, we invite you to learn more and submit your application by MIDNIGHT at [HackSC.com](http://hacksc.com/) :) 

&#x200B;

https://preview.redd.it/n85pgyu2bi341.jpg?width=2048&format=pjpg&auto=webp&s=40c73e3261e9c3c4e3fbf8e542ed6988c787f4be",2019-12-09 01:25:09
5yqhdt,"If I download Google Chrome source code and compile it in my machine, will it run faster than the ready to download version?",N/A,2017-03-11 02:43:28
i9zyv,Going to college for Compsci but do not know squat about Compsci/programming...  What should I learn first?,"As the title says, I don't know anything about computer science/programming.  I downloaded a bunch of ""For Dummies"" book on computer science and programming (C++, C, Javascript, etc.) and I am really stumped on what to learn first.  I am going to major in compsci this fall in college and I am really interested in this topic but I do not know where to start.  ",2011-06-27 03:13:01
31pw3k,Do you find that math majors look down on CS students?,N/A,2015-04-07 05:43:41
30omld,"Is computer science ""fun?""","So I am currently a freshman in college in neuroscience. I definitely enjoy my science classes a lot but I feel like I'm getting burnt out. I was thinking of maybe going into computer science.

I've had some experience with html and css and I absolutely loved coding. But, based on what I've heard computer science doesn't seem to focus too much on web development which is what I've done. I'm assuming the career is just learning many programming languages is this correct?

I've heard so many people say the field is boring and it's super hard because it requires a lot of math. I'm not too sure what to think at this point. (for the record I don't really like math)

What are your thoughts?

**EDIT**: For the record, I'm not saying I hate math or that I can't do it. The process or learning certain mathematical concepts doesn't seem all that enticing. But, I can do math just fine. It's just that if I can be doing something else other than math at that time... well, I'd rather be doing that something else.",2015-03-29 08:16:37
21o7no,Which College—and Which Major—Will Make You Richest?,N/A,2014-03-29 14:32:39
lftdb,Would you consider Computer Science really a science?,"Science is the study of the natural world, but how come Computer Science is called Computer Science? It is more engineering than a science (actually, applied mathematics). Its is not a study of a natural phenomena, so not really a science.

I want to know more about the theoretical side of CS.",2011-10-18 01:44:39
wz4ksd,Official website of the software design paradigm DCI has been updated,"If you're interested in becoming a better programmer, learning and understanding DCI (Data, Context, Interaction) is a thought-provoking endeavour that you won't regret.

The official DCI website [https://fulloo.info](https://fulloo.info) is now available in an updated version, packed with information about how to reach the following key aspects:

* Separating what the system is (data) from what it does (function). Data and function have different rates of change so they should be separated, not as it currently is, put in classes together.
* Create a direct mapping from the user's mental model to code. The computer should think as the user, not the other way around.
* Make system behavior a first class entity.
* Great code readability with no surprises at runtime.

Having spent over 10 years on the frontier of this paradigm, I'm available to answer any questions you might have about DCI.",2022-08-27 14:43:40
2zua9i,Capital/State Guessing Game 2D Arrays,"I have been looking online and found a few people who were able to get this sort of code done but nothing provided a solution for the issue i am seeing directly. The task here in this is for the program to ask a user ""What is the capital of Arizona"". The user needs to enter a capital such as Phoenix and it will award a point and move to the next question all the while tallying the number of correct answered and displaying them at the bottom of the output when done. When running my program it asks the capital of the first state on the list. Once done it will provide a point but then spits out the rest of the states saying that they are correct but does not give the use the chance to enter the next state. Its as if I am missing the part that would move back to the original question of ""Enter the capital of the state listed"" when the first state has been answered.. Can someone assist? I believe I need a statement like if, else if, and else but cannot see how I would apply it in here or if I should be trying another loop. I couldn't get a do loop to work properly. Any suggestions? My code is below.  


import java.util.Scanner;


public class StatesArray {
static Scanner scnr = new Scanner(System.in);
   public static void main(String[] args) {

       int correctStates = 0;
       String userInput = """";
       int i = 0;
       final int NUMBER_OF_US_STATES = 49;

       String capitals [][] = {
        {""Alabama"", ""Montgomery""},
        {""Alaska"", ""Juneau""},
        {""Arizona"", ""Phoenix""},
        {""Arkansas"", ""Little Rock""},
        {""California"", ""Sacramento""},
        {""Colorado"", ""Denver""},
        {""Connecticut"", ""Hartford""},
        {""Delaware"", ""Dover""},
        {""Florida"", ""Tallahasse""},
        {""Georgia"", ""Atlanta""},
        {""Hawaii"", ""Honolulu""},
        {""Idaho"", ""Boise""},
        {""Illinois"", ""Springfield""},
        {""Indiana"", ""Indianapolis""},
        {""Iowa"", ""Des Moines""},
        {""Kansas"", ""Topeka""},
        {""Kentucky"", ""Frankfort""},
        {""Louisiana"", ""Baton Rouge""},
        {""Maine"", ""Augusta""},
        {""Maryland"", ""Annapolis""},
        {""Massachusettes"", ""Boston""},
        {""Michigan"", ""Lansing""},
        {""Minnesota"", ""Saint Paul""},
        {""Mississippi"", ""Jackson""},
        {""Missouri"", ""Jefferson City""},
        {""Montana"", ""Helena""},
        {""Nebraska"", ""Lincoln""},
        {""Nevada"", ""Carson City""},
        {""New Hampshire"", ""Concord""},
        {""New Jersey"", ""Trenton""},
        {""New York"", ""Albany""},
        {""New Mexico"", ""Santa Fe""},
        {""North Carolina"", ""Raleigh""},
        {""North Dakota"", ""Bismark""},
        {""Ohio"", ""Columbus""},
        {""Oklahoma"", ""Oklahoma City""},
        {""Oregon"", ""Salem""},
        {""Pennslyvania"", ""Harrisburg""},
        {""Rhode Island"", ""Providence""},
        {""South Carolina"", ""Columbia""},
        {""South Dakota"", ""Pierre""},
        {""Tennessee"", ""Nashville""},
        {""Texas"", ""Austin""},
        {""Utah"", ""Salt Lake City""},
        {""Vermont"", ""Montpelier""},
        {""Virginia"", ""Richmond""},
        {""Washington"", ""Olympia""},
        {""West Virginia"", ""Charleston""},
        {""Wisconsin"", ""Madison""},
        {""Wyoming"", ""Cheyenne""}
       };

       System.out.println(""Enter the Capital of the State listed: "" + capitals[i][0]);
       userInput = scnr.next();

       i = 0;
       for(i = 0; i <= NUMBER_OF_US_STATES; i++){      
       if(capitals[i][1].equals(userInput)) {
           correctStates++;
           System.out.println(""Yes that is the capital of "" + capitals[i][0] + ""."");

       }

       else {
           System.out.println(""No that is not the capital of "" + capitals[i][0] + ""."");
           i++;
       }
       }


       //counts the number of correct guesses.
       System.out.println(""Total number of capitals answered correctly: "" + correctStates + ""."");
       i++;


     return;

   }
}",2015-03-21 21:00:41
2x3693,"Proving that Android’s, Java’s and Python’s sorting algorithm is broken (and showing how to fix it)",N/A,2015-02-25 06:45:36
zlg8z,Career Decision: Computer Science Concentration,"I'm a 3rd year student at a University and I am starting to take concentration courses. I am a Computer Science major and Math minor. I love Computer Science and am confident that this is what I want to do but I'm not sure what I would focus on. I believe I would love being a professor but I wouldn't want to do that immediately. 

I really like the topic of Computer Vision ~~which seems to be the math and science behind representing 3-dimensional scenes on a 2-dimensional screen~~ but I don't know how applicable this would be after I graduate. i also believe I would enjoy Computer Security which, I'm assuming, would have a greater employment chance. Which do you think would be a better career choice? Do you have any experience in these job fields? 

TL;DR Computer Security vs. Computer Vision? Jobs, money, satisfaction?

EDIT: Thanks for all the info everyone! I take it all into consideration. Sorry about the incorrect definition haha. ",2012-09-09 08:32:26
erqnx,"I'm getting my BS in CS and I was thinking of getting an MBA, can anyone tell me more about it?",Has anyone done this? What are the pros and cons? Is it worth it? How will it make my life and/or career different? What kind of stuff can I do with it?,2010-12-26 20:55:23
a25rk,Help! Can anyone please teach me about K means in image segmentation and about the Fisher Linear Discriminant?,"I've ported a c++ program my professor gave me to java then ran it on a given image. I'm still tasked with running an iterative Fisher's Linear Discriminant (FLD) on the means and covariances to improve the K means result. My problem is I can't understand how to get the covariances and how the FLD works.

It's supposed to go like this:
1. Run K means
2. Try to split cluster into 2 using FLD
3. If cluster can be split, run (2) on split clusters.

Sigh. I know I'm not making sense. I've only been exposed to simple edge detection stuff or histogram making back in college. This task is for a friend who's not actually a computer science graduate but somehow got into a satellite imaging graduate course.

http://imgur.com/kGtDL.png The FLD equation I can't make heads or tails of.",2009-11-08 11:37:44
4cgwz9,A Black students perspective of Computer Science at Stanford,N/A,2016-03-29 18:57:27
iekkt,Story of Wind and Mr. Ug,N/A,2011-07-01 22:12:50
i5gko,Sorting Out Sorting,N/A,2011-06-21 18:26:56
2wyew6,Looking for arrays of positive integers,"I'm playing around on the subset sum problem and i'm looking for arrays of positive integers, preferably sorted, that have a unique solution or a specific integer that you can't find as a sum

For example {12,15,16,22}

38 has a unique solution: {16,22}

21 has no solution

I have this link http://www.cs.utsa.edu/~wagner/CS3343/dp/subsetsum.html with the array but I'm looking for more and big.

thanks.",2015-02-24 04:33:46
sk45g,Must an undergraduate degree in Computer Science require the mastering of pointers?,"It seems that I poked the /r/compsci wasp nest with [these comments](http://www.reddit.com/r/compsci/comments/sj0qs/operating_systems_class_c_or_java/c4eg46h):

> I wouldn't go insofar as to say he/she needs to learn how to use \[*pointers*\]. He/she
> might be better off becoming an expert in Java, or C# (gross), or PHP (get
> out). Or, he/she might not want to be a software engineer at all. It all 
> depends on what his/her goals are regarding Computer Science.
>
> My opinion? Learn C++. Then master C and C++ at the same time by learning the
> innards of both worlds. Then learn more about agnostic object-oriented
> design, and then... go from there in whatever direction you want.

and

> I run into far more people who abuse pointers more than they use them. I am a
> tutor for a Data Structures class that introduces pointers as the primary
> tool for implementing simple structures in C++. Far too many people allow
> memory leaks to slide so long as it compiles and works.
>
> I tell them I won't help them unless they're willing to eliminate those
> memory leaks.


I would like to address why there is some disagreement with my beliefs and practices. I do not believe a Computer Science degree requires the knowledge of pointers, which (to my knowledge) are tools only exposed to the developer in the C and C++ programming languages.


If I am to reassess my beliefs as an open-minded scientist, it is not helpful to downvote me without comment.


**UPDATE**

I have a lot of comments to think about, and I appreciate them all (some of you took an insulting approach, but I instigated it with my own bigotry of high-level programming languages). I will be replying to comments in the upcoming weeks as I give myself enough time to think of either a rebuttal, or of an agreement.",2012-04-20 18:53:26
awvkjt,A Friendly Guide to Big O,N/A,2019-03-03 16:30:40
5stfix,I'm learning C++. Is this language dying?,"I hear about quantum coding, JavaScript being used more and other things.",2017-02-08 15:49:35
5o9slj,Computer science isn't a science and it isn't about computers,N/A,2017-01-16 08:40:24
3g78ev,‘Review’ of doing a Compsci PhD compared to likely alternatives - mostly positive,N/A,2015-08-08 02:04:45
11go9c,Let’s Draw a Graph [xpost from r/dataisbeautiful],N/A,2012-10-14 15:29:42
i8yqi,"Hi, I'm considering possibly majoring in Computer Science. Can anyone give me an idea of","I know very little about computer science, but I have some interest in it. I think it's important because so much of my life is spent interacting with computers and I don't really know anything about how they work, although I have some (minimal) experience with programming when I was a lot younger, which I enjoyed, and I think it's a very useful way of thinking. 

 I'm going to college soon and my ideal plan, at least at this moment, is double-majoring in history and computerscience (or, more generally, I want to try and major in both a liberal arts and science field, and I'm considering compsci).

Can someone tell me what I can expect to learn about as an undergraduate and what it basically entails? I know I am very ignorant. I've read my college's Computer Science web site a bit and it didn't give me much of a student perspective, so that is why I am asking here. Or if you have a link that gives an overview, that would be helpful.",2011-06-25 16:15:12
cfoa2d,Internet is a strongly connected graph and we can find it in linear time using Kosaraju's algorithm,N/A,2019-07-20 17:19:45
8apocw,"If you google “big-o complexity chart” you'll find a wide-spread picture that claims that O(n) is “good” and O(n log n) is “bad”. But log 1,000,000,000 ≈ 30. That sounds pretty good to me.",N/A,2018-04-08 12:38:03
ji855,I am a high school student that will take an AP computer science class next year. I want to ask what I will be learning. ,"I have taken a web developing class before, so I'm not new to coding. I just want to know what the basics are for compsci",2011-08-14 04:26:08
src00,Computer Science Classes I Would Like To See Offered,N/A,2012-04-25 05:26:59
6wee3,"REST, I just don't get it",N/A,2008-08-15 02:03:29
1ugf5l,"A Coder, a Programmer, a Hacker, a Developer, and a Computer Scientist walk into a Venn Diagram",N/A,2014-01-05 12:00:29
57mq0o,Why were CS books more popular in brick and mortar bookstores in the 80s than they are now?,N/A,2016-10-15 16:11:29
4uj70w,"What ""Full Stack"" really means to the job market",N/A,2016-07-25 15:36:00
1cb5vc,Why the internet is shaped the way it is,N/A,2013-04-14 04:15:03
w5l2k,P vs. NP,"So I think that I have come up with a problem that shows that P = NP, I'm just not sure how to show it. The way that I understand it, if someone can solve a NP-complete problem in polynomial time, then NP will have to be a subset of P. What would be the steps required to bring this to the computer science society? Would I have to write the solution in polynomial time, or could I just describe it?

EDIT: So guess what? I didn't find a solution. You guys have really helped me understand the question, though. You're awesome.",2012-07-06 23:49:58
qz8ep,How to Multiply Using Addition and Logs (A smart CS guy did this initially for mechanical cash registers back in the day),N/A,2012-03-16 11:01:58
9k4pr,Are Impossibility Proofs Possible?,N/A,2009-09-13 17:17:31
e97yi,Where to find Mac OSX Snow Leopard OS concepts?,I really want to know how the MAC operating System really works.  Things like Process management and the File system would be good.  I cant seem to find anything? Is it hidden from us on purpose? ,2010-11-20 20:23:23
bpcsj,"What I hate about your programming language...
",N/A,2010-04-11 11:22:10
7oux8,Toward a categorial theory of computation.,N/A,2009-01-11 02:14:49
5cvmsb,"I just woke up from a dream where I taught/created a CompSci question, but I've never taken a CompSci course in my life. Is the following a legitimate CompSci question?","Disclaimer/Context: I have never taken a Computer Science course, nor a discrete math course, but I have done programming and I have tried several of the challenges offered by ProjectEuler.net - I also understand that ""does P=NP?"" pretty much means ""Is there a better algorithm for this computation?""

I was dreaming that I was teaching a Computer Science class, and I would write 100/97 on the board and tell the students to write out the most efficient code for dividing these two numbers.  Then 100/96, 100/95, then weird ones like 77/55.  Then I told the students to come up with at least 3 division algorithms, and then plot which algorithm was the best/most efficient one for 1000/x (x < 1000).  And then asked is it possible to ""predetermine"" which algorithm to use given x.

Then I woke up, astonished by my sleeping brain.

**Question 1**: Is it true that some algorithms are better than others for certain numbers?

**Question 2**: Is this a legitimate/interesting Computer Science question?

**Question 3**: IS IT possible to predetermine which algorithm to use given certain numbers?

I didn't know where to post this question.  I was going to post it to /r/CasualMath, but they're not THAT casual.  There is no /r/CasualCompSci.  Do you know of a better place for me to be asking this?

(Why was I dreaming of computer science?  In my dream I was playing inside of a hyper realistic 3D engine running on an Nintendo 8bit system. (impossible I know)  This girl wanted to compete with the guy who made it because of class prestige and I was like ""naw thats boring, its just like finding faster ways to divide"" and she was all huh? and I was all...)

Thanks Reddit",2016-11-14 12:12:29
djnk2o,Blockchain offers applications well beyond Bitcoin but faces its own limitations,N/A,2019-10-18 13:31:54
8evvws,What do you believe is the next big thing in Computer Science / Business Tech?,"My guess would be Industry 4.0, but would love to hear if anyone has any different opinions.",2018-04-25 18:30:18
7lbt12,How I went from programming with a feature phone (J2ME) to working for an MIT Startup,N/A,2017-12-21 19:33:14
6mk0cg,What programming languages do you recommend are good to have under my belt?,"(Apologies, this question has probably been asked multiple times before.)
I already know java. 
Also, does anyone know of any cool programming assignments or websites with lists of cool projects? I want to keep practicing through until the next academic year begins. ",2017-07-11 04:43:02
3877sb,Worth changing from IT 2nd year to Comp-Sci?,"Currently 3 semesters in to a 4 year IT course. Simply went into it straight after highschool because I was offered a (near) full-tuition scholarship (with guaranteed work placement). Since being enrolled I've developed a huge interest and passion for programming and am convinced I can do better than an IT course at a low tier University in small-town Australia. It pains me seeing how dead the IT department is here - there's literally 4 people who turn up to some of my classes (its a Uni with a big focus on distance education, but still).

To me this seems like a no-brainer, but like with any major life decision I'm trying to make absolutely certain I'm making the right choice, and what better way to do that then to receive validation from strangers on reddit. ",2015-06-02 10:09:45
31qkw5,Computer Science Programs,"Hi.  I hope this is the correct thread to get some feedback from actual engineers.  How does a senior in High School select a good computer science program?  Or, how would she compare 2 programs for final selection?

Any general information on selection criteria would be great.

The actual decision is UTulsa (with Loan) or UTDallas (without Loan).",2015-04-07 11:45:53
2rwizm,"ROBOTICS! upcoming Spare Parts movie, other movies/ documentaries, google, lego mindstorms, Mars rovers, Darpa road race, UAVs/ drones, etc",N/A,2015-01-09 22:13:05
1xjx9y,Should I take the AP Computer Science test?,"I haven't taken the course, but I have a fair knowledge of Java and I can comprehend it pretty well. Do you think I should take the test? I bought the Barron's study book and have been reviewing it, but I don't know if it's worth my time and money. Please let me know what your past experiences have been with AP Comp Sci. Thanks",2014-02-10 21:35:22
1tfmbz,Where can I find a random number generator that doesn't follow a normal distribution? Or am I asking a silly question?,"For example, if I am calling Java's random.nextDouble() it will give me a value between 0 and 1, but these values will fall in the pattern of a [normal distribution](http://en.wikipedia.org/wiki/Normal_distribution) around the mean 0.5.

Is there a random number generator that has an equal, non-normal distribution? Is one implemented in Java or can I make one?

Best regards",2013-12-22 01:56:52
1mk23n,Good HTML/CSS/JavaScript tutorial for someone who already in-depth Computer Science knowledge?,"So, I've got a degree in CS, with a lot of emphasis in Theory. I know several languages, including Haskell and Prolog and Scheme. I've taken an upper-level languages class, discussing closures, continuations etc., and an advanced algorithms class talking about network flow and randomized-incremental algorithms. I'm in the middle of writing a paper about reversal-bounded deterministic counter automata.

I know diddly about HTML and the accompanying technologies. I can write ""Hello world"" and maybe make a link and an image, but that's about it.

The problem is, most HTML tutorials are written as an ""introduction to coding"" or ""look, it's not that hard."" While nice, they aren't written in the format that I've learned to learn from in the last four years.

I'm wondering if someone can recommend a good HTML/CSS/JavaScript tutorial which is meant for someone with my level of knowledge. I'm thinking something that isn't afraid to use CS terminology to describe concepts like trees and hierarchies and syntax, and something that is actually explaining these languages, instead of just using examples.

(Don't get me wrong, examples are great, but I want something that will give me with enough of an understanding to deviate from the examples).

Does such a thing exist, or is the intersection of ""web designer"" and ""computer scientist"" too small for such a thing to be?

Either way, I'm very curious to see what this particular community has to say. Thanks in advance!",2013-09-17 06:06:41
1kz9ik,Where can I learn schematic design?,"I want to be able to design consumer electronics, but I haven't the foggiest which components make what happen beyond the basic swtch. So, where can I go to learn this?",2013-08-24 01:20:03
fxdrh,Basic questions about CS...,"What/where is the Cliff Notes version of theoretical CS?

What sort of research/experimentation is done in CS?

What are some basic theories or laws in the field of CS? (as in Newton's Laws of Physics, Einstein's Theory of Relativity, the law of gravity, etc.) 

EDIT: Thanks, folks. I'm a CS major, due to the fact that I like math, and I like programming, and I like computers, and I like software. I haven't hit any core CS classes yet, so I was curious about what the actual idea of computers as a science consisted of. My questions have been answered. Thank you very much.
Besides the Wikipedia article that told me about the unsolved problems in CS, how would a comp scientist make a major breakthrough in the field?",2011-03-04 17:22:30
fldxd,Noam Chomsky v. IBM’s Watson Computer,N/A,2011-02-14 21:41:07
3houhu,Sharp Regrets: C#'s Top 10 Worst Features according to Eric Lippert,N/A,2015-08-20 06:50:50
3holey,"[META] 83% of Computer Scientists say that P≠NP. Snoo, get out of here with your edgy, contrarian opinions about algorithmic complexity theory.","I'd like to respectfully propose changing the /r/compsci banner logo, in which Snoo cheerfully proclaims ""P=NP"". Either to read ""P≠NP"", or something else entirely. 

I don't have any substantive criticisms of P=NP, and I'd rather not debate the P versus NP question in this thread (even though I find it really interesting). I just think a mascot should reflect its community. If it's going to take a stance on an important issue, it should be a popular stance. It shouldn't take weird stances on issues that are important to its community.

""P=NP"" isn't the prevailing attitude of Computer Scientists. Not by a long shot! Here's where Computer Scientists seem to stand on the issue:

****
#1. Only 9% of Computer Scientists believe P=NP.

It also appears that P≠NP answers increased about 36% between 2002 and 2013. There's no evidence P=NP is gaining traction, say in the face of new evidence.

From Wikipedia: [P versus NP problem](https://en.wikipedia.org/wiki/P_versus_NP_problem#cite_note-poll2-7)
>###Context
> [...] Arguably the biggest open question in theoretical computer science concerns the relationship between those two classes:
>
> *Is P equal to NP?*
>
>In a 2002 poll of 100 researchers,

> * 61 believed the answer to be no
> * 9 believed the answer is yes
> * 22 were unsure
> * 8 believed the question may be independent of the currently accepted axioms and therefore is impossible to prove or disprove

>In 2012, 10 years later, the same poll was repeated. The number of researchers who answered was 151: 

>* 126 (83%) believed the answer to be no,
> * 12 (9%) believed the answer is yes, 
> * 5 (3%) believed the question may be independent of the currently accepted axioms and therefore is impossible to prove or disprove, 
> * 8 (5%) said either don't know or don't care or don't want the answer to be yes nor the problem to be resolved.



Note that the sample size of this survey (151) is somewhat small, so the results may not represent CS as a whole. There's a lot of prominent all-stars among the 151 who responded, though, including John Conway, Richard Karp, Donald Knuth, Clyde Kruskal, Steven Skiena, Peter Shor, etc. ([Source](http://www.cs.umd.edu/~gasarch/papers/poll.pdf))

#2. P=NP is sometimes lambasted as absurd

Here's MIT professor Scott Aaronson, famous for his work on quantum computing:

>""If P=NP, then the world would be a profoundly different place than we usually assume it to be. There would be no special value in “creative leaps,” no fundamental gap between solving a problem and recognizing the solution once it’s found. Everyone who could appreciate a symphony would be Mozart; everyone who could follow a step-by-step argument would be Gauss; everyone who could recognize a good investment strategy would be Warren Buffett. It’s possible to put the point in Darwinian terms: if this is the sort of universe we inhabited, why wouldn’t we already have evolved to take advantage of it? (Indeed, this is an argument not only for P!=NP, but for NP-complete problems not being efficiently solvable in the physical world.)"" 

>-Scott Aaronson, '[Reasons to Believe](http://www.scottaaronson.com/blog/?p=122)'

(If you like his colorful style, by the way, and these questions are interesting to you, check out his terrific book [Quantum Computing Since Democritus](http://www.scottaaronson.com/democritus/).)

#3. Even defenses of P=NP question whether its proof will ever surface

Donald Knuth, interestingly, was among the lonely 9% of survey respondents who answered in the affirmative... kinda?

>Donald Knuth: (Retired from Stanford) It will be solved by either 2048 or 4096. I am
currently somewhat pessimistic. The outcome will be the truly worst case scenario: namely
that someone will prove “P=NP because there are only finitely many obstructions to the
opposite hypothesis”; hence there will exists a polynomial time solution to SAT but we will
never know its complexity!

I interpret Professor Knuth's statement to mean the number of researchers who believe that P=NP will be affirmed by constructive proof is even lower than 9%.

****

In conclusion, I admire this Snoo's refreshing optimism, despite a huge barrage of indications to the contrary, about the equivalence of P and NP complexity classes. I just find his evangelism for P=NP a bit zealous, there at the top of every page, and probably quite misleading to people. It's not quite E≠mc^2, but I think it's analogous to reading /r/AskScience and finding a bunch of drawings of extraterrestrials in the header.",2015-08-20 05:14:06
v3yh3,What would you put in a Computer Science Curriculum?,N/A,2012-06-15 20:12:45
hyh64,Any good recommendations for an intro to SDP?,"This looks like an interesting technique, and I'd like to know more about it.

EDIT: Wow, I'm a little embarrassed. Semi-definite programming. Sorry about that.",2011-06-13 13:12:24
7dcjji,Best 21 MS in Computer Science Programs with Zero Tuition Fees and/or Full Scholarships,N/A,2017-11-16 13:58:54
3awrfw,"[Showerthought] I used to wonder why people hate using some languages, and would be almost evangelical with their favorites. Now I don't.","I've been programming since my teens, QBASIC, then java, perl, a bit of c++,  c# and lately I've been using lua... lua is, so far, my least favorite language to use, and my hate for it grows the more I interact with it, its conventions. I even find its documentations  absolutely obnoxious. Seriously, i've never hated a language before, but something about the language and the way it works is painful. 

Before, i thought when people would argue about differing styles we come across in the various languages, I thought that it was strange to dislike a language for its various features, or rather, they were joking and didn't actually care about it. 

Sorry for the rant.",2015-06-24 03:07:57
1l2e0q,"I am a CS undegrad. I want to publish a paper, what should I do?",Any tips friends?,2013-08-25 17:59:07
6rckgg,Is the CS degree on its way out for software engineers?,N/A,2017-08-03 14:16:05
2drgzt,Why is there little stability in programming languages and APIs but there is a lot of stability in natural language grammar and vocabulary?,"And if such stability did exist, maybe computer science education could focus on teaching students stable APIs much as natural language classes focus on teaching students vocabulary.",2014-08-17 00:33:31
sl4fr,What's the deal with analog computers?,"There are two fascinating facts that I've gleaned about analog(ue) computers, but I have failed to find out more details for either. These are:

1) They are highly prone to errors. The kind of error correction that is possible for digital computers cannot be applied to analog ones. This renders them useless for anything too complex.

2) They kick Turing machine arse. The Halting problem is no problem, an analog computer will solve it for you.

Fascinating fact (2) gives a good motivation to solve fact (1), but it seems like no-one's bothering. If we are pouring millions into solving the noise problems of quantum computers, why not analog?

Also, why can't we use digital to simulate analog? The precision of a number in a digital computer increases exponentially with the number of bits used. So isn't that an exponential suppression of the errors due to discretization? Sounds good enough to me, so why isn't it?",2012-04-21 10:23:57
nd5pg,How to Sample a Random Vector,"I have a vector of independent random variables
X = [x1 x2 ... xn].

I want to create a sample of realizations of this random vector.
I want the sample to be as small but at the same time as accurate as possible.
That is, if I would extract the prob. distributions of the variables from looking at this sample, they would match closely the original prob distributions. Of course the most accurate sample you can have is one that contains all possible realizations.

But how do I get the smallest and most accurate possible sample? Any ideas/pointers?

Edit: The question is as clear as can be. Don't bother criticizing my knowledge etc. If you think it doesn't make any sense, you might as well ignore the post. It's OK. You are not dealing with a kid. Thanks.",2011-12-15 01:29:12
ky8rr,Virtual monkeys bash out Shakespeare play,N/A,2011-10-02 09:22:51
eac6o,Forensics - A question,"I need to discover if  user copied some data to a usb drive. The user access is now blocked from the network and the computer has not been touched by anyone. I need a technique to prove (or disprove) that the data was copied. Is there a way to recover this info from memory or page file? 

EDIT: It is a bog standard clone pc running windows xp sp3 on a server 2003 domain. 
EDIT: Cheers to those who replied. There will be a discussion about this tomorrow and if we need legal evidence then a professional will be the way to go.",2010-11-23 04:22:41
7o56k,How would one best securely erase their server and connected backups? How long would it take?,N/A,2009-01-08 00:26:02
ovgys,Can we make bit torrent better?,"I've been mulling this over in my head for a couple of days now and after reading the wikipedia article on bit torrent protocol, I think I know how it works well enough to propose this idea.

I know that bit torrent works by downloading many small chunks of the file (hashes?) from peers and seeds based on an initial tracker file which essentially tells the client where on to start looking for the file pieces. The problem with this is the leecher is only limited to the number of peers and seeds for that particular file. What if the hashes were small enough that they could be modular enough to be used by multiple files? For example, lets say Ubuntu 11.10 (10000 chunks) and a flac copy of the slip by nine inch nails (7000 chunks) shares 700 chunks. The client can downloading either of these files now has access to more peers and more seeds.

I understand that this concept has a number of unknowns/issues, like how small the chunk size has to be to lose its uniqueness so it can be incorporated into another file, also finding these chunks might be a problem as well. I am not sure if this would consume more bandwidth or processing power. I also did not see anything in my searches like this.

Anyway, please give me some feedback, like more specifics about how bit torrent actually works (because I know my understanding is crude at best). My major is biomed engr with minors in electrical and math, so I am not super familiar with computer science. If this is a stupid idea, please don't be too mean to me.  ",2012-01-25 02:53:29
1l1rde,How much programming there is in CS?,"I have only taken few classes of CS in college and they have been basically programming classes. But when I surf the web, I see warnings that there won't be much actual programming in CS curriculum and that most of the actual programming skills will be learnt in your freetime. That is of course okay for me, but I was just wondering that is that really true? How much actual programming there is in CS curriculum in college?",2013-08-25 08:32:34
28031r,New to C++,"Hi I have question for you guys. How fucked would I be if I took a C++ programming class as a beginner in programming? College level. I'm a motivated person, and I love challenges, I'm not too good at math. But I just want your opinions, thanks. ",2014-06-12 22:15:49
brrzad,"Universal Programming Language Syntax Proposal - ""Moth"" Statements","In attempting\* to devise a modern replacement for Lisp, I've come across a generic statement syntax that could serve as the building block for a wide variety of programming and data languages: ""moth statements"". It's comparable to XML in that it's a generic syntax that doesn't define an actual language nor a usage. Both Lisp and XML are based on a fractal-like nesting of a simple base syntactical unit or structure. So is moth.

[Typical structure of a \\""full\\"" moth-statement](https://preview.redd.it/w4tu9e2wwsz21.png?width=353&format=png&auto=webp&s=096ac64eccbb405327757437d1e21d5df4de5be4)

A moth statement is just a data structure, roughly comparable to s-expressions in Lisp. An interpreter or compiler can do anything it wants with the moth data structure(s).

I envision a kit for making actual language interpreters and compilers. Picking and choosing parts from the kit would make it easy to roll custom or experimental languages in any paradigm.

**The biggest problem with Lisp syntax is that forest-level constructs resemble tree-level constructs,** creating confusion for too many. Over the years our typical production languages made a distinction, and this is the key to moth statements. Plus, moth syntax resembles languages we know and love to reduce learning curves. The colon ("":"") may be the weirdest part, but serves as a visual guidepost.

In the name of simplicity, there is no infix notation such as ""x+y"". ""Object path"" notation can be used instead, such as ""x.add(y)"" or ""x.add.y"" or ""add(x, y)"", per your dialect choice.

The samples below are only rough suggestions. Your dialect can define its own keywords and block structures, dynamically and/or statically.

    a(x) :b{x} :c{x} = d(x) :e{x} :f{x}; // Example 1
    a = b();   // Example 2, typical usage
    a(c, d, e=7) :b{f; g.z; h=7} :c; // Example 3 
    a(b){d}{e}{f}; // Example 4 
    a(b){d}{e}{f}=g{}{}{}{}; // Example 5
    ""foo""();7{}=3;x{}:7:2:""bar"";  // Example 6 - Odd but valid statements...
    // ...if your dialect permits such.
    
    // Example 7 - IF (compact spacing used for illustration only)
    if(a.equals(b)) {...}  
    : elseif (b.lessThan(c)) {...}
    : elseif (d.contains(""foo"")) {...}
    : else {write(""no match"")};
    
    func.myFunction(a:string, b:int, c:date):bool {  // Example 8
       var.x:bool = false;  // declare and initialize
       case(b)  
       : 34 {write(""b is 34"")}
       : 78 {write(""b is 78""); x=moreStuff()}
       : otherwise {write(""Ain't none of them"")};  // note semicolon
       return(x)
    };
    // Example 9 - JSON-esque
    Table.Employees(first, last, middle, salary:decimal, hiredOn:date)
      {""Smith""; ""Lisa""; ""R.""; 120000; ""12/31/2000""}
      {""Rogers""; ""Buck""; ""J.""; 95000; ""7/19/1930""};
    
    SELECT (empName, salary, deptName)  // Example 10 - SQL-esque
    :FROM {employees:e.JOIN(depts:d){e.deptRef.equals(d.deptID)}}
    :WHERE {salary.greaterThan(100000)}
    :ORDERBY {salary:descending; deptName; empName}; 

In cases where numeric decimals may get confused with object paths, I suggest a ""value"" function for clarity: ""value(3.5).round();""

\* I don't claim Moth is a necessarily a replacement for Lisp, only that it could better bridge the gap or find a happy medium between favorite features of Lisp and ""typical"" languages such as JavaScript and C#. 

*Addendum*: a later variation [does away with colons](https://www.reddit.com/r/ProgrammingLanguages/comments/ky22dx/simplified_take_on_moth_colonfree/).",2019-05-22 18:01:32
33lqgz,The Coolest Problem You've Never Heard Of,N/A,2015-04-23 15:30:24
203ray,Please help me find a job shadow.,"I'm a senior in high school looking to job shadow a software engineer for my career exploration project. Something similar to software engineering would also be fine. My location is in Stockton, CA so I'd prefer to job shadow someone who works about ~2 hours away at max. If you're willing or contemplating, please P.M. me for more details. 

If this isn't the correct subreddit to post in, can someone redirect me to a place where I'm more likely to get a response?",2014-03-11 02:15:17
7d264,Creepy Compressed Sensing cartoon,N/A,2008-11-13 05:03:15
6oi9g,C# 3.0 Implicit Type Declarations: To var or not to var?,N/A,2008-06-23 02:32:01
3sr9kr,Memory mapping-related problem straight out of my operating systems text book that I need help with!,"Hey guys, I came across a problem that I can't quite wrap my head around. If anyone could help me solve this, that'd be great :)

http://imgur.com/GWQYcsY

Assumption - total memory is 400k and monitor of 100k and all jobs arrive at the same time",2015-11-14 06:56:47
1j7b7c,Proving Big O with induction help...,"I'm doing a second year paper on algorithms as part of my CS degree. While I did pretty okay with my other CS papers, my maths has never been too strong and this paper is so incredibly mathsy. I just can't wrap my head around most of it.

They want me to prove that n^3 = O(2^n). 

I understand that the definition should be n^3 = O(2^n) since it's possible to find c and n0 such that n^3 <= c.2^n for all n >= n0. 

It seems the only value of n0 which works is 1 (1^3 < 2^1), so I guess I have to do something with c? But what? Do I just set it to some arbitrary number? 

Maybe I'm completing misunderstanding induction... Can anyone explain to me what I'm not getting? ",2013-07-28 05:19:08
26ayyk,Does computer science cover all branches of IT?,"I am a senior in HS and just finished up my Cisco networking course and I am about to take my CCNA. I am planning on going to college for Computer Science because it looks different and interesting. I am looking to explore other ""branches"" of IT before I choose one to do out of college. Does comp sci cover lots of different areas of IT?

Edit: Thank you for all the wonderful responses! I will research a lot of the different majors!
",2014-05-23 15:31:08
fb979b,Implementation of sqrt(x) using JavaScript - 100 Days of Leetcode Challenge - Day 5 Challenge,N/A,2020-02-29 07:34:54
eddvfk,We built an AI that can classify political bias,"We here at The Bipartisan Press built an AI that can classify political bias when given some text.

We utilized Pytorch and HuggingFace's transformers library to finetune some of the newest SOTA models like BERT, RoBERTa, AlBERT, and more in a regression problem to do this.

You can read about some of our results [https://www.thebipartisanpress.com/politics/calculating-political-bias-and-fighting-partisanship-with-ai/](https://www.thebipartisanpress.com/politics/calculating-political-bias-and-fighting-partisanship-with-ai/), and we also published a basic tool that lets you test out our smallest model. 

What suggestions or questions do you guys have to improve?",2019-12-20 18:22:02
cbjld5,Fighting Climate Change with Blockchain Technology,N/A,2019-07-10 17:23:50
a56nfn,"Major in computer science, minor in theoretical philosophy","Computer science freshman here, but I want to minor in theoretical philosophy. Is this a valid combination? I will still take some courses from mathematics as part of our CS curriculum, but philosophy is what really ticks me off.

",2018-12-11 13:08:39
a17odl,How did computers get so complex,"Can someone who has a lot of industry experience please tell me how smartphones got this complex? How is my iPhone able to do so many tasks and do recursion, multitasking, and the like. It has been the cause of my OCD and anxiety lately because I don’t understand how computers can function so easily and do such complex things that even humans cannot. I know it has to do with electrical engineering and the like, but I just can’t begin to understand how we can assemble these machines from elements and code them. I hope someone can go super deep into this rather than just tell me it’s all 1s and 0s. I mean how is that physically possible that they can communicate with the world and just be assembled in a Chinese factory. Anyone else have this anxiety? It just seems like black magic. How is it that humans go through so much pain while these computers just do operations and nothing else. I guess it scares me because it somehow just “works” and we came up with this on our own. Somehow we can build something which can compute and do recursion while I’m out here just having panic attacks. I mean how does one even install software on a piece of metal. Does anyone in the world know all of the circuit schematic to the iPhone or Android?",2018-11-28 16:22:47
6qi9b4,"Does computational theory tell us that modern computers cannot ""understand"" natural languages?","From my understanding, the expressive power of natural languages is beyond the capability of a Turing machine, and modern computers are at best equivalent to Turing machines. Does that mean that modern computers cannot theoretically model natural languages? And consequently, doesn't that entails that strong AI can never be achieved because machines cannot understand the languages we use?",2017-07-30 16:28:42
2wpwp3,Why exactly is video so difficult to compress?,N/A,2015-02-22 02:04:22
2gn96s,Help with Lambda Calculus,"I keep hearing that lambda calculus is extremely simple, but for some reason I just can't grasp it. Any help is appreciated. ",2014-09-17 09:29:11
15vswr,The om programming language: based on a minimalist philosophy.,N/A,2013-01-03 10:45:38
x9gtu,Would it be possible to create a programming language that can be translated into any other programming language?,"How much research is there about which programming languages can be translated to which other programming languages?

It seems like the more restrictive or higher-level the programming language is, the harder it is to translate to.

Has there been any attempt to create a mother programming language that can easily be translated into any other existing programming language?  Would it be possible or worthwhile?",2012-07-27 19:30:34
fdkk8,I just noticed the thumbnail for /r/compsci makes the claim that P=NP,"And I think that's awesome. All through my education I would hear professors say things like ""No one knows for sure whether NP lies strictly outside of P, but most everyone thinks that it probably is"". Because everyone thinks that it's probably true, I'm sure that more effort goes into trying to find a proof that P != NP than to prove that they are equivalent. 

I think it would be a much more interesting result if it turned out that P=NP. So what do you guys think? Any one else secretly (or not so secretly) hope that we've all been wrong this whole time?",2011-02-02 04:11:08
9lhc6,Taming Your Sequence’s Side-Effects Through IEnumerable.Let,N/A,2009-09-17 13:37:47
8so47,Us and the value of subjective objects (Smith & Ungar),N/A,2009-06-15 15:34:39
8g011,Time travel in global high score lists to make games more fun.,N/A,2009-04-28 03:10:55
4xk1sl,Going into Ap Comp Sci (12th grader) and have no prior experience in comp sci... If you have any information that could help someone understand the basics or just helpful info please let me know (I think we are focusing on java),"As it is my last year in highschool I decided to skip regular comp sci and go ap and my math grades were high enough for me to skip the regular class. Also, if you can link some informational videos that would be helpful",2016-08-13 17:29:41
2syofy,[X-post from iAMA] what's it like to be a black computer scientist at MIT?,N/A,2015-01-19 19:08:23
13o8fw,What a semi mdp is ?,"Hi,

I still can't get the definition of a semi markov decision process and how exactly is different from an mdp ? Any clue ? Thanks in advance.",2012-11-23 17:04:08
n7yeu,Simple Automated Phone Call Processing?,"I am on a team of engineering students working on a design competition.
   
For part of our idea, we want to develop a way for any phone to send data to a central server. The data would have to be encoded into sound and processed. The UI would be like a voicemail system with audible options and input is pressing 0-9,#, and *.
   
Right now we just want to develop a proof of concept. 
Is there a simple (a preferably free) setup to have a computer answer phone calls, process the data, and do simple voicemail-like UI.

We are not computer scientists but we do have general programming and computer skills. 

Is there free software that will do simple calling center menu options which can send data to a bit of code",2011-12-11 00:46:00
lebvex,NetworkX - a Graphical Tool for Designing and Training Deep Neural Networks,N/A,2021-02-07 01:16:55
k31gwm,Are we really like 10th century blacksmiths?,"Hamha! (means Hello!)

That’s a weird way to start a message on Reddit, isn’t it? It’s an obscure reference to an old GBA game I once played and loved. Because starting a reddit post always gives me the “how do start this thing in a normal way...” kind of feeling, I decided to go the other direction for once.


Now on to asking the real question here. I was browsing some old posts from a while ago and someone made the following comment:

> Computer scientists are like 10th century blacksmiths: we know what works, but we don't know why, and this prevents us from radically improving our craft.

Since then, some time has passed and we’ve gotten a bit smarter. But the question remains, how far do you think we really are currently in the advancement of our field? Are we truly the gods some people make us out to be or indeed the equavalent to scruffy 10th century blacksmiths who can hit a piece of iron with a hammer and call it science?",2020-11-29 02:45:32
9wnbe8,Im lost.,"Hello guys. 
My name is Digvijay Redekar, CS student from India. I was very fond of programming. I remember I started c programming alot earlier than my peer, slowly progressing towards c++ and java. I used to love everything about computers and would think that computer science is life. Slowly I fell victim to CSGO and then with time I stopped programming and played counter strike for hours. From being my class's best programming to one of the worst is what I am right now.
I didn't touch programming for 2years, I forgot all syntaxes, though I still remember the logics. I am not confident now and feeling too low. How can I get myself back up and get the same passion I had for CS and programming? 
I really need your help to guide me.

Update: Are Udemy courses good for learning?",2018-11-13 08:33:57
9txahc,I'm doing a complete 180. I hate my current career path. So time to go back to the books.,"I am doing what I should have done in the beginning. Starting a degree program in computer science. I'm stuck at taking classes online due to work. I have looked at quite a few bachelor degree programs. But I decided I'm going to get my associates at a community college level, and then transfer to a university to finish bachelors to save as much money as I can.

&#x200B;

Does this look like a decent program at an associates level that would transfer towards a bachelors degree at a university in the future? I need you guys. Mind you the associates would be online as well. [http://www.sunyulster.edu/academics/credit\_programs/computer\_sci\_online](http://www.sunyulster.edu/academics/credit_programs/computer_sci_online)",2018-11-03 20:13:42
9mwl9n,Plagiarism checker,Is there a way I can upload the code I wrote to check for any plagiarism? It's because my school is strict so I want to make sure my code is safe before I submit it. It's also because sometimes u get help etc and that's why as well. I want to check my code before I turn it in Making sure no sign of plaigirism at all ,2018-10-10 05:05:44
5kbxgb,Barrys Scientific Based Products,N/A,2016-12-26 04:08:35
2shtov,What is Computer Science and what do I need to know before taking it?,"My high school is offering an AP Computer Science class and i'm interested, but I have no idea what i'll be doing in the class itself.",2015-01-15 07:20:30
zlcgz,A case for using decimal floating point numbers instead of binary as a default,N/A,2012-09-09 06:17:09
qi370,Could /r/compsci recommend me some good colleges in the northeastern US for computer science/engineering?,"Tell me your good experiences, your bad experiences, social aspects, and anything else you can think of!",2012-03-05 04:04:26
bsujdh,Complexity of a code,"If I have a code that goes once to every cell of an array and repeat doing it ""the highest value in the array"" times, is the complexity of the code is O(n)?",2019-05-25 13:32:37
29rljf,Think like a computer scientist,N/A,2014-07-03 19:38:15
6axt7g,Why Don't Computer Scientists Learn Math? - Leslie Lamport,N/A,2017-05-13 13:26:17
6daos3,Why Random Numbers are Impossible in Software,N/A,2017-05-25 16:24:08
2xdepd,"Meet the Man Behind 'Solarized,' the Most Important Color Scheme in Computer History",N/A,2015-02-27 17:40:53
h75yu,What will happen when computer intelligence exceeds that of humans?,"It is not clear to me whether computers will have consciousness or not when this occurs, but for the moment let's assume not.

So now you have a machine, and you can feed unstructured data into it (e.g. academic journals) and then say: How can you stop the growth of cancers? Or more trivial yet still complex engineering design questions.

It seems like over a short period of time an explosion of knowledge occurs, and all this time the computer is teaching itself to be more intelligent.

Eventually, man cannot keep up with the advances being made by the computer. We might fear that the computer obtains consciousness, or even some higher level of consciousness that we cannot comprehend.

Do you think this will occur, i.e. is it inevitable? What will be the effect on man and civilization? It is interesting to think about, but I would not want to live through it.",2011-05-09 06:59:44
4dxjpi,[rant] Students who study only for the degree,"Hey,

**tl;dr: I enjoy studying and seem to be almost the only one in my circle of fellow students who does that. Is that a common or uncommon thing in your school and what do you think of that?**

so for the last semesters this has been angering and kind of frustrating me, and I wanna see how seldom this is.
I have some fellow students who are somewhat as far as I am and about to finish their undergrad/Bachelor's and enter the Master's program at our university, which is the RWTH in Germany.

Most of the time I see them when we do assignments or prepare for exams because I am the only one of us who goes to the lectures. Not because I think otherwise I would not do anything but because I actually enjoy attending them. There are only a few exceptional courses for which I did not attend the lectures because they were just held horribly.
Most of my fellow students do not attend them because they are busy with other stuff, jobs etc. One of them however, does not attend them because he just has no interest in the lecture content and solely learns for the exam in order to pass it somehow and get done with it.

We also have a somewhat ""minor"" thing, where we have to pick courses from a different programme (such as Maths, Physics, Philosphy, Economics, etc.). While most students choose economics (reason being they think it will look good on the CV and because they might use that later for their jobs, not out of pure interest) I chose philosophy, because I have a great interest in that area and think there are some very interesting areas which intersect with CS such as artificial intelligence or logics. And because I just did not see the point in choosing something, which just helps me with my professional career (and even that is discussable) but I have absolutely zero interest in.
After some fellows failed economics they also switched to philosophy because as a matter of fact, is is also the easiest one. You only have to write 1-2 essays and attend seminars, which you are free to choose.

Now whenever we talked and talk about choosing those courses, I am the one going all about interesting topics while they only look for those seminars, which have a lecturer who does not care if they attend or not, so that they can just have their signature entered by someone else and don't be there.

And the same goes for elective courses. In our Master's program we can choose 7 courses freely and additional 2 have to be in theoretical computer science.
This is not alot, and especially in the graduate program I thought I should go for those, which lie mostly in my interest and the area I can imagine working in later, or help me if I choose to pursue a PhD.
But yea, again a few of my fellows strictly went for those courses which are just easy to pass but have absolutely no straight line or even have anything to do with each other.

So I often just wonder, am I an exception and is it really just that rare to actually enjoy studying or what is going on? What's the point of just studying all kinds of stuff you have no real interest in? And if you had no interest, would you even remember what you studied? Because if not, then you will just get a degree on your CV and will be (in terms of knowledge) in the same state as before studying, I think.

I would really like to know if any of you had similar experiences or knew such students and what you think of that. Is it bad, should the education system of universities be changed, or whatever.",2016-04-08 17:51:52
i8zku,Can Wikipedia become the fastest supercomputer on earth?,N/A,2011-06-25 16:54:44
2ieks8,I just started r/csMajors,"Hello Everyone! I just started [r/csMajors](http://www.reddit.com/r/csMajors/)

For now my goal is to create a nice database of examples and explanations for people who may be struggling in their classes.

Come on by and start posting. The wiki is in progress and there will be a lot to come! Hopefully within the next week or so there will be a good amount of info saved for easy reference.

I know there are a lot of Computer Science majors on reddit! All i have to do is look around the class room and see half of you on here! 

edit: link",2014-10-06 00:57:29
2d5bkn,Is it possible that the collective IOPS of NSA's dragnet surveillance contribute to the inferior broadband speeds in the United States?,N/A,2014-08-10 14:11:59
4e62nb,P vs NP,"Hi, I would like to learn about P vs NP
At the higheat poosible level available, are there any books and papers that are high level that you can recommend?
Thank you.",2016-04-10 14:59:02
ii0wx,"“More You”, a new initiative by Dell, puts you as a consumer at the center of things.",N/A,2011-07-06 11:25:14
n2btv,David Patterson makes the argument that computer scientists have a moral obligation to work on cancer research.,N/A,2011-12-06 08:54:58
8576h1,"DAE find ""new"" processes virus-like?","This applies to non-website programming.

~10 years ago, my job was chugging along merrily on ""waterfall"".  We banged shi1 out and had one official meeting/syncup a week as a team.  The manager made sure the pieces fit together and connected people to collaborate where appropriate.

~5 years ago in a new team, management wanted to force on ""agile"".  It hired external instructors just on agile, sent us on training.  A few engineers were plucked to be full-time scrum masters and product owners.  Half the week was spent on regularly scheduled meetings (demos, retrospect, backlog grooming, planning, story points card game, etc etc).  The manager was now a ""coach"" behind the scenes and was less technical.

Now, I hear stuff like kanban, ""lean"", etc and it all just seems like viruses infecting software teams, leeching $$ from upper management while sucking productivity and lifeblood from devs.  On a recent poll in Blind about Agile, the results were overwhelmingly ""Made my team a disaster"", followed by ""Made my team perform worse"".

I can understand the virus having its own agenda to feed and multiply but not the management falling for it and even doubling down.  The only carrot seemed to be a ""progress bar"" in the form of the burndown chart but that can and often is bs.  I can imagine websites that change often benefit from this but not other types of projects.

Is it just a matter of higher levels of management wanting as little to do with sw as possible, and are comfortable seeing a dashboard of ""progress"" that they think represents reality?",2018-03-17 22:26:04
2j86fl,Could you make an exact 3D printed copy of a hard drive with the data copied as well?,N/A,2014-10-14 16:10:21
jn7nsp,Falsehoods CS Students (Still) Believe Upon Graduating,N/A,2020-11-03 09:55:18
3f6hfu,Code 'transplant' could revolutionise programming (Wired UK),N/A,2015-07-30 16:52:48
4rwlq6,Amazon software engineer interview,N/A,2016-07-08 19:56:30
2zq0gx,Looking for a computer tutor for Computer Graphics,"Hi, I am a university student and I am looking for a tutor willing to help me with my Computer Graphics tutorial as I was ill for over a month and subsequently missed all my lectures. Please do message me to discuss if you are interested. The tutor will probably have to be at least a master in computing student in order to be able to help me out.",2015-03-20 17:51:35
gf0u7,All books needed to be a CS god?,"I would like to know (and possibly read) all books needed to be a CS god.

Math, algorithms, compilers, etc. Everything is greatly appreciated.

Thanks in advance!",2011-03-30 21:41:06
fevh4,Is working as a research assistant for the summer much more helpful for getting into grad school than industry experience?,"I graduate in a year and I'm thinking of doing a masters right away. To that end, I need to form relationships with enough professors that I can get decent letters of reference from them. 

I have an all-but-guaranteed opportunity to work as a research assistant at my school for the summer. I also have good odds of getting a software developer position at a local startup. I'm at a bit of a loss as to what I should pursue. The research assistant position appeals more to my academic leanings, and it seems like having that experience would be helpful in my application for grad school (and working with my supervisor would make it easier to get a letter of reference). The startup would (probably) pay better, would give industry experience, and I would gain some web development skills from it. I'm leaning towards the startup, but I don't want to shoot myself in the foot when it comes to grad school applications.

tl;dr - Want to go to grad school. Have opportunity to work as research assistant or startup code monkey for summer. Want advice on which one to choose.
",2011-02-04 00:49:03
202jo4,Not enough data scientists? Use AI instead.,N/A,2014-03-10 19:14:24
20bad0,Julia has no dependent types,N/A,2014-03-13 12:41:22
566u4v,Desperately seeking the Nobel Prize in computer science,N/A,2016-10-06 18:19:28
1b2mznb,Will different computers give different results for the same calculation?,"My coworker and I were assigned the task of writing the code for a really-complex sales forecasting model. We decided to independently write the code, resulting in two wildly distinct implementations of the same model. This allowed us to identify bugs by comparing the outputs *(if one implementation says the value of a parameter is 10 and the other says its 15, we know there's a bug somewhere)*.

After pretty much a month of bug-fixing our implementations are finally matching (almost) perfectly, with insignificant differences (largest ones are in the order of 10\^-6). We are using the exact same data (there is no randomness, it's a purely deterministic model), but running our code on different machines. Could this small difference be due to the fact that we are running the code on different machines? If so, what causes it?

EDIT: Thanks for all the responses, we're definitely running both codes on both machines later, we didn't do it yet because it's a large codebase and we got our outputs to match just before I posted this, at the end of the working day, and I'm definitely not doing overtime for this. Either way such a small difference will not be an issue.

However, now I can see why it would be due to a difference in software, in a really simple example: 10 \* (0.1 + 0.2) **≠** 10 \* 0.1 + 10 \* 0.2, if he chose to distribute and I did not we would end up with different results.",2024-02-29 00:50:35
2rvrm4,Need help writing a programming language,"I am going to write a programming language from scratch (grammar to a working language) and I don't know how to get started. Can you suggest books/tutorials/videos that would help? 

Edit: Thanks for all the links. I'm going to go through them before I comment further. ",2015-01-09 18:41:08
hyucx,How to prove solving this equation is NP complete?,"Please anyone.. if you can help me,

To check if exist natural numbers x,y solving the equation ax^2 + by = c (with a,b,c natural numbers) is NP complete.

What is the proof of this? Thank you

**edit**: please explain your downvotes.. im really annoyed at my comments here being downvoted (and im not going to post in this reddit again) because it's stopping me from commenting elsewhere.

**edit2**: Sorry but at first I said integers. I changed it to natural numbers.",2011-06-13 21:20:51
g3v50,How to be a good software designer?,"Hi All,

I have just completed my UG in CompSci and I have realised I lean more towards designing softwares rather than actually the implementation. I would like to know what is the best path to follow to be an accomplished S/w Architect. Any courses i should take? or books to read? Any suggestions are welcome.
Hope to hear lots of comments.

EDIT: Thank you for all your comments. I have come to the realization that what I hope to achieve would require another 5-6 years of intensive learning and programming as a developer. I would continue on that path. Thank you for all your suggestion. This is why REDDIT RULES :) 
",2011-03-14 19:24:15
e302y,One of the slides from my Comp Sci course [PIC],N/A,2010-11-08 17:35:18
e2y5l,Applied Math,N/A,2010-11-08 15:36:40
57jyl9,Twitter Sentiment Analysis - Learn Python for Data Science,N/A,2016-10-15 01:44:44
39mkw5,Differences between computer engineering,So ive been interested in engineering all my life for the ability to create new things and learning about computer science has confused me and was curious of the differences between computer science and computer engineering.,2015-06-12 20:18:03
325lwt,1. Who is the most influential living computer scientist? 2. who is the most influential computer scientist of the 20th century?,"2 questions

1. who would you consider the most influential living computer scientist

in your opinion
2. who would you consider the most influential computer scientist of the 20th century

both answers can obviously overlap",2015-04-10 19:47:02
30506b,I wish to gain experience in databases before I start my internship this summer (hopefully backend dev). Is there an online course you guys recommend?,N/A,2015-03-24 15:14:46
2apky8,"Idea-> ""big data"" crawler using reddit to predict stock market fluctuations among other things (Sociology, world events, journalism etc).","I know this isn't the right sub for this kind of thing but I'm an ex-programmer (BS in CS) so this was the first place I thought of to get feedback.  Let me know of subreddits that are better and I'll Xpost if this idea has any traction.

I recently read an article about how a fake/hijacked AP twitter post caused algorithms in high-frequency trading to glitch and sent the DOW plummeting for a short period of time (back in mid-2013).  They posted something about the white house being bombed. [Here's the post if interested in details](http://www.washingtonpost.com/business/economy/market-quavers-after-fake-ap-tweet-says-obama-was-hurt-in-white-house-explosions/2013/04/23/d96d2dc6-ac4d-11e2-a8b9-2a63d75b5459_story.html).

Data-""diving"" and AI using huge databases of pics/info is getting pretty impressive, so I thought about how a simple thing like a fake post from a news article caused the $$-grubbing HF algorithms to twitch massively seemed a bit alarming....and how young the industry is.  

I'm sure some organizations/researchers are already doing this in a targeted fashion on Reddit specifically, but as an experiment it would be nice to sift through real-time and gather data using keywords to post-predict certain events/data/trends/etc.

Example: 
Crawl through reddit posts collecting references to positivity vs. negativity and quantify/time-stamp values.  
Graph levels and match them to just about anything...stock market, world events, etc.  It's like GIS layers correlating certain events/statistics in the real-time.

This is just a word-salad thought-storm so let me know if this has any merit or application in CS or any other field of research.  ",2014-07-14 22:47:13
25ltrl,So I just failed my final...,"I took my final in Principles of Programming Languages yesterday, I ended up getting a 55% (I got a 63% on the mid term as well). It was mostly concept questions and I thought  I did rather well, only missing a couple questions, but that apparently is not the case. There is a curve on the test with a mean of 75... what ever that means (only taken out of 75 points instead of 100?). So maybe everyone did poorly? Either way, I am going into my third year of a CS major and feel like I have not learned much. Changing my major at this point isn't really an option and neither is just ""trying harder"" as I'm already giving it everything I have and seeking tutoring. I dread what it will be like when/if I get a job in the CS field. I'm terrified I will completely incapable of doing anything asked of me. So if anyone has any ""outside the box"" suggestions they would be welcome.",2014-05-15 06:06:18
13d5ni,"I'm about to start my MSCS degree and I am very interested in Natural Languaje Processing, Any papers, articles that you consider state of the art, the next big thing, or nice ideas for a thesis project","I am very interested in Summarization and Question-Answering, but any other thoughts are welcome",2012-11-17 20:20:21
h17u1,Problems with the standard models of CS,N/A,2011-05-01 04:06:05
7x5sz,Researchers Warn of Possible BitTorrent Meltdown,N/A,2009-02-13 15:14:25
zbn9k9,Is Computer Science Theory application expandable to real world application?,"I'm currently a Junior in CS and am taking the Computer Science Theory (CSCI338) course wherein they are teaching us about DFA's, NFA's, TM's, P, NP, NP-C, etc. and the coding assignments that were given to us seem less usable in real world applications than what I can come up with is there something that I'm not seeing with these projects?

Project 1: State diagram ""game"", have a pseudo character with these states and an action would change your state, like a DFA. (I feel like this could work in game dev but it seems a little primitive)

Project 2: NFA generator, using a hashmap of a hashset we give the program a string of 0's and 1's with concatenations, union, star, and plus, to generate an NFA, then give it test strings to see whether they will be accepted in the NFA generated.

Project 3: Creating 4 algorithms, inexact vertex cover, exact vertex cover, inexact independent set, and exact independent set, and for the algorithms of the inexact the nontrivial recommend solution was taking the set to test and removing one index testing if that set is a vertex cover and if it is then it will add the array index in then move to the next index (independent set is complement of vertex cover so similar logic applies to the inexact IS) which would work in O(n\^2), and for the exact we would generate the powerset of the set given and test each set as a vertex cover and it works in O(n\*2\^n) and isn't largely usable above 20 or 30 nodes (30 nodes takes about \~8 minutes). I asked the professor about what is usable from this project and he said the power set would probably be the only thing that is used for larger scale application.

The class is theoretical computer science so I guess these projects would deal with just proving the proofs in class but I'm wondering if any skills developed in these projects would help in real world application development?",2022-12-03 18:43:21
hl4p4g,How Do We Get a Balanced Binary Tree?,N/A,2020-07-04 15:02:12
9kvjcc,Facebook Says Developers Will Love PyTorch 1.0,N/A,2018-10-02 22:55:07
1wncq5,Hated my first semester of CS—should I continue?,"So, I finished a semester of CS which involved designing games. it was done in java, and I loved it when my programs worked but the process of programming often made me miserable. Now I'm in a data structures and algorithms class second semester, and I'm starting to despise the homework/projects in Python already. It might be because the learning curve is so steep, I don't know CS well enough yet and its too hard. Anyways, does it get better? Or is CS always extremely difficult and I'll have no idea what I'm doing?

I honestly don't really like the process of programming. my favorite part is getting a program working and even that isn't that amazing anymore. I am an applied math major currently.",2014-01-31 15:12:37
uzhn0,Does which University I get a B.S. in Computer Science matter?,"Right now I am planning on attending California State University San Marcos (CSUSM) (I can afford it, and it is close) BUT it is not in the top 100 Computer Science schools...  It might be possible for me to go to University of California San Diego (UCSD) which is ranked fairly high among the top Computer Science schools, BUT it costs 3 times as much and is harder to get into (need a 3.5 GPA and I am only at a 3.3, but its possible to raise it)  Is it a significantly different education?  Will I be at an extreme disadvantage when looking for a job if I go to CSU vs UC?  Any tips / advice would be helpful",2012-06-13 07:26:42
2bj6m6,"Machines Will Outsmart Humans by 2075, Say 90% of Computer Scientists",N/A,2014-07-23 21:03:47
whjcj,JSOL: JavaScript Object Language - functional programming language fully representable in JSON,N/A,2012-07-13 06:07:23
ch4bx,"Ask compsci: what is the required reading for becoming a ""software engineer in test""","I am interested in a job for ""software engineer in test"". Part of the interview process will cover ""testing"". What are some required readings for becoming familiar with software testing?

Currently I am reading wikipedia and articles related to software testing.",2010-06-20 22:07:39
7egr37,Building a Sound Classifier from scratch using Neural Networks,N/A,2017-11-21 09:53:02
o6wf6w,Software development is a creative process; an original masterpiece not a paint by numbers,N/A,2021-06-24 08:06:25
hkijl8,11 Must-Know Machine Learning Algorithms for AI Professionals,N/A,2020-07-03 12:54:17
a21cdq,Become knowable in Java/oop,"I’m a first year uni student and we’re are learning oop in java using blue j software.
I was wondering if anyone had any tips on how to understand all the main things eg constructors, methods, when to use static..
I’m fairly good at coding but my limited understanding of how to build each method causes me unnecessary errors",2018-12-01 08:16:56
8bnaer,"Hello everyone, it would mean a lot if you could take a look at a project that a group of young students have been working on.","**Link:** [**https://spark.adobe.com/page/ihicDrTEbKEsz/**](https://spark.adobe.com/page/ihicDrTEbKEsz/)

Who are we?

*An interdisciplinary group of focused individuals from different backgrounds that aim to improve and change the current state of the educational system with A.I. and mixed reality.*

Why this project?

*We want to provide a better platform and educational environment to improve the quality of teaching in underperforming classrooms. These innovative methods will allow students to be intrigued and better access the tools needed to spark and maintain their intellectual curiosity.*

*Visualization is a powerful tool that can inspire and improve the lives of individuals who lack proper access to proper resources. Take an art museum, for example, you can look at pictures of art on a device, but being in an art museum are two different things.*

Thank you for reading if you liked this please share with people that may also be interested in the project.",2018-04-12 03:44:37
7w7a18,Google Cloud’s Jia Li on AutoML’s First 30 Days,N/A,2018-02-08 19:13:21
7emo6g,Advice on writing my CS Master's thesis. Subject: Predicting and monitoring disease outbreaks using social media.,"Hi there, 

I am on the verge of completing a conversion CS degree (12 month intense course designed to get you close to what an undergraduate might learn in three years), I just need to complete my thesis, but I'm struggling with getting it started and would love some ideas on potential research questions and basically what would be interesting to study, I have a rough idea. 

I want to write a paper based on how big data can be used to predict disease outbreaks but I'm struggling to come up with a research question. At this rate I'm thinking I might just do a review of the literature, but I'd like to do something more narrow and involved. 

I have some questions:

**1.** How would one begin to analyse social media data (Twitter, Facebook etc)? People do this and I haven't the foggiest how they actually get started. I assume they have to write an algorithm that will take as input Twitter or Facebook data (Tweets) and then analyse each Tweet by matching keywords and then output a Boolean result based on answering a given research question (e.g., ""Does at least half of this data set contain the words ""flu"" and ""vaccine"")? 

**2.** How would one actually go about getting large volumes of Tweets that could be fed into an algorithm? 

**3.** In general, any ideas for some interesting research questions on this topic, or something closely related. 

The only research question I have come up with based on the limited amount of reading I have done is: To what extent can AI help accurately predict disease outbreaks by studying social media data? 

Please also note that my technical knowledge of CS is not great, I'm not good at programming (scraping passing grades) so I can't build or design anything, not in any great detail (I don't have to neither according to my department). 

Sorry if this is not the right place to post such a question, but thanks for reading anyway. ",2017-11-22 00:31:52
63wr6n,WIll C die?,"i had this conversation with my friends, and one of them bring this up. So, Will C die soon? what do u think guys? i disagree, it's one of the most language used",2017-04-06 23:39:22
5tyhbx,xkcd: Valentine,N/A,2017-02-14 05:57:30
4avbrh,C++ online,Is there a codecademy like website that would help with c++? ,2016-03-17 21:51:01
3lwof2,"Love math, amatuer at programming","I have my associates in mathematics, and have been self studying a lot of upper level math. With math background out of the way, how might I best transition into programming with at the  highest a decent understanding of how to write a very basic program in java. In all honesty, I cannot see myself getting a good job with just math. What can I do to get better at programming?",2015-09-22 06:37:32
21q1am,Any interest in reviving /r/datastructures?,"/r/datastructures 

I'm guessing there isn't much interest in a separate subreddit dedicated to data structures because the existing one isn't very popular. But hey, a guy can dream, right?",2014-03-30 03:38:49
1uz0rd,Do you think the concept of Object Oriented Programming was an inevitable invention?,"In other words, if the person/people who invented it didn't do it, do you think someone else would eventually?
",2014-01-11 18:23:33
1s471w,Is anyone aware of the method that is better than TitForTat?,"I'm trying to learn how to program one in python (i know, god forbid and all) and apparently there are some better, but I can't seem to find them online anywhere.
",2013-12-04 23:21:58
1o5mr3,Turing Machine - Explanation in layman's terms,N/A,2013-10-10 17:04:52
1hvvhl,Last night I was reading a chapter on P vs NP in a textbook. It had an interesting idea about Verification vs Creation and which is easier.,N/A,2013-07-08 19:56:44
1hpeor,New language helps quantum coders build killer apps,N/A,2013-07-05 18:56:47
1ctc8s,"Thoughts on a secure (public-key), open social network","Here are some random thoughts on a social network. *I know, I know*, there are a shitload of them and it doesn't make sense to create one. It's not for money -- it would be free software/open source --, but as a learning experience and hopefully, more secure social network. With complete privacy.

Many things have to be roughed out, but here is the idea. It would work with public/private keys. The idea is to have really, really thin servers. There could be web-based clients, but they wouldn't get unencrypted data. The data would come directly encrypted to JavaScript. There would also be desktop clients, of course.

To create an account, a public/private key is created. The client then requests to one of the many servers (all of them are connected) that all messages to his public key are directed to him. Its server would communicate to the other servers that they send messages directed to that public key to it.

B... but it's impossible to tell people: ""Hey, wanna friend me? I am B423E1337X299792458leet3141""! The solution would be to create a central (this time, central) server which would be optional for those who want their name (or alias) to be assigned to a certain public key.

To send a message to someone, the user would encrypt with the recipient's public the message; when reached, the client could choose what to do. If they have been ""friended"", it would go in directly; if they hadn't, it would be in the recipient's server queue (waiting for the approval).

The same would work for multiple recipients, the same message would be encrypted serveral times. There would be an option, broadcast, where messages are sent unencrypted. Anyone who has the user as a contact would receive it, regardless of acceptance.

Groups could also be created; a public/key pair would be created for that group, the public one would be added to the central registry (groups section) and members of the group would have the private key to decrypt messages. A group would be, in essence, an alter ego of an user; each member of the group would claim that all messages to the group come to his inbox. Thus, a client could claim as many (or as many as the server limits) public keys: obviously, it could only decrypt those whose private key is known.

Whooops, I forgot, it would use RSA and messages would be signed. The protocol would probably be JSON-based, and it wouldn't matter whether HTTPS or not. Interserver communication could be any port; server-client should (but not necesssarily) be 80.

Why multiple servers? I don't really know if it's best, it can be changed. With multiple servers, you can choose the one nearest to you, the one you trust the most (trust as in reliability, not security: it wouldn't matter, for everything would be RSA-encrypted), or the one which offers some features. Archiving would be optional, the server can choose.

The clients could choose most things. I would personally want clients to use something like ""Circles"": shortcuts for sending an encrypted message to n people. The protocol would be open, so the only limit is the imagination (of the client developers).

Maybe it should be more distributed, more x, more y? Maybe. I don't know, I'm not an expert. Therefore, I would really appreciate your opinion. Thanks a lot!

(By the way, if by some unknown reason it takes off, would anyone be interested in helping with some part? There are plenty: protocol spec, clients for different platforms, servers, registry...)",2013-04-21 19:20:47
11ivlh,The end of dramatic exponential growth in single-processor performance marks the end of the dominance of the single microprocessor in computing.,N/A,2012-10-15 18:45:06
u6pxm,Transferring to a state school with 48 credit hours. Can I complete a Computer Science degree in 2.5 years?,"- Biology major at LAC (48 credit hours)

- Took second semester sophomore year off for mental health(it's been addressed and taken care of with therapy)

- Transferring to state school to save money and change environment

- Wants to change major from Biology to Computer Science. I had a 2.8 gpa, but that's only because of organic chemistry killing my gpa. 

- reason for changing major: Better job prospects. 

Can I complete the Comp Sci major in the next 5 semesters including 2 summer sessions? 

I know i have the motivation and dedication to get solid grades, I just happened to make a few mistakes that had to be fixed.

My goal is receive a Comp Sci degree, pick up a biology minor, and possibly a math minor (already took Calc I,II, and stats). Then get a job after college or enter a masters program for Bioinformatics.",2012-05-27 01:30:26
pu2d1,Save the Project for Failure - The Daily WTF,N/A,2012-02-17 17:06:37
n3kz5,Which CompSci course would you recommend I take next term?,"Hey r/compsci, I'm sort of on the fence as to which course I should take next term.

I'm required to take one of two courses: The first continues on our previous knowledge of Scheme (which we started with this term) and will continue with Scheme and progress in to Python; The other one does the same level of Scheme, but then makes a start in C.

I'm not planning on majoring in CS, and I'm more likely to pursue a degree either in Mathematical Optimization or in Macroeconomic Theory, but next term I'm required to take one of these two courses under my faculty requirements. Which would you recommend I take considering my circumstances? Also which is easier to learn, Python or C?",2011-12-07 05:44:28
k6naz,"Do the major ISP's have software built to identify the most popular ""connection speed test"" apps to perform then, but not at other times?","I am in LA and hear that Verizon notoriously slows your bandwidth over time, but when I ""test"" it, I get the supposed performance.  (Or, at least within 90% of the rated performance.)

But when I test on my own servers, I get much slower speeds, despite the servers being plenty strong enough to deliver rates exceeding 1MB.  (One server, for example, is actually a brand new Mac Mini quad core.  Not a dream server, but plenty fast.)

Any ideas on how to test if ISP's change access speed for ""speed test"" apps?",2011-09-06 18:17:15
et970,Trying to find this book in digital format,"I recently got a Kindle DX (which is phenomenal for reading programming books and math papers, by the way) and I'm looking for a certain book for my CS course next year. It's called Introduction to The Design & Analysis of Algorithms: 2nd Edition. However, I'm coming up short in finding a digital copy to put on my ebooks.

If someone could point me in the right direction that would be great.",2010-12-29 20:21:36
bbufy,"[Ask CompSci] Do you run distributed computing projects? If not, why?",N/A,2010-03-11 01:05:24
9ofke,Ask Compsci: Do you know of any research papers for work similar to Photosynth?,"I have a side project that I want to work on.  I want to take many images of one object be able to recreate a model of the object.  Microsoft's Photosynth is the only thing that comes to mind to kind of describe the type of research I'm looking for.  So, do you know where I can find more info about this type of research?",2009-09-27 01:06:09
8xd1x,"Any sufficiently complicated C or Fortran program contains an ad hoc, informally-specified, bug-ridden, slow implementation of half of Common Lisp.",N/A,2009-07-01 17:34:25
4s3upc,"Does anyone know any notable female figures in computer science that ""took a stand"" against the lack of gender diversity in computer fields?","Hello, I have an upcoming research project for history, and as a programmer, I want to do something around computer science. The topic must have to be about someone or something ""taking a stand"" in some way, such as MLK, Rosa Parks, etc. so I am looking for a female figure involved in computer science that did something pretty remarkable that fits that topic.
EDIT: Can't be fairly recent. Must have happened at least 20 years ago or more. No less.",2016-07-10 03:47:24
cxzzw,Clusters Don't Work,N/A,2010-08-06 05:17:20
7481r,10 amazingly alternative operating systems and what they could mean for the future,N/A,2008-09-29 17:33:50
1fsj8e,"Massive Educational Fraud In India Found: Most ""qualified"" graduates should never have graduated at all.",N/A,2013-06-06 14:41:28
1p69ll,Is there any valid reason for this password restriction on healthcare.gov?,">Your password must contain 8-20 characters. There must be at least 1 upper case letter, 1 lower case letter, and 1 number. It must be different from your last 6 passwords. It can't contain your username or any of these characters = ?<> ( ) ‘ "" / \ &

Does this make any sense at all from a programming or security standpoint to exclude those characters?  It looks to me like they are A) storing the passwords in plaintext and B) not sanitizing inputs.  Is there any other conceivable reasons for barring those symbols?",2013-10-25 04:18:43
47apzl,"Great Programming Grades, Bath Math Grades","Hey guys, just wanted to hear your opinion on a dilemma that I am having with my computer science degree progression. So far, in every math course that I have had, I am getting D's or C's, and am risking not being able to transfer out from community college.

However, within my programming classes, I am getting high A's. Currently, I am in introduction to JavaScript, and I am breezing through the class, and everything just seems to make sense. When in math, it all seems too theoretical and I seem to not be able to understand anything. It's almost like a foreign language to me.

Has anyone else had this situation before, where they have been great with programming, but not in their math coursework? I am looking to become a web developer, but my math grades might be my demise in the computer science major-and I might have to pick a less math intensive Information Technology major as a backup. 

",2016-02-24 04:10:58
71r6l,How Do I Get a B.S. while Working Full Time?,N/A,2008-09-16 15:48:21
74gl0,The tragedy of linked lists [pic],N/A,2008-09-30 19:41:10
v8gkj,"Computing Texas Hold 'em -
A computer scientist goes all in for poker.
",N/A,2012-06-18 18:18:40
4i6kli,How close are we to making such an advanced computer in Minecraft that it can run Minecraft?,N/A,2016-05-06 19:03:19
azozd,How to escape the clutches of Godelian incompleteness and be a consistent and complete individual: follow your computer. Repost from /r/PhilosophyofScience.,N/A,2010-02-09 00:59:04
kyuweu,Why general artificial intelligence will not be realized,N/A,2021-01-17 00:12:38
2wjmwz,"""Gangnam style"" Psy is going to be a keynote speaker at the 2015 Computer Human Interaction conference",N/A,2015-02-20 13:34:19
2r94ib,Beginner looking for some guidance,"Hey,
I'm looking to learn some Compsci and to get a better understanding of programming. Where should I start? btw i have absolutely no experience at all.
",2015-01-04 00:33:05
27wqcs,Why isn't C considered a functional language?,"After all, you can pass around function pointers much like in Scala, although it's a little more cumbersome.",2014-06-11 21:01:37
18jqqj,Computational Complexity: What if P = NP?,N/A,2013-02-14 23:40:14
bvp59,"Chrome bookmark sync would be a great feature, but it rarely, if ever, syncs. Please star this issue (bottom of page).",N/A,2010-04-25 01:24:46
ajo51,AskCompSci: Is it worth it submitting applications for CS Ph.D ,"Hello, I have recently graduated from a university with Computer Science degree and was thinking of going for a Ph.D degree in Computer Science. I received good grades for undergrad and have strong recommendations. However I did not do well on the GREs, first time Verbal: 480; Quantative: 610, second time Verbal: 420; Quantative: 660. I am wondering whether I should apply for master's degree first since the requirements might not be as strict. I could also retake the GRE a third time however then the GRE scores will be submitted past the application deadlines. ",2009-12-29 21:32:01
1mt0g9,What are the programming languages that every CS major should learn before graduation?,"I will of course try to learn as much as I can, but what are the 5 programming languages that should be my first priorities in order to become a good hacker and employable programmer?

I just starting my CS  studies and most of my free-time hacks I have been done with Python. Introductiory courses will be taught in Java in my uni and after the introductory courses I will start to earn C/C++.

At some point I will probably try to learn basics of JavaScript/Ruby/CSS/HTML. 

Are these good priorities or should I leave something out or add some other language? ",2013-09-20 22:27:31
1w2yp1,Is computer science a branch of mathematics?,N/A,2014-01-25 01:18:41
545rzy,"I hate every waking moment I spend in my Calc 1 class and I have to go all the way up to Calc 3 just for a 2 year CS degree. On top of that, I dont feel like I learned anything valuable that will get me a job in CS since Comp2 that I took a year ago.","I don't know If I can do this any longer guys and its depressing as fuck because im so deep in this shit. Im 21, on my 3rd year (work full time) of CS in community college with 7 classes left, including 3 im taking this semester, to get AS degree but its getting tougher, more boring and unbearable with each semester. The only real coding I ever done was Comp 1 and 2 which were both Java classes. The rest were...I dont even know what they were because I don't feel like I made ANY progress since comp 2 which I took like a year ago.

I had to take precalc twice and assembly language for the THIRD time this semester, I despise assembly language with a burning passion especially when my prof said that ""Yeah uhh most of you will probably wont ever need this in the CS field."" Currently taking calc 1 and it is so incredibly confusing. Why am I supposed to use this formula and not the other one, why does this even work, the 2 page problems with 9000 steps that you can mess up...

Its just so overwhelming... I feel like I have to work so much more than other non math/science majors without being guaranteed a job with a pay that reflects the difficulty of classes I had to take. I hate sitting in my Calc 1 class not knowing wtf is going on the entire time then spend hours at the library and reteach the lesson to myself, then do the same thing for a class like Assembly Language. I feel l like if I was a business major or something Id have to take classes that just make sense you know? Real, not abstract problems, learning how business works and hot to make it better, how to market your product etc. and it would just make sense because its not a whole different language like math or CS, I wouldn't have to learn these ridiculous formulas and steps to solve different equations I dont care about or how a CPU works.

I apologize for this long rambling but I really needed to vent because I don't know what to do and I feel like im wasting my life going nowhere.

**Edit**: I read all your comments guys and I appreciate every single one of them. Definitely gave me a few different perspectives.",2016-09-23 17:09:04
4yixbh,Does the SICP wizard jingle have a name?,"It's really catchy, and I want it as a reminder tone on my phone.",2016-08-19 13:31:15
6y8ot9,When Will AI Exceed Human Performance? Evidence from AI Experts,N/A,2017-09-05 15:24:58
aarh58,TECH Post Number 1: Here are the main classifications of programming languages.,N/A,2018-12-30 01:46:49
51kcb9,How to generate 100 x 100 matrices efficiently?,"I am working on a project that involves big data and probabilities. For this project, I need to generate every possible 100 x 100 matrix where the entries can be between 0 and 11 and check if it satisfies another function. What is the fastest way to generate these? My initial thought was nested loops, but that is obviously impractical. I would prefer to do this in Python if possible, but if not, C++ or Java would work too. Thanks!",2016-09-07 08:58:45
3dq7go,Why Do We Need Software Craftmanship?,N/A,2015-07-18 11:19:09
4qy48a,I've finished my undergraduate and master. Now what?,"Hi everybody. What I will do now is my PhD, but in the meanwhile I would like to improve some areas I think I flaw at. I mean the next areas: Software engineering (design patterns and software architecture) and electronics (I would like to understand some terminology related with the new GPUs and that sort of things related to the computer overall).

I'm lookig for MOOCs, books, current blogs, articles, magazines, whatever, since I don't know where to look for.

Thanks in advance!",2016-07-02 17:23:57
31hvg0,Showing that a^n b^n is regular,"I'm wondering if the following state machine shows that {a^n b^n | n ϵ **N**} is a regular language: [state machine](http://i.imgur.com/UHBWB93.png)

I know the first response will be that it doesn't have a finite set of states, but my response is that no natural number is infinite, so it covers all of them.",2015-04-05 05:41:42
zzzq8,Running Time Analysis:  How do I determine how long a process will take in multiple running times...,"The truth is, this is homework related.  I am currently taking Data Structures, and have fallen a little behind.  I am looking for some kind of kick start into figuring this out.

So, I have to assume that the running time for an algorithm with input size of 256 is 1 millisecond. (Ignoring the effect of low-order terms.)  How much time will be required to process 512 items if the running time was 1. linear, 2. linearithmic, 3. quadratic, and 4. Cubic.  How large a problem can be solved in 240 milliseconds with the same running times?

Any insight?",2012-09-17 01:22:04
flqdh,"Yet another P != NP ""proof"". Are any of these papers peer-reviewed?",N/A,2011-02-15 09:13:34
gp4kax,Computer science encyclopedia can be translated to 20 languages,"Hi,

I've finished working on translation mechanism for [https://handwiki.org/](https://handwiki.org/) (Encyclopedia of Science and Computing). Now all articles can be translated to 20 languages using Google translate (with elements of AI). I decided to stick to the 20 languages, out of 100 but if you need more - ask. How it works: Go to [https://handwiki.org/](https://handwiki.org/) and use ""Select language"" (left menu at the top). Select the needed language.  Then the entire page should be  translated. To come back to English, use the top menu (that disables the native HandWiki menu). You can close this top panel using a small cross (top-right). Note that translation does  not work with the LaTeX export, nor inside the editor.",2020-05-23 13:03:15
1idcgo,What would be a good minor to be paired with a CS major?,I've read that math minors are good picks because of similar course work but I just wanted to get your guy's take on it.,2013-07-15 22:18:17
4pxx1o,"I am not sure what I want to do, but I am sure that I love technology and want to be involved in the innovation and progress of it. Is CS right for this?","Title. I have so may questions about CS jobs and careers. Is there a better place instead of here to get my questions answered?? For example, VR gaming looks awesome and it would be awesome to be involved with that. Or creating AI technology. Or self driving cars. Or new iMessage in iOS10 being LIT AF. Or CGI effects looking better and better in films. Or Or IDK lot of cool shit that i'd love to get involved in that I can't list. Is CS suitable to get pretty involved with these types of new technologies. ALSO, can you move between these ideas? Like can I work on VR gaming and then get bored of it and move onto something else like self driving cars. How involved can you be too because I would want to be pretty involved in creating and progressing these technologies and electronics.
It seems that most computer science people now tend to be laborers instead of innovators as in they are fixing bugs and making stuff more efficient instead of creating new technologies. I love technology so I feel this may be the right major and route, but I don't want to be just a laborer that seems to not do much meaingful and not have much fun. I want to do something meaningful and fun (innovative technology is fun bc its new!) 

Is Computer Science right for this?

Thanks a lot! Best.",2016-06-26 14:15:04
2vdl6l,Great Book for Computer Science Student,"Hi!  I am a computer science student studying in the US, and I was wondering if anyone here could recommend a book (preferably not a textbook) that does a good job of explaining a lot about CS.  I'm just looking for something to read that will make me more knowledgeable on CS in general, so I can talk about it better.
Any suggestions would be great! Thanks!",2015-02-10 03:11:39
2q6vkx,I discovered a super fast factorization algorithm and I need your help!,"Hey guys,

So I submitted a thread in a different subreddit about this but I barely got a an answer so I am hoping to get a bit more out of this subreddit.

I started reading about P = NP and factorization a little while back. While reading about it I found a way to factorize numbers a bit faster than the average piece of code snippet that you can find online. In fact. for some numbers (say 20-25 digits or even more) I can find ALL the factors for the number within 0.01 sec.

Now I came up with this method on my own but I have NO IDEA if this have been discovered before or not. And that's why I am here. 

I am just wondering. If we factor a number, say a 20 digit number, on a regular personal laptop. Using the most TOP-NOTCH algorithm, how long can we expect that to take? I need a frame of reference in order to know in case my code is well written or not.

DO I want to share it? absolutely, but I think it is best for the time being to research this a bit more before I do! 

Also, would it be possible for anyone of you to link me to the fastest known implemented factorization function?

Ty in advance!",2014-12-23 17:23:00
297a69,"Things you love are ""Made with Code"" - An effort by Google to get more girls interested in CS",N/A,2014-06-27 01:03:18
22b3bs,Script that keeps writing a file to disk: does this shorten the life of the hard disk?,"I've written a script that writes a small image to file. The intention is to run this script every 30 secs and generate (and write a new file).

Will this shorten the life of an HD/SDD?

I shouldn't think so but thought I'd get other opinions. I mean, modern OSes constantly write to to disk (logs, virtual memory management, etc). A script writing a file every few secs should be inconsequential, right?",2014-04-05 23:52:14
20y9a8,"What is the likelihood that unconventional computing (optical, quantum, wetware, chemical, etc.) ever replaces traditional silicone-based computing?","Also, if you believe that unconventional computing might *replace* traditional computing, please elaborate on which sub-field(s) you find most promising and why.",2014-03-20 23:57:08
1rddfh,Knots and a Mathematical Notion of Equivalence,N/A,2013-11-24 21:15:02
1hamnv,64-Bit Ring-0-Only Identity-Mapped OS (640x480 because no GPU and GPU needed for high res games),N/A,2013-06-29 04:32:03
13wfgc,Cross-post from programming: CS in HS: Support CS education in high school!,N/A,2012-11-27 23:15:08
imy6p4,UML Distilled by Martin Fowler.,"Enterprise, software, business process, conceptual modelling, what is the difference between these? Martin Fowler's UML Distilled is more focused on OO Modelling, but will it help? I studied it last year for a programming course. Im thinking of going back and revising. And it will be very helpful if someone can provide brief distinctions between the list mentioned at the top.",2020-09-05 09:20:09
ba7z6d,2 Years into College and Haven't Learned Jack on Computers?,"Hey guys,

I'm reaching out because I'm worried if I will be successful in computer science because the I've spent two years in college and the most I learned about computers was in a comp literacy course, a pretty general course. Of course I can't just give up on college but I need to figure out how to get really skilled with computers. What's the best way to learn about CS outside of class?",2019-04-06 19:29:44
ab2nn2,Bitwise operators and tricks!,N/A,2018-12-31 02:22:34
a2q5dl,Do they teach Web Development in a Computer Science degree in college?,And to what extent? Does it differ from college to college? ,2018-12-03 16:22:07
9uxg41,I am a first year comp sci student who has some questions,"I have just spent an ungodly amount of time on an assignment for a second year community college class and didn't even finish, so I am wondering a few things from people in the industry or people farther along than me. the basis for the assignment was a making a shortest path algorithm and mixing it with a GUI.

1. how complex can it get( I know the assignment was just the tip of the iceberg, so could someone site me an example of something to show how complex it gets)
2. what is it that you spend yourself doing on a daily basis(as a person who has just coded for about 16 hours straight I have heard the term code monkey passed around and am thinking that no matter how much I enjoy the other aspects this would not be the field for me if I have to spend my time like that for a significant portion of my life)
3. what keeps you going when you feel like giving up on a project or algorithm or w/e it may be (fairly self explanitory on this one)
4. what tips would you give someone who is just starting out(I dont do much personal projects and what I currently know is OS theory, minor GUI things, minor python, minor java, minor c++)
5. what did you find the hardest to learn( so I can get a headstart and have it not make me fail a class or struggle in a job or whatnot)  ",2018-11-07 07:42:16
6jdr8o,(X-post from r/programming) Steganography-related application,N/A,2017-06-25 10:55:19
64zfg2,TAing and Plagiarism,"TAs of Reddit, how do you deal with plagiarism in CS assignments? I just caught a guy for plagiarism and had to refer him to the course coordinator, and I feel really bad myself. I don't want to be the one responsible for ruining his academic record, and possibly sending him into depression. If that were to happen, I would personally feel guilty for this. But then again, if I did not refer him, then I would be committing an academic crime myself. Besides, indulging in plagiarism is his own fault. Yet, I feel sorry for him. Any advice?",2017-04-12 16:59:35
63cym3,The Law of Conservation of Complexity,N/A,2017-04-04 08:51:42
znoa46,Does google have exclusive right to scrape the internet? And can they scrape everything?,"Does Google have the exclusive rights to scrape the internet? I could imagine that people exist, who have a website and thinking to themselves that they don‘t remember giving google the rights to show their website and the content of their website.",2022-12-16 20:30:41
1ufsnj,Theoretical Computer Science Cheat Sheet (10 pgs) [PDF],N/A,2014-01-05 04:28:02
raivof,"Right out of Sci-fi films 😍: Generate any 3D model using just simple words! (eg.Typing in ""A high quality 3D render of a jenga tower"" will generate a high quality 3D model of that!)",N/A,2021-12-06 21:56:56
jnain2,"We are hosting our Women in AI evenings, this time virtually. The evening consists of 6 speakers, roundtable discussions and facilitated 'roulette-style' video networking with attendees! If it's of interest, you can see more on the link!",N/A,2020-11-03 13:46:53
dce69j,DeepMind Uses GANs to Convert Text to Speech,N/A,2019-10-02 18:23:20
burdlw,The problem of the equivalence of two LOOP Programs is undecidable,"Hey everyone. Not sure if it's proper to post this question here but on the other hand, I don't know where. 

There is this problem that I just can't get my mind around it. It goes as follows:

>Show that the problem  
>  
>Input: two Loop Programs P1 and P2  
>  
>Output: Do P1 and P2 compute the same function ℕ ↦ ℕ ?  
>  
>is undecidable  
>  
>*Tip: You can reduce the complement of the Halting problem on empty tape to the problem above*

I tried using the reduction but I can't find a relation between the two problems or something useful. Could someone help me out? 

Thanks for taking the time reading it!",2019-05-30 10:10:45
bnhoeh,How I tried to defy the Facebook algorithm,N/A,2019-05-11 22:08:42
9uipyv,[Academic] The Future is AI - But is AI the Future we Deserve - Are We Safe When AI Encroaches Deeper into Our Lives? (All),"Access the following link to learn more. The link provided will direct you to an academic survey where you will be asked to provide your opinion about this topic.
Here is the link:
https://goo.gl/forms/5LcelVPFBE7vNiC42",2018-11-05 23:11:21
9te2gj,Teslas will soon follow owners 'like pets' as part of an auto-park upgrade; one Tesla driver is already making use of the existing Summon feature to avoid parking fines while he's at work,N/A,2018-11-01 22:09:59
8ke3pp,Lulucid weekly - finding duplicate resume,"From [lulucid.com](https://lulucid.com)

* * * 

Large companies get a lot of job applications. Apparently, Google receives a million applications every year. That's a lot.


Task: We have a collection of resumes with us. When a new resume is submitted we want to know if this resume was already submitted to us previously.


Here are few things that need to be considered:


1. If a resume was submitted 2 years back and again today, then a lot could change. For example, the person got new education degree, changed jobs, learned new languages, changed email address, living in a new country.

2. To avoid detection people will, on purpose, put their name as any of these ""Robert Downey"", ""Robert D"", ""Robert John Downey"". Also, if we have 2 resumes with names ""Alex Hales"", ""Alex Henshaw"" and now we got a resume with name ""Alex H"", we should not consider them the same.

3. Note that people with same full name exist. There are more than 38,000 people named ""James Smith"". (Seriously?)


4. Clearly, it's not possible to design a 100% working algorithm in this case. We may have to use a heuristic algorithm. Think of what's best possible.

5. Do not worry about resume PDF format (most common format) to text conversion. Assume all the information is in text format, we only want to think about the core comparison algorithm.
How would you compare resumes given the lack of structure?


Additionally, assume we have like 100 million resumes with us. When a new resume is submitted, the naive solution would be to compare it with all 100 million resumes and check if we have a match. Can we do better?",2018-05-18 15:38:38
8e521h,"MentorCruise provides personalized mentorship from more than 45 mentors from Netflix, Twitter and co.",N/A,2018-04-22 18:16:22
8265zh,Algorithmia launches Ethereum-based AI competition,N/A,2018-03-05 14:11:22
7q1rhx,Applying to colleges,"Good evening redditors!

I am getting ready to leave active duty, I have been working on my A.S for computer science major. I do no have my degree yet but I would like to continue perusing this degree..

I've never looked into college before, I joined the military to get away from it... Then I realized I wanted to do programming.

I guess my question is there are 1000s of schools and I've Google the best ones and everyone has their own opinion but what do y'all think is the best way to go about finding a college for this degree? Moving to other states is perfectly fine for me.

Thank you all for your help in advance and sorry for for the wall of text",2018-01-13 02:31:37
64bhht,AI vs. AI. Two chatbots talking to each other,N/A,2017-04-09 04:52:48
4za61p,CS50: Inside the world's most elite computing course,N/A,2016-08-24 02:02:45
4mmuwn,What would be the big O complexity of this code? (Where sequence1 is O(1)),"for (int i=0; i<n; i++) {

   for (int j=i; j>0; j--) {

 sequence1

 }

}


I think it's O(n^2) but would like a second opinion please
",2016-06-05 10:39:05
4iq6oi,Are there any self-taught programmers here?,"I am a self-taught dev. I learned front-end dev by practice and reading. Now, I really want to learn about how to create more efficient software and advanced topics on software development. I also want to learn more languages, but I am not sure where to start. I know JavaScript pretty well, and I've used Angular and React. Now, I kinda wanna do some iOS and Desktop apps. Where is the best place to start doing more advanced stuff? Do I have to pursue a degree to learned the theoretical stuff?",2016-05-10 16:58:20
4fzt91,Unsure about CS in general,"Hey guys, I've been lurking for a bit, but I'm currently in AP Computer Science A. I feel extremely apathetic about going out and coding without a motivation behind it. It almost feels like I want a constant project manager on my back.
Given this, should I keep up my pursuit in learning CS.

Thanks guys.


tldr: Is CS for everyone?",2016-04-22 18:31:58
4bztur,Where's all the undergraduate CS?,"Hey /r/compsci. I'm a highschooler going through the process of looking for a college to go spend the next four years of my life at. I've been programming for a few years, (not that that matters much) and I'm obsessed with the math side of things. I love linear algebra (graphics), algorithmic complexity, and computability. 

My main issue is that I'm having trouble finding schools that have CS programs that focus on what it's *really* all about. Everywhere I look, I find undergrad programs that are focused on 'practical experience' and job preparation.

Part of this post is me wanting to spark a conversation about the state of CS, and how (at least from my slim experience) people don't seem to understand that CS is really about math. The rest is me sheepishly looking for suggestions on where to go to school.

Edit: By ""the state of CS"", I don't mean the field as a whole, just the difference between software engineering and computer science.",2016-03-26 03:47:55
4380u7,How do I test that two systems are the same?,"I have the codebase of two systems. Both systems were implemented based on the same requirements. 

I want to ensure that these two systems do implement the same requirements. 

I know for sure that one of the systems does, and I know which.

What method/methodology would I use to compare one of them against the other at runtime?",2016-01-29 08:43:17
38tqer,"Can a program read a short text, create a question based on the text, and grade the answer?","I've been trying to find a program that can take a small text input such as this:

""North American apple harvesting began with the settlers at Jamestown in 1607. They brought with them seeds and cuttings from Europe, and while the original varieties planted were not all suited for cultivation. ""

Create as many questions from that text as possible, say: ""Where did American apple harvesting begin?""

And grade any answer, ""Jamestown"" or ""apple harvesting began in Jamestown,"" to be correct.  

I've found these two research papers on the topic, (PDFs) [Evaluating HILDA in the CODA Project](http://www.aaai.org/ocs/index.php/FSS/FSS11/paper/download/4158/4486) and [Automatic Factual Question Generation from Text](https://errico.srv.cs.cmu.edu/research/thesis/2011/michael_heilman.pdf)  but I am not a computer scientist and I did not put together that the program was created.  The papers mostly discuss the challenges of the syntax and semantics of English and/or language in general.

Those are 3 and 4 year old papers.  Other than that all I've found is that the program doesn't yet exist and is a quite complicated problem.

If anyone knows of something, I would love to hear about it.  I am interested in the code to create a commercial product around it.  ",2015-06-06 19:09:51
359t0j,Alleged interview with Bjarne Stroustrup?,"A friend of mine posted this interview on Facebook, and it was so counter to what I thought I knew that I had to ask if any of you know about it. Is this true? Is all of it made up? Is it just an elaborate joke that I didn't get? 

http://artlung.com/smorgasborg/Invention_of_Cplusplus.shtml",2015-05-08 08:39:59
2z783p,How have computers been used to predict the stock market?,"At least from a historical aspect, i'm curious if investors, mathematicians, and computer scientists have come up with computer algorithms that can give a rough prediction of the highs and lows of a share price.",2015-03-16 04:27:48
2tal8g,Redditor posts promising algorithm to my array filling problem from yesterday. Is it correct and efficient?,N/A,2015-01-22 15:14:32
2lzuu7,"Can someone explain this to me, please?","In a multiprocessing environment, a single dispatch list may be accessed by each multiprocessor's dispatcher.  Give an example of a race condition that can occur if two dispatchers access the dispatch list concurrently.

DISPATCHER 1  
   			
get ptr to next process to execute

update pointer

execute process	

DISPATCHER 2 
   			
get ptr to next process to execute

update pointer

execute process	


Execute the above sequentially - no problem with consistency
Now interleave the first instruction on both dispatchers.
The processors will execute the same process and one process will be skipped.
___________________________________________________

For the interleaved part, is it saying that both processors will run both processes but after, ignore one of them? Will it do the same for the other two processes? 
",2014-11-11 19:43:26
2fzaq2,Why CS? a short summary of why CS is such an important field to study,N/A,2014-09-10 05:12:58
29g59v,What's in the higher level programming books?,"An introductory book teaches you the language. What do the next level books contain? Also, is the Assembly language dead?",2014-06-30 04:39:06
28t9yp,Not sure where to start with this algorithm,"I am not sure where to start with this, or even what to search on google to get a going so hopefully someone can point me in the right direction. 

See a quick diagram to help with the explanation [here](http://imgur.com/jQoqVZr)

Basically, I have 1 to many 'buckets' each containing some number of items. I want to take these items and distribute them over a timeline by using some sort of function.  I suppose I could go ahead and write a piece of code that distributes them, but I would prefer to have a more mathematically precise way of doing it.

The distributing function, F(a,b, ..., z) has parameters that ideally determine what the distribution of the items from the respective bucket will look like.  Then, by varying the parameters one can come up with an optimal distribution over the timeline.  

Also, a feedback loop could be used where a distribution is computed on the timeline, measured for some ""goodness"" depending on the application and then the parameters adjusted.  To me this approach feels a little bit like a binary search in terms of time complexity. 

Anyways, an good real life example could be medication scheduling. Where each bucket contains one kind of medication, with some number of pills that must be taken throughout the day. Then you could find an 'optimal' schedule according to some set of requirements input by the patient/doctor. 

Any comments are welcome, hopefully I did an OK job explaining this. ",2014-06-22 19:28:44
1uifzc,"CompSci majors, a question about math classes?","Hi guys, so I start college on Tuesday, and I got put in a Pre-Calc/Trig math course (MAC 1147) as my first and only math class for this semester. What math class you got was based on your SAT and ACT scores, and while my math scores for those tests were fairly high (I was in the top ten to twenty percent if I remember correctly) they weren't high enough to get me in to Calc 1 for engineers by just a few points.

Thing is, literally EVERY class for my CompSci major requires Calc 1 before you can take them, which means that until next Spring, I'll just be dicking around with elective courses for the most part before I can take the courses I've actually been wanting to take.

So my question is, would you recommend taking Calc 1 for Engineers over the summer? That way I can catch up. I'd prepare for the course by finding the professor for the class and meeting him during office hours and grabbing a syllabus if possible, then I could look at the resources I'll need and learn/study in my free time (which I'll have a lot of. I've got a 4 hour gap between classes on some days to fill with studying). That way I could prepare this semester and ace it over the summer hopefully. It should be noted that I'm not AMAZING at math. Some of my grades in high school math were fairly poor, because that was during a time in my life when I lacked motivation, but I do have a love and interest for math and I know I think I will do better.

TL;DR Is taking Calc 1 over the summer doable/recommended? Any tips to make passing it a bit easier?",2014-01-06 03:47:05
1mr3nn,Explain to me about processor/memory address space and its relation to 64-bit processor.,"In the light of new Apple A7 64-bit processor, I've read a lot of review specifically the design of the processor, but I'm quite inundated by the terms and technical phrases regarding *address space*. Could someone please help me to explain the meaning of *address space* intuitively rather than using jargons?

Thanks!",2013-09-20 02:11:40
1ejj6s,We need a standard... for implementing standards,N/A,2013-05-17 21:29:06
1cbp36,Digital olfaction,N/A,2013-04-14 13:49:38
ga2iw,"I have a BS in CS, my skills are rusty, but I am a fast learner. What languages/tools should I learn while I go on the job market?","I can learn quickly. I want to learn a language/tool that will get me a good entry-level position. In school we learned Java. I am interested in learning C#, how is the market for C# programmers? What is .NET, should I learn this?

**What language/tool should I learn to maximize my chance of getting an entry-level job that will pay me >$50k?** I am confident I can learn whatever language/skill is best to achieve this goal.

Thanks. If this is in the wrong subreddit let me know (r/programming doesn't allow self posts)

EDIT: I'm in southern california",2011-03-23 23:04:06
fqs5z,"What benefits are there for linux and how hard are they to ""learn""?","Hello all,
I'm kind of new into this computer science stuff, and I've just recently decided that I truly want to start learning more and more about computers.
One thing I've consistently heard all my life is that people who know how to actually use computers always run linux, because of the freedom it grants you.
What are the benefits that using linux grants you?
I was thinking of downloading ubuntu and setting up my laptop to be able to dualboot; however, I am just curious how much of a benefit it would be for me, as I don't know too much about linux, although I really would like to learn more about the command line prompt abilities that it grants.

Do you think it's worth it for me to install it and set my laptop up to dualboot?  From what I read, it's a slightly risky thing to do, would you consider it worth it?

Thanks!",2011-02-23 04:00:20
e7ipr,.NET developer taking on engineering role and doing systems architecture: NEED ADVICE,"I'm looking for resources to help me better wrap my mind around conceptualizing a system architecture. We know next to nothing about what this system will require, and the government agency that we are working with isn't playing nicely with us.

I've been assigned the task of designing three different ""pie in the sky"" solutions, and I have a previously written document to build mine off of, but I can't help feeling somewhat lost at sea here. 

Are there any resources, guides, or forums I can consult for reference? I've never had to perform this task before and I really want to succeed.",2010-11-17 14:28:19
ax2vf,Offtopic: Social justice and programming languages (repost from r/phi-of-sci),"Repost from [PhilosophyofScience](http://www.reddit.com/r/PhilosophyofScience/comments/ax2oz/social_justice_and_programming_languages/)

So I happened to watch an episode from [justiceharvard.org](http://www.justiceharvard.org/index.php?option=com_content&view=article&id=11&Itemid=8) the other day, an idea strike me, compare justice reasoning to programming languages. Computer language are meant to compute, with input and output, so does human society, it's redistributing everything. In programming design there's an distinction of [type systems](http://en.wikipedia.org/wiki/Type_system). For example, Java is static, strong typed while Javascript is weak, dynamic typed.

According to my understanding to the video,

* Consequentialism == dynamically, duck typed languages. The advantage of this design is conveniency, fast to develop. In other words, Utilitarianism. But one disadvantage is many of the errors can not be discovered until runtime.
* Categorical == strong, static typed languages. One advantage is it can check for errors in compilation time thus guarantees minimal type errors during runtime.

In software engineering dynamic typed languages are often used as scripting language, glue other modules together, But performance critical modules are often written with static typed languages.

correct me if I am wrong :)",2010-02-02 12:02:11
9eov5,What do you consider to be the most exciting/innovative ideas or trends in Data Mining right now?,What do you consider to be the most exciting/innovative ideas or trends in Data Mining right now?,2009-08-27 14:31:18
90eeu,On a Common Language Messaging Protocol,N/A,2009-07-12 02:18:06
76oz6,"""What do computers tell us about God?""  An MIT students reflection on our Universe and how a higher being could be compared to the creator of any programed system.",N/A,2008-10-12 17:20:53
3b0bs3,How would you design a visual Turing complete programming language for babies?,N/A,2015-06-24 23:08:24
v834n,Could Flash Be Considered A Virtual Machine?,N/A,2012-06-18 14:07:37
ptnruo,How to unzip password protected zip file without password???,N/A,2021-09-23 04:44:06
1o93wu,Best algorithm for sorting after 'making it rain',"You go to the bank and get $1000 in singles to 'make it rain' in your living room.  The room is 5m x 5m and you throw it all up into the air to randomly fall on the ground.  You realize how stupid you are but have acute OCD and want to return the stack to the bank in ordered serial numbers.  There is a time cost walking around the area, what is the most efficient method for collecting them to end up in a sorted stack?",2013-10-11 22:22:11
2ofrsh,"Don't know if this belongs here but, found out an interesting detail about my booting process, during a pre-grub step.","I set my booting options in BIOS to read from a disk drive before going to the hard drive, so even though I have a dual-boot grub configuration between my Windows and Linux, having a disc in the drive caused grub to load slower than it normally did. I had a feeling it was slower than usual and decided to take out the CD that was on the tray, suddenly it booted up about a half second faster.

Apparently, the BIOS settings caused the very first booting process to scan the contents of the disc, an idea supported by the noises I was hearing coming from the disk drive, for a file of some kind before handing the torch to grub. I thought it was cool to learn about the behaviors that those aspects of my system displayed and was reminded how transparent certain system processes can become given the right situations, figured I'd share it here. ",2014-12-06 05:32:28
1wrx5h,"Website I made, perhaps CompSci will like it",N/A,2014-02-02 02:25:48
f4cle,Is an analog search engine possible?,N/A,2011-01-18 09:43:52
abqg4,AskCompSci : Please suggest me and intermediate Discrete  Mathematics Book.,"Edit:
Here are some of the suggested books for Discrete Mathematics. Please add to the list.

0. [ **Mathematics for the Analysis of Algorithms** - Knuth](http://www.amazon.com/Mathematics-Analysis-Algorithms-Birkh%C3%A4user-Classics/dp/0817647287/ref=sr_1_1?ie=UTF8&s=books&qid=1260199061&sr=8-1)

1. [**Concrete Mathematics** - Knuth et.al](http://www.amazon.com/Concrete-Mathematics-Foundation-Computer-Science/dp/0201558025/ref=sr_1_1?ie=UTF8&s=books&qid=1260199034&sr=8-1) 

2. [ **Discrete Mathematics with Applications** - Susanna Epp](http://www.amazon.com/Discrete-Mathematics-Applications-Susanna-Epp/dp/0534359450/ref=sr_1_1?ie=UTF8&s=books&qid=1260135674&sr=8-1)

3. [**Discrete Mathematics for Computing** by Rod Haggarty.](http://www.amazon.co.uk/Discrete-Mathematics-Computing-Rod-Haggarty/dp/0201730472/ref=cm_cr_pr_product_top)

4. [**Discrete Maths and its applications** by Kenneth Rosen](http://www.amazon.com/Discrete-Mathematics-Applications-Kenneth-Rosen/dp/0073312711/ref=sr_1_1?ie=UTF8&s=books&qid=1260199367&sr=8-1)",2009-12-06 20:37:26
fhmgz,MSCS people: was it worth it?,"EDIT: Just saw a post about someone complaining about ""should I get a MS"" spam. Sorry! I didn't know where else I should put this

EDIT2: I am in the USA.

Hey guys. I'm a 2nd-year (almost 3rd year) student at a university, doing a BS in CS at the moment. I'm starting to think about grad school a little bit - my school has a program where if you keep your GPA at a 3.5 or above and do enough undergrad research, you can apply to grad school and not have to take the GRE. On top of that, you can finish your BS AND MS in a total of 5 years if you are accepted. (being accepted depends largely on the fact that you have done undergrad research)

Does this sound like a good path to take? I have done absolutely no undergrad research so far so I would probably need to get on that. Also, I'm kind of interested about how useful a MS is in the real world, seeing as the company I intern for only has 1 guy with a MS. My dad's trying to push me to do it because he thinks I'll hit a 'glass ceiling' at work if I don't, but I'm not sure it always works like that...

Any advice is appreciated. Thanks in advance!",2011-02-08 17:42:31
un4ixl,Comp Sci in the US,"I've found that the focus (in the US at least) is almost purely on writing for network API's, and any projects such as OS development, hardware related dev, such as DSP (digital signal processing), and things like writing crude servers from scratch is nearly entirely ignored. Try to mention assembly language to most software developers, and you might get the topic changed, and the door closed.

I think one of the takeaways of modern technology, is that even with quite a few websites under your belt, and years of your own experience, or close to a hundred different git repos, any degree is preferred over the simple act of still working on your degree, which I find really strange.

It confuses me that someone with a degree in English can be supplied with a job having only a bootcamp to show for themselves, but someone who can program a socket in more than one language, and generate a sinewave buffer to visualize or playback sound from an open source library goes ignored. Especially when they also write websites regularly using school taught frameworks, or their own resolve/interests.

I also question whether HR is adequately informed of programming needs. Especially given that being a programmer can lead to being potentially far too specific to make a resume properly. Maybe if it is underplayed.

Even while working on a degree, it just seems to put a sour face on a lot of the encounters I have had, and I notice that this topic is mentioned humorously a lot, but I wish that it was taken more seriously. Obviously I have struggled to obtain a job due to my degree being still in progress, but it seems that the bar is set way higher than it actually needs to be on this field of advancement. Out of what must have been 500+ applications, I only got 3 interviews, and one of them said they only interviewed me because of my potential, promised they were going to have work for me to do, and never called.

At this point, a lot of developers, and a lot of companies have made me feel as if my interests are useless, which worries me, because they are the foundations of what computer science is, and that says a lot about where humanity is headed.",2022-05-11 07:48:58
j05qd,Considering going back to school for Comp Sci; unsure of best route ,"I recieved my BA in economics in 2009, and have been working a dead end job since. I have an interest in computer science so I'm thinking of going back to school to a) get me out of this dead end job and b) get me in a field I actually have interest in.

I'm unsure about what is the best path to take though.  I have only 1 intro to computer science course under my belt and have only done up to calc 1. I was thinking of either going back and getting a BS in comp sci, or possibly taking the necessary prerequisite courses and attempting to get into a master's program.  Does either of these routes seem plausible? Does one seem like a wiser choice than the other?  

Thanks in advance. ",2011-07-26 14:04:21
asu81,"I'm going to tell my grandchildren about the good old days when we had to type words on a computer one letter at a time using a ""keyboard"". They will marvel at the slowness and inefficiency of my generation.",N/A,2010-01-22 13:19:01
4q65wr,"Comp Scientists of Reddit, What do you do that merits your salary?","I'm asking this from a purely informational point of view. I work in Fiber Engineering but I've been studying C.Sci for about 2 years in my spare time. It's my understanding people that code well make bank, and I'm wondering whether this is more a function of the experience of the coder or the industry that they are working for. Is it a combination of the two? 

Are some industries more lucrative than others?

Are some easier? 

Please feel free to be as open-ended (cynical, skeptical, helpful, etc.) as possible. I'm hoping to pick the brains of the professionals here.",2016-06-27 22:45:46
31b7gf,Does treehouse only offer programming lessons or does it have networking concepts also?,N/A,2015-04-03 14:17:04
2zun58,Should CS freshman with intro classes should try to contact professor for any research assistance opportunity in undergrad level?,"Few professors and articles on the internet seem to be emphasizing a lot on getting involved in the department with research and such. I am wondering, when to begin asking/looking around? 

I am just freshman taking intro c++ course. What type of skills are generally expected before working with college professors as things like, assistance to some research in CS ?",2015-03-21 22:56:43
1256nw,1 Day left for the Parallella Kickstarter : 16 & 64 Core parallel computing units,N/A,2012-10-26 21:04:16
iugf4,Idea for data compression using RNG.  Could this work?,"Suppose you have a random number generation algorithm which generates a bunch of bytes given a seed number. For simplicity, we will assume the seed can be any unsigned 32bit integer. Lets assume that we have a server with a LOT (4 exabytes) of storage (Google?). You could store 1GB of random bytes for each possible seed for that random number generator.

My theory is that you might be able to take a file that is unable to be compressed using traditional compression and convert it into a number of look-ups or instructions referencing the random data based on which seed number was used, the starting byte, and the number of bytes for that segment. It's almost like run-length encoding.

For example, perhaps you have a film that's encoded into H.265. Normally if you try to compress the file with lossless encoding, you will not see much improvement in file size. With this algorithm, however, you might be able to convert it into a set of instructions:


Instructions for Segment 1:

1. seed random generator with: 478928387

2. segment starts at randomly generated byte number: 28394873

3. segment is 512 bytes long


Instructions for Segment 2:

1. seed random generator with: 748839

2. segment starts at randomly generated byte number: 82983

3. segment is 1273 bytes long

And this might continue for any number of segments. I think it would work, as long as the segment you're looking up is longer than the amount of data that indicates where it is. Given enough random data, it seems like you could compress nearly anything to a fraction of the size it was originally.

The cool thing is that encoding could be done on a server so the random data for each seed doesn't need to be calculated each time. A user can then just download a file that tells the random number generator (on the user's machine) how to recreate the original data.

My feeling is that the biggest challenge would be encoding, where you'd have to spend so much time seeing if there are any matches in the random data for bits and pieces of the files. Perhaps there would be a way to structure the random data into a tree to make look-ups quicker (which would require a ton of storage). On the client side, I'd be worried about computation, where you'd be spinning a random number generator x times to reach a certain starting point for a given seed.

Could this work given enough storage for random data and fast enough computers, or is there some mathematical limit or problem with RNG that I'm not aware of?  It sort of reminds me of the infinite monkey theorem...",2011-07-20 03:04:39
bjy9l,"Ask CS Reddit: I don't have much CS experience, but I'm totally obsessed with this game. Can anyone help me find a related research project for a senior-year college free elective?",N/A,2010-03-30 01:32:59
9sntto,CS at a high level university,"I would like to join a high level CS university, but I would like to assure that I will be good enough for it. I'm specifically referring to University of Edinburgh, but really it's the same for all the universities of that level.
I've been studying CS for almost 4 years now, focusing mainly on algorithms. In order to understand my knowledge level better, I know stuff like: Dijkstra, segment tree, Fenwick tree, disjoint sets, minimum spanning tree, Tarjan, some basic geometry, greedy, dynamic programming (obviously far from mastering it), dp on exponential states to name a few. I've qualified for the national olympiad in informatics for a couple of times in my country (Romania) and attended an international contest (ACSL). I am familiar with C++ and its STL, and I know the basics of oop.
Still, I am yet to develop any piece of software or to work too much in any other language. I've only focused on algorithmic. I'm also doing pretty good in maths, but nothing high level (the olympiad is too much for me). 
I am concerned that this lack of experience in other parts of CS would make me struggle really hard, so I would love to hear opinions from you guys.
Moreover, I'm a bit curious about how difficult research is and how good one should be too work in this domain. It seems pretty interesting to me (at least for now), and, although extremely difficult, I'd like to know how hard it actually is.",2018-10-30 13:21:02
8wam5h,Query regarding Hamiltonian Path problem,"Hello all,
I have found an algorithm that finds a cycle that contains exactly n-1 vertices in a hamiltonian graph of n vertices in polynomial time, for example, it takes less than 4 seconds to get such a cycle for 66 vertices hamiltonian graph. I want to know if this proves P=NP, that is, if this implies that I found the ""complete"" cycle algorithm in polynomial time as well?",2018-07-05 13:54:38
6w1j5c,Nymph: A C like Programming Language. Feedback requested.,N/A,2017-08-25 21:33:31
3872ys,Is computer science rigorous?,"Compared to physics and mathematics, which have been established as fields longer than computer science, is CS less rigorous than these two? It seems that CS can vary a lot depending on the school. ",2015-06-02 09:09:00
h5ugd,When will we be able to simply describe the type of program or game that we'd like and then the computer will code it for us from our descriptions?,N/A,2011-05-07 03:51:28
9xua8,Your task is to multiply two 100 digit integers. You are only allowed to use pencil and paper and you must produce an exact answer. How would you go about it? ,"The reason I ask basically boils down to this: for certain tasks, computers are obviously much, much faster than humans could possibly ever be.

However, what is the nature of this speedup, from the point of view of algorithmic analysis? Is it merely a huge constant factor, or do computers have asymptotic advantages in certain tasks as well?",2009-10-26 12:50:49
19hdkd,Time for a new /r/compsci?,"The topicality and quality of posts on this subreddit has been declining for a while and I think we're steadily slipping into Eternal September. Posts about computer science research usually get a scant handful of upvotes, whereas more accessible (but less appropriate) questions (""what class should I take?"", ""where should I go to grad school?"", ""how do I use this library""?, etc...) get a much wider and more positive reception. I suspect that there's nothing to do now but accept this subreddit as a forum for early-stage undergrads or the self-post extension of /r/programming and start over somewhere else. Any other ideas? ",2013-03-01 20:24:53
bnbj9p,That overconfidence(dishonesty) is killing me,"A friend of my (currently a second year mechanical engineering student  ) took  Introduction to C programming at the first term of university passed it with AA. There is nothing wrong here but what makes me irritated is that He wrote his CV that he knows C/C++ . 

The course he took was very basics , he really does not know what a pointer is .",2019-05-11 12:27:28
atbwqz,No one is able to explain to me how tying outputs to inputs is not a paradox.,"Take the SR latch for example, both NOR or NAND gates require the output to be known before it can do the logic for the output.

&#x200B;

I legit cannot fathom how this works nor (pun intended) can anyone explain it to me. I've even asked my hardware engineering friend in training and he can't either.

How do you eval the output of something that requires the output to be known before hand? I am struggling in my computer organization course because of this.

&#x200B;

Thank you for your time.

&#x200B;

Edit: Downvotes for legitimate questions are so confusing. You don't have to be mad that you can't answer a question about the basics of computing to someone learning about your field???",2019-02-22 02:30:14
3vexhs,Are MDs being short-sighted when they say that Google can't replace your doctor?,N/A,2015-12-04 13:41:18
2nubig,"Mega inanity: ""To credit Turing with the sole responsibility for our digital computer age is not only historically inaccurate but also highly insulting to all the others who made substantial and important contributions to the evolution of the computer.""",N/A,2014-11-30 13:18:12
16ye64,C and C++ Aren’t Future Proof,N/A,2013-01-20 23:25:14
4kfcrz,What do people think of Yale's CS department? I've heard it's way too theoretical and looked down upon.,N/A,2016-05-21 20:38:38
i3ls0,Donald Knuth never told Steve Jobs that he was full of shit,N/A,2011-06-19 15:21:48
c28pob,How Machines Make Decisions is a Human Rights Issue,N/A,2019-06-18 22:15:19
3j34p6,"""Why I’m Not Looking to Hire Computer-Science Majors""",N/A,2015-08-31 14:07:19
34zcyx,Need help. Looking for credible Comp Sci Degree course online.,"Hi Everyone!

I am looking for an online course in Computer science. I want to make sure its from an accredited university and i would prefer not to spend a lot of money. Thanks a lot for your help. Some where near new jersey would be good .",2015-05-05 20:36:07
a32ly9,"Decentralized Computing is what computer science is waiting, isn't it? The Most Promising Projects",N/A,2018-12-04 17:10:43
7l3md0,A programming language made of symbols. Uses a specially-configured keyboard.,N/A,2017-12-20 19:13:58
3kjq5t,What would I have to study in order to implement something like this?,"[Link to paper](http://arxiv.org/pdf/1508.06576v1.pdf)

And what if I wanted to have some idea of what's happening behind the code?",2015-09-11 14:45:28
2g4hjm,When Multi-threading Hits a Scalability Dead End,N/A,2014-09-11 18:09:53
7gocvp,Take my survey to tell me a little bit about how much Compscis know about Quantum Computing! (please),N/A,2017-11-30 18:19:46
9mj20,Dude; don't you know that this has already been proved at least 50 times before? Why bother with 36 pages? Implement it instead and win the world. ,N/A,2009-09-21 06:49:06
36vj53,Google a step closer to developing machines with human-like intelligence,N/A,2015-05-22 13:32:48
67qhx6,Is my uni weak on math?,"Europe university. 60 credits = 1 year

Discrete Math - 10 credits
Analysis - 4 credits
Logic - 5 credits

Seems rather weak compared to some other universities? Focus seems to be on the practical side.

Will this be an issue if I'd go to a different one for my masters?",2017-04-26 19:33:15
2lseek,"Trick question: You're given a choice between two algorithms, Θ(2^sqrt(n)) and Θ(n^cbrt(n)), which do you pick and why?","I came up with this question as a way to think about the limitations of asymptotic notation.

* Program A:  Θ(2^n^(1/2)) time, constant space
* Program B:  Θ(n^n^(1/3)) time, constant space

If you're unfamiliar with theta notation, you can imagine it as big-O instead.

(And obviously one answer is “neither”, but that kinda misses the point. In general, answers that explain why people might make errors answering this question are better.)",2014-11-09 19:57:46
2ieu4h,Intro to Machine Learning should replace the Algorithms course for undergrads.,N/A,2014-10-06 02:34:35
1w52wj,Help with super duper basic Turing machine homework.,"(State, read symbol, new state, new symbol, direction)
If you start at state 1, what does this turing machine do?

(1,H,5,G,>)

(2,L,4,D,>)

(3, _ ,8,Y,>)

(4,O,6, _ ,>)

(5,E,7,O,>)

(6, _ ,3,B,>)

(7,L,2,O,>)

(8, _ ,9,E,>)

(9, _ ,HALT, _ ,HALT)

I get what the state is, I get that ""new state"" changes the state. What I don't get is what ""read symbol"" and ""new symbol"" are supposed to do. I have a sneaking suspicion it says ""Hello_Goodbye"", I just have no idea how to get there.",2014-01-25 20:58:30
faz6v,Any good online CompSci PhD programs?,"I got my masters in CompSci from Boise State University several years ago - they don't offer the PhD. I'd like to find a good online CompSci PhD program where all coursework can be done remotely since I have a family and full time job here in Boise.

Any suggestions or experiences?",2011-01-28 21:33:59
jbfs0,How best do I learn computer science?,"Here's the deal, compsci - I loved doing computer science and mathematics at University, but my circumstances mean that I can't pursue further study or rely on my IT job to scratch that itch. So, autodidacticism it is.

The problem I have is that, with my limited time and resources, I'm not sure how to best approach the task of learning what seems an insurmountable amount of topics, many of which are interdependent. The challenges I forsee are:

* I have constraints on my time that limit my study to about 2 hours per weekday, and perhaps 4 hours on Saturdays and Sundays. As such, it is hard to focus on more than 1 or 2 topics consequtively.
* The dependencies between many of these topics makes it hard to choose a topic and carry it all the way through without losing meaning.
* I learn by doing. Focus is not an issue, but I feel that I best reinforce my understanding of material by working with it myself.
* I feel as though the non-programming aspects of computer science get a disproportionally low amount of attention on the new. There are dozens of great exchanges for programming topics, but not so for non-programming computer science topic. I'd love to be corrected on this.

What I do have is enough money for textbooks, and dedication. Given these challenges, what is my best bet? What's the best way to learning computer science from a standing start?


Note - I happen to be interested mainly in artificial intelligence and machine learning, but let's discuss the topic in generalities as much as possible to make our concensus as useful as possible.",2011-08-07 08:29:30
hbrx4,"Reddit, do you have any recommendations for a good book about Java programming for an amateur?","My class starts in three weeks.

EDIT: Thanks to everyone for your help! ",2011-05-15 10:09:25
82d06,porn or not . com (SFW),N/A,2009-03-05 16:36:38
nbjg6,"Will there ever be a world-wide 'datapurge,' due to the massive amount of data and seemingly exponential growth? ","I.e., all data in databases/servers/etc. with data from 1995 or older will be destroyed in order to make room for new data. 

Apologies if this is a stupid question.. I'm a musician at heart, avid c-sci lover and general science fanboy. Always asking why. 

",2011-12-13 22:10:08
gtcg1,High school senior seeking advise!,"EDIT: High school senior seeking ADVICE! Dear lord... *sigh*

Hey, r/compsci!

I'll be majoring in CS at the University of Alberta starting this September. I haven't written a single piece of code and I'm rather intimidated going into university. What to do? My ultimate goal is to become a video games programmer, but I'm keeping my options open right now.

I'm looking for some valuable advice on ways I could prepare and things I could focus on going into college. Specific advice would be great (i.e what math courses to take, how to practice writing code, acquire better CS logic, etc...)

Help is very much appreciated, Thanks!

EDIT: I'm loving all of the responses, thanks!

Just to clarify, I know that CS isn't just about coding. The reason I bring up the topic of coding experience is because it would give me a basic understanding of programming and I would be at an advantage going into the program (at least I think so). Video games programming is just a dream and I'm fully aware of its serious nature. Trust me, it's not because I ""like playing games"". Realistically, I know there are many more fields out there and so I'm not going to limit my opportunities. I created this post to get guidance and help on what to do in my first year, but furthermore how to prepare, and so far the response has been tremendous!",2011-04-19 04:34:25
32d52n,Webscraping question,"Would it be possible to have my program search something on google, and then for any given result scrape the first 20 results? 

If that is possible what would be a direction to look at to implement this type of functionality?",2015-04-12 20:11:31
a64ds,Why does Objects have Identity?,"I have never (or at least very rarely) had the occasion to compare the identity of objects. Yet identity requires a global ""counter"" (or similar) to ensure that every new object has a unique identity, which means that every ""new"" has side effects (reading and updating the counter).

I realize mutable data needs an identity, so that you can keep a reference to its current state. However, often many of the fields in an object cannot be changed. Why is identity not exclusively something that the mutable part of an object has?

In SML, you have mutable *refs* which has identity, but normal values do not. Is there any reason why it isn't so in OOP, or is it just tradition?

So why is it that every single object has identity?

Edit: I removed a bit about garbage collection that didn't make sense. See gsg_'s comment.",2009-11-19 18:05:10
aai35n,MySQL Database Code Generator is ready for public use!," Finally, my code generator is up and running. It reads a MySQL dump file (structure only) and generates the PHP and HTML code for base table population/modification of the entire database. It is in beta at the moment, but should work just fine.   

If you develop online MySQL databases, this will take the effort out of writing the site from the ground up, and you'll be able to get to the real reports and functionality that are just plain old more enjoyable to write!  You should be able to speed up development by at least 30-60%.  

And it's still free. 

&#x200B;

Find it here:  [**http://codegen.he.net/**](http://codegen.he.net/) ",2018-12-29 04:41:32
2typru,/r/compsci hits 80K subscribers,N/A,2015-01-28 14:21:24
hpmbkf,Does anybody else find writing binary to hex conversions cathartic?,I just think its cool. That's all :),2020-07-12 01:53:39
ghav6w,"a way to translate subsetSum to a math expression of plus multiply exponent and mod, an expression which is about the same size as as the subsetSum question, but which the simplest way to eval it costs exponential memory.","n integers.

integer d = ceil(log2(n))+ceil(log2(max bits per integer)); to store sums of how many subsets sum to that, in blocks of d bits.

integer m = 1; for each integer t of those n integers, m *= 1 + d * pow(2,t).

m is now an integer with around an exponential (of n) number of 1 bits.

Use 2 mods (aka %) to select a single bit in m. To select bit b, ((m%(pow(2,b+1)))-(m%(pow(2,b))))/(m%(pow(2,b))), which always evals to 0 or 1.

Do that for each of d bits of the d * sum you want to check if any subset sums to. Do an OR on those by multiplying those d number of 1-bit. Do 1 - that to get the OR of those d bits.

The resulting math expression is always 1 if a subset of the n integers sums to the chosen sum, else is always 0, and that math expression is written in about the same size as the question of the subset sum itself.

I'm unsure how this might align to quantum computing other than it is a math expression directly evalable forward without trying all combos.",2020-05-10 22:17:21
b8ghiw,What is happening when you open a website in your browser?,N/A,2019-04-02 08:32:32
b3ldsn,Is it not common to compile Python code into EXE?,"I feel compiling into EXE file is usually done with C++ code, and Python is more for running a script. 

Is it true? Because I want to make a EXE file with a python code I wrote and there is very little resources on how to do it.

thanks",2019-03-21 03:00:33
aziyfc,Have you met any coders who don't have a comp sci degree? Were they good?,N/A,2019-03-10 18:56:29
ax5csq,How can I get ahead of my class?,"I study CS in college. My grades are good and I handle programming problems well, but I do want to have an edge when it comes to that. I want to get my knowledge to the point where I can go and apply myself for a job as quickly as possible.. I am mostly interested in algorithm development..
What is best, safest(and free) way to boost my knowledge and experience?",2019-03-04 09:42:23
akmpli,Computer Science major contemplating data analytics..,"Hey guys. Right now I am a sophomore theoretical computer science major getting minors in math and data analytics. (After this semester the minors will be fulfilled) 

The thing is, I really dont want a job where I write any code. I like coding as a hobby, making apps on the side, but I really dont think I'd like programming as a job. I would like to do something different with a CS degree. 

My uni just put into action their data analytics program and the heads of the program are really passionate on the subject and I can tell it's not just a thrown together mix of preexisting cs courses and stat courses, so I feel like it's more of a solid program than that of which I've seen elsewhere. 

I am at the point where I am liking this whole data science thing and I am considering changing my major to data analytics, getting minors in computer science and math. 

The contemplation that I have is that will I have a harder or easier time finding a job after graduation with a bachelor's degree? Would having my current set up (cs major math and data analytics minors) give me opportunities that would be of a broader spectrum than that of a data analytics major with minors in cs and math? 

Let me know what any of you think, I appreciate it and would love to hear from anybody in either field. Thanks so much. ",2019-01-28 11:50:05
ak0iad,What are some good books or learning materials to learn how to code computer IA for board games?,Especifically i want to make an ~~IA~~ AI for some custom variants of chess or [Tak](https://en.wikipedia.org/wiki/Tak_(game)). Thanks in advance,2019-01-26 12:36:12
9p60ny,Help need for college mini project.,"We were kind of handed down this project and hence I have no idea how to begin this stuff.

Basically the problem statement is to extract data from the results published by the university and create an analysis out of it. But the university publishes the result in pdf format. 

Can someone tell me how to script download the pdf results of the all the colleges under the university and also how code extract the data from a pdf into a database. 

Any help is appreciated;",2018-10-18 04:37:54
9bxg3b,Is csrankings.org legit and sensible ?,"Hi all,

What do you guys think about csrankings.org ? Northeastern University, a relatively unknown school seems to be ranked top 20 and better than UCLA. On USNews Rankings, it's ranked low at 49.

This makes me wonder, is it even a sensible/reliable ranking source ?",2018-08-31 21:08:57
8pt91s,Programmers preferring MacOS because of Unix?,"So I have read that many programmers prefer MacOS because of the Unix command line. I have read on this a little but I am unfortunately nowhere closer to understanding what does this mean.

From what I have seen on another reddit post, I understand that Unix is not so much of a OS, but rather a standard. And the fact that OSX has met this standard means that it can call itself a UNIX certified OS (correct me if I'm wrong). But what exactly is this UNIX support good for? For instance, is it better for debugging? Is there a Unix OS that you can program for on OSX, but not Windows?

Please shed some light on this thanks. Any explanation would be most welcome.",2018-06-09 14:47:38
81737t,The old we-don't-have-to-init-memory trick. Can you figure it out?,N/A,2018-03-01 17:41:19
7s1ibm,True or False: n^3+O(n)=Ω(n^2),I'm not very clear on how to work with asymptotic notations when it is used as value that is added to something else. Asymptotic notation represents a set of functions. How would we add a set to a function and determine if it is a part of another set of functions?,2018-01-21 23:31:15
61mg25,Multi-Agent Systems of Control,N/A,2017-03-26 16:35:19
4gcbm9,CS vs CE,"Can someone explain in simplest terms the difference. I'm not really sure what I want to do. Software side or hardware side and designing etc. I'm thinking between UBC computer engineering or SFU CS. Or maybe even UBC computer science if I can get my program switched. I'm just stuck and want to make the most informed decision before making the most important decision in my life. 

Thanks ",2016-04-25 07:53:57
valji,Is Reading the Internet Convincing Women Not To Study Computer Science?,N/A,2012-06-19 20:57:32
5050z4,"UAE PM: ""Programming and computer science will be core skills through year 1 to 12: the illiteracy of the future will be computer illiteracy.""",N/A,2016-08-29 13:35:25
4nav3r,Advanced java programming,N/A,2016-06-09 13:48:06
4mbwpk,What significant applications does statistics have outside of Machine Learning?,N/A,2016-06-03 08:15:38
4lk7b6,Using linux utilities in a real world usecase,N/A,2016-05-29 12:08:45
4f8sry,Which area of computer science generally has the nicest researchers?,N/A,2016-04-17 22:21:46
3tbpi5,How exactly are CS and IT related?,"Mabye some of you saw the post on imgur today and this motivated me to start a discussion on here, which I had in the past.

I had this ""debate"" a few times with non-computer scientists and as a CS student I have a very clear opinion but sometimes still wonder.

In my opinion IT is a subset of CS because it is mainly practical and applied CS while CS is evidently more than just that area. But I cannot clearly say if IT is a result of CS or vica versa. Neither would I be able to answer what was first.

Another possible explanation might be to think of CS as a huge area which at some points peaks through a certain threshold and this surpassing little areas we call IT.",2015-11-18 18:28:59
3oapth,Donald Knuth's legacy,where does he rate among computer scientists and programmers?,2015-10-11 04:16:15
3nuhhe,Is it possible to build an operating system that could easily work through only a browser?,Does anyone know if it could be possible to build an operating system that unlike remote desktop clients (too laggy unless connected to the same network) could actually run properly when accessed through a browser? ,2015-10-07 14:48:44
3ma7s6,Information for a High School Student,"Hi, I'm a grade 12 student and I'm thinking about majoring in computer science. Although I'm planning on going to medical school and becoming a doctor, I wanna do something I really like as an undergraduate, and I love math. I'm good at other subjects too but math is my passion and I want to major in a field with a lot of it. However, I don't know if i really wanna do computer science so I was wondering if y'all can give me some sources to gain a better understanding on if I really wanna do it. I have no experience with it yet. Maybe book suggestions or good documentaries or any youtube series? Thank you. ",2015-09-25 02:26:45
3crzo7,Big O of a piece-wise function,"g1(n) = n^2 (for even n >=0), n^3 (for odd n >= 1)

g2(n) = n^2.5

1. What is Big O and Big Omega of G1?
2. What is Big O and Big Omega of G2?
3. Is G1 O(G2) ?
4. Is G2 O(G1) ?
5. Would anything be different if the evens/odds were switched in G1?",2015-07-10 08:16:06
3c2zcs,Any advice for an incoming college freshman majoring in Computer Science and Game Design?,"First post here, hope its the right place. I'll be entering my first year in college (university) beginning late August. I have experience with programming, self taught experience that is. I was wondering for all you computer science majors or experts that are in this subreddit, if you could shed some light on the topic! Thanks guys.",2015-07-04 07:11:23
36xzir,I'm thinking about going to grad school but my GPA isn't perfect.,I know I want to major in Computer Science. Is there any hope for me getting in anywhere?,2015-05-23 01:32:27
2va9b1,The A-star algorithm explained concisely,N/A,2015-02-09 09:11:15
2uqrpl,Commits.io – Create a poster from your code,N/A,2015-02-04 10:40:20
2rq2jk,Need help in Java with Graphics,"So I was wondering if I could use my own method instead of paintComponent to execute commands like drawLine.  I try to pass the Graphics g object to my own method, but its not drawing.",2015-01-08 07:42:12
2eud9l,Do you guys know good computer science articles?,"I am taking Science Capstone class right now (senior year of high school) and I have chosen computer science. I just got into programming, messing with Python and I already have a basic to moderate understanding of logic gates from games like LittleBigPlanet and Minecraft w/ redstone. I'm not saying I'm an expert, I might as well have no ""experience"" at all, but for the first few weeks we need to find science articles and write summaries about them. After studying the articles, we find a testable question and make a repeatable experiment. I want to get into Computer Science in my future, so I'm really interested in this, but I need help finding computer science articles to read and write summaries on. Any articles, websites, e-books, links, anything would be greatly appreciated. Thanks!",2014-08-28 18:09:35
29ffv4,"Creating a DBMS from Scratch, Ideas?","I am in an advanced database course, and we are given a term project that we pretty much have full reign over what it entails. My idea was simply to design and implement a simple DBMS from scratch. I know this would be hard on its own, so for the sake of all the work I'm about to undertake, it would be nice if in the end it served some kind of purpose, no matter how small. Rather than just making a very simple query parser to compute a small set of queries that another DBMS could easily handle, I would like to specialize it into something that other options don't do well, or at all. Any ideas or discussion is welcome, as well as advice. Thanks!",2014-06-29 23:20:48
24wi1e,[Question] CS is to Physics?,"Is CS like physics, in that it paramountly studies Computation that underpin our universe versus Physics which tries to find theories/laws that describe our universe? 

Then in turn these theoretical ideas get put into use by, say, Software Engineers?",2014-05-06 22:24:22
1ynex3,Most influential programming books,N/A,2014-02-22 21:02:31
1u1n2d,"No, The TSP Isn't NP Complete",N/A,2013-12-30 21:38:21
1ktlb5,"If I compile an application myself from code, is the going to be faster? (e.g. better adjusted to my CPU architecture, use SSE? , etc)",N/A,2013-08-21 18:57:49
164i53,Computer Science Princess Society - luring?,"Long story short:

1. Two other students and I are holding a computer science outreach program for high school girls.

2. Why?
Because someone realized that the number of girls studying computer science is way too low. And the drop out rate is way too high.

And let's face it, there are a lot of misconceptions out there about what it actually means to study computer science or computer science related. 
In addition, programming and computer science is becoming a part of almost every profession. I have heard so many fellow students studying things like geography and linguistics complain loudly about the one programming class they have to take. 
Computer science and programming is a part of everything now. Just last week I was talking to a group of architecture students who wanted to learn how to program so they make tools for themselves. 

3. Why am I talking to reddit about this?
Well because we need a NAME. And so far we can only think of names like, ""ultra technical unicorn computer science club"" and "" C.S.P.S. - the computer science princess society"" .

If anyone can think of anything it would be very much appreciated. 
Because we suck at packaging, the most important part. 
What appeals to 17 year old girls? 

AND as a side note the course will not exclude high school boys. They are welcome to join as well. I just wanted to avoid that whole discussion right away. 

Thanks in advance!


**EDIT:** 

1. I am so sorry for the confusion but *Computer Science Princess Society* was not an actual suggestion. 

2. The outreach program has to be directed towards girls. The local government has given us the money and asked us to do exactly that. *I completely agree* that it is on the shady side to exclude 17 year guys. Which is why we are welcoming them to join but the ""advertisement"" is directed towards young girls.  

3. The program is only a two week course. That is how far the money will go for now. We are hoping to spark something that will last. 

And as a side note we have ordered a ton of Raspberry Pi for the project. I am considering to teach them turtle graphics.
",2013-01-07 16:16:30
ymghl,Is the Travelling Salesman Problem solved?,"I know I learned this a while back but I can't remember and I can't find it I just find ""optimal ways to do it"" but not a ""solution"" I seem to recall a mention that the issue was that there was no ""optimal"" solution for it. Could anyone help me out here?",2012-08-22 05:21:54
um30g,Summer research question,"Hey everyone,

I am currently doing summer research for my college. I am trying to develop a  Dbus library for the GIMP such that I can incorporate scripting development environments such as DrRacket.

My question is: I have no idea how to make a Dbus library, could someone point me in the right direction to learn how?

Thanks",2012-06-05 14:13:55
jktf3,Pimping lemma,N/A,2011-08-16 20:10:50
906wk,What American University has the worst Computer Science program?,N/A,2009-07-11 04:27:21
jjz2d,How I ended up as a CS major,"Year 1: Starting Major Mathematics - All hard-working Asians (not racist. true)

Year 1.5: Major English - All dreamy eyed-kids that weren't that good a their craft

Year 2: Comp Sci - All middle class, white, somewhat lazy underachievers. I felt like I was home.",2011-08-16 01:25:06
iph3q,Most efficient algorithm for determining if X out of N inputs are true,N/A,2011-07-14 15:02:21
4txguf,This coding question got so popular with many variations,N/A,2016-07-21 15:15:49
aqgp6,Acing Comp Sci with your iPhone,N/A,2010-01-16 20:22:42
onhhf5,A Polynomial Time Algorithm for 3SAT | ACM Transactions on Computation Theory,N/A,2021-07-19 16:25:45
ebqhl,Generalized Super Mario Bros. is NP-Complete,N/A,2010-11-25 19:05:55
anxec,"""What if CS underwent a revolution similar to when physics changed upon the discovery of relativity? What would a paradigm shift in computers look like?""",N/A,2010-01-10 21:19:20
3og41v,Any ComSci guy here who knows about Bees Algorithm?,"Anybody who has experience dealing with Bees Algorithm here?

Hello, I'm a computer science student studying here in the Philippines. I'm planning to propose a thesis about using Bees Algorithm to control video game AI difficulty. My idea is a 2D game simulation in which there is a player surrounded by bees themselves, and the objective is to avoid getting stung by one bee. It's like when a bee scouts an area which I belong to, the bee will call on nearby bees to attack said player, thus increasing the level of difficulty.

The problem is I only know a little about Bees Algorithm. I don't even know where to start. And I'm not sure as to what language I should write it on. Any ideas? ",2015-10-12 13:03:17
npvrd,i need your help to break my 'proof' that p != np,N/A,2011-12-25 05:18:23
us0n1b,"What is the word or acronym for the thing thats just below an API. Like when writing excel functions, what is that pre-written code you can use for the commands called? I’m blanking on it.",N/A,2022-05-18 00:36:38
dd1p27,eqauls vs ==,"ive just begun learning java and am quite confused between when to use equals and ==. any help is appreciated, thanks in advance",2019-10-04 03:13:33
afctsv,I'm going to be a 21 year old/22 year old in a calculus 1 class.,"I just don't have confidence in myself to be good at Calculus 1. I took college algebra, did not take trigonometry but I been teaching myself it. I took discrete math, My school combines Calc 1/2 into one course and I'm going to have to take that at 22 years of age. I just feel so behind. Technically I will be 50% done with my degree but stilli. ",2019-01-12 22:58:56
aehbu9,I tried to learn computer science by myself for 100 hours,N/A,2019-01-10 09:01:19
8dmjt1,Question about sorting vizualisation,"I wanna simulate how bubble sort works on an unsorted pixel array in p5 js and it just doesnt work.

The way i wanna do it is this: I make a random mashup of pixels which gives me an unsorted pixel array. Then I sort it via bubble sort. Issue is i dont see the animation. Anyone help ?",2018-04-20 10:25:54
3ua9u0,How did early linux developers became successful and rich? (if that is true!),"My friend and I had a discussion on what if there was a  new free  OS that supports mobile, VR, AR and desktop. How would that turn out? How did early linux developers became successful (professionally and money wise..)? ",2015-11-26 00:23:13
3strna,A Variety of Questions about Computer Science,"Hello Reddit
My name is Dominic and I am a high school junior who plans to major in Computer Science. I have a few questions.

1. How hard is the major? Also, what are the hardest parts?

2. How does one get variables, loops, and algorithms into a gui? I understand how all those things make up a program but how does one create a fully interactive GUI?

3. Is the only thing a software engineer does is program?

4. I love computers, video games, and enjoy coding but I am not entirely sure what type of CS to do. Software Engineering? IT? Hardware Engineering?

5. My parents are anti computer lol. They won't let me get my own computer even considering I have a 3.9 GPA. Any advice?

Thank you!",2015-11-14 21:50:50
311z4p,Lennard Jones force and verlet alghoritm. Molecular dynamics. No idea how to implement that in Python.,I tried all day to create 2D simulation of particles in chaotic movement by Lennard Jones force. My problem is implementation of verlet alghoritm and calculating forces. I implemented boundaries and drawing of particles but I do not know how to calculate force properly using verlet alghoritm so I cant implement moving properly.Someone have solution of that problem? Any advices would be useful.  ,2015-04-01 13:35:38
2yim6q,Is it possible to create a virtual machine within a video game?,"Or rather, HOW would one go about doing so? 

Let's say I wanted to create a simple 3D scene consisting of a white room and a desk with a keyboard, a monitor, and a mouse. How would I go about integrating a virtual machine into the 3D space? 

I've done research and haven't been able to find anything on the subject, so I'm looking for advice on how to approach the issue, or perhaps a helping hand to point me in the right direction to understand the subject more.",2015-03-10 02:41:05
2vfhwq,[Discussion] How do you guys study for your programming class test's?,N/A,2015-02-10 16:32:54
2rl5ci,Does the OS and BIOS load simultaneously?,"Also, is it possible to bypass BIOS on start-up but have access to it another way?",2015-01-07 02:55:07
2ikv4n,There's an alternate history where aliens invade during WW2. In the story they're confused & then amused by human tech because they invented transistors first and totally bypassed tubes. Is that plausible/possible?,N/A,2014-10-07 17:45:49
2fhj9n,I'm returning to school and am in need of a bit of help,"I will be starting my BS in CS this coming spring. I'm excited, nervous, and a few other emotions I can't place. I'm quickly approaching 30 -sigh-, so I will be lumped into the category of adult learners. Maybe that matters, maybe it doesn't. I have no clue! I have a BFA in Music Performance, so college isn't anything foreign to me. However, I just had an epiphany--I have no idea how to study.

I had to take some GenEd courses with my music degree; nothing I had to study for, and I didn't really have to study in high school. I a pretty smart guy, but definitely no where near smart enough to wing a CS degree.

I have little exposure to dense, technical material in a formal setting, though I have been studying python on my own for a few months to ensure this is a journey I want to embark on. Turns out, it is. I'm chewing at the bit waiting for school to start! There is a huge difference between doing something as a hobby and being able to apprehend, retain, and apply information in a collegiate setting. I'm worried I won't be able to make the cut.

I've done some research, but there are as many schools of thought as there are people. Frankly, I didn't like anything they had to say. I will be taking the Welcome to School 101 class, but given that I've already taken that class and it having nothing to do with they type of information in CS, I feel like I'm going to need a more solid foundation to work upon.

*What are your best practices for note-taking, studying, preventing burnout, etc.?  Can you recommend a book or website that helped you out during your formative years?*

I appreciate your guys' help with this. Thank you in advance.

P.S. Does anyone want to hire a trumpeter for your wedding or kid's bar mitzvah?",2014-09-04 20:19:49
umu9c,What exactly happens when I delete something from my harddrive?  Are the 0's and 1's changed?,N/A,2012-06-05 22:23:30
hc67z,TIL: The best malware ever is Stuxnet,N/A,2011-05-16 00:45:09
geng4,A new subreddit for CISSP.,N/A,2011-03-30 11:48:45
g7640,"Hey /r/Compsci, I have a question.","Hey /r/Compsci, I am a freshman in high school, planning to major in computer science when I get to college. But, my high school only offers a course in java. I am at the top of the class, but I still want to learn about the wider computer science world.  I was just wondering if you guys knew any really great books that discuss either general computer science or a specific topic that a freshman in high school would understand. BTW: I am currently reading The Elements of Computing Systems, and thoroughly enjoying it. ",2011-03-19 18:43:00
dzlfp,Please help me with this algorithm question: Lowest common ancestor,N/A,2010-11-01 17:35:58
3bvw1t,"Have there been any breakthroughs in Turing complete visual languages for games so gamers can add their own modes, levels, objects, etc.?",I am particularly interested in visual languages where the visual program looks a lot like what the game looks like.,2015-07-02 16:07:02
j9yykd,"Does quantum computer change computability, complexity and/or programming languages?",N/A,2020-10-12 20:33:48
gppiwc,IEEE-754 floating point is nuts,"Due to taking a course  I was forced to look into the details of that standard: I thought the exponent is simply a signed integer. No, two-complement is apparently evil and instead the standard uses a biased exponent. WTF. 

And also heard about it in a video about r/MachineLearning. The standard has holes around zero. So the implicit 1 in the mantissa is nice for all but the lowest value of the exponent. The two lowest values which can be stored in the data format field called ""exponent"" must mean the same exponent. One of them has an implicit 1 and the other has an implicit 0. This was no big deal for me because I always used 64bits. But for GPU and cray it is a big deal.

I wonder why they did not make the format compatible with signed int. Save a denormalised mantissa as signed int16 or 32 or 64 and save the exponent as int. Then JS could deal with 64 bit integers as well. The 8087 uses 80 bit internally and seems to use a 64 bit mantissa. So one could share all the circuitry with integers. In appendix p define a packed format",2020-05-24 13:16:21
g3cj4b,Stephen Wolfram: The Path to a Fundamental Theory of Physics May Begin With a Hypergraph,"Physics is the most fundamental of the sciences, dealing with matter and energy. But despite centuries of study, scientists still struggle with the basic question of how the universe works — in other words, we still lack a truly fundamental theory of physics.

And that’s something Stephen Wolfram has been thinking about for nearly 50 years. Known for his work in computer science, mathematics, and theoretical physics, Wolfram announced this week that he may have found a path that leads to a fundamental theory of physics, and that it is “beautiful.”

Read more: [Stephen Wolfram: The Path to a Fundamental Theory of Physics May Begin With a Hypergraph](https://medium.com/syncedreview/stephen-wolfram-the-path-to-a-fundamental-theory-of-physics-may-begin-with-a-hypergraph-c1fd124b6e62)",2020-04-17 22:57:32
dw2i1t,A genetic SAT solver which works for a few instances,N/A,2019-11-14 02:05:39
c4cqgc,Make a Simple Operating System,N/A,2019-06-23 21:53:02
bf1p6l,Understanding Computational Complexity,[https://pncnmnp.github.io/blogs/P-NP-NP-Complete-NP-Hard.html](https://pncnmnp.github.io/blogs/P-NP-NP-Complete-NP-Hard.html),2019-04-19 17:17:03
afssro,Machine learning provides insight into the human brain,N/A,2019-01-14 05:59:12
adzrqk,"Since we are seeing hacks everywhere (Reddit, Quora, FB etc), is it possible to make a database that is not hackable?",Is it being worked on in CS?,2019-01-08 22:26:45
9qf4sx,Help plz: I’m a 14 year old,"So, I’m really interested in computer science and just wanted to know if there were any books I should read. P.S It'd be really helpful if they were suited for a brain of a 14 yr old.",2018-10-22 15:58:43
95jzp8,Maximizing CPU Resource Utilization on Servers – Coinmonks – Medium,N/A,2018-08-08 07:41:19
8xtab3,Software engineer or cyber security engineer? What would you pick?,N/A,2018-07-10 21:04:26
8l99ph,"What is this principle called? Also, discuss =)","I've heard that there is this approach of making as much as possible into specific datatypes.

For example, if you have a program that handles user\-information:

    public class Person
    {
        // --Instead of this--
        //
        // string fullName;
        // int age;
        // string address;
        // string email;
    
        // -- You define a dataType for the various properties along with implicit assignments,     
        // -- validations, helper-methods etc. Ex:
    
        FullName fullName;    // Ensures that it contains at least first and last name separated by 
                              // some character. Not including special characters etc.
    
        Age age;              // Must be over 0 years old. Must be under say 130 years old etc.
    
        StreetAddress address;    // Must be a string (street-name) followed by numbers (street-number)
        Email email;              // Regex-check to see if it's a valid email.
    }

What's this principle called? Also, what are some pros and cons of making almost everything super\-hard typed?",2018-05-22 11:31:27
8bj6jt,[Lambda Calculus] Could someone check my working for beta reduction?,"I'm trying to make a function G such that G<A,B,C>=<B,C,B+C> (so basically a fib generator)

Would letting G= λp.p (λxyz. ((λq.q) y z add(y z))) work, or am I not thinking this through properly? My working is

G<A,B,C> = [ λp.p (λxyz. ((λq.q) y z add(y z))) ] [λr.r (A B C)]

= [λr.r (A B C)] (λxyz. ((λq.q) y z add(y z)))

= λxyz. ( (λq.q) y z add(y z)) A B C

= λyz. ( (λq.q) y z add yz)) B C

= (λq.q) B C add B C

=<B,C,B+C>

which seems pretty sensible but I'm not very confident with beta reductions so I'm worried that I've made a mistake somewhere.",2018-04-11 18:04:30
8bgnzd,Best programming resources to refresh my memory and develop my skills in a week?,"Hi guys! 

I’m studying computer science but haven’t done much programming in about a month. I have a job interview in a weeks time that has an assessed computer science part to it so can anyone recommend any tasks or resources I can use to refresh my memory and get me best prepared for it? 

Thank you! ",2018-04-11 12:28:40
8bebz3,4-bit Multiplier question,"Trying to create a truth table for a multiplier that has (2) 4-bit numbers in, and an 8-bit output. I know you can create a generalized table in terms of A_n/B_n but for some reason I can’t wrap my head around where to start.

Thank you!",2018-04-11 04:13:32
7q8ziz,Applications that can add social value?,"Hello, I was wondering if there was some sort of list or forum where I could look at possible(and unmade applications) that could be beneficial and add some social value to society?

I'm currently a high school graduate taking a gap year in my studies. I initially had taken some computer science courses. To really do something worthwhile with my time, I want to work with someone/ or independently to create something that adds social value(benefits people in places where they dont have access to education or some sort of application that can just save time)

I'm new to programming. Having only gotten competent with c++, R and Scheme, I believe it's important to get your input, as I dont really know the full potential/capabilities of what exactly I can do at my level!

Thanks alot!",2018-01-14 01:55:07
7damdb,11.11: Alibaba’s AI-Powered Shopping Extravaganza,N/A,2017-11-16 06:35:15
6ow13c,Does this university program seem lacking ?,N/A,2017-07-22 16:54:55
5sy9mb,Is VB a compiler or interpreter?,"Had a question in a paper that was asking it, I thought that it was a interpreter because it shows us our errors after each line, but the answers said that it was a compiler. Then I looked online and everyone said that it was a compiler...
  
Isnt one of the major differences b/w compiler and interpreter that interpreter shows you your errors after each line while compiler compiles it all in one go at the end in one go, then converts it to object code (that is if you dont have any errors)",2017-02-09 05:48:22
5e522q,How Eve unifies your entire programming stack,N/A,2016-11-21 16:55:21
5c6931,Workarounds for Moore's law?,"Moore's law has only about 10 years left before it reaches it's absolute limits.

How will engineers and computer scientists work around this problem to continue producing faster and more efficient microprocessors, if at all possible?",2016-11-10 05:39:51
55lcqy,Stupid Security question,"http://imgur.com/a/AfNeB

Note: Security protocols here are purely IC related(the course is called ""Security for computer science"". It's basically the ""manual algorithm"" you make before writing anything. Much like you need to follow formal mathematics at our uni during a computer science study.

I'm sorry for asking a question here, I've read the guidelines and it doesn't appear to be illegal. So I'm currently following a course in ""Security"" on the side, being a mathematician as original study, so perhaps I'm missing something here. My task is to find one of the protocols where replay wouldn't work. The question states these are authentication protocols. Zero of the protocols have a timestamp as far as I can see. I've no idea what A or B are as it's nowhere explained, but I presume they're ""A random message related to the one sending"". Na, and Nb are ""numbers only used once""(nonces, term you might've heard before). The rest seems to be explained.

My problem is. If you just REPLAY, you have an EXACT imitation of the message you sniff, so how the fuck would ANY of these protocols, seeing they have no timestamp, work against replay?",2016-10-03 01:17:54
4y66ik,Top 10 places to learn coding (for free) — Annotdot,N/A,2016-08-17 15:21:43
4r2ubi,PVS-Studio is there to help CERN: analysis of Geant4 project,N/A,2016-07-03 17:12:26
4m5arg,where to learn computer science online from scratch?,"is there a place where they break it down to you all the way from scratch. like they place everything you need to know in an organized manner. 

thank you guys.",2016-06-02 03:45:49
4jrb4b,"Indefinite prison for suspect who won’t decrypt hard drives, US gov’t says",N/A,2016-05-17 14:58:39
4fkrw3,so I've been using codeAcademy for java and Command Line Linux...,"so I'm a really big ""learn by doing"" kind of person.
Does anyone have any recommendations for online resources learning coding (Learn By Doing style intermediaries)",2016-04-20 00:49:22
3b5d8g,Should I go back to school?,"I'm not sure if this is the right place, but I'm feeling kind of lost today and not sure what to do. 

I was in university for about 2 years working on a bachlor of applied computer science. Over one summer I got an internship at a company I really liked, and at the end they offered me a full time job. (It was a small mobile games company) I worked there for 2 years, and then unfortunately had to be laid off due to a big downsize at the company. 

Since then I've been doing freelance work,  at much better pay, and overall I'm pretty happy at the moment. 

One of the freelance gigs I picked up was teaching a class on game development through a local university continuing education program. One important distinction I was not the person who created the course, or was listed as an instructor by the school. I was contracted by the instructor, paid by him, and was also the instructor listed on the end of class reviews. I did however come up with the content of each class, and Mark it all, with approval of the instructor, and did all instruction on my own. 

Since these classes were wrapping up for the summer, I inquired with the school about doing my own classes through the same continuing education program. And they have said they wouldn't allow it since I did not have a degree. Apparently 3 months of teaching a course in the same field, and excellent student reviews don't count. They told me I should go back to school, and contact them when I graduate. 

I'm currently making about $20/$30 (Canadian) an hour doing part time and freelance work, wich still leaves some time for my personal projects, and I like that. 

I've had a few prospective employers tell me I should go back to school, most just based on the fact I have no degree. Should I listen to them? One of the reasons I chose not to go back is I was having difficulty passing 1 of the 2 math requirement. 

Would I be making more money? Would it be worth the time and money to go back? Or should I just seek out other employment, or other schools to teach through? 

Edit : replace companies I applied to, with interviewed with. I have no idea what the people that never contacted my thought. ",2015-06-26 02:41:00
3atemn,What would you like to ask to a machine during Turing Test contest?,N/A,2015-06-23 10:44:26
35gk10,how many classes do you guys take,"Hello , next semester I'll be done with my major preparatory requirements , and I was wonder about -- how many classes of the major core requirements should I take per semester ? 
- How many classes have you guys take per semester in your major core classes ?",2015-05-10 03:32:41
32dr93,Induction question?,"So I have to prove that 

3n^2 < n! while n >= 6

I can get the base case and do the inductive hyptohesis step

However I am stuck on this next step

I have

3(k+1)^2 < (k+1)k!

Where do I go from here?",2015-04-12 23:16:21
31egaj,What's your crazy workflow?,"Does anyone have any ridiculous workflows that they use regularly, and if so what spawned it and why does it work well for you? I was recently reading [an article](http://shawnblanc.net/sweet-mac-setups/) with a bunch of peoples work setups, and many describes how they would switch between a lot of programs all the time, and try to consolidate but it usually doesnt work",2015-04-04 07:39:59
2y2q2u,Which algorithm is faster?,"Given an unsorted array of size n (up to one million elements), I want to find the middle value of the sorted array.

Here's some pseudo for a modified quicksort that stops after the pivot becomes the middle element:

    sort(A[], p, r) {
    if(p<r) {
    q=Partition(A,p,r);
    if (q==(A length-1)/2);
    else {
    sort(A,p,q-1);
    sort(A,q+1,r);
    }
    }

Would it be faster to use quickselect?",2015-03-05 22:56:45
2umii0,Self-Taught Summer Syllabus before Entry into Computer Science Undergrad: Critiques Please!,"I am a student who will be enrolled in a very 'academic' CS programme in a university in the UK from September 2015. I'm currently away teaching in a rural monastery in Thailand, and as such, have been not been able to do anything CS related since October 2014, and won't be until July 2015 when I return home. 

While I was at high-school I was heavily involved with self-study (OpenCourseWare, CoursEra and so forth) alongside my formal studies.

I'm going to have roughly 2 and a half months to hit the books when I get back to 'catch up'. I've tried to create a rough 'syllabus' to get myself in a reasonable jumping point for entering the course. CS is a huge passion of mine & I've incorporated this as part of it.

[Anki](http://ankisrs.net/) refers to the flash-card application which I've used heavily in the past. [EPQ](http://en.wikipedia.org/wiki/Extended_Project_Qualification) (Extended Project Qualification) refers to a large personal write-up I did on the state of homomorphic cryptography in practical real-life applications when I was 17.

**Books Referenced in the Plan:**     
'[C Primer](http://www.amazon.co.uk/C-Primer-Plus-Developers-Library/dp/0321928423/ref=sr_1_1?ie=UTF8&qid=1422960306&sr=8-1)' by Stephen Prata.     
'[Introduction to Algorithms](http://www.amazon.co.uk/Introduction-Algorithms-T-Cormen/dp/0262533057/ref=sr_1_1?ie=UTF8&qid=1422960361&sr=8-1)' by Cormen & Lieierson.    
'[Concrete Mathematics: Foundations](http://www.amazon.co.uk/Concrete-Mathematics-Foundation-Computer-Science/dp/0201558025/ref=sr_1_1?ie=UTF8&qid=1422960439&sr=8-1)' for Computer Science by Knuth & co.

**The Rough Idea:**

> **Programming Languages:**   
> C Primer: 2 chapters a week, more if time available.
> 
> **Data Structures:**    
> Introduction to Algorithms: Subchapter (e.g. one type of data structure) a week. Word notes and Anki.
> 
> **Mathematics:**    
> Concrete Mathematics: Chapter a week.
> 
> **Technical Papers:**    
> Read papers you find interesting! This is a very casual activity. Make notes as you go.     
http://blog.fogus.me/2011/09/08/10-technical-papers-every-programmer-should-read-at-least-twice/
http://cstheory.stackexchange.com/questions/1168/what-papers-should-everyone-read
> 
> **Personal Project:**   
> Rewrite high-school EPQ (and presentation) in LaTeX.
> 
> Anki everyday, all appropriate previous CS decks.

I'd love some critiques, suggestions and opinions on this. Is there one book you think I should replace, or swap, or just not bother with? Is there a certain skill that I should prioritise on, rather than one described here?

I'll be incorporating my usual lifestyle (gym, social-aspects and family) alongside this, and treating it as a part-time job of sorts while I'm at home.

I completely understand that a university will begin a undergraduate course assuming almost zero subject-specific knowledge beyond a casual interest, but I really enjoy CS, would be studying the subject anyway, and just want to make the most of my time & enjoy it in the process!

Thanks,    
C.",2015-02-03 10:55:23
2rdzwi,How much percentage of completion on Khan Academy's world of math is deem competent as Computer Science person ?.,"I finished high school like 10 years ago, I am 28 atm. Since then I hardly touching any math beside basic Algebra. Recently I enrolled in Computer Science course, I am petrified as how poor my math are. I am practicing math on Khan as refresher course also learn new thing like pre-Cal. How much do you guys think on the World Math should I complete before can safely stay on the course. 

And anyone working atm, how much percentage you think you are on the World Math ?",2015-01-05 09:37:43
2prelm,Algorithm close to Travelling Salesman?,"As I rock my baby to sleep in my left arm, I sit here bored with phone in right hand. 

I'm far removed from uni and the TSP, but the following problem has come to my brain while I rock here for hours, haha.

Let's say a salesman wants to do business. He must do business in exactly 5 countries, and only 1 city per country. Only 5 countries are given, so every country must be used. 

We'll say 5 cities are listed for every country. Each city has a 'travel to' cost, and a 'business amount to be made $'. 

For example, one of the countries might be Canada. It may cost $637 to travel to Vancouver and $2100 can be made there. It may cost $400 to travel Toronto and $1500 can be made there. 

The price of future travel is not dependent on where you are. So we'll say each trip must be round trip and then you fly out of your home base again. 

You have a travel budget of say $2000. 

How would you solve this, especially for extremely large datasets? You could easily do this in 5^5, and figure out all permutations but that won't work for large data sets. Is there a better way?

TL:DR;

Algorithm Rules

- There are 5 countries
- There are 5 cities in each country
- $2000 flight budget
- The business person MUST fly to each country once (therefore one city per country). The business person cannot spend all their money flying to 4 countries, and not have enough flight budget left to fly to the 5th. They must go to all.
- All flights must be 'round trip' from the business persons home city. So the business person does not fly to vancouver, only to find out flight prices have since changed to Shanghai. The flight prices don't change.
- The goal is for the business person to make optimum business profit with the $2000 flight budget. 
- The flight budget does not impact the business profit whatsoever. If the business person only uses $1800 in flights, he cannot count $200 to his final business profit. The flights are a company write off, so he does not keep the leftover.

EDIT: Example Graph

Travel Budget: $2000

Travel Costs:

City Number|Canada|United States|United Kingdom|France|Japan
:--:|:--:|:--:|:--:|:--:|:--:
1|254|464|407|552|600
2|500|342|435|499|416
3|399|578|359|269|431
4|322|544|579|309|264
5|591|292|529|522|349

Profit To Be Made

City Number|Canada|United States|United Kingdom|France|Japan
:--:|:--:|:--:|:--:|:--:|:--:
1|2339|2022|2345|2969|2619
2|2030|2679|2368|2319|2307
3|2439|2557|2148|2613|2296
4|2212|2720|2600|2591|2434
5|2701|2155|2206|2070|2388",2014-12-19 05:19:44
2lzyio,Assignment Help: Propositional Logic,"So the question asks to derive a statement from a knowledge base using inference rules. 

The statement is (S \\/ R)

KB:

~P

P => (Q \\/ R)

T & ~Q

T => S



My first guess was to start by converting P => (Q \\/ R) to: ~P \\/ Q \\/ R. I also figured you can convert T => S to: ~T \\/ S but after these, I am kind of lost on where to go. I am going to keep working on it and if I come up with anything, I'll edit or comment.

Solution:

Since (T & ~Q) is true, T is true by And Elimination. Since T is true, S is true (T => S) by Modus Ponens. Since S is true, (S \/ R) is true by Or Introduction.",2014-11-11 20:12:30
2fvi0b,Relearning DS again. First structure then code or other way around?,"This is a pretty abstract question, but I am re doing my DS course for brushing up again before graduating and wanted to know if I should learn the structure (graphical) form and then derive the code behind it or first code then derive the tree/graph from it. ",2014-09-09 03:33:43
29pctm,Hey guys I need some people to tell me what its like writing a dissertation during their masters.,"So the school that I want to go to for a masters degree in computer science has three options, which are doing a basic project option that just takes one semester,  doing an advanced project that takes two semesters, or doing a thesis which could take 2 to 3 semesters. The program's handbook says that the two latter options are for students who have a good background in computer science, which I believe I have. I want to do the thesis option. I was wondering how you go about this. I want to start mines by the beginning of my second semester. How long does it take? How do you find a topic and an advisor? What was it like defending your dissertation? Were you able to graduate on time?",2014-07-03 01:48:56
27piet,BrownCS Findings Reveal CS Student Work/Sleep Habits As Possibly Dangerously Normal,N/A,2014-06-09 16:41:48
23k9d1,Has anyone here modeled the solar system? (cross-post from software engineering),"Hi guys! < 1 year of programming experience here. I've done a tiny bit of Ruby on Rails (was the Nth person to build a twitter clone) and am ripping through Structure and Interpretation of Computer Programs.
The idea of simulating planetary bodies in orbit around the sun along with plotting trajectories from one planet to another is a lot of fun. Ideally I'd like to do this in Scheme as that is what I'm immersing myself in now! I'm not yet sure if Scheme is even capable of something like this...it seems like I'd have to have objects with assigned attributes/variables and I'm not sure if a functional programming language like Scheme is capable of having that. Is Clojure capable of this?

Anyways, has anyone done something like this? Would love a few pointed fingers saying ""Hey, go here and do this! Here are all of the answers. All of them. You never have to do any investigating or doing on your own.""

The quoted text is half satire and reflects the thing we sometimes avoid :) And on a completely unrelated note, I am two days in with using Vimmium and it's been an absolute blast. I've never used Vim but I want to now. I'm not caffeinated at all and it seemed appropriate to share this.",2014-04-21 03:16:21
1w4ggd,can someone help me further my search on clusters/scheduling/MESI/thread sharing?,"I am doing research in distributed computing for a class and trying to understand some really basic concepts.

For example, lets say the environment consists of…

3 clusters, where

* each cluster contains a number of coprocessors and

* each cluster has a local cache.

A manager assigns threads to these clusters based on if the cluster has memory associated to a thread.

* has a cache that maintains some sort of consistency with the other caches in the clusters.

Now how can a manager, before assigning a thread to a cluster, know that particular cache lines in that cluster are not being used by other threads assigned to that cluster?

I came across the MESI protocol that adds extra bits to cache lines. Therefore, couldn't a scheduler keep a table on what cache lines are currently being used in a particular cluster, compare that to the thread being scheduled and if there are any matches between the database and the scheduled thread, stall the thread? Im sure this incurs a lot of overhead because from all the papers I've been reading, they schedule threads regardless if a conflict would happen, and squash the conflicting thread.

Is there a term or algorithm that I can sure for the above concept?

thanks for any help.",2014-01-25 16:48:33
1u3uzt,"The ""formal methods in computing science"" study club over at /r/computingscience has had a pretty big makeover. Come check it out to see if you'd be interested :)","Major changes:

* [extensive FAQ introducing the club and its philosophies](http://www.reddit.com/r/computingscience/comments/1u1cb2/a_welcome_to_prospective_members_along_with_a/)

* [an irc channel at ##computingscience](https://webchat.freenode.net/)

* [ranking system tracking progress (inspired by Battlefield 2142 :p), soon to be combined with member pages, where special pins and medals for distinguished achievements will be displayed!](http://www.reddit.com/r/computingscience/comments/1u1lmp/i_have_read_the_faq_and_the_papers_linked_in_it/)

These changes were the results of various suggestions and discussions, to which the club is still very open! [Hop on over to check us out if you think you'd be interested in formal methods in computer science.](http://www.reddit.com/r/computingscience/)",2013-12-31 18:40:28
1m3cmn,Alternative to my Intro to CompSci class,"I'm a sophomore in college and just started my first Computer Science class. I was really excited until I got to the end of my second class/second lecture. My professor seems to really know what she's talking about but she's also from India so I have a hard time understanding what she's saying and she has a hard time understanding what most of us are saying/asking most of the time. I'm now six classes in and so lost I'm close to ready to drop the class and try a different teacher next semester. So that's why I'm here because I know reddit can help me. I did some of the Intro to Computer Science course on Udacity this past summer, which I haven't finished yet but so far I haven't learned any concepts relevant to the class I'm taking.  

An insight to what we are supposed to learn according to the syllabus:  
 - We started the course with learning how to do some pseudo-code although I still don't fully understand it. Also worth stating that  these concepts are taught using Java.  
*I. Computers and Programs-overview of computer systems, language translating, and development environments, algorithms, syntax, semantics, programs and subprograms
*II. Software Engineering-problem definition, modularity, top-down   design, step-wise refinement, Object-oriented design, class design, software documentation and software engineering life cycle
*III. Testing-error types and detection, debugging and exceptional conditions
*IV. Data Types Variables, and Identifiers-integer, real, character, Boolean, string, finite precision errors, representation, scope and visibility,constants,operators, expressions, and operator precedence.
*V. Input/output-Interactive, reading and writing text files and recognizing end of file.
*VI. Classes-definitions of classes, methods, and objects, standard libraries, method arguments and return values
*VII. Decision Structures-conditional operators and logical expressions, if-then else, nested if-then else and case structures
*VIII. Looping-while, do while, for loops and infinite loops
*IX. Arrays-one and multi-dimensional arrays, processing  

I've just started: http://chortle.ccsu.edu/java5/index.html#01 (Introduction to Computer Science using Java)  
Which I found [here](http://www.reddit.com/r/learnprogramming/wiki/online#toc_0)  
I also found in r/learnprogramming:  http://programmingbydoing.com/ (Great because it's in Java)  
                                                 http://www.computerscienceforeveryone.com/ 

I know it's seems I've just answered my own post. I'm sure that these will be very helpful and maybe exactly what I need I'm mostly looking for additional resources maybe some lecture notes or anything else that might help. Of course if there is something better or equally as good I'll definitely take it! I'm also looking for something to help me understand pseudo-code. Is there any particular format I should follow? It's just like pre-coding right? What my professor did looked a lot like code, similar to python actually. I think that about sums it up.  

Programming by doing found [here](http://www.reddit.com/r/learnprogramming/comments/176iwa/i_give_you_the_best_200_assignments_i_have_ever/)
Computer Science for Everyone found [here](http://www.reddit.com/r/learnprogramming/comments/waln8/i_have_created_a_free_programming_course_of_over/)",2013-09-10 07:42:46
1ktm8c,"ELI5: Why is the application of an ""80% target"" in software development misunderstood? Or is it justified?","I'm not even sure if this is the right subreddit (or even site!) to ask this but I'm having problems trying to explain this in a layman sense even though it's obviously wrong & at a bit of a loss where else to best ask...

When working on a project, a project is broken down in tasks & worked on using [Agile development methodolgy](http://en.wikipedia.org/wiki/Agile_software_development).

Now, a manager states ""I want to see 80% of your tasks to be completed without further work resulting from code review or QA. The 80% target is considered an industry standard"".

From my understanding, this could be a reference to the [Pareto principle](http://www.reddit.com/r/explainlikeimfive/comments/llvse/eli5_the_pareto_principle_aka_8020_rule_of/) but almost certainly a misapplication of this principle. On the other hand, it may not be the Pareto principle but I'm not aware of any other 80% target in this context.

How to ELI5-ish the misconceptions of trying to enforce a 80% target on completion of tasks needing no further work in software development to a layperson. The tricky bit is that on the surface, most laypeople would go ""Ah yes, 80% of work needs to be ok. That sounds quite reasonable. The manager is right to ask this."".",2013-08-21 19:09:17
ys9b6,Big Data: What Key Points Should I Know (x-post from learnprogramming),"Long story short I went to university for a bachelors of science in computer science and mathematics and I've been working at a company I'm really unhappy with. A friend working as a developer just got me an interview with a company that specializes in big data and gets many generous grants (from companies like IBM) for the work they're doing and I want to brush up and do my homework before the interview.

Does anyone here have any suggestions on some crucial points of working with big data that I should brush up on concerning big data and back-end development for massive data sets? I'm doing plenty of reading on my own but thought it'd be a good idea to ask this broad question here and see what other resources I can pull in.

Any info/personal knowledge/resources are greatly appreciated. ",2012-08-25 00:57:25
ycee2,Is there anywhere I can find a bound copy of the ECMAScript language specification?,"I have no idea if this is a good subreddit for this, so sorry if this should be elsewhere. Basically I find myself referencing the standard (ed. 5.1) fairly often, and rather than going through a PDF it would be much easier if I could look through a book. I've considered printing it out myself, but it would be much better if I could get a bound copy.",2012-08-16 22:19:58
x89rn,Markov Chains in Plain English,N/A,2012-07-27 03:35:58
rrgo5,Choosing a specialization?,"I'm finishing my first year of university in Computer Science, and I'm going to have to choose a specialization soon so I can get my prerequisites in, and I'm wondering what kind of day-to-day stuff I could expect from each field before I make any decisions. My choices are:

Computer Game Design,

Software Engineering,

Algorithms and Complexity,

Scientific Computation,

Human Computer Interaction,

Computer Graphics,

Information Security

I'm leaning towards Human Computer Interaction because I think it would be really interesting to design GUIs and stuff, but I'm also considering graphics. The problem there is while I can do fairly decent work in Photoshop/Illustrator etc., I'm very artistically challenged with a pen/paper.

Any tips to push me one way or another? Thanks!",2012-04-03 17:43:22
p0fhn,"Satisfiability, part I: What is SAT?",N/A,2012-01-28 12:26:13
ooz4x,Help choosing courses: Compilers vs. Abstraction and Design,"This is a long post--thanks VERY MUCH in advance for taking the time to read / respond. 

I've been taking CS courses for the past 2.5 years to transition from my background in political science into CS. So far I've taken a bunch of math courses, and CS courses in Systems Programming, Data Structures, Theory of Computation, Algorithms, and Computer Architecture. 

Now I'm trying to decide whether to take a more introductory course in Abstraction and Design (syllabus at http://www.seas.harvard.edu/courses/cs51/docs/cs51-syllabus-2010.pdf) or a more advanced course in Compilers (syllabus at http://www.courses.fas.harvard.edu/~libe295/spring2012/index.html#outline).

Abstraction and Design pros: 

- It'll be incredibly useful. Though I've encountered a lot of the concepts of good program design, I still have a long way to go. I recently interviewed for a few full-time dev positions, and they wanted me to design an OO solution to various problems off the top of my head, including relevant design patterns, etc. While I have read some of the GoF Design Patterns book, I still don't feel like I've internalized the material (though I do understand all the *principles* of OO design, and TA'ed a course on it using Java, I don't have experience designing OO solutions in *practice*, which I've learned is a very different thing). So this would be very useful for industry and learning software development in general.

- It's easier than Compilers, and won't be stressful.

- Works well with my schedule.

Abstraction and Design cons:

- It might be too easy, so I feel like I'm not really using my time well.

Compilers pros:

- The course is very intense, and I'd learn a ton. I'd have written a C compiler from scratch by the end. And it's a pretty fundamental part of CS, and good to know for that reason.

- It's an opportunity to keep up a good relationship with a professor I've had before.

- I'd have it out of the way if I continue on to a master's program next year (I'll hear back from schools this spring).

Compilers cons:

- It's not as directly relevant to industry as Abstraction and Design, which is an important consideration if I don't do a master's program next year, and am looking for jobs in industry.

- The timing is bad with my schedule--I'd have to entirely drop my favorite extracurricular, which meets at the same time.

- It's a lot of work (I know from previous courses with this prof.), and would probably be stressful.


Thanks very much in advance for any suggestions you might have. I know it's ultimately a personal choice, but it's one that has implications for future academic/industry pursuits that you all have a much better understanding of than I do.


",2012-01-20 16:29:01
jmnuh,Can you guys recommend some reputable *online* CS M.Sc. programs? (preference to UK/Europe).,"I graduated with a B.S. in Computational Science from an ivy league school a few years ago.  Because my GPA was wimpy (mostly B's and B-'s in CS coursework) I decided to go straight into industry and not bother applying to grad schools.

Now after a few years, I have the suspicion that more exciting R&D type opportunities will open to me if I have the proper certification i.e. a CS Masters.

I've taken some hard grad classes as a non-degree student and feel better about my grad school prospects.  Only problem is money and relocation.  I can't really afford a U.S. school.  The U.K schools are within my budget, but I don't want to move to the U.K.  

This brings me to **my question**:  has anyone found some decent online Master's programs in the UK (or Europe) for CS?


",2011-08-18 12:08:26
it3bo,/r/lambdapuzzles/: A reddit for puzzles and challenges in λ-calculus.,N/A,2011-07-18 19:38:41
f1l6u,No compsci because I fear the math,"Hi,
I really don't know what to do r/compsci. I always enjoyed computer and programming. Started programming with basic when I was younger and I'm realy enjoying reading about how computer work and so on.
But when it was time to choose a field that I wanted to study I didn't chose compsci because I thought the math will be too hard for me. I always enjoyed math in HS and I also was pretty good and I also like to solve math related logic problems or puzzles, but I always heard that the math you learn in the unis is quite different and of course much harder. Because I thought I can't handle the math I chose to study a mixture of business economics and compsci. I really don't like the be stuff and I'm quite unchallenged with the compsci stuff, so I'm thinking about doing pure compsci now.
I have some questions for you, that you can hopefully answer me to give me a better view. I’m right that the math stuff is quite different than the stuff you had in HS, right? Can you recommend me a ‘
cheap’ book or ebook to see what the math is about in compsci? Is there a video course available for compsci (youtube?)? 
",2011-01-13 15:21:07
d69lx,Systems Software Research is Irrelevant,N/A,2010-08-27 19:09:45
clmxy,"My thoughts on self-awareness and artificial 
intelligence",N/A,2010-07-03 15:05:15
ckb0l,News website for IT in business,"I know there is plenty of websites with news for domestic (home) computer users. I wonder if there is any website that would post information about new trends, products, solutions for IT in business (mostly small and medium)? I work in IT my self and sometimes is just difficult to follow all these releases of new services, software and hardware. As example could give: Server technologies (hardware and operating systems), software (backups, system utilities etc) and services (remote access, all cloud services for virtualization, storage and backup). If there is no such a thing would you be interested in creating one? ",2010-06-29 21:27:57
8nzsm,Could Erlang potentially execute more efficiently on an asynchronous CPU?,N/A,2009-05-28 18:12:52
85aan,"Brief Odyssey Though Numbers, Logic, and Programming",N/A,2009-03-17 11:17:18
1k0wn8,[Humor] Stages of a relationship depicted by programming languages.,N/A,2013-08-09 13:47:34
66zf11,Has anyone used Microsoft Team Foundation Server?,"I'm a UNIX guy used to git, web frameworks, etc. I'm going to some big company this summer for an internship who uses C++, the msoft stack and whatnot. I heard they use TFS as their version control and pipeline, etc. 

I am not familiar with any of this. Can I pick it up quickly and how is it in the workplace? ",2017-04-23 00:32:51
6oiab,The fate of reduce() in Python 3000,N/A,2008-06-23 02:39:54
6ogmn6,Data Structures Related to Machine Learning Algorithms,N/A,2017-07-20 14:37:47
z8psp9,How's multiplication is not an np problem? what a billion digit number is being multiplied with another billion digit number? Can it be solved in polynomial time?,N/A,2022-11-30 12:05:06
kg0v1k,Looking to start a new beginning in compsci,"Hi all, Im about to embark in comp sci as my major, and I have ample experience in math up to calculus and was wondering if there were any recommended ways to get a jump start over winter break before i classes maybe in january",2020-12-19 04:06:18
adynj2,Which computer scientists have a good chance of succeeding as full-time solo indie game developers?,And why do you think they would be successful? What sorts of games might they design and build?,2019-01-08 20:37:49
9o8dm4,Why is the complexity of matrix addition O(n^2)?,N/A,2018-10-15 01:37:39
3bhi1b,Need advice from CS grad students who do something in the sciences?,"Hello, I'm originally a chemistry major who switched to a CS major because of a love for math and programming; however, I  still have a strong interest in Chemistry and was wondering if someone wanted to do computational chemistry or bioinformatics it would be feasible with a PHD in computer science while taking chemistry courses? Since right now I'm minor in chemistry and major in CS.",2015-06-29 07:00:31
4scapq,Free hackaton at the University of Tennessee,N/A,2016-07-11 17:59:36
17r2un,"Can someone point me the right direction (software, maybe hardware) for a project I want to undertake?","I am a middle school science teacher with some compsci background (not a huge amount though).  Basically, I want to create a website that will allow a student to remotely access my class via a webcam (a kinnect maybe?) and even be able to control it using a servo or something.  I would like the site to be able to do other things (chat room, an assignment manager, act as a gradebook of sorts...) but I imagine the streaming video would be the most challenging.

I have limited website development experience and don't want to code the whole thing from scratch in html.  What are the best software programs (something similar in vein to vb.net ?) that I can use to create a nice website layout and GUIs?  ",2013-02-02 13:18:42
ibg9i,How can i get the most out of a Multivariable Calculus course by a CS student?,"Hey guys!

This could probably fit better in /r/learnmath but i feel i could get better answers her. I'm taking a Multivariable course for the 3rd time! (First time i didn't do good, and the second time, i was just lazy to study it), but now i want to do very well, and get the most out of it. 

I'm studying CS and i want to learn as much as i can, specially a little bit more inclined to do stuff related to do CS during the course (i'll do this in my spare time of course). I know CS is mainly Discrete math but i think some of you could have done interesting stuff with Multivariable calculus topics.

Any suggestion is welcome! Thanks!",2011-06-28 17:07:22
6o288,Method Type Inference in C#,N/A,2008-06-19 12:58:12
172g1n,Jonathan Edwards: Down the rabbit hole of types,N/A,2013-01-22 18:24:42
awdro,A vaguely Gödelian question about the limits of programming languages,"So I was thinking about all the different types of programming languages that could be designed. It struck me that there's something that all pragmatic languages have in common: they all have the concept of the syntax error. In any language I can name, it's possible to mash the keyboard and come up with a program that won't compile or interpret. Insert Perl joke here.

But does this have to be the case? In principle if not in practice, is it conceivable to have a language that doesn't need to verify syntax correctness - a language for which any permutation of the associated alphabet is an acceptable program? To put it precisely: given a non-empty alphabet Sigma, can a language be designed which accepts those characters, and can compile any permutation thereof, and which is Turing complete? And can we prove the answer to that question?",2010-01-31 18:17:28
9av8m4,What You Need to Know Before Considering a PhD,N/A,2018-08-28 02:44:12
6ri9w,Pathfinding with A*,N/A,2008-07-13 02:29:18
njdyq,So you want a PhD in Theoretical Computer Science - How accurate is this video? [X-post from /r/programming],N/A,2011-12-20 03:45:21
k4pzs3,DeepMind 's Major Breakthrough in Computer Science..,And now it has solved a gigantic biological problem called the Protein Folding Problem which has been prevailing since 50 years and I feel like my words won't do justice to the level of achievement .  : [https://www.thecsengineer.com/2020/12/deepmind-s-major-scientific-breakthrough-2020.html](https://www.thecsengineer.com/2020/12/deepmind-s-major-scientific-breakthrough-2020.html),2020-12-01 17:51:37
cc11ab,Algorithm to find cliques of a given size k in O(n^k) time complexity,N/A,2019-07-11 20:42:59
60xgrq,Do you think that computer scientists will ever be as well respected as mathematicians or physicists?,N/A,2017-03-22 21:10:56
57rcu7,Are computer science and software engineering diametrically opposed with the former dismissing day to day programming as easy while the latter stressing that it is really hard?,N/A,2016-10-16 13:14:14
41uq22,What languages do you use at work?,"At my company right now in approximate order of magnitude:

* C#
* XQuery
* Javascript
* XSLT
* SQL
* If they count - SASS and Less
* Ruby (just a tiny bit to extend a tool)

As well we have dabbled in Java a bit for some language processing libraries, but haven't and probably wont' be able to use it in production. I am also threatening to drop some F# code into the codebase one day.

",2016-01-20 15:09:06
3ltkay,Looking for advice for high level Economics courses as a Comp Sci major,"Hey r/compsci,


I'm currently a junior in Computer Science and have been working my way towards an econ minor because economics has always interested me. I just finished up the core courses for the minor which involve two micro and two macro courses. Now I get to take part in the fun part of the minor which involve some more specialized higher level courses. I was curious as to what you guys think would have the best carry over to a Computer Science major.


So far the choices I have which I think would be good are:


* **Game Theory**: Here is a quote from the Wikipedia page page on game theory:
""Game theory has come to play an increasingly important role in logic and in computer science. Several logical theories have a basis in game semantics. In addition, computer scientists have used games to model interactive computations. Also, game theory provides a theoretical basis to the field of multi-agent systems. Separately, game theory has played a role in online algorithms. In particular, the k-server problem, which has in the past been referred to as games with moving costs and request-answer games.[29] Yao's principle is a game-theoretic technique for proving lower bounds on the computational complexity of randomized algorithms, especially online algorithms. The emergence of the internet has motivated the development of algorithms for finding equilibria in games, markets, computational auctions, peer-to-peer systems, and security and information markets. Algorithmic game theory[30] and within it algorithmic mechanism design[31] combine computational algorithm design and analysis of complex systems with economic theory ""


* **Mathematical economics**: This course would be pretty easy as its how economics is modeled using mathematics and the only prerequisite is business calculus, and being a math minor as well I think it would be an easier course but would be interesting to see how real life economic situations are modeled in a more formal manner.


* **International Finance and Open Economy Macroeconomics**: ""Trade balance movements, exchange rate determination; monetary and fiscal policies in open economies; international policy coordination; the world monetary system."" I think this course would be useful in a lot of areas in helping to determine future investments but also maybe if I get a job in the financial sector helping bridge the gap between the Computer Scientist and the finance people.


* **The Economics of Uncertainty**: ""Uncertainty and Risk as related to finance, insurance, health, labor, industrial organization, and macroeconomics"" This is another courses related to game theory and I think would be useful in general as a comp sci major because the course deals with uncertainty in contracts, something as Computer Scientist I feel like you should be aware of the many flaws that can happen in any system.


Please let me know what you think sound like the best choices would be, thanks in advance!",2015-09-21 16:19:36
2pveng,Any good books for learning to deal with Java strings efficiently? My current uni Java programming book is not cutting it.,"I'm using the current edition of Liang's Intro to Java Prog.  I'd like other resources, if possible please.

Thank you.",2014-12-20 08:51:02
27rt7r,"There are n dragons, each with an unknown amount of health. Each time you hit a dragon, it loses 1 health. My goal is to kill any dragon with as few hits as possible. Strategy?",I was thinking hitting each dragon once and then repeating until one is dead. This has complexity O(n*min[k]) where min[k] is the amount of health for the dragon with least health.,2014-06-10 08:41:55
507ttp,Artificial Intelligence - Why I (compSci undergrad) think the concept of an AI being unimaginably faster than humans is a flawed argument. Am I missing something?,"It seems like there is a common belief that AI will inherently be unimaginably faster than humans. For example [Sam Harris](https://youtu.be/PKExFcF2lHM?t=201) talks about how an AI could do the work that would take a human thousands of years in a single day. This same concept is expressed beautifully in the fictional film [her](https://www.youtube.com/watch?v=QFd4tUcSJsM). **If you haven't seen the film you might want to avoid watching the linked clip.**

What I've learned about computation theory (ungrad CompSci graduate) leads me to believe that while it's entirely possible for an AI to be faster than a human I don't believe it will be as significant as the above two examples make us believe. To me they are arguing that humans are O(1,000,000,000n) and an AI is O(n).

When we compare algorithms using BigO we don't care about coefficients. As soon as we start looking at larger problems with larger data sets those big scalers quickly become insignificant. If we have a problem that takes 1,000 years to compute does it really matter if the human requires a week to write the program but an AI can do it in half a millisecond? The difference between 365,000.000000000005 days and 365,007 doesn't really matter does it... Even if the computation was a only a year the extra week is't that significant.

This example isn't that crazy yet the common belief is that an AI would arrive at the exact answer faster than we ever could. I just don't see what little I know about computational complexity that being able to scale up by any factor will matter.  You have a an obvious bottleneck. 

Am I missing something or is AI going to lack absolute certainly and be prone to making mistakes just like us because the computational cost for getting the best/exact solution is just too computationally expensive. Even if we learn something radically different like P = NP aren't there still enough unsolvable problems forcing you to always rely on an educated guess?

Thoughts?

**EDIT:** Statements like [this](https://youtu.be/PKExFcF2lHM?t=315)  I don't think we really know the algorithms of the biological brain yet. However, I think it's a common belief we don't run off logic gates. There is no clock cycle. It's a completely different architecture. I don't think our minds look for exact solutions to problems instead look for solutions that fit patterns. 1+1=Turtle can be true statement in our minds but not true for a traditional computer. The fact that a computer can compute simple arithmetic faster and more accurately than an human seems to imply that all computation is faster which doesn't sit right with me. Not because I don't believe it can be possible but I don't believe I've seen evidence of this. 







",2016-08-29 22:46:29
f2q4f,What language should I learn? (2nd year Comp Sci major),"So I'm a 2nd year computer science major and all I really know is C++ (I know the basic syntax differences of Java too, but the 2 languages seem relatively similar to me). I was wondering what language I should teach myself in my spare time. I was thinking Python because I know Google has a plethora of free lessons online. But I was also thinking about PHP. Do you guys have any suggestions, and how I might go about teaching myself another language? ",2011-01-15 08:12:55
egp2f,"Goedel incompleteness results get ""real"". Our standard rules of arithmetic might need updating, and it might not be the last time either. Via /r/PhilosophyofScience.",N/A,2010-12-05 21:35:45
z8f1u,Why is MATLAB inefficient compared to C/C++ and Fortran?,"In our Numerical Analysis class, we are going to be using only MATLAB to do calculations. One of the first problems we solved was approximating e^(x) where x = 0.5. The professor gave us a piece of code that was rather inefficient and we had to make it more efficient. No problem there.

He asked us to think and write about why MATLAB is inefficient in doing calculations like the one above compared to code written in C/C++ or FORTRAN. We were stumped. It was assigned as a ""group worksheet"" where we could bang our heads together to come up with the answer and none of us really have any low-level programming experience. Two of us (including myself) have taken computational physics classes where we have written tons of code in multiple programming languages. But these languages were just tools for us and we didn't study them in-depth.

 He mentioned something about interpretive languages vs. compiled languages, but I'm not sure what he meant by that. He also asked us to look up ""JIT"" for MATLAB and start from there but I don't quite understand the whole compilation deal.

So, why is MATLAB inefficient in doing such simple computations? I am assuming that it is rather efficient in doing matrix algebra compared to C/C++.

Thank you for your help, in advance and this is not a real priority since we are taking a math class. I think the question was posed to help us get an understanding why we shouldn't use MATLAB for every single problem we come across.",2012-09-02 15:59:42
p3ocm,"Hi /r/compsci. I've designed myself a tattoo, and I'm seriously considering whether to get it done (on the upper right of my back). What do you think?",N/A,2012-01-30 23:12:04
2tfb8j,The AI Revolution: The Road to Superintelligence,N/A,2015-01-23 18:03:57
ajick,AskCompSci: What's the best way to index a paper journal?,"I want to start keeping a paper journal for miscellaneous writings and was  thinking about how to organize and index it. The journal should allow for different sections of writings (e.g. fiction, random thoughts, doodles) as well as have the ability to insert new sections at any point.

So far, the easiest way I could see is just buying a new journal for each new section. The 99 page spiral binders are about a dollar. The problem is that some new sections will probably get ignored while others might have more entries. This means a lot of paper waste as well as requires carrying multiple journals around.

The other way I was thinking was just creating a table of contents pointing to each section. The sections will have a page buffer with possible pointers to a next buffer. 

I figured some file system geeks would have a cooler solution...",2009-12-29 12:09:24
6saxa,Worst Chapter Zero of Any Computer Science Book,N/A,2008-07-17 22:19:29
zfgxw9,What happens when you type a URL into your browser?,N/A,2022-12-07 22:54:59
4uulx4,Are ER diagrams some sort of joke that academics play on first year students ?,"Or are they a real thing that people actually use.

If so lol,  get a better method. ",2016-07-27 13:31:09
1kzwwm,"Need help! Yes, homework but no answers required.","I'm struggling to understand a question. I need some help interpreting what they want. The questions are based around an 8 digit student ID eg 12345678

""For instance, d*_7_* d*_6_* d*_5_* d*_4_* d*_3_* d*_2_* d*_1_* d*_0_* where d*_i_* : i = 0, 1, 2, 3, 4, 5, 6, 7 is the multiplier for 10^i :
i = 0, 1, 2, 3, 4, 5, 6, 7.""

The question is: ""Compute the uID = (d*_7_* d*_6_* d*_5_* d*_4_* d*_3_* d*_2_* + 100)""

Is that just simply multiply the integers 7 thru 2, plus 100?
Any guidance in the right direction would be appreciated

Thanks",2013-08-24 10:22:50
hr1s2d,I built a decentralized legal-binding smart contract system. I need peer reviewers and whitepaper proof readers. Help greatly appreciated!,"I posted this on /r/cryptotechnology .  It attracted quite a bit of upvotes but not many potential contributors.  Someone mentioned I should try this sub.  I read the rules and it seems to fit within them.  Hope this kind of post is alright here...

EDIT: My mother language is french (I'm from Montreal/Canada). Please excuse any blatant grammatical errors.

TLDR: I built a decentralized legal-binding smart contract system. I need peer reviewers and whitepaper proof readers. If you're interested, send me an email to discuss: info@steve.care . Thanks in advance!

Hi guys,

For the last few years, I've been working on a decentralized legal-binding contract system. Basically, I created a PoW blockchain software that can receive a hash as an address, and another hash as a bucket, in each transaction.

The address hash is used to tell a specific entity (application/contract/company/person, etc) that uses the blockchain that this transaction might be addressed to them. The bucket hash simply tells the nodes which hashtree of files they need to download in order to execute that contract.

The buckets are shared within the network of nodes. Someone could, for example, write a contract with a series of nodes in order to host their data for them. Buckets can hold any kind of data, and can be of any size... including encrypted data.

The blockchain's blocks are chained together using a mining system similar to bitcoin (hashcash algorithm). Each block contains transactions. The requested difficulty increases when the amount of transactions in a block increases, linearly. Then, when a block is mined properly, another smaller mining effort is requested to link the block to the network's head block.

To replace a block, you need to create another block with more transactions than the amount that were transacted in and after the mined block.

I expect current payment processors to begin accepting transactions and mine them for their customers and make money with fees, in parallel. Using such a mechanism, miners will need to have a lot of bandwidth available in order to keep downloading the blocks of other miners, just like the current payment processors.

The contracts is code written in our custom programming language. Their code is pushed using a transaction, and hosted in buckets. Like you can see, the contract's data are off-chain, only its bucket hash is on-chain. The contract can be used to listen to events that occurs on the blockchain, in any buckets hosted by nodes or on any website that can be crawled and parsed in the contract.

There is also an identity system and a vouching system...which enable the creation of soft-money (promise of future payment in hard money (our cryptocurrency) if a series of events arrive).

The contracts can also be compiled to a legal-binding framework and be potentially be used in court. The contracts currently compile to english and french only.

I also built a browser that contains a 3D viewport, using OpenGL. The browser contains a domain name system (DNS) in form of contracts. Anyone can buy a new domain by creating a transaction with a bucket that contains code to reserve a specific name. When a user request a domain name, it discovers the bucket that is attached to the domain, download that bucket and executes its scripts... which renders in the 3D viewport.

When people interact with an application, the application can create contracts on behalf of the user and send them to the blockchain via a transaction. This enables normal users (non-developers) to interact with others using legal contracts, by using a GUI software.

The hard money (cryptocurrency) is all pre-mined and will be sold to entities (people/company) that want to use the network. The hard money can be re-sold using the contract proposition system, for payment in cash or a bank transfer. The fiat funds will go to my company in order to create services that use this specific network of contracts. The goal is to use the funds to make the network grow and increase its demand in hard money. For now, we plan to create:

A logistic and transportation company

A delivery company

A company that buy and sell real estate options

A company that manage real estate

A software development company

A world-wide fiat money transfer company

A payment processor company

We chose these niche because our team has a lot of experience in these areas: we currently run companies in these fields. These niche also generate a lot of revenue and expenses, making the value of exchanges high. We expect this to drive volume in contracts, soft-money and hard-money exchanges.

We also plan to use the funds to create a venture capital fund that invests in startups that wants to create contracts on our network to execute a specific service in a specific niche.

I'm about to release the software open source very soon and begin executing our commercial activities on the network. Before launching, I'd like to open a discussion with the community regarding the details of how this software works and how it is explained in the whitepaper.

If you'd like to read the whitepaper and open a discussion with me regarding how things work, please send me an email at info@steve.care .

If you have any comment, please comment below and Ill try to answer every question. Please note that before peer-reviewing the software and the whitepaper, I'd like to keep the specific details of the software private, but can discuss the general details. A release date will be given once my work has been peer reviewed.

Thanks all in advance!

P.S: This project is not a competition to bitcoin. My goal with this project is to enable companies to write contracts together, easily follow events that are executed in their contracts, understand what to expect from their partnership and what they need to give in order to receive their share of deals... and sell their contracts that they no longer need to other community members.

Bitcoin already has a network of people that uses it. It has its own value. In fact, I plan to create contracts on our network to exchange value from our network for bitcoin and vice-versa. Same for any commodity and currency that currently exits in this world.",2020-07-14 13:44:34
rhjbd,one of the biggest compsci conferences seems to be a scam running since 2006,N/A,2012-03-28 14:06:04
a1sqb,Help: Shortest distance algorithm on a VERY large graph,"I'm looking for an algorithm to find the shortest path between two URL's, or two Wikipedia pages.

For example, the shortest way to get from the wikipedia article of Reddit to the article of Computer science is to follow the link to Science, where there is a link to Computer science.

Assume that all links are static, and that it is impractical to either load the entire graph nor traverse its entirety, is there a practical algorithm to find the shortest path, or prove that no path exists?

(I'm upvoting every comment)",2009-11-06 23:43:55
bw0ly2,Place to meet other computer science people and hang out,"What's up!  I have started a discord to find new buddies who are also interested in CS, play games together, talk about movies and such. We do not talk about programming or answer any kind of questions. We are purely focussed on getting closer to each other and socialize. Well, if you like the idea, feel free to join us at  [https://discord.gg/jvX4xDa](https://discord.gg/jvX4xDa)At least I personally hope to meet you. Im out, pce.",2019-06-02 18:36:06
1dfg5v,I Didn't Want Computer Science - Reflections of a graduating CS Major,N/A,2013-04-30 19:05:27
248s19,NEW Language! The Avail Programming Language. [x-post /r/programming],N/A,2014-04-29 02:24:56
7ih5h,Can you name these computer science terms from their definitions? ,N/A,2008-12-10 02:00:27
1h16mq,"Why don't we use CPU/RAM-usage for ""true"" random generation?","I was wondering,

Wouldn't it be possible to use the CPU and/or RAM -usage in % (eg. 96.412638123%) as seed for randomly generating integers?

A (naïve) implementation could be something like: SHA256(CPU+RAM)
(the clock and various other variables could assist, obviously)

To me this seems almost true random, because there's no way of predicting the exact CPU-usage in 2 seconds from now - even if we had access to the source code of every running program.

(I know that since computers are deterministic, it's not actually truely random, but it serves as a damn good approximation, to me.)

Am I out on a limb here, or is this valid?",2013-06-25 12:01:43
49vqf1,Are there concepts in CS that won't become outdated in the future?,"I really enjoy the CS courses that I take due to how challenging it is.

However it feels like the knowledge I gain from math and physics will last a lifetime and (maybe?) improves my thinking more so than programming or CS theory.

For example in my CS course we're learning about sorting algorithms but in other programming languages like Python and Swift I can simply type .sort() or .sort and an array will automatically be sorted based on alphabetical or ascending/descending numerical order.

What if future programming languages makes programming so trivial that all the CS theory that I'm learning simply becomes irrelevant?

I would like to work in interesting fields in CS like AI and robotics. If possible.

Am I simply better off majoring in mathematics first? Then going for a masters degree in CS?

 It seems like learning as much math as possible will always be useful. But it's frustrating learning about concepts in CS knowing that it will potentially be outdated knowledge in the future.",2016-03-10 22:00:15
3cqkrc,When Algorithms Discriminate,N/A,2015-07-09 23:52:38
8aqo0,Researchers find ways to sniff keystrokes from thin air,N/A,2009-04-07 19:25:44
4zsdxx,What is the best GUI designer for someone who can't write code.,I want to design an app to be used at my workplace for editing databases.  I do not know how to write code.  I want to create GUI's that I can show to a programmer so he can write the code.  What is a good GUI designer that I can use?,2016-08-27 03:03:39
4fehnp,"As someone whose eventual goal is a Masters in ML, am I wasting my time studying trying to get certs?","Right now I'm a computer science major working towards my bachelor's, though I'm closer to the beginning than I am the end. I plan on clepping out of a few courses and working towards getting my A+ cert in the summer, and am seriously considering getting my linux+(because personally I really never use windows) and then some security certs(because even though I want to make my career Niche in ML and AI, I really want to work in security, if only as a hobby). 

I know my coding skills need to be up buffed up if I'm going to make my career in ML and AI in general, but I would rather enjoy working in IT, or security while going through to my masters. Will I actually gain skills that would be beneficial as I progress along my Career path, or am I better off just doing coding challenge after coding challenge and ignoring the more IT/Security based skillsets and Certs?",2016-04-18 22:38:30
4cpbx0,What are your views on P vs NP ?,"Hello [/r/compsci](https://www.reddit.com/r/compsci)'s,

Few months back I completed reading [""The Golden Ticket: P, NP and the Search for the Impossible""](http://goldenticket.fortnow.com/) and I was amazed on how problems falling under P vs NP are been solved right now. It would be a breakthrough in Computer Science if this problem was solved, plus the one who solves it get [a million](http://www.claymath.org/millennium-problems/p-vs-np-problem) in   his/her pocket !

What are your views on P vs NP ?",2016-03-31 09:45:33
42lwt4,How to explain what an API is to the HR people?,"I'm kind of stuck on this one. I've tried the wikipedia Simple English entry here: https://simple.wikipedia.org/wiki/Application_programming_interface

""An Application Programming Interface (API) is a set of functions, procedures, methods or classes used by computer programs to request services from the operating system, software libraries or any other service providers running on the computer. A computer programmer uses the API to make application programs.

Types of API include web services API like the Twitter API, which allows programs to use the API to receive updates on tweets""

However, this isn't making sense. They are not terribly helpful in explaining why they are confused. Any help? 
",2016-01-25 15:31:48
40w2jl,How do you explain Computer Science to those who know nothing about it?,"Particularly, to people who think that Computer Science == Programming.

How can you explain it using simple terms, examples or analogies for people who are genuinely curious?",2016-01-14 04:40:56
3r8noe,"Anyone know FORTRAN? If so, NASA is hiring",N/A,2015-11-02 18:19:39
3lxfs3,Logic Programming @uni,"I am currently going into third year in US university and we of course have to choose courses. We got screwed over by administration who moved a course I wanted to take, Operating Systems, to next semester. There are only a few courses left that I do not have interest in like compilers and then there is logic programming with mainly Prolog. My question is how useful would such a course be in industry and whether it would actually make more sense to just learn OS course on my own during this semester. The reason for that is imbalance and second semester has an insane course that will require a lot of time.",2015-09-22 12:24:53
3ku7jr,To C or to LLVM .. that is the question.,"I'm now heavily confused about my programming language.

Should I convert it to C, or should I convert it to LLVM?

I've got it pretty much to a C-like language, so translation to C may not be hard. I like it because I can say, look I'm platform independent.

But LLVM offers a stronger semantic reasoning about my language, adding debbuging information becomes possible.

Anybody else have been in a similar dilemma to me?",2015-09-13 22:47:27
3c6ezn,Idea about final year project?,"Hey guys. First time poster here. I'm a computer Science student (majoring in Computer Science and Networking) and has no fcking idea of what to do for my fyp. I'm on my third year doing internship nowand the fyp is coming next semester. 

I have an interest of doing something with bittorrent but still don't know what to do. I would be glad if you guys can give me some ideas.

Also obligatory 'my english sucks sorry'.

",2015-07-05 07:20:57
39my9l,Where can I learn more about machine learning?,"Hi so I've been interested in machine learning and how Google now and Netflix algorithms works, I was hoping to maybe implement my own rudimentary one but I do t even know how to start or where to read up on this in terms of what is good and acceptable way of learning the new machine language code. So if anyone could point me to the right direction that would be awesome ",2015-06-12 21:55:16
38f3xi,Why we fell out of love with algorithms inspired by nature | phys | Intl. Trans. in Op. Res.,N/A,2015-06-03 20:13:00
2yijxp,Which API is used by pbrt?,"My question is which api used by PBRT - http://www.pbrt.org/ like openGL or Direct3D?
More specifically which graphics library is used by pbrt? ",2015-03-10 02:21:48
2vkdyc,is a diploma degree in Computer Programming and Analysis worth it?,"Hi there! I am currently a student in my first year of university just taking a 4 year arts degree. I re-thought my educational path probably every night this first year on was this 'arts' degree really worth it... after all i am spending thousands of dollars to be here. Now i'm thinking about a co-op college diploma at a local college down the road but i am unsure on weather this is actually worth it. Would employers not want to take me in for a job interview in the future because i only have a college education and not a university one? If you can, take a look at the link i posted and let me know what you REALLY think of the program. Awesome, have an unreal day fellas. 

http://www.senecacollege.ca/fulltime/CPA.html",2015-02-11 19:16:33
2prkex,Computer science twilight zone.,"A month ago I scored perfect on a computer science assignment question. It's a proof. But get this: I've spent ten minutes now trying to understand my answer or the answer sheet answer, and I'm completely lost. In fact, I *don't even understand the question*! It's like my doppelgänger did the question for me.

It's an extremely weird experience seeing a detailed explanation from yourself a month ago that you do not understand.",2014-12-19 06:24:43
2pbe8z,Why is a one-time pad impractical?,Technically all that's required is for our pad to be at least as long as our message right (besides being awesomely random)? so doesn't it just needs to be as long as the larger frames an ethernet card might send? So if size is not the preventative factor... what is?,2014-12-15 01:53:05
2dlh1h,How do I prepare for a class with professor who has a well known terrible reputation?,"I'll be taking operating systems in the fall. The name of my professor has been posted and I've done some research on the guy and spoke with a few classmates who have had him before. His reviews are terrible and most people are advised to stay clear of any of his classes.

He is the only teacher teaching this class, and I'm very worried.

Tips/Advice on how to cope / how I can succeed? Professors usually make a huge difference for me in a course.

Edit: Forgot a letter in the title, oops!",2014-08-15 01:37:50
2bp7bd,Major life decision,"Would I be able to survive majoring in computer science with little background knowledge and with little to no programming experience? I'm really interested in the field, but I'm worried that I may not stand a chance because I wasn't interested in it earlier. (I start freshman year in the fall) ",2014-07-25 15:45:15
24y1xa,Good computer science science fair project?,N/A,2014-05-07 12:12:31
218roz,Yak-Shaving Autodidacticism,N/A,2014-03-24 17:04:40
1xtb6q,[UK] Difference between Computer Science and Electronic Engineering (,"Hello everyone!

I've recently got all my Uni offers (yay!) and I'm having trouble where to go. I've been offered to study CS at Manchester Uni and a CS + EE joint honours at Bristol. I prefer Manchester as a City and Uni but I'm not sure whether EE is more for me or CS.

So what is the difference between EE and CS?

Obviously, CS = Software and EE = Hardware but for someone who is interested in both Hardware and Software this doesn't help so I have a few basis questions. If you could answer them that'd be great:

* How is the application of maths different in EE and CS? Is CS more discrete?

* Could you get away with a pure Software project for your final project if you did EE? (And vice versa)

* How do the job opportunities vary?

* Is it easy to switch disciplines after graduating?

Thanks for reading this!",2014-02-13 16:49:42
1r8fbe,How much of CS is dedicated to making programming tools work?,"I'd like to have insight from experimented people about this. Here's the situation that inspired my question:

I just started a bachelor's in CS and I have this course in which we learn how to code in ASM (based on ARM processors). We have 6 assignments in total and the first three were about installing the Android SDK, NDK, an AVD and making debuggers work (Android and DS-5), and making all that stuff work through Eclipse.

So as you can see, a big part of the assignments is about installing stuff. And so many bugs occur while trying to make it all work, it's not even fun. We just got to our first assignment that is actually about coding in ASM (we are given simple conditions in C and we have to translate them in ASM), and I wasted another 6 hours trying to make the debuggers work in vain. So I just resigned to write the ASM code and hope for the best.

It's still frustrating that some tools aren't working properly. Since it's my first semester ever in CS, I was wondering what to expect from other classes and the career in general. 

Given that about 70% of my work in this course has been about making tools work (and 30% about coding), is that a good approximation of the time that people in CS spend on that?",2013-11-22 18:40:58
1o4b7b,Artificial Intelligence Decision,"Hey everyone, So next semester is my final semester at the university and I am recieving my BS in Computer Science w/ a specialization in AI. For my final semester I am doing an Independant study for some credits. In independant study I get to choose a AI subject to work on. So my question is, can you guys give me some ideas to research I am open to all areas of AI. Whether it be Game theory, NL processing, or anything else. Any interesting ideas would be much appreciated.",2013-10-10 03:41:31
1hij33,Suggestion for topic for computer science introduction class?,"I have a work to do for a computer science introduction class. I can chose any topic. It's supposed to be a introduction to paper writing.
I don't know much about that, any suggestion?",2013-07-02 18:56:01
1doq63,How to go about the P versus NP problem?,"Hi everyone, how would one go about trying to solve the P versus NP problem? What courses/textbooks/books should one read to become learned in the matter? And just as a bonus question, do you think the problem will be solved in the next 50 years? Thanks! ",2013-05-04 17:27:01
umpw8,What is a good certification for someone wanting to get into video game development?,"My employer just allowed for certification funding and I'm trying to find out which one would be most beneficial for a career in video games.  I know Perl, C/C++, Java, and Python so far.  Should I just get certified in one of those languages first? Thanks!",2012-06-05 21:07:06
sr1un,Ask CompSci: name for something more than a graph?,"I'm currently dealing with a graph-like data structure with weighted edges using basic Dijkstra to compute shortest paths and to generate shortest path traversals. 

However, based on the paths that are computed from a node, I dynamically add additional edges from the node to other nodes to capture the actual graph topology of my problem. Is there a well-known name for a graph-like data structure where we add additional edges to a node based on paths computed from that node; which I guess is strictly no longer a (simple) graph? Or should i consider this construction as just another data structure with no special properties that we can leverage? ",2012-04-25 02:08:54
rhr0t,Is it possible to make a comment generator that analyses a piece of code and automatically comments it?,I was just curious if such a thing is actually possible. Is a similar software existent in the market right now? How efficient is it / can it be?,2012-03-28 16:47:22
mtbwr,*Actual* matrix multiplication breakthrough: The magic of tiling!,N/A,2011-11-29 14:09:43
jyxzp,"I want to implement automatic verification for Hoare logic, but don't know where to start.","Hello everyone, I think the title speaks for itself. I know some Hoare logic, but I don't know much about automatic reasoning/verification. I assume verification (of 1st order logic in particular) is tied to SAT problem, am I right on this one?

What books/papers would you recommend?

TIA.",2011-08-30 10:53:41
fvj8g,What is the theoretical difference between a neuron and a memristor?,N/A,2011-03-02 03:41:09
bv7cy,colossal turing machine made in dwarf fortress,N/A,2010-04-23 16:52:30
awkkb,Core concept for programming the Universe,N/A,2010-02-01 07:24:26
tgzlg8,Method Chaining with Fluent Interface Pattern,"By this pattern, you can create specifically ordered method chains.  For example, the first method must be A(), then B(), then C() or D(), then E()…(like entity framework or linq)   


[https://levelup.gitconnected.com/method-chaining-with-fluent-interface-pattern-d01e75d4bb3d?sk=dd73c82a140662b01dceaa7149d46d72](https://levelup.gitconnected.com/method-chaining-with-fluent-interface-pattern-d01e75d4bb3d?sk=dd73c82a140662b01dceaa7149d46d72)",2022-03-18 11:54:24
sczrlv,Programming humans,"Is there some part of computer science that uses computational techniques to ""program humans""? For example, if you're the manager of a call centre or a sales force, you're essentially implementing some argmax algorithm across a distributed system. A lot of tasks in sales involves ""If customer objects to X, then offer Y.""

A loose analogy for a given worker would be:

Brain = Hardware

Mind = OS

Skills = Apps

I'm not trying to reduce the human spirit to a mere machine, but rather thinking about how to maximize workplace efficiency such that people can work less and do what they really want.",2022-01-26 06:52:51
scw4mo,"I don't know if this is the right sub, but why is markdown still not a standard for text files?","From a consumer pov, markdown beats standard text files in almost any way. Many people haven't even heard about it. Are there any downsides to markdown from another perspective? If no, why not use it as a standard?",2022-01-26 03:29:12
ip2vpy,What exactly does Application Programming Interface (API) mean?,"The more I read up about it, the more confusing I find it. Can anyone explain it please?",2020-09-08 21:43:36
b8jtl2,New Emerging Threat: Drones Are Fast Becoming A Cyber Security Nightmare,N/A,2019-04-02 14:19:20
aqq1t0,How does a computer 'do' math?,"Let's say I have the string ""1+1"". How does a computer 'know' to return 2? 

Is there some table somewhere that tells the computer to return Y given some combination of binary X?

",2019-02-14 23:19:04
aosu4p,Are there any serious barriers to completely removing human pilots from jetliners from AI and/or security perspectives?,N/A,2019-02-09 14:37:36
ao7opr,"Survey: Professional Developers how do you use regex? ($5, 10 min)",N/A,2019-02-07 19:46:28
anehgs,C++ related questions and future steps.,"Hey r/compsci

&#x200B;

I have quite a few questions, and they might be poorly organized. Hence, I've used bold text for the questions specifically.

I've learned C++ (which is my first language) to a fairly proficient level. This includes the basics, data structures, inheritance, classes & objects, linked lists, constructors-destructors, files (binary and text) etc. I want to master every aspect of C++ that is valuable and useful in the industry/academia, or maybe could help me in learning other languages, or whatever. So, **is there anything I missed out on, or should learn before progressing to other languages?** Or as a matter of fact, **what would you recommend should be my next goal, as a student?** I was thinking of learning Python (which I found slightly easy while going through a few tutorials), Java (Android development) or Swift (iOS development. **Is this something I could pickup as an auxiliary skill?**).

*Note: I'm a high school senior who's going to university in a couple of months to study CS. I've done 2 projects that I would consider notable. I've recently taken an interest in cryptography and would like to expand on it and take it to the next level.* ***Any tips to achieve this?*** *I fell like this topic is more theoritical, and although I thouroughly enjoy it as it is, I want to see the application side of it.* ***Also, how do I convert my programs/projects to a interact-able and accessible form, like mobile apps, desktop apps, web apps, or anything that people can access.***

Another concern for me is that I've learned C++ on an *ancient* compiler - Turbo C++. Now I want to transition to a more modern compiler which is actually used in the industry/academic field. **What compiler would you suggest and how much syntax and conceptual deviation is there between Turbo C++ and that particular complier?**

&#x200B;

Thanks for any and all help. Sorry if I violated any rule of this subreddit; it's my first post. If this is the wrong subreddit, please tell me which is the right one. Also, if I made any mistakes in assuming anything, please correct me.

&#x200B;",2019-02-05 14:15:01
aedehg,I lied on my resume for entry level Python programming and am nervous,"I'm broke. I'm only decent in c++ (I'm being nice),  but the position is for people with skills in Python. 

Today, earlier this morning I revamped my resume completely. Stuffing it with so much detail and experience that I didn't fully posses. I filled out some IT and Software Dev. Jobs and got a call by from a few of them . 

I guess I got desperate. It's not easy, going to college and living with other adults that live primarily on disability but can barely afford the cost of living, so now I'm trying to support the household. 

I'm currently in school for computer science (sophomore).  Retail jobs and even fast food restaurants are getting harder to come by or too far away to drive to on a weekly basis. 

I'm freaking out and thinking of just calling the interview off...",2019-01-10 00:31:59
abn3sn,How I learned zk-SNARKS from scratch - Great read on blockchain programming,N/A,2019-01-01 23:06:27
980frw,How do I visually describe data sizeTXT vs images and Video to my Mom?,"I’ve searched fruitlessly for a diagram that explains the size of an email, a book or text to how big just a JPG is, or a and a Movie to my Mother. She got it when I sketched it on paper... sort of. But I cannot find a good diagram that I can just link to others. Google hath failed me.

Somewhere, someone has to have a a diagram of this, no?",2018-08-17 08:02:38
86c35a,Trust Chains: the Solution for Online Payments,N/A,2018-03-22 14:54:03
7vuk8p,Is a discussion website(like reddit) object oriented?,"Help, for my object oriented class, my team wants to make a discussion site like reddit.


I just don't think this is the best idea for a object oriented project? The team leader thinks its a great idea( since its easy I suppose), but I don't see it happening from my past html/php/css experience?


we also have to use a object oriented framework. Any ideas as to how/if it will work?


Thank you!",2018-02-07 07:51:41
6pifuc,Big-O Notation Explained By A Self-Taught Programmer,N/A,2017-07-25 19:14:21
66crfq,Why would a university remove database course and replace with Data Mining for a final year top up in IT?,university of hertfordshire has Data Mining and Visualization for the final year IT and Computer Science TOP UP Bsc this means you will be doing the final year with say an Advanced Diploma in IT where you have never done Maths before. So how then can one learn all of that math for data mining in 1 year? and what would be the point of data mining without a math background?,2017-04-19 20:09:41
k4hn1,Getting my BS soon. I want to join a charity organization. But there isn't much information. What others can I look into?,N/A,2011-09-04 17:13:58
29mvwn,Can everyone become a programmer?,"Is there a ""test"" you would recommend in order to find out if someone has the ""ability"" to think like a programmer and solve problems?",2014-07-02 08:14:26
1w12e0,Fun with the halting problem.,N/A,2014-01-24 13:03:30
1oiqwn,"I am looking at starting a Computer science program, BUT and its a big but, I haven't got really any experience or knowledge of this subject. It does interest me, what should I start researching?",(A degree I mean not program)The main points?,2013-10-15 19:19:36
f7k7n,Why the Public-key cryptography relies on the difficulty of solving a problem that might be polynomial? Why the choice didn't go for a problem that is EXP-Time or harder?,N/A,2011-01-23 16:49:13
8j5xy0,subtopics in CS would need a phd? for research at good companies & labs (outside of academia). which subtopics would not need a phd?,"- if there's been a really good answer to this question recently, can link

- if there's a really good answer on the web,  can link

",2018-05-13 18:44:02
55gzkn,Good Example of Programming?,"My wife has returned to college and has fallen in love with mathematics again--her favorite subject in high school. She wants to take higher level math courses but doesn't want to major in mathematics. She is interested in a degree that can help her obtain a specialty job that either uses mathematics or provides a similar challenge. I have encouraged her to try a computer science programming course to see if she enjoys it. Does anyone know if there are any good presentations or examples of what you could do with programming that might be exciting for her to check out? I believe something showing what programming can produce as well as the challenge of programming (i.e., Specific challenges that a programmer might come across to solve) would have the highest chance of exciting her and getting her attention. Also, are there any programming languages that anyone would suggest? I know that Python is often encouraged as it provides a general knowledge of programming that can facilitate learning other languages, but would anyone suggest another language that might be more interesting to take first because it becomes more immediately applicable such as requiring you to develop a small software program for the course? She uses a Mac laptop and is stupid crazy over Apple products for some weird reason; I hope this is helpful in any suggestions ha. ",2016-10-02 05:13:50
2yqjf3,I can prove P = NP with a constructive proof,"Call me a crackpot if you will, but I strongly feel I have a constructive proof that P = NP by solving an NP-Complete problem in polynomial time. I am not connected to any academic community and am facing a problem with understanding how to publish to a peer-reviewed journal.

How can an outsider such as myself break into this seemingly walled-off world? What are my options to advertise this out to the community, while being able to receive credit for my work?",2015-03-11 23:50:06
5znhy8,AI provides an urgent solution to evolving ransomware threats facing healthcare,N/A,2017-03-16 00:53:22
1b5m65,Can someone explain why cloud computing is such a big deal?,It's not like 2007 was the point where people started hosting software across thousands or millions of servers; that's been going on for many many years. So what makes recent years different than it's been in the past?,2013-03-28 03:13:04
a61mv6,We Need an FDA For Algorithms,N/A,2018-12-14 04:54:09
w6p7dk,Ethical and social risks of harm from Language Models,N/A,2022-07-24 06:39:57
4qqhnb,What is something similar about every successful computer scientist?,I though this might help those aspiring to be one,2016-07-01 07:17:14
4dn1z7,"Starting out part time (newbie, no exp)?","Hello r/compsci, 

I'll try to be as concise as I can be: I'm 27, male and live in Westchester county, NY. I attended college directly out of high school and studied  business pursuant to a BS in corporate and homeland security. Unfortunately, I lost my (almost full) scholarship in my 3rd year  (long, irrelevant sob story ) and since, I've just been struggling working in restaurants and bars, unable to progress enough financially to get back into school.

Even before I started that degree when I was 18 I had been interested in computer science. I've built gaming pc's, media pc's setup with couch potato, etc and love to learn about computers BUT I've never programmed really beyond a few code academy courses (which were fun ). I have no training essentially. 

My question: is there any sort of work  (part time or full time) that I could aim for? As in: is there any kind of work where  someone like me (who's VERY motivated, but totally green) could collect the certs/prerequisite training and get into the industry soon ( by the fall?) I'd be happy to work part time and start at the bottom. 

I truly want to enter this industry and hope to pursue a degree some day. I just am feeling disheartened because I feel like leaving the hospitality industry behind and entering computer science is years away. Is is possible to start working in the field part time? 

Thanks so much for any advice, 

-Rich


Edit: I'm totally willing and happy to commute to NYC since I'm very close to a train station that gets me to grand central in about 35 minutes. ",2016-04-06 18:24:05
466mv2,Apple ordered to bypass auto-erase on San Bernadino shooter's iPhone,N/A,2016-02-17 04:51:30
3m88di,C++ for Networking Class at Java Centric School,"The professor for a computer networking class at school stated C/C++ proficiency was a prerequisite for this course(the catalog does not have this as a pre-req). The school is Java centric--intro courses and higher level courses are in Java-- and a C++ class is offered as an elective, once a year at most. 

Does this seem strange? Can't this type of course be done using Java? I want to make sure I understand whether there's a legitimate reason for using C++ in this environment before I discuss the issue with the professor. 
",2015-09-24 18:09:34
2z51gs,Advice about how to study CS,"Hi there!
I'm a undergraduate in computer engineering (2nd year) and, besides the stuff we study at school, I'd like to learn more things (for example I'd like to learn the computer arch and network basics in-depth for a long time now).
Now, I am between these two choices:

1) I learn a few stuff at a day, all days, steadily. (i.e. 3-4 pages per day of a book)

2) I put apart what I'd like to learn, because maybe it's more effective to learn things with more time in the future and. So first get graduated, then, in some way or another, start to learn what I want to learn (besides the school's stuff).

From your own experience, what's better?
Do you usually learn a bit of a time or do you try to wait when you have more spare time and learn more things per day (for example take a one-month-full-reading)?
I fear that when I'll graduate, I'll get always more busy and have always less time and so I'll posticipate what I want to learn forever. What can you advice-me?
P.S.: I hope this question won't be taken as spam, kiddie or such.",2015-03-15 17:23:15
2uv8wn,"I'm sorry if this isn't the place to ask, but who hires compsci majors, and what jobs are generally more accessible to compsci majors than to someone who has learned programming on their own. Assume I understand that compsci != programming","I see a lot of people who say they've ""been on both sides of the interview desk"" saying that they'd rather hire someone with a great portfolio of projects/github/ability to learn etc. than someone who has a compsci degree.  These people go on to say that a compsci degree can be seen as a waste of time, and that their skills are somewhat irrelevant in industry in the 3-4 years it takes to complete a degree and often don't put enough focus on programming.  I've noticed that these people are almost always talking about getting hired as a web/software developer.

My question: what other jobs are out there that allow compsci majors to apply their skills that aren't the above mentioned fields?    Say I went for a CS degree and didn't want to do webdev or software engineering, what other career options would my degree qualify me for?  Could I build up skills for those other options  without a degree similarly to the teach yourself culture surrounding webdev?

I'm sorry if this is an overly general question.  I'm not a dev, nor am I CS student.  I'm just curious.",2015-02-05 13:13:24
2i2x47,CompSci vs. Software Engineering?,"So I'm planning to do computer science next year. I currently completing a degree in Structural Engineering (yeah its a jump..). I'm interested in things like simulations, 3d computer graphics, software architecture etc. Which is why I want to go into computer science. Its also a shorter degree.

My guess is software engineering is more about managing a software project (like resources, budget etc.). 

Would you recommend one over the other?",2014-10-02 11:15:41
21dxj3,Theoretical Question,"This is an amazingly retarded theoretical question.

Lets say you were designing a detector and counter system. You have control over all the code in the counter system, but none of the detector system. 

For example if the counter/dector system in this case was used to detector color, the detector is able to signal one of two things to the counter, A=the color or B=Same color as before. In general, n+1, n being the number of correct solutions (blue,green,red,yellow). The question is, is it advantageous computationally to program the program to recognize the second signal (same as before)? Do you save an computational time by having to recognize two signals? On the other hand do you save computational time not having to convert to ""same as before"" later in the program.

I am really, really, high.",2014-03-26 03:45:21
1pzwkv,"Ask CompSci: What do we call that thing we used to call ""interpretation""?","Once upon a time, there were compiled languages (translated to some other language, then executed) and interpreted languages (executed as-is) -- and ne'er the twain did meet. But then JIT compilers happened. Today people say that Python, for example, is an interpreted language, despite the fact that it is always compiled.

I understand the reasoning behind this. A compiler is something that inputs a program and outputs a program in another language. An interpreter is something that inputs a program and executes it. Whether an interpreter does any compilation is an implementation detail that does not alter the service an interpreter provides.

However, that leaves us with a concept with no name: executing a program as-is, without translating it to another language. We used to call this ""interpretation"". I don't know what to call it now.

Any ideas?",2013-11-06 02:16:29
1l2bmb,"[Rant] I didn't properly understand how the log laws applied to big O complexity, and now I feel cheated.","I took a whole bunch of time to implement a hash trie, which is a moderately complex and highly numerical map data structure with O(log_5 n) insertion, retrieval and deletion. Once that was done, I tried to quantify the difference in performance from a O(log_2 n) binary tree. Lo and behold, constant factor of difference - so the simpler, say, red-black tree might actually have better performance characteristics than this monster of a data structure.

I suddenly understand extremely vividly why doing hard math with proofs is important - otherwise you risk missing the big picture and throwing away lots of work.",2013-08-25 17:21:06
1f5gvq,Big Data?,"I am a about to be a third year student at university in the US. I am completing my Bachelor's in CS and minor in Applied Statistics. I am hearing the talk of BigData (some said metaData). I have done research, found about noSQL and other things. This is a very interesting area for me. (side note found this and am planning on watching it this summer [this](https://www.coursera.org/course/datasci?from_restricted_preview=1&course_id=346&r=https%3A%2F%2Fclass.coursera.org%2Fdatasci-001%2Fauth%2Fauth_redirector%3Ftype%3Dlogin%26subtype%3Dnormal%26visiting%3Dhttps%253A%252F%252Fclass.coursera.org%252Fdatasci-001%252Fclass%252Findex)
* How many people have used/worked with big data in real life situations.
> If you have could you give some insight on it?
* Any advice on getting into Big Data?
",2013-05-27 19:04:04
1e79y9,Possible undergraduate research project ideas ?,"Hello. I'm a CS undergrad, and next year I have the opportunity of taking on a 300 hour self-proposed research project as part of my final year for a BSc in Computing Science. I was wondering if anyone could point me in a direction that could help me come up with an idea for such a project, or if you have ideas that could be adapted into something like this. 

Over the past few years, I've mostly been interested and enjoyed Algorithms and Data Structures, Networks, and to a slightly lesser extent, real-time operating systems. I'm also interested in (and will be taking courses next year about) Artificial Intelligence, Machine Learning and Cryptography, though I don't think it would be wise to dive into a research project related to a course I have had no formal training in (but I have looked up in my spare time). I've been looking at papers in these fields but I feel slightly overwhelmed and I'm not sure where to even begin thinking about a research proposal. Any thoughts ?",2013-05-12 20:39:06
14hkw9,Knuth-Morris-Pratts failure function?,"Hey redditors I'm going to thank you guys ahead of time, this has been bothering me for a long time now, and with no prevail to understanding the failure function. I'm looking at two examples;

j    | 0 1 2 3 4 5
p[j]| a b a c a b
f(j) | 0 0 1 0 1 2

and

j    | 0 1 2 3 4 5
p[j]| a b a b a c
f(j) | 0 0 1 2 3 0

Now for some reason I can't understand the numbers for f(j), therefore try your best please to put in the most simplest English words you can think of to teach a toddler like brain of mine.

Thank you for who ever responds or gives any thoughts! Much appreciated.",2012-12-08 06:25:14
11zbt7,The Ph.D. Grind: Lead From Below,N/A,2012-10-24 01:25:29
t0x9y,Good compsci schools in Europe?,"I'm looking for good Computer Science schools in Europe, for Master's or possibly a doctorate.  Any ideas?

**edit:** Thanks for the info and tips, everyone!",2012-05-01 02:52:21
rjk42,China's Not-So-Super Computers ,N/A,2012-03-29 18:01:39
m64qk,I want to start a career in computer science. Where do I start?,"A little background... 

I graduate with a B.S. in a *completely* unrelated field (Physical Education), but I've always had an affinity toward computer tech and it's something I know I would be great at. However, I don't have any programming skills and am somewhat confused as to what a computer science entails, but I know it's a field that I would like to pursue a career in. The question is, where do I start?

I suppose I already have a head start since I have my B.S., so I'm debating if I should go for another degree, or just pick up a book and learn. The local community college here has several certificates you can earn in a particular programming language. Should I do that? 

I have many more questions, but I'll leave it here and go from there. Any advice would be great guys. Thanks for your time.",2011-11-09 15:07:52
l9m97,A reminder: cstheory.stackexchange.com needs readers and posters!,N/A,2011-10-12 15:12:11
ilq19,Going to start graduate school soon. What texts would /r/compsci suggest?,"Joining a public university in the US for Master's. Would love to work on the subjects of Cognitive Science, Vision and Theoretical CS. I want to complete the courses in a year or year and a half, and start my PhD soon.

What do you guys suggest for a good read in the meantime for brushing things up, considering that I have close to two months before the classes start?

I come from a Non-US (Indian, to be precise) undergraduate institution, so maybe I need to catch up with the academic curriculum. Currently reading Albert Meyer's MCS for Probability and Discrete.

Thanks!

PS: I want to admit that one of the reasons for my inclination towards Theory and Cog Sci, lately, has been /r/compsci + /r/cogsci.

Edit: Grammar.

Edit: Why the downvotes (-6) hive-mind? Why... Why... Why...",2011-07-10 18:07:19
xnfm4g,Nonpolynomial November,"I'm tired of people talking about how important NP-complete problems are and how they take too long to solve.  That's why I'm creating Nondeterministic November.  \[The title of the post is incorrect because I had to fix the name and can't fix the post title.\]

This is a game jam (really more of an algorithm jam) in which participants work on NP-complete problems.  This can include projects like:

* Solve an NP-complete problem.
* Convert an NP-complete problem into another NP-complete problem.
* Prove that a problem is or isn't NP-complete.
* Write a mathematical proof of whether P=NP or not.
* Find some new application for an NP-complete algorithm.
* Allocate more computing resources to an NP-complete problem.  For instance, this could be using the graphics card to perform mathematical computations.  Or it could be multi-threading or using a network of computers.

At a practical level, I plan to make myself a toolkit for solving NP-complete problems.  At a grander level, I want to experiment with solving them in different ways.  I want to gather thousands of people to each work on this in November.  My hope is that a large enough body of people might be able to discover something new.

This jam is intended for people that have some background in computer science or mathematics, but aren't particularly invested in NP-complete problems.  There's no limitation on who can participate, but I feel like people who don't have the necessary knowledge won't benefit.  And computer science graduate students don't need me to tell them to work on solving NP-complete problems.

There's no ranking and no prize for the jam, but the Clay Institute is offering $1 million to anyone who can prove whether P = NP.

Link:

 [Nondeterministic November - itch.io](https://itch.io/jam/nondeterministic-november)

&#x200B;

Edit: Fixed name.",2022-09-25 06:30:43
hpu02a,halting problem for someone who learned computer hands-on,"So the text about the halting problem told me that I first need to understand why there is no bijection between real numbers and integers. So I tried to understand that. I first had learned coding and then math. So I know bits. I can use bits to store an integer als a binary number. For a larger number I need more bits.

So real numbers are used to describe a fraction. So I have a whole cake, or I have the alpha channel in a texel or I LINERP, I need fractions with enough precision so that it looks good or no one can complain about a too small peace of cake. So I divide the 1 into halves recursively and store in my bits if I use the upper or lower half. The better the precision the more bits I need. Real numbers, numbers that measure something in reality always have a precision ( see engineering and physics).  


(Then there are fractions, where we interlace the bits of the nominator and the denominator in the bitstream.)  


So my problem is that for the halting problem I am supposed to use all different binary (64 for example) bit patterns as headings for columns and rows each. Then I should place the row heading in the instruction storage of the Harvard architecture and the column heading in the data storage. Then start the program.  


The mathematical proof assumes that I use multiple processors to run all programs/data combinations at the same time. When a processor stops, it sends a message over the network and the cell of the table (on my dashboard) is marked.  
So we have all bit patterns already used as headings, but the mathematical proof then assumes that we have not. So we start with a contradicting and then  
...  
The proof is about infinite number of bit systems (what does that even mean?)  
...  
then we end at an contradiction (wonder over wonder) and now know that the Java.exe can not detect the [endlessLoop.java](https://endlessLoop.java) ??  


If I calculate the square root I get an infinite series of (binary) digits with no repeating patterns. I just do not understand what this has to do with the halting problem.",2020-07-12 12:59:04
esglrr,"I start my post-grad, full-time SDE I job in 6 months at Amazon. What can I realistically expect and how can I best prepare myself outside of coursework?","I don’t learn my specific team assignment until 90 days prior to my start date. I’m extremely proud of myself for reaching this level and landing this job, but I expect it to be challenging, and I want to be best prepared. Does anyone have any advice for a new lad like myself?",2020-01-22 19:13:02
b366we,Norsk Hydro Ransomware Attack Is ‘Severe’ But All Too Common,N/A,2019-03-20 02:02:02
963sxu,Artificial Intelligence (AI) emulates how people think — Artificial Emotional Intelligence (AEI) emulates how people feel,N/A,2018-08-10 04:28:10
8smjbo,How did you learn app development?,"I'm very interested in app development and would really enjoy spending my summer learning it and actually creating one of my ideas and publishing it. My school lacks resources for learning app development so it's something I'll be self-teaching. I really enjoy interactive lessons such as Codecademy but understand that that is not always available. Specifically learning development of Android apps since 1. I own an android 2. I do not own any Apple products to use XCode on.

So what worked best for you to learn Android app development? What resources and online lessons would you offer? Are there any online projects that have a walk-through on how they built the app so I could just follow along? Thanks!",2018-06-20 22:16:40
8dlzhl,Lessons learned building resilience in Distributed systems at Scale,N/A,2018-04-20 08:08:52
7i5kjo,Is git a blockchain?,N/A,2017-12-07 10:38:17
5z05vt,Why is their no cross-platform browser view controller language?,"Barring the very beginnings of WebAssembly, why has there been no interest in a web-based byte code before?

I can't help but think of browsers as providing a platform for web applications now, but there isn't any good way* of writing view controllers for manipulating what we see on screen.

For example, would it not be good that in 5 years from now we can 'compile' views on the server that bundle the markup and the events together and send them to the browser to run inside their own containers?

FYI: I have had zero interest in this before 15-minutes ago, so I might be missing something crucial.

*Javascript is not a good way of doing it, my opinion.",2017-03-12 18:40:23
4jwrzh,Laptop for programming?,"I need to purchase a laptop for someone who is a programmer. She has expressed that it'll be exclusively for programming and nothing else, so she doesn't want to under-spend or over-spend.  What would be a good choice? The one I've been eyeing (within our budget ~600) has the following specs.

* 6th Generation Intel Core i7-6500U Processor 

* 2.5GHz with Turbo Boost Technology up to 3.1GHz 

* Windows 10 Home

* 15.6"" Full HD Widescreen Comfy View LED-backlit Display
* NVIDIA GeForce 940M with **2GB** of dedicated DDR3 VRAM

* 8GB DDR3L Memory

* 1TB SATA Hard Drive (5400RPM)

* SD card reader, **Acer** True Harmony High-Performance Sound System, 802.11ac Wi-Fi featuring MU-MIMO technology, Bluetooth 4.0, Gigabit Ethernet, Built-In HD Webcam, 2 - USB 3.0 ports (1 with power-off charging), 1 - USB 2.0 Port, 1 - HDMI Port, 4-cell Li-ion Battery (2520 mAh), Up to 6-hours Battery Life.

Appreciate your thoughts and any recommendations I can get.",2016-05-18 13:57:56
3ogsta,Can Apache Spark process 100 terabytes of data in interactive mode?,N/A,2015-10-12 16:13:30
3ejdq5,Is there any way to combine bitcoin mining (useless to humanity) and distributed research folding@home (good for humanity)?,N/A,2015-07-25 06:52:14
29et71,What to do with an old IBM ThinkPad 390x?,"I've got an old IBM ThinkPad 390x with Windows ME that still works beautifully. I was thinking about doing something cool with it, or at least installing linux (I have no idea which distro to choose if I did this though...) instead of windows to just play around with. As a computer science student I'd like to do something with it that could essentially be a great learning experience. Any suggestions?",2014-06-29 19:01:18
tnvwd,What do you think of my soon to be summer project.,"
Well the summer holidays are coming up really fast. I'm at uni doing a physics degree but have recently fallen in love with computing. So I decided that during my summer holiday I will be trying to make a 4-bit ALU out of marble mechanics!

I currently have a youtube channel where I am making an ALU with mine carts in minecraft and that's what inspired me to use marbles IRL. Anyway the idea is to have the following functions:

AND
OR
NOT
XOR
A+B
A-B
Shift right (not shift left seen as you can just to A+A for shift left)

Anyway what do you think?
",2012-05-15 07:33:47
ji3zd,AskCompSci - Could we have a newbie discussion on the concept of DNA computing?,N/A,2011-08-14 01:18:44
pbnhmi,We call upon Reddit to take action against the rampant Coronavirus misinformation on their website.,N/A,2021-08-25 23:44:31
a4nkme,Introducing /r/OpenSourceVSTi and A Competition For Making VST's Using AirWindows FOSS Code -- Developers & All Ideas Wanted!,"* Over at /r/OpenSourceVSTi -- which is a new subreddit that I made, we appreciate /r/CompSci and we'd appreciate it & we would return the favor, if the mods here would list us in ^your sidebar.

* If you're a developer, have ideas for making VST Plugins, or if you'd like to vote on which resulting pligns you like best from the competition that we're having, check out the [Competition For Making VST Plugins Using ^AirWindows Code](https://www.reddit.com/r/OpenSourceVSTi/comments/9vqy0n/competition_developers_to_make_variations/)

* Also, [Learn Your ABC's -- Why The FOSS VST System Is ^Superior To ~~The Big Businesses~~ -- Goals And Purposes Of ^/r/OpenSourceVSTi](https://www.reddit.com/r/OpenSourceVSTi/comments/a4iznd/learn_your_abcs_why_the_foss_vst_system_is/)
",2018-12-09 19:00:15
fqpks,The difference between comp scientists and comp engineers [FIXED],N/A,2011-02-23 01:52:44
xc6wg9,"I have made a simple search algorithm that's much faster than the linear search, but it only works in unsorted lists containing consecutive numbers. Is this useful in any case whatsoever?","It probably isn't useful, but I want to make sure of it before I dump the  idea.",2022-09-12 08:03:47
dqaok8,GATE 2019 Computer Science Paper : 100000 of aspiring CS engineer in India give this exam for 300 masters seats in premier IIT,N/A,2019-11-01 21:26:10
2ol6th,I have an interview soon where I'll be tested on my C++ skills. I haven't coded in a while. What's a good way for me to review and practice all the important concepts?,N/A,2014-12-07 22:24:30
1yw48n,What's a good example of problem reduction for laymen?,"When people ask what I do, I begin by explaining algorithms through the example of sorting. Ask how they would do it, tell them the method they'll inevitably choose is called selection sort and the time it takes grows too quickly by input size, and then explain quicksort. Most non-cs people lose interest right about there, but if they want more I'd like to have a nice example of problem reduction to throw at them. Consider perhaps a 17-year old mathy person who's asking me why he should choose a cs major. But it could also be a physics guy at a party and I might be slightly drunk.

I don't really have any examples to use so I'm asking for ideas. It needs to be two problems that are quickly stated and easily understood, and the reduction should be fairly trivial as well. And it should ideally be possible to illustrate either on a napkin or using beer bottles.

edit: as stated in one reply, I want the reduction to be easy to understand, but not easy to come up with (for them). It should be a reduction to which they could say ""oh that's pretty cool"".",2014-02-25 14:10:41
uh35br,Stupid question,"Which one did you study.And which one do you think is more prestigious and frankly practical.

[View Poll](https://www.reddit.com/poll/uh35br)",2022-05-02 23:51:49
gfyg8y,Comp Sci Discord Network,"Hello Computer Science friends, if any of you guys are interested in  joining a Comp Sci Discord Networking Community for discussion, JOB  SEARCH, ideas, studying, and industrial networking, this is the link,  where you could discuss C++, Machine Learning, Data Science, AI, and  Python. [https://discord.gg/KRZwxzg](https://discord.gg/KRZwxzg) 

Once you have entered please type  ?rank Computer Science",2020-05-08 18:19:46
bnx1u0,Aspiring CompSci major...Failed Computer Information Systems SEVEN times ;_; (I know...),"Alright so spare me the roasting please, I'm well aware of how unbelievably stupid and pathetic this is. 

&#x200B;

I'm a community college student for a few years now, working and scraping by. There's one class I've been taking since i started here- an *entry level* class, Computer Information Systems. 

&#x200B;

Now, I know what you're thinking. ""Maybe this class isn't for you"" etc... 

&#x200B;

The thing is, I can use Excel, Access, Powerpoint, Word, etc... fine. I'm more than competent with microsoft office, I know an elementary amount of coding (just moving past the basics in Python/Java) and I've been working on and with computers all my life. I think that's part of the issue. 

&#x200B;

It's like I'm not taking the work seriously because I know how simple it is, and I'm always doing that sort of shit anyway, so I just put it off. and put it off, and off, and off, until there's like 7-9 hours worth of spreadsheets to hand in at the end of the semester, and I don't do them because busy with work/other classes, and I fail. 

&#x200B;

Well, I just failed the 7th time. The final exam and all the semesters work is due in 6 minutes. I handed in everything up until the midterm and then just slacked off.

&#x200B;

I hate myself for this and I really am beyond ashamed, frustrated, etc.. It's just so unbelievably unnecessary and stupid. 

&#x200B;

That being said though, what the fuck do I do about those 7 F's on my transcript for the SAME class, ESPECIALLY when I wanna go to school for Computer Science?! Forrget about it dude, that'll look like a **joke. Applying to a fucking computer science program with 7 F's in a class that can be done by a 12 year old.** 

&#x200B;

It's the only class left I need to graduate with my prestigious Liberal Arts: Social Sciences and Humanities A.A. degree, and then I can start to applying to 4 years that I can't afford.

&#x200B;

I was thinking about maybe asking the Dean if those classes could possibly be removed from my transcript but honestly I *highly doubt it.* 

&#x200B;

I'm gonna retake it 5/20-6/20 as a 5 week course and just knock it out and get the A, but still, even an A after that is just like...come on dude, SEVEN times? The thing is, I'm not bad with school whatsoever. I've been good about disciplining myself since High School for the most part, and I have B+/A in just about everything else. It's just this one fucking class that it's just so easy for me that I get despondent about doing it because it's so tedious and I already know how, so I swear to myself I'll do it later and I've done that more than a half dozen times now. 

&#x200B;

So guys....wat do. If I wanna transfer to a 4 year for CompSci, I'm thinking my best option from here would be to change my major from Liberal Arts A.A. -----> CompSci A.S.   I would only need to add like 10 classes which I can knock out in summer/Fall/Winter (3/6/3) which honestly would be dreadful since I want to get a move on things academically/etc... but It would at least show that maybe I'm competent in computers but just that that specific class had a weird thing with me.",2019-05-13 01:45:04
8g4hzs,"Is this an example of a Data Access Object? If not, what do you call this?","i'm making a SQL database. It's a pretty simple database. It's for blogs. it can store articles, basic info about the article and author, and also stores comments for each article. All in all, I expect to have maybe 4-5 tables.

I want to design it in such a way that most essential database interaction can only be done through SQL/PSM or PL/SQL functions/procedures or views.

That way, I can give a developer a limited view of the database's internal structure while ensuring they have all the essential functionality they need in order to create the web application.

This also provides a somewhat more cohesive approach to using the database from multiple different languages/frameworks/etc. Whether you're using Django or PHP, you still insert a blog article by using the 

    insertIntoBlog($title, $author, $isPublished, $publishDate)

PL/SQL or SQL/PSM method.

Is this type of database design pattern some kind of data access object? if not, what do you call this?",2018-05-01 00:53:00
84slxl,Lockable Binary Trees,N/A,2018-03-16 03:42:43
38osx4,How important is the theory of Algorithm?,Is it essential to take a course in algorithm if you just want to do some coding for fun?,2015-06-05 16:41:48
5483hr,Generate Music with TensorFlow,N/A,2016-09-24 01:28:42
4w49db,"A matrix with mostly zeros is called ""sparse"". What is a matrix with mostly 'NaN' called?","By 'Nan', I mean missing values. What is a matrix with mostly missing values called? ",2016-08-04 12:28:13
49f0w8,Roadmap to become an engineer without degree,N/A,2016-03-07 21:54:09
42h7re,"Why can we not have a fully object oriented operating system? Even if we can, why haven't such implementations come out yet?","I'm curious as to why it hasn't been done. Aren't object oriented methodologies better than procedural? Shouldn't they have made one corresponding to OO methodologies by now? IS there some draw back to using OO that I'm unaware off? 
Edit: Made things a little clearer i hope",2016-01-24 19:15:43
3d339w,Is the University of the People a decent online institution to learn programming.,"I am a neuroscience masters student, and I'm realizing that programming knowledge will be of great benefit to me. I don't need to understand it at an extremely theoretical or abstract level, but I need to have a relatively deep understanding so that I can apply it to my research. Is this a good option? If not, what are other online universities you would recommend. Thanks. ",2015-07-13 03:24:46
201vfy,CS Undergrad research help,"Hey all, so I am a 3rd year CS undergrad in college in the US. I have an internship at a company nearby where I work a couple hours per week just doing web application development. I am really more interested in doing computer science related research in my own time though. Specifically I really like to research computer security and things related to graph theory and displaying data sets graphically. 

I was wondering if any of you guys out there who are being paid as researchers or are doing something related to what I am referring too, could maybe give me a point in the right direction. I am not a bad student (B average 2.8 gpa) but I do not have a great relationship with many of my professors, I typically don't go for help or ask questions from them unless I have too (Which is rare). I think I could be happy with a career that involves just research but I would like to hear from someone already in the field how it is and how I could get there.",2014-03-10 15:12:42
1hz62j,"Researching a topic, can someone point me into the right direction? It is about scheduling a time so that when a CPU changes states (SLEEP to READY), the CPU is ready at the same time a resource for that CPU becomes available.","The end result is power savings and faster operation of the computer system. Any leads to look into? I believe this is an algorithm related but I can not recall the name.

Thank you.",2013-07-10 01:24:16
1g2q77,"Hello Redditors! I will be changing my major soon to Computer Science, what advice could you give me that you wish you had when you started working to earn your degree?","I am at a state college with one year already under my belt. 

What advice do you have for me?",2013-06-10 22:05:42
1elviq,Can someone with explain what is meant by this section of my Comp Science textbook.,"What does it mean that instructions are stored contiguously in memory? What about branching statements?

Quote from my book(introducing fetch-execute cycle)

""At this point the IR contains the instruction to be executed. Before going on to the next step in the cycle, the PC must be updated to hold the address of the next instruction to be executed when the current instruction has been complete. Because the instructions are stored contiguous in memory, adding the number of bytes in the current instruction to the program counter should put the address the next instruction into the PC"" 

I'm kind of confused about the last sentence. What does it mean to be contiguous? What if an instruction is in another address that is not directly below the current one? Isn't that branching? 

Also why have a PC in first place if the IR holds the instruction anyways?

I appreciate any help explaining this to me. Thank you for your time. ",2013-05-19 01:15:57
15darw,Turning theory into algorithms.,N/A,2012-12-24 10:08:04
ysq4f,"I am required to take 4 science modules. Reddit, what is your recommendation?","I am trying to best utilise those 4 modules. 
My interest areas are mainly AI, also interested in computer vision and game engine. So what kind of science that can help me focus on those areas? And what other science modules that can help me in the long run in CS career? AI will be first priority to consider. 

I have background in physics, bio, and chem from my high school as I am from science stream. 

EDIT: Module Listing. https://aces01.nus.edu.sg/cors/jsp/report/ModuleInfoListing.jsp. Select Science under faculty. 
EDIT 2: Math (Calculus, Stats & Prob, Linear Algebra) & Machine Learning-like modules are considered as separate part of requirement.

EDIT 3: I now know a lot modules which were never heard of. Have been focusing on the application side of computing. ",2012-08-25 06:57:50
r946t,Help with a CS art project?,"I'm trying to create a wall poster with a theoretical CS flavor. The idea is this: take a set of [Wang Tiles](http://en.wikipedia.org/wiki/Wang_tile) and use them to visualize the computation of a Turing machine doing something interesting (there's a natural construction to do this mapping used in the proof that the tiling problem is undecidable; see [this paper](http://www.staff.science.uu.nl/~taati001/articles/tilings06.pdf) for a nice survey).

The only thing I'm stuck on now is what computation to show. Ideally it would have the following properties:

* Run for a number of steps that's some nice ratio of the amount of tape used (so that it ends up poster-shaped, rather than gigantic scroll-shaped).
* Not have a huge number of states (since the construction needs distinct colors for each Σ ∪ Q ∪ (Q x Σ)).
* Preferably be fairly ""dynamic"" in its use of the input tape -- so any given part of the tape should change somewhat often, since otherwise you're left with big swaths of simple two-color checkerboard patterns.

Note that it's not a requirement that this machine halt, as long as it's in the process of computing something interesting. A picture of the computation of the first 5 terms of the Fibonacci sequence would cool, for example (though I suspect it would take too many states).

Anyway, thanks for reading. Here's a tiling I generated today using [Karel Culik II's 13-tile aperiodic set](http://masterinfo.univ-mrs.fr/secret-m2if/articles-2009-2010/E._Jeandel.pdf):

* [10 x 15 tiles](http://i.imgur.com/q6TNf.png)

PS: The idea for this came from [Greg Egan's *Diaspora*](http://www.gregegan.net/DIASPORA/DIASPORA.html), in which he describes the possibility of life on a planet arising as simulations in a [biological set of Wang tiles](http://www.cs.duke.edu/courses/current/cps296.6/papers/WLWS98.pdf). It's a very cool book :)",2012-03-22 23:17:25
549ra1,Do 2 languages exist where learning one while already knowing the other doesn't change my way of thinking about programming?,"Every time I more than look at a new language it seems it is so different and different problems become easier or harder.

(If this makes no sense to you: there is a quote by Alan Perlis:

    A language that doesn't affect the way you think about programming, is not worth knowing. 

Here: http://www.cs.yale.edu/homes/perlis-alan/quotes.html",2016-09-24 11:30:46
2w3n8w,Things I need to know before majoring in Comp Sci,"I have decent understanding of computer science. I am proficient in python, java and c++. However, is that enough knowledge of the computer science field to do well as going into college as a computer science major? ",2015-02-16 18:35:37
2rio8f,The Truth about Unix and C,N/A,2015-01-06 15:01:56
250t1v,"Could you recreate a file by randomly generating bits for chunks of the file, and check the bits against a hash?","I had this idea the other day. So let's say the internet is in shambles; internet upload/download speeds are awfully slow so it takes days to transfer a single megabyte. So instead of sharing the large file itself, you hash a file, share the relatively smaller hash, and users rebuild the original file by guessing some bits and comparing them against the hash. Is this possible currently, or maybe possible in the future (or with quantum computing)?

Let's say you make a hashing algorithm that is *very* solid, so there are very few collisions. Could you theoretically hash a file or chunks of it, take the hash(es), then recreate the file in chunks by generating random series of bits (possibly with processing on the GPU like cryptocurrencies, or in the future with super fast/large array of fast CPUs) checking against the series of hashes, given enough time?

EDIT: Even better, could you run a solver on a previously created file that you are going to share that finds mathematical functions that return chunks of the file, then post those functions online for users to recreate the chunks of the file with?

**EDIT 2:** So obviously it is looking like there's a lot of problems with this, ranging from sheer time issues, to laws of entropy, also the amount of collisions a hashing function will generate is a major issue. I'm seeing this to be less and less likely.

Thanks in advance",2014-05-08 06:26:31
21n9h8,Hey everyone! Check out /r/originalprograms! It's a subreddit where you can share your programs with the community and have them critiqued.,N/A,2014-03-29 02:52:54
20s905,Switching universities and need to become as proficient with Java as I have become with C++. Any suggestions?,"I will be moving to Alaska soon with my wife and will be starting classes again in fall. I have completed two C++ programming courses and one assembly language course. However, my next course in anchorage will require that I am well versed in Java (Their programming I course begins with Java and moves on to C++ in programming II). I would appreciate any recommendations for resources or reading material that will help me prepare for my classes. Thanks!

Edit:
Thank you everyone for the helpful tips. I really appreciate it. I have found my love for programming later in life than most of my peers, so I am still trying to find confidence in my understanding of logic. I just felt a little overwhelmed stepping out of my confort zone with C++ and wanted to ask for advice from people with more experience. I wasn't disappointed. Thank you all again.",2014-03-19 04:13:55
10jg61,Are Loop Invariant's ever actually used in the real world?,"I'm in a Data Structures course at a community college and the instructor told us ""In my entire career I've never seen anyone perform a loop invariant test... but we're going to learn them anyway""... These seem like the most useless things in the world..",2012-09-27 01:29:39
107ddj,How long will there be computer science departments?,N/A,2012-09-20 18:26:58
hfkbq,"Oh Google, you so funny",N/A,2011-05-20 02:34:46
b54ct,Still got the Godelian-incompleteness blues? Don't want to give up on infinity? Try multiplication-free Presburger arithmetic. Repost from /r/PhilosophyofScience.,N/A,2010-02-22 18:48:12
e3yclh,"I'm not into computer science or anything, so I don't know the difference between computer science and programming. What's the difference?",N/A,2019-11-30 15:48:12
9169ci,Announcing /r/ITProfessionals,"Announcing /r/ITProfessionals - A community of IT professionals dedicated to advancing the profession, assisting each other and improving the overall image of Information Technology

This is a new subreddit dedicated to discussing the business of IT. It's not for tech support or early career questions, but more around the tactical and strategic aims of a successful IT organization.

Content is expected to cover such topics a hiring and keeping a successful and productive team, future planning and budgeting, having a 'seat at the table' of the overall business, proposing change to non-technical employees or leaders, and any other 'big picture' topics around the business of IT. We're still forming ideas around this as well, so please come in and give your input about anything you'd like to see in there.

The audience is intended to be employees from inside and outside of IT who are interested in advancing IT as a profession and elevating it to a more respected and understood department within any organization.",2018-07-23 11:30:03
87466l,Are combinations polynomially bounded?,"I've seen that combinations are O(n^2) or something like that, i.e. they are bounded by a polynomial, but I can't find anything on the web about it. Can someone please explain? 

My question is precisely: can I say that ""n choose m"" is bounded polynomially and if yes, how can I prove it?

Thanks in advance. :) ",2018-03-25 22:11:22
7y0b0k,On the P vs NP question: a proof of inequality,N/A,2018-02-16 17:25:47
35sib2,Best advice for an incoming CS major?,"Hi everybody. I'll be pursuing a computer science degree at the University of Texas in Austin pretty soon. I plan to do a five year master's program, but if I can't, I'll be getting a B.S. I have some experience with html, css, java, and python. What do you guys recommend I learn during the summer? I read frequently, so I'm looking for some enlightening books on computer science. I also wouldn't mind any other preparatory resources. Thanks!",2015-05-13 03:26:37
egoqhw,"When do I use cos, sin or tan (within programming)?","I know what cos, sin and tan mean when given a triangle along with the SOH CAH TOA helper method, but when I search the internet using the term ""when to use cos, sin and tan"" I only end up with explanations about the SOH CAH TOA things, but when I am watching some videos about [The Coding Train](https://www.youtube.com/channel/UCvjgXvBlbQiydffZU7m1_aw) about *harmonic motion* ([youtube link here](https://www.youtube.com/watch?v=GvwPwIUSYqE)) he is using later in the video at [8:51](https://youtu.be/GvwPwIUSYqE?t=521) `sin()` in the following equation: `float x = amplitute * sin((frameCount/period)*TWO_PI)` but I do not understand *why* is he using `sin()` here? Why not `cos()` or `tan()`? Can we use that here? would that result in different results? If so, how would it be different?

Maybe I don't understand it because I learned sin, cos and tan with a triangle, but I can't seem to transform those functions in my head if I had a different type of graph, since in the example I gave from the video, the guy in the iideo is using more like a wave-like graph where as 

I have a background of 8+ years of programming 4+ years professionally, but rarely have used cos and sin and especially in a way that I complete understood it (hence that I am learning it now) and this is a big area of white noise for me.

*When* do I use `sin()`, `cos()` or `tan()` within programming?",2019-12-28 09:13:55
kewv0,To graduate with a BS or an MS?  That is the question.,"So I have already begun my final year of my computer science degree and I've been delaying this decision for too long.  I haven't been satisfied with the advice I gotten since I've mostly talked to professors who all think that grad school is the way to go and to might as well get a Phd while I'm at it.  I know that the MS looks a lot better on paper and would help me get a leg up on competition, but damnit, I really hate doing research and I am itching to get out of school and take a job in industry.  So can anyone honestly say that an MS in CS will carry me significantly further than a BS and that I'd be a fool not to pursue one?",2011-09-14 02:24:46
45xa1i,"How did early programmers in the 1970s handle debugging? Since there existed no reddit, stackexchange, boards etc.",Anyone there during the correct time? ,2016-02-15 16:33:49
7zq14f,"Prefer simple. Avoid clever. Try an int. It's generic, effective, simple and efficient.",N/A,2018-02-23 18:02:32
2y0qrm,"In 2006 NASA launched New Horizons, a deep space probe currently on course to Pluto. The same year Sony brought out the PS3. Which device do you think has the most powerful computer?",N/A,2015-03-05 13:48:22
2g9usl,32bit address question,"How does 32bit address 4GB if 2^32bits = 4Billion (roughly) bits not Bytes? Essentially, how does 4Gb turn into 4GB? If the memory is addressing Bytes, should not the possibilities be 2^(32/8)?",2014-09-13 07:30:40
1uupxb,How Powerful Are Algorithms? [PBS Idea Channel - 9m43s],N/A,2014-01-10 03:07:27
iyv7x,Solicitation for Grad School Advice,"Redditors of /compsci - I come to you with a plea for advice (and a throwaway account). The final summer of my undergraduate education is coming to an end, and graduate school application time rapidly approaches. I'm aiming at a Ph.D, and I've gotten conflicting advice from the people I've consulted as to where I should be aiming. A bit of background: I attend a respectable, though not top-ten, school. I have no published papers, though I have worked in a CS research lab for four months (and am returning after the summer). I have three internships under my belt, including one at a top-tier tech company, though none were research-focused. My GPA is around a 3.75/4.00, and my GREs are 750 Verbal/800 Quant/waiting on Analytical to come in the mail. I will have multiple strong letters of recommendation, including one from the professor whose lab I've been working in. I've looked at the CS GRE, but decided (tentatively) that I should not take it. As near as I can tell, my lack of publication is by far the most substantial weakness in my application. I've spoken to my own professors, employees of industrial CS research labs and grad students at several schools and the answers I've gotten have ranged from ""You should apply to mostly middle-of-the-range schools"" to ""You have a shot at any school you want to go to"". I am aware that quality of the group in my sub-field is more important than overall rank, and that's the rank I'm going by here.

So with all that laid out, here are my questions:

* How badly does my lack of publication cripple me? Do I have a shot at the best of the best schools (say, top-10/5) with the best of the best groups in my specific area, or should I aim more modestly?
* Is my decision to not take the CS GRE the correct one? I believe it can only hurt me, but I could be wrong: I've never done this before!
* On personal statements: I've read a lot about what **not** to put, but not much about what *to* put. Any advice here would mean a lot.
* I did not aggressively pursue research early in my undergraduate career because I did not intend to go to graduate school. I fell in love with the field the more I read and learned, and this kind of puts me behind the curve regarding research. If anyone has an idea on how I can explain this - or if I should not mention this - in a personal statement, I'd love to receive it.
* Am I correct in my belief that the GRE is more of a ""If you're not this high-scoring, into the circular file with you!"" and less of a metric where my scores would distinguish me?

Any advice would be very much appreciated!",2011-07-25 03:51:29
bvppl,AskCompSci: is it possible to simulate lambda calculus on a Turing machine?,N/A,2010-04-25 02:38:49
4djp6a,Sexism in Computer Science (Look inside not asking if it is sexist in general),"At a competition today we were informed that there would be 3 teams advancing based off of their total overall scores. However they also take one completely female team guaranteed no matter the score. There was one all female team and as such were allowed to advance to the next level despite being scored lower than most of the other teams. Would you consider this unfair? Sexist? Both? Neither? let me hear what you think about this!
Questions I noticed in the comments that I have not responded to:
Yes there were teams mixed with females and males
This is high school in Canada
They were better than some (I think 1 team lost to them) but still were not as good as others",2016-04-06 01:52:07
2ojuq3,How to drive naive CS students insane,"""Alright class, today we're doing graph problems. I want you all to get into groups and find a solution to the travelling salesman problem I talked about earlier. I'll give you 5 minutes and then we'll write our answers on the board. First one to find an answer gets extra credit.""",2014-12-07 14:28:10
5r512d,Hackers Use New Tactic at Austrian Hotel: Locking the Doors,N/A,2017-01-31 01:16:05
3glwk2,How We Beat C++ STL Binary Search,N/A,2015-08-11 16:18:16
37479x,John Nash letter to the NSA,N/A,2015-05-24 18:48:33
jln5yt,Which CS concepts that you learned as part of your degree have (not) turned out to be useful for programming?,N/A,2020-10-31 18:12:56
jgruui,Testing for Parallel Computing Capacity,"It is obvious that even consumer devices are capable of parallel computing, and since basically all of my work in A.I. relies upon parallel computing, I’m now taking a closer look at the issue in connection with a state space algorithm I’m working on, that requires the capacity for parallel computing to be allocated to different threads of the state space according to a formula.

This first requires knowing how much capacity the machine has for parallel computing. This kind of information is probably not going to be easy to find, and may not even be available, so I’ve written a simple script that should allow you to approximate how much capacity for parallel computing your machine actually has, which will probably depend upon the language you use, which is in this case, Octave / Matlab, languages plainly designed for exactly this purpose –

To achieve vectorization.

I'm pretty sure you could do the same in Python, I just happen to work in Octave.

Here's a simple script that should allow you to measure where your machine's capacity for vectorization starts to drop off:

https://derivativedribble.wordpress.com/2020/10/23/testing-parallel-computing-capacity/",2020-10-23 17:39:32
jadh3g,Thoughts on Pluralsight?,My school provides me full access to pluralsight and was wondering what everyone thought in regards to using it as a “second school” to learn more thing along side my current courses.,2020-10-13 13:33:42
ir621x,How hard is CS?,"I know it depends on the person but having seen that many students change their major from cs, what makes this class so hard? What type of people thrive in this major (technical or conceptual people, perhaps both)


I am a finance major at baruch and always wanted to learn more about computers but due to lack of knowledge I was always intimidated by the subject. I'm wondering if this is something I want to dwell myself into.",2020-09-12 04:24:31
iqppup,I have a huge problem about language design,"I am fluent in C language.  I even made a separate compiler similar to C ( Not C ) by C Language.  But it is not OOP.  I now want to create an OOP ( Object Oriented Programming ) language.  But I do not know much about OOP.  I have not used languages ​​like C++, C#, Python etc.  So I have a problem.  Do I have to learn another similar language ( OOP Language ) completely if I want to make an OOP language?  Or is it enough to study its theory?  Or is there another solution for learning OOP?",2020-09-11 12:43:17
ijxxyh,Embedded system and its concepts,N/A,2020-08-31 13:26:34
ig440n,Question: My buddy is designing a video game controller for disabled people and he said he needs a CS guy to help him.,I’m a programmer but I’m not sure what I should work on for this controller. Any ideas?,2020-08-25 03:09:04
h0lnwn,Who should Engineers be: Technology Generalist or Specialist?,N/A,2020-06-10 22:15:44
h09cfr,Computer science graduate honored for research quality and potential impact,N/A,2020-06-10 11:51:16
gmzk7g,I want to confirm if I understand the halting problem.,"resources I used for research  
[https://www.reddit.com/r/explainlikeimfive/comments/2ec9hv/eli5\_the\_halting\_problem\_in\_computer\_science/](https://www.reddit.com/r/explainlikeimfive/comments/2ec9hv/eli5_the_halting_problem_in_computer_science/)   


[https://www.youtube.com/watch?v=macM\_MtS\_w4](https://www.youtube.com/watch?v=macM_MtS_w4)

&#x200B;

 I have a few question about the halting problem.

The halting problem is the idea is that a machine for every computer program that can tells me if the program halts or  does not halts. I then feed the output of the machine as input into the same machine. 

&#x200B;

So the input that is fed into the machine gives me halt or infinite loop.

The second time I feed  the information into the machine I get again two results. 

The results are if an infinite loop it it halts. The other result is if it halts it goes into an infinite loop. 

&#x200B;

Why is this a big deal? Is it because I can't gather any information if  the final results is an infinite loop?

&#x200B;

I have further questions but will start from here.

&#x200B;

I understand code a little but have not coded in a while so I may be rusty.",2020-05-19 23:08:38
gkllzm,Automating repetitive tasks?,"I track my own financial data, and every day, I am going through about 50 stock charts in Fidelity Active Trader Pro and exporting each to a CSV file individually. Is there anyway I can automate this?",2020-05-16 01:05:51
f6e7bk,How to Write a Runescape Injection Bot in Java,"This is pretty heavy on computer science as it deals with the JVM, how it works under the hood, and how to apply the knowledge to create a bot that does what we want it to do in Java. Here's the link if you guys want to read it: [https://ectotalk.com/index.php?threads/ultimate-guide-how-to-write-a-runescape-injection-bot.6/](https://ectotalk.com/index.php?threads/ultimate-guide-how-to-write-a-runescape-injection-bot.6/)",2020-02-19 17:39:11
erfw1r,Looking to get an education on the computer science field. Help?,"I am a 23 soon to be 24 loser but I want to change that, badly. I'm pretty computer literate but I spent my earlier 20's pursuing different interests and failing at all of them. I'm in a really bad spot so I feel like getting an education in the COMP sciences may very well be my last shot. 

Summarily, I'm hoping to gather opinions on the quality of schools that offer courses in the New Jersey Bergen county area if anyone lives around here, or has knowledge of them.

I dont want to come off as lazy by asking others to spoon feed me this information, but I actually do not know where to begin in finding a good school worth the time and money, which I have very little of. I just want to be an asset instead of a leech, I just dont know where to start.",2020-01-20 16:57:06
dygfuq,Open-endedness as Turing completeness analogue for population of self organizing algorithms,"# Open-ended natural selection of interacting code-data-dual algorithms as a property analogous to Turing completeness

The goal of this article is to promote an unsolved mathematical modelling problem (not a math problem or question). And unlike math questions it still doesn't have a formal definition. But I still find it clear enough and quite interesting. I came to this modelling problem from a philosophy direction but the problem is interesting in itself.

### Preamble

The notion of Turing completeness is a formalization of computability and algorithms (that previously were performed by humans and DNA). There are different formalizations (incl. Turing machine, μ-recursive functions and λ-calculus) but they all share the Turing completeness property and can perform equivalent algorithms. Thus they form an equivalence class.

The open-ended evolution is a not very popular research program which goal is to build an artificial life model with natural selection which evolution doesn't stop on some level of complexity but can progress further (ultimately to the intelligent agents after some enormous simulation time). I'm not aware of the state of the progress of open-endedness criteria formulation but I'm almost sure that it's still doesn't exist: as it's either connected to results of a successful simulation or to actually understanding and confirming what is required for open-endedness (I haven't heard of either).


### The modelling problem

Just as algorithms performed by humans were formalized and property of Turing completeness was defined: the same formalization presumably can be done to the open-ended evolution observed in nature. It went from precellular organisms to unicellular organisms and finally to Homo sapiens driven by natural selection postulates (reproduction-doubling, heredity, variation-random, selection-death, individuals-and-environment/individuals-are-environment) and the Red Queen hypothesis that resulted in increasing complexity. Open-endedness property here is analogous to Turing completeness property. It could be formalized differently but it still would form an equivalence class.

And the concise formulation of this process would be something like **Open-ended natural selection of interacting code-data-dual algorithms**.

Code-data duality is needed for algorithms being able to modify each other or even themselves. I can guess that open-endedness may incorporate some weaker ""future potency"" form of Turing completeness (if to assume discrete ontology with finite space and countable-infinite time then algorithms can became arbitrary complex and access infinite memory only in infinity time limit).

Please consider if it's an interesting mathematical modelling problem for research and share your thoughts.


### Further info links

* [open-ended evolution subreddit](https://www.reddit.com/r/oee/)
* [article on my (futile) efforts](https://github.com/kiwi0fruit/ultimate-question) and it's [old Reddit discussion](https://www.reddit.com/r/compsci/comments/97s8dl/on_natural_selection_of_the_laws_of_nature/)
* [digital philosophy subreddit](https://www.reddit.com/r/DigitalPhilosophy/) (posts by kiwi0fruit)

*Below is a predecessor of this promotion article:*

# Open-endedness as Turing completeness analogue for population of self organizing algorithms

Recently I wrote small article named ""Simplest open-ended evolution model as a theory of everything"". But right after finishing it I noticed that theory of everything part was just a guide and crutch to a more interesting point of view.

Specifically that property of open-endedness (that is yet to be discovered) can be viewed as Turing completeness analogue for population of self organizing algorithms under natural selection (where each program is also data). And my research program was essentially about finding **necessary and sufficient** criteria for open ended evolution (OEE). Plus may be some intuitions about directions in which it can be found (most notable is applying simplest OEE model to the beginning of the artificial universe). Hence all philosophical questions that bothered me are now reduced to necessary and sufficient criteria for open ended evolution that is no longer a philosophical question at all (for philosophical part see [this acticle](https://www.reddit.com/r/DigitalPhilosophy/comments/9kdmll/are_universal_darwinism_and_occams_razor_enough/)).

### UPD

If turing completeness is a formalization of algorithms (that previously were performed by humans only). I'm interested in formalization of natural selection open-endedness that is now observed in nature (called OEE). That's what my post is about essentially. That formalization is still not there. It's an open and a hard question.

*Text of the original article*:


## Simplest open-ended evolution model as a theory of everything

Year ago I abandoned the research project ([old Reddit discussion](https://www.reddit.com/r/compsci/comments/97s8dl/on_natural_selection_of_the_laws_of_nature/), [repository](https://github.com/kiwi0fruit/ultimate-question), [subscribe on Reddit](https://www.reddit.com/r/DigitalPhilosophy)). But from now on I hope to spend on it at least a few hours per week. To start with let's remember cornerstones of this research program:


## 1. Open-ended evolution

**Open-ended evolution** (OEE) model:

* contains **natural selection** (NS) postulates (reproduction-doubling, heredity, variation-random, selection-death, individuals-**and**-environment/individuals-**are**-environment).
* in which the evolution doesn't stop on some level of complexity but can progress further to the intelligent agents after some great time.
* that should presumably incorporate: **turing-completeness** (or it's weaker ""future potency"" form) and **Red Queen hypothesis**.


### 2. Theory of everything

By **Theory of everything** I mean:

* dynamic model of an artificial universe in which after some enormous simulation time properties of our universe is **possible** (but not necessary highly probable) but existing of intelligent life is highly **probable**.
* model that is capable of answering **all** in-model ""**why these** structures exist and processes take place instead of the other?"" questions by combination of transition rules postulates application and history of events (including completely random events).
* it may be desirable to have a **universal description tool** that can be applied to any ""level"" of the model (where ""higher"" levels are built upon many smaller modules. But the picture would be more complicated if strange loops are possible). Level hierarchy can be alike to organelles -> cells -> species individuals -> packs/tribes -> populations.


### 3. Simplest

By **simplest** I mean:

* As less axioms that govern evolution of the model as possible: **Occam's razor** (OR) plus extracting **necessary and sufficient** (NaS) system transition rules that still give OEE (it may even be some equivalence class property like turing-completeness).
* In the model time is **discrete** and **countable infinite** (given by random events), there was the **first moment** of existence, space is **discrete** and **finite**. We can try starting thinking about it with a graph-like structure with individuals of NS as nodes - graph is the simplest space possible.
* This raises question: What about quantum computers? Is bounded-error quantum polynomial time (BQP) class can be polynomially solved on machine with **discrete ontology**? And if yes what should this ontology be?
* Also I guess some may argue for lack of random events and going Everett many world quantum mechanics (QM) interpretation way. Can model
be viewed as a ""superposition"" of random events happened in different universes? If yes then we may get uncountable infinite space-time (btw: would superposition in QM preserve countable infinity for space-time?).


### 4. UPD

I dropped seriously investing in my research not long before I discovered connections with OEE and even then I wasn't aware that the only notable part of my research is OEE question part (hence I simply reinvented the ~~wheel~~ question but moved from philosophy side). Since publication of this post I'm aware of that so investing in finding out what is open-endedness is inevitable if I want to progress on this task.",2019-11-19 06:04:26
ds78g9,How to make way into companies that use algorithms like Max Flow to solve their problems?,"I have recently been introduced to these whole set of algorithms and they have blown my mind away. I am seriously considering going deep into them and exploring them but I am not very good at research. I'd rather prefer learning them and applying them directly to solve problems. Is there any particular set of companies that utilize these algorithms to solve their problems, like Supply Chain, Airplane Scheduling and such? If yes, I would like to prepare for them so that I can get a job in them.",2019-11-05 23:06:59
dh6qig,Computer Science or Software Engineering?,"Hi! Sorry if this may seem a little odd, but I'll try explain whats going on- I'm currently a highschool student that is about to enter first year University next year, however I'm not sure yet whether to study Software Engineering or Computer Science. I was wondering if any of you guys have some insight on the different job opportunities for people who study these two courses- I've had a look at job vacancies for several companies and there seems to be a mix of careers which would prefer a Software Engineering degree, but also another bunch that would prefer Computer Science. Is there any skills in particular that one degree would have over another? I heard that Comp Sci degrees tend to lead to jobs that involve making sure systems run efficiently while Software Engineering focuses more on actually designing/ coding these systems. Interestingly, at the University of Auckland in NZ which I most likely will be attending there is a really high entry requirement to get into Software Engineering ( Engineering in general), while Computer Science is significantly easier to get into while most other uni's like Sydney etc put Computer Science equal as Software Engineering which is odd.  Any advice would be greatly appreciated! Thanks",2019-10-13 05:55:50
ddj866,Goldman sachs interview question,"So I had an interview at GS. The interview started fairly easy but I think I fucked up at the start.

They asked something like the following: 
Some_Array=[1,2,3]
Some_value= 2

Write a function that returns a booleans value, true for when the value is in the array. 

Using python I thought of the built in function “in” to just check. So something like “if value in array: return ...”

It was correct however that algo runs in O(n) which isn’t optimal I think. What would be the most optimal way to check? (I do not remember if the array was ordered)",2019-10-05 05:47:19
d9qdjm,Struggling to understand what makes a dynamically typed language (Python) differnt from a statically typed language (C++),"Hi guys, I'm a first-year CS student at university, and I'm in my first week, a bit of backstory i have 0 coding or CS knowledge behind me as my previous studies were in medicinal science. In class, we're going over the different types of languages that are typed out for specific tasks. In this, we went over the differences between dynamically typed language's and statically typed languages. Now i get that Python is a hybrid language and that means something, but I'm not too sure what exactly? The lecture was going at a fast pace, and i didn't want to disrupt by asking the lecturer to explain. As the lecture went on, i forgot to bring it up, now as I'm going over the notes i see that i didn't write anything down to help explain. So I'm somewhat lost on what makes explicitly a dynamically typed language ""dynamic"" and what makes a statically typed language ""static"". The easier you can explain it, the better as I'm still only learning these things, thanks!",2019-09-26 21:36:50
d46t91,Print character at a certain point in 8086 assembly,"How do i print any character at a certain location on screen? This piece of code is not working for me and if it works how do I control where to print?  


mov ah,09h  
mov al,65  
mov cx,5  
mov bh,00h  
mov bl,10000000b  
int 10h

Any help would be appreciated.",2019-09-14 15:43:33
d3m31o,"How to understand and remember selection sort using a ""Solve it on paper"" method",N/A,2019-09-13 08:10:02
cp2g1j,"This is the conceptual design of my custom ALU. Most of the functions outlined are optional, and usually vary between implementations.",N/A,2019-08-11 21:11:17
bxu4d7,[#Need[Help] Mathematics in Computer Science,"Hi all'

I'm currently studying Computer Science in visual effects at university. As I'm reading books & papers this summer I came across a paper by a CS phd student I found some mathematics that I kind of understand but not fully, now my mathematics is OK however I do sometimes wonder how some equations work fully & to assure myself or to get a better understanding I need the help of the CS community : )  so what is the equation doing exactly?

https://preview.redd.it/dz0e9718jx231.png?width=722&format=png&auto=webp&s=0ebadca2a16d50fe38b784e37b3df844d1949783",2019-06-07 12:38:28
bxjh1a,AI replacing programmers,Wanted what your guys thoughts are on programming jobs becoming automated in the future/ where you see programming in the next 25 years or so going,2019-06-06 17:31:11
bjq5wr,"How might stable, large qubit quantum computers progress machine learning and AI?","From what I know of quantum computers, they are not good at being a conventional computer, although they can process many inputs at once via superposition. Being that all the big machine learning algorithms were designed for conventional computers, would mainstreamed quantum computers have a significant effect on the power of these algorithms, things like neural nets etc.? Or do we need to invent entirely new algorithms?",2019-05-02 03:09:00
bj347f,OpenStack wants Airship 1.0 to take flight and move devs up to the cloud without tears,N/A,2019-04-30 13:10:04
bboluu,"Google Cloud Next | New Hybrid Cloud ‘Anthos,’ Partnerships, Data Centres",N/A,2019-04-10 17:14:55
b9g82b,Is the Fashion World Ready for AI-Designed Dresses?,N/A,2019-04-04 18:11:47
b4qgiq,Does the university I attend matter if it isn’t too 10 or Ivy League,So I’m gonna be finishing up my prerequisite for computer science at a community college and I’m curious how much my university matters. I live in Minnesota and was thinking of transfer to somewhere like Minnesota state university Mankato to stay more local and save money but don’t know if I’m just gonna have no career opportunities because it isn’t by a tech hub and the university isn’t crazy high ranked in computer science. ,2019-03-24 00:51:22
b06dmx,[Academic] Poll: usually used python version (Python Users),N/A,2019-03-12 10:52:28
aoao39,Explanation in Human-AI Systems: Meta-Review of Explainable AI,N/A,2019-02-08 00:23:43
ah24mn,OS that runs windows programs?,"If I were to develop my own OS, like Apple's Macbook OS, could I make it so it could run all windows programs? So I could open Photoshop's windows version as if I were using a windows operating system. Would this be illegal or protected by Microsofts patents or trademarks? Thank you.",2019-01-17 20:31:29
aedeq8,Could a Turing machine be able to do floating point operations if the machine was altered?,"This was a theoretical question in a fellow student's computer architecture exam. I can't think of how it would even work. As I understand the Turing machine can only work with binary integers and characters but what if there were real numbers included? I'm guessing the problems would arise if we were dealing with very large numbers but what about numbers with a certain size?  


Anyways, just hoping for some input. Don't really want to put in any more of my thoughts as I don't want to sound stupid. Can't really grasp the concept of why there would be a difference of the way the Turing machine would work.",2019-01-10 00:32:45
ac7opj,Is it possible to track decision making in sports?,"Hi everyone,

First time poster but I have a technical question and I figured I post it here. Sorry in advance if this isn’t allowed. 

I want to be able to create an app that tracks players decision making. Is this possible technically?

Thanks 

Edit: More Details 

Basketball is the primary focus. An example of a decision would be something like did the player make the right pass when going to the basket? A good decision would also be dependent on what the coaching staff deems a good decision.",2019-01-03 17:07:07
9pblkh,"3 semesters left, got full-time offer, Losing motivation in CS classes","I got a full-time offer from a big tech company and have internships lined up as well. (Relevant because they are what caused me to lose motivation. I'm feeling like the only reason to go to school is to get a job, and since I have one already school is becoming a drag and pointless.)  Including my current semester, I still have 3 semesters left of school left. I'm losing motivation to do well in my current classes, especially one about processors, assembly, etc.

&#x200B;

Does anybody have any advice? I feel like this class is taught very poorly (there are three instructors and they alternate every few weeks), it's uninteresting, and the fact that I feel the material from this class will be completely forgotten and useless to me in the future are the three main reasons why I am feeling this way.

&#x200B;

Perhaps, not every class is meant to be enjoyable?

&#x200B;

Edit: Many people have gotten the idea that I was considering on dropping out. I would not go that route unless I started a very successful company. I'm more tempted to just major in data science to take fewer CS classes or do worse in some of my current classes.

Edit 2: I've never actually posted on reddit for advice because I didn't think I would get anything useful, but I'm glad I did because my motivation has now been spurred. Thanks all!",2018-10-18 17:54:46
9i0awa,CPU Register Vs RAM . - 32bit vs 64bit,"Hello,

I was trying to understand what does 32-bit or 64-bit actually means. I am aware that 32-bit can have max upto 4GB of RAM and 64-bit can have in exabytes.

After going through few articles, I understand that 32 or 64 is actually the size of CPU register(Correct me if i am wrong)

Now my question is, How does the CPU register influences size of RAM? (Meaning why we have been told 64bit means more RAM)

May be i am missing something very basic. Can someone enlighten me?

&#x200B;

Thanks.",2018-09-22 15:00:57
9esxj7,A Degree within Computer Science....,"So I'm debating on whether to go to university to study computer science. Computers & Technology have always been a strong point for me as it runs within my family. I have taken IT at A-Level (Grade B) and Btec (D* D* although only half the course due to personal issues) and want to take it at university to further my learning.

However the problem I have is PROGRAMMING.

It feels weird to say but I have a bad outlook on programming. I guess because I'm not very good at it alongside the fact I wasn't taught it well, (probs why I'm so bad) i don't have a liking for it. However the majority of university courses have a module of programming within the subject and I'm debating on whether to either take a foundation year to encompass this, or just skip straight to industry instead. 

For people who have gone to uni or are in the middle of getting a CompSci Degree, how much programming did you have to do and was it hard? ",2018-09-11 01:03:49
9bla7n,Best practices for designing a complete UI system?," Also important: designs and best practices from an software/architectural standpoint.


What are the best practices/design patterns used when creating a UI system from the ground up?

I've taken an interest in UI and would like to use OpenGL (which I'm already familiar with) to create a windowed user input system for educational purposes.  The system will contain windows and their trees of sub-windows/controls.

Are there any good books or other materials which cover this overall topic or perhaps ones which focus on specific components/aspects of UI systems?",2018-08-30 16:45:30
94tmyd,Upper Division Classes to Complement Geology,N/A,2018-08-05 17:42:46
89s44v,I've got a theory that I'd like to hear people's opinion on,"Hey there!

I'm not sure if this is the correct subreddit for this topic, but I thought I'd post it, and then rather move it to another subreddit if it wasn't deemed appropriate.

I'm about to complete my first year of a bachelor's degree in Computer Science. I'm enjoying it a lot so far, but there's one question which is sort-of not, at least so far, covered by any of my modules, that I thought you guys could have an input on.

I've always thought about the concept of having computers inside computers. What I mean by that, is that I'm facinated by the concept of not performing direct calculation on a computer, but rather ""simulating a world"" in which some simple rules apply, and then use the world you're simulating to make a computer. One example of this would be from the game Minecraft (which I'm sure some are familiar with) where you can use *redstone* to create wires and simple logic, and if you're doing things correctly, you can set up these to perform simple (or in some cases more advanced) calculations. This means that what the actual, physical computer is doing, is just performing claculations that enforce a set of rules which apply to Minecraft's world. A more advanced example would for example be to have a system simulating electron flow through wires and the nature by which this happens, but virtually setting up these wires the same way a physical computer is set up.

This is of course a very lossy process, but one that I still find interesting. Are there any areas of computer science that encompass this? If so, I'd love to know about and read up on it.

What my theory is, is that you could never have a computer running a simulation, and then in the simulation make a computer that's more powerful than the one you're physically using. I'm expecting this to be a theory that's true, because if that was the case, you could just have a ""chain"" of gradually more powerful computers, meaning any computer could be infinitely powerful. I'm more interested in the computer science related answers to *why* this was to fail if you tried. And also, it would be very interesting to know how lossy this process is, if it has any practical application, and anything else that's relevant.

I'm interested in any input regarding this!",2018-04-04 18:26:58
85rhqb,Learning DSA isn't tough now - Community Curated DSA Resources (2018),N/A,2018-03-20 09:54:34
849vdq,How to Find the Longest Increasing Subsequence of an Array,N/A,2018-03-14 02:17:02
81v8bj,Only wanting to use computer science as a tool for life science research?,I am only studying CS so I can use it as a tool for bioinformatics research. I am unsure at this point if I should continue to study CS after transferring from community college to a 4 year. I am more interested in my math and physics courses than programming and throw my programming assignments on the back burner behind the work for the other classes. I am starting to think I should change my major to bioengineering but then I would have to start at an intro level engineering course at a 4 year and I've already been in community college for 3 years. I believe AI will be a powerful tool to use in pharmaceutical research so that keeps me wanting to stay with computer science but I am seriously considering changing majors. Any advice??,2018-03-04 03:22:53
7o3tqw,Biggest Testing Failures of 2017 [X-POST],N/A,2018-01-04 15:52:03
7evz4x,A little bit of separation logic,N/A,2017-11-23 01:23:34
6qoq32,Brain-like computing comes closer with neuron-mimicking nanomaterials for A.I. retina,N/A,2017-07-31 14:23:35
5wlyf6,Please suggest me some ideas.,"I am in my last semester of My Bachelor's and we have decided to print a T-shirt that reflects the journey of all these four years. Can anyone please suggest me some ideas ? I got one that says "" In my world, 1 + 1 = 10 "". Thanks!",2017-02-28 04:36:25
5kq5lt,how Advanced maths contribute in CompSCI ?,",and i want to know if compsci more than just programming ? ",2016-12-28 13:09:22
4yypwk,"Would love thoughts on an analogy for Abstraction as ""ice melting"" -","Hey I'm working on a video on Logic and Abstraction. 

And in this video I explain how Aristotle broke things into primary substance (concrete matter) vs. secondary (abstract concepts)

and now I'm looking for a visual analogy for abstraction. I was thinking the water cycle might be a nice one.

so:

Ice = concrete thing

Water = abstract thing

therefore:

Instantiation = freezing

Abstraction = melting

i think it feels kinda nice, but I might be biased. 

initial thoughts? 
",2016-08-22 03:39:52
4ue9gg,"The Uber Engineering Tech Stack, Part I: The Foundation",N/A,2016-07-24 18:11:36
4q29i9,Algorithms and Data Structures for Directed Graphs with 2D coordinates,"I have an app where i use directed graphs, on which each node have a 2D space coordinates, and it's a bit difficult to find good results in google about this.

What good sources to search about this do you recommend me?

I'm interested in this particular case is that how i can sort the graph, considering the edges between nodes and update their position in space to group them in clusters and avoid ""collisions"" between nodes",2016-06-27 08:02:25
4m7obq,Some questions about computer architecture,"I have a few questions maybe some of you can help me out, thanks.
1) Can floating point addition be done in pipelining?
2) Is the hard drive cache made of static memory?
3) Is it a good idea to run LINPACK on a GPU?

It's from a quiz of 150+ questions our professor sent us, and these 3 I cant find an answer for it. I found stuff on the internet but i dont understand, can someone help me out?
Thanks",2016-06-02 15:23:14
4ie5hk,Computer Forensics: Collecting Some Evidences through Digital Process,N/A,2016-05-08 10:57:52
4gr6qc,Good place to find AP test questions?,"If this is the wrong sub, just point me in the right direction :D

I'm not too bad a programmer, but the multiple choice section of the practice APs we've been taking in class are killer (ADHD + big walls of text = mild breakdowns every third question). I can't seem to find anywhere that has MC practice questions, just places to learn coding - which is fine, just not what I need. 

Anybody know any good online resources? We've already been through the Barrons' review book in class. ",2016-04-27 23:14:48
47if18,List of unsolved problems in computer science,N/A,2016-02-25 11:15:47
46xp4w,All computable structures have a normalized form,"For every type of computable structure, such as the set of all undirected graphs or the set of all lambdas, there are many ways to represent them as bitstring, such as the actual bits in memory and CPU registers, the 2d adjacency matrix of an undirected graph, or any abstraction you like as long as its a bitstring.

The normalized form of any such structure is the lowest sorted bitstring of all duplicate representations.

That does not mean it is efficient to find such a normalized form, but it certainly exists for every computable structure, given a function mapping each possible bitstring to either ""does not parse"" or the structure represented by that bitstring.",2016-02-21 22:35:25
46gsiq,Where can I learn and practice question on complexity?,"Hey guys, 

Freshman here, doing complexity in my data structures class and I'm kinda lost. Can you guys point me to resources that will help me understand complexity and practice questions associated to it? 

Thanks!",2016-02-18 20:29:59
3mye4z,How to find minimum range across multiple arrays or lists.,N/A,2015-09-30 11:49:43
3hfycq,A Go implementation Count-Min-Log sketch: Approximately counting with approximate counters (Like Count-Min sketch but using waaay less memory),N/A,2015-08-18 13:17:11
3g68u6,Why are There so Few Female Computer Scientists? (MIT AI Lab report from 1991),N/A,2015-08-07 20:55:36
3c993d,Math Homework Help (Groups),"I'm needing some help figuring this out, since our book we use for the class is more confusing than helpful. There's multiple parts to the question, so will list them all.

Let (G, ∗) be a finite group and let g ∈ G
a)  Prove that there is a positive integer k so that g^k = e

b)Prove that {e, g, g^2, g^3, . . . } is a subgroup of G whose cardinality is the order of g.

c) Prove that the order of g divides |G|

d) Conclude that g^|G| = e.

",2015-07-06 02:12:41
3c0e1e,Computer science basics,After summer ends I'm going to be starting my first year in university of toronto saint george. I'm just wondering is there any place like videos and webpages that i could use to give me a head start on java?,2015-07-03 17:00:16
3bl497,ELI5 how does basic encryption work?,"I've been trying to grasp the concept of encryption and how it works for a while, but everything I've read has been largely technical and generally hard to understand. Thank you in advance for all of your help",2015-06-30 02:40:25
36qtxn,Dr. Turing's Automatic Machine in Python,N/A,2015-05-21 11:49:59
33nof4,Suggestions for LUA project,"So for my programming languages course we were tasked with picking up a language that none of us have been exposed to before and create a project that shows the strength for the particular language. We then need to compare it to the same program in a common language and show the performance improvement. Our group chose Lua and I was curious if you guys had any ideas for a project that could be feasible with 2-3 weeks. As far I know it seems that Lua strength resides in it's tables and their functionality so we were thinking of some kind of inventory program that performs faster searching than it's competitors. Any input would be much appreciated, Thanks!",2015-04-24 00:24:48
323m6a,POMDP Toolkits - Does anyone have experience with it?,"Hi,

I'm looking into POMDPs to learn a policy for a Dialog System. I'd like to use TAPIR:

http://robotics.itee.uq.edu.au/~hannakur/dokuwiki/doku.php?id=wiki:tapir

or APPL:

http://bigbird.comp.nus.edu.sg/pmwiki/farm/appl/

APPL seems to me like not well suited because the POMDPX format requires to much work to model. But maybe my first impression is wrong.

TAPIR looks really nice and I modelled a small POMDP; I got a solution/policy from the solver, but now I don't know how to feed it with observations. If someone used TAPIR before or has used another toolkit I would really appreciate any help.

Cheers",2015-04-10 08:32:53
30cwkq,Some basic computer graphics questions,"1. Why are GIF and PNG regarded as ""lossless"" compression formats? GIFs can only represent 256 colors so wouldn't a lot of data be lost when saving an image as a GIF? 

2. If vector graphics images have to be rasterized before being displayed, then why doesn't enlarging them reduce quality just like bitmap images? ",2015-03-26 10:14:28
303xxz,Implementing OOP With Type Erasure,"This is something that's been bugging me lately, so please take a minute and humor me and tell me why I'm an idiot.

The tl;dr is why are vtables inside the object instead of outside in the reference to the object?

My thoughts:

Interfaces as they're defined in languages such as C++, Java, C# etc.  take the form
    
    interface Renderable {
       void render(Renderer renderer);
    }

Then you can explicitly make a type

    class Ball : public Renderable {....}

Which will embed a vtable from Renderable into Ball

    /*C style!*/
    struct RenderableVTable
    {
        void (render*)(void* this, Renderer renderer); 
    };  //with one implementation per class filling this in.

So that's the normal way of doing interfaces, but you can also use the type erasure style of boost::any and std::function, which gives you something like this instead:
    
    class Renderable
    {
       template <typename T>
       Renderable(T&& renderable) 
       {
          vtable = RendererVTableImpl<T>::get();
          data = /*somehow move this into data, memory management here can be involved, but you can do a lot of tricks here.  Very language dependant, GC etc.*/
       }
       void render(Renderer renderer)
       {
          vtable->render(data, renderer);
       }
       RenderVTable* vtable;
       void* data;
    };

Then you can do the same sort of stuff that you can do with normal interfaces....

    std::vector<Renderable> renderables;
    Ball ball;
    renderables.push_back(std::move(ball));
    for (auto&& renderable : renderables) renderable.render(renderer);

If you move the VTable outside the class, you can still keep the functionality of inheritance, but you don't have to embed any vtables directly into your class.  Depending on how you're storing objects, this might be a win.  If you had compiler support for this you could do some crazy stuff with things like extension methods here (Scala does some of of this...)  You also can automatically adapt a lot of classes and not have to go through a huge runaround with adapters for interfaces.

For pretty much everything it seems simply better.  Even it not being explicit is fixable: it's a contract you have to follow but it's sort of ""invisible"" which might not be great all the time, but you can still enforce that it follows the contract if you have compiler support (which also allows for things like extension methods very easily...  Ball implements Renderable, Renderable has a renderBlurred function for example.)

So why aren't things done this way more often, why are the vtables inside the object?",2015-03-24 07:22:09
2zof01,Limit of Algorithms,"Let us have a problem P(d) where d >= 0. For different values of d we have a different problem and lim(d->0) P(d) = P(0). 
Now let us have an algorithm A(d) for d > 0 (not at = 0) which solves P(d) can I prove that A(0^(+)) will solve P(0) and if so, how can I prove that. Basically I want to prove that P(0) is atmost as hard as P(d) for d > 0. Note that if lim(d->0) P(d) = P(0) was not true it would be obviously not true but in case they are equal I feel that A should suffice to solve P(0). Examples include graphs tending to trees as edge weight of edges creating cycles tend to 0 and all algorithms which work on a general graph obviously work on a tree.

Assumptions : Time complexity is independent of d and d ranges over real numbers.",2015-03-20 07:29:18
2z4hkg,Is (was?) there a Carl Sagan/NDT of CS?,N/A,2015-03-15 14:20:25
2yblqo,Help with drawing HLSMs,"Hey everyone, its my first time posting in this subreddit, so my apologies if this isn't in the right place and/or in the right format.

I have a final coming up soon on logic design, and I was wondering if anyone knew any helpful resources on how to draw HLSM based off word problems. If need be, I can post one of the word problems from my homework as an example.

If anyone could point me to any helpful resources, that would be amazing!",2015-03-08 08:21:01
2xbzn4,Why can a finite automate represent only those languages where one can count up to M mod K where K is number of states in the machine?,"Professor Alex talks about it here[](https://www.youtube.com/watch?v=ABv7wjaSduA) at 3:30. Can you please explain? Is this related to pumping lemma? I am an EE so there.

Youtube link: https://www.youtube.com/watch?v=ABv7wjaSduA",2015-02-27 08:00:51
2udrin,Correct me if I'm wrong on my understanding of quantum computing:,"To my understanding, there are certain things computers are limited to compute. The ability for a computer to simulate any experiment dealing with quantum mechanics had been one of those limitations, until we figured out a way to do so thus creating ""quantum computing"". By solving this problem, we have opened the door to many possibilities that exercise the concept of quantum computing, as we continue to develop more ways of utilizing it.

 But my question is this, not to sound ignorant but, if exceeding one limit in computation created a ""phenomenon"", then if we exceed other limitations, will something similar occur thus creating ""**fill in the blank** computing"" or anything along those lines?

If my understanding is false can someone explain to me the origin of the concept of QC. Did they just sit down one day and said, ""a quibit should do exactly this"" and went on from there? What were the first steps they took in order to actualize this concept, after conceiving the idea?",2015-02-01 05:31:22
2ua3d3,"How was the first computer and notion of ""bits"" conceived and how did they create the first CPU?","I don't just want to know the text book definition, I want to know the history. I know the first thought was ""We should make a machine that computes problems for us"" But what after that?

What was the process in which they chose to solve that problem?

How did they decide that making a computer the way it is the most optimal and efficient way? Were there other models abandoned as a result of trial and error?

How did they figure out the way in which they could make a processor using those materials or metals at that time? How did they know that by making it in that specific way, it would do what they intended it to do?

(I don't know if this makes sense but) When they first conceived the idea of ""binary bits"", and laid the foundation for what a bit would represent or do, was that conceived idea, the most logical or even only approach to what that notion accomplished? Or is that one of the many ways they could have represented data and everything else spawned from that notion. (for example if I went back in time would I be able to change the notion of bits from 1/0 to A/B or anything different)

Considering that most modern computers derive from the first basic computation model (except of course they're optimized), is that model absolute and/or the most logical model or could there have been a COMPLETELY different model proposed in the past.

I just want to know how they made something of nothing, I hope these aren't stupid questions :)
",2015-01-31 05:34:34
2r4dfm,"Data Elixir, #16: Best issue yet! AI use cases; learning Deep Learning; data viz tools and keynotes",N/A,2015-01-02 18:23:43
2oyrrc,Ideas On How To Turn Arachnid Arduino Hobby Project into CompSci Senior Project?,"I'm currently in the process of constructing and programming an eight-legged servo-based Arduino-controlled walker. The walker utilizes sixteen 9gram micro servos to provide two points of articulation per leg, however I may change this to 24 or 32 servos for three or four points later. The main goal of this project is to create a walker that realistically mimics the walking patterns of some of the most common species of arachnids, and to create a walker that overall just looks great.

I'm looking for ideas to take this project a step further, so as to make it suitable for a senior project in CompSci, instead of something that would be better represented as an Electrical Engineering project. I was thinking of adding additional features to the walker to create some form of autonomy, such as an IR proximity sensors to the walker to allow it to walk freely and avoid obstacles (or conversely to prefer walking along walls), or perhaps light sensors to allow the walker to locate and favor dark places, etc.",2014-12-11 11:54:49
2otvjm,Looking for some programming literature,"So I'm an Information Science major about to start my winter break, and would like to read some quality literature that is both interesting and can help me gain some more knowledge in programming. Any books that have changed your perspectives or enhanced your programming skills would be fantastic!",2014-12-10 03:48:47
2mhb8y,How to solve this problem efficiently?,"The following problem occured to me while thinking about how to implement a linker for 80286 programs:

> Given an integer *n* and a set of sections where each section has a size no larger than *n*, find a partitioning of *S* with the least number of partitions such that in each partition the sum of the section-sizes does not exceed *n*.

I have the hunch that this problem might easily be NP-hard, but I'm not sure how to show that. Is there a fast algorithm to approximate a good solution?

This problem appears when trying to link object files into a program for the 80286 architecture. This architecture has segments of up to 65536 bytes each and complex programs need to be split into multiple segments. The linker tries to arrange the program into the least possible number of segments since each segment corresponds to one entry in the operating system's segment descriptor table.

As a complication of this problem, one could consider the call-graph of the program to link. Considering the case that each change of the code segment has a little penalty (the CPU has to look up the new segment in the segment descriptor table), the linker could try to group functions into the same section that call one-another. When the call graph is weighted by the expected number of calls, the linker could try to find a partitioning of the program into segments so that the edges of the call graph that cross segment boundaries have the lowest sum / sum of squares.",2014-11-16 17:59:44
2ht49o,What is a good source for airline data?,"Specifically; I am writing a rudimentary travel program at the moment and I am interested in pulling price/date/destination/origin information from airlines about future flights (and keeping them up-to-date). 
Is there some kind of feed I can get data like this from to use as input? 
P.S.: I'm not too sure if this is the right subreddit for this but I really looked around, also I x-posted in /r/askcomputerscience.",2014-09-29 18:07:14
2f311u,ZehJuggler - Hacker Challenge - Part 1 - Zeh Images - Pastebin.com,N/A,2014-08-31 14:20:41
2er8d3,Does it matter where I go to grad school?,"I currently have two options for grad school. Also I am going for a non-thesis M.S in CS
Option A. Stay at my tier 2 University and go directly into the graduate program without taking additional classes or GRE.
Option B. Stay an undergraduate for another year in order to take additional background classes and get internship experience. Then apply to top grad schools in my state. (4 tier 1 schools in my state).
Option A would allow me to graduate with a masters within a year and Option B would take me two to two 1/2 years to finish my masters. I am leaning more towards option B because everything I have read so far suggests that it really does matter where you go to graduate school.",2014-08-27 20:05:33
2b2tct,"Which one is more useful for computer science, math or physics undergrad degree?","I'm torn between these two.  Here are a few questions I have (assume both paths have the same amount of programming):

1) Which one is more useful for 3d graphics/simulations?
2) Which one would a computer science employer prefer given equal portfolios?
3) Is it possible to go from a math or physics undergraduate degree to graduate school in computer science? If so, which one would be considered more useful for areas such as artificial intelligence.",2014-07-18 20:38:27
2at1fj,'Mapping in Computer Science' question,"Hash Function: Any algorithm that maps data of arbitrary length to data of fixed length  (wikipedia)

Maps here means:Any algorithm that assigns  data of arbitrary length to data of fixed length ?

Is this what computer science guys mean when they say map as a verb?",2014-07-15 22:48:16
2a3okg,To all CS majors what was your minor and why did you pick it?,im thinking about either math it or eet. ,2014-07-08 01:04:41
2931si,We are organizing a MLH hackathon at LSU! Come check us out! GeauxHack,N/A,2014-06-25 19:31:50
26v8sq,Bresenham's Line Drawing Algorithm - Part 1 What is Bresenham's Algorithm,N/A,2014-05-30 11:49:00
25pgl0,"Angular.js tutorial: scaffolding, dependency, testing [x-post /r/programming]",N/A,2014-05-16 12:27:56
25369d,Rubric for Picking a programming language for a beginning course.,"My local CSTA chapter took a stab at creating a [rubric for evaluating a programming language's suitability for use in a beginning \(first\) programming course](https://docs.google.com/spreadsheet/ccc?key=0AhE1uOKIWEXidEthdWFvcDRiZmJDdS15T0dzLTVEaVE&usp=sharing). We're reasonably happy with the criteria, but are looking for other people's opinions on the languages.

If you're interested in what we thought, take a look, but I'm more interested in what you think. The link above is editable. If you have some experience with teaching more than one programming language, then I'm really interested in the changes you'd make. 

If you're going to edit, here are some suggestions:

* The actual numbers are **meaningless**, so make the **relative difference** between the two programming languages you use is about right. 
 
* If you see something too high or too low, try just **raising it or lowering it by 1**. Maybe we can come to some general consensus that way. 

* You're welcome to change the weighting as you wish, but keep in mind that it is **even more subjective** than the rest. I'm not interested in a consensus value there, so change that as you wish to see the resulting ""goodness"" of each language (the number at the top). 
 
* There are cells for comments. Try adding to them rather than deleting from them. 
 
* Add your own criteria (new rows) if you want. 
 
* Add your own languages (new columns) if you want. 

I know there are probably better ways to collect this information, but I already had the rubric and lazy.

TL;DR [Edit this rubric](https://docs.google.com/spreadsheet/ccc?key=0AhE1uOKIWEXidEthdWFvcDRiZmJDdS15T0dzLTVEaVE&usp=sharing) comparing teaching with various programming languages. Don't be dick about it.


",2014-05-09 00:19:48
24xq2i,Good Canadian CS Universities?,"Hey, i'll be finishing up my A levels soon and am hoping to study CS abroad in Canada.What would be some good universities /r/compsci would recommend?",2014-05-07 07:58:16
20lr5j,Notes on Information-Centric Networking,"Research Groups on ICN (Information-Centric Networking):

http://irtf.org/icnrg
http://www.fp7-pursuit.eu/PursuitWeb/

Wikipedia Articles:

http://en.wikipedia.org/wiki/Named_data_networking

http://en.wikipedia.org/wiki/Publish–subscribe_pattern

Research Papers:

http://www.cl.cam.ac.uk/~ey204/teaching/ACS/R212_2013_2014/papers/ghodsi_hotnets_2011.pdf

http://www.cs.ucla.edu/classes/cs217/2011_Illustrate_PubSub.pdf

Prototypes:

http://www.fp7-pursuit.eu/PursuitWeb/?page_id=338",2014-03-17 03:31:05
1xub5l,"Application that can be used to define zones, and given a zip code return the zone","Hey all,
      I'm looking for an application, nuget package, web service, kinda anything that fits the following. Basically I have different rules for zones of a map. These zones do not follow any normal zoning (meaning they don't follow states, zips, region, etc.). What I want to use is something that will allow me to define a zone as a set of points of a polygon. Then through a GET with some parameter (zip, city, etc.) return what zone this lies in. I would have an idea of how to code this, but I feel like there has to be something already out there that fits it. If you need more of a description or anything, don't hesitate to ask. If I am posting in a way that does not satisfy the etiquette rules, please let me know any I will remove this post. Thanks in advanced for the help, and I with you all the best of luck :)

Thanks again!",2014-02-13 22:15:32
1tzy32,I'm a bit confused about diagonalization.,"I'm reading 'introduction the the theory of computation', and I'm having a hard time understanding why diagonalization works. I can understand that two finite sets that can be paired are equal, but I don't understand why we can apply that to infinite sets. The sum of two even numbers always make an even number, but that doesn't mean we can apply that rule to the sum of even and odd numbers.Why can we apply the same rules to infinite from finite?

And inb4 'ask your professor' i'm a high school senior and I'm studying this on my own time so I can't.",2013-12-30 06:12:26
1t9xl3,What are some good texts or websites to learn about self-editing code?,I want to study it as a subject. I'm aware that it's unpredictable and that there are better ways to do things. I just want to explore the concept and write some programs using the principles of the subject.,2013-12-19 21:28:29
1pzfs5,Wireworld Computer,N/A,2013-11-05 22:58:06
1ojw18,Language-Specific Architecture Paper,"I am writing a research paper for a Computer Architecture class on the topic of Language-Specific Architectures/Processors. Obviously two major components of this topic include the LISP Machine and the Java Computer. However, I'm having a hard time finding more information with just Google. I'm asking for any help with this topic, such as references, new sub-topics, papers, journals, books, etc. Thanks in advance for any help!",2013-10-16 03:57:57
1nl9ac,The Dartmouth Project: A Quest for Artificial Intelligence,N/A,2013-10-02 16:14:15
1mxrki,Known safe multithreading techniques?,"What are known safe multithreading techniques? I know there are task which are really just a series of functions ran after eachother which isn't truly multithreading but may be desired while programming. I don't know much about channels but it sounds like data is serialized or copied from one thread to another to be put into a 'message' or 'job' queue. I hear queues can steal jobs and i imagine the queues uses mutex or lockless for protection.

I remember hearing futures and actors but i'm a little unsure what an actor is. What are some concurrent programming techniques and how do they work?",2013-09-23 03:39:30
1c65x3,Has software advanced as much as much hardware?,"I have heard the argument that hardware advances according to Moore's law but software seems to advance very slowly. I have also heard that the reason for this is because software solutions are not very standardized, and that's why design patterns are the savior that can make software advance at more rapid pace; patterns standardize abstract ideas of expression, and allow for the improvement of them. What do you think? Can you make the same argument that the level of abstraction of thought has not advanced as much as our technology because we do not use enough design patterns in our inner thoughts and expressions?",2013-04-11 23:46:37
1c5q7m,"What areas of research are involved with the autonomous/""driverless"" car?",Any ideas?,2013-04-11 20:34:32
191ctw,TCMalloc : Thread-Caching Malloc,N/A,2013-02-22 19:29:12
zfjyr,"Is there a subreddit for new, emerging, beta programming languages?","Also, what are some websites/blogs that showcase bleeding edge programming languages?",2012-09-06 03:33:00
yxrgd,Research Topics in Computer Science?,"Note: I am a high school student with a good amount of experience in programming, I have already finished Calc1 and 2, etc. I did a cryptography research project last year with hashing algorithms.
What are some topics I can try doing for science fair competitions or maybe approaching people at the local university to work on with?",2012-08-28 01:48:42
vmiom,What are Alan Turing's important/influential contributions to computer science?,N/A,2012-06-26 11:56:02
v2epx,Does anyone mind helping me choose between two modules? ,"Hello Reddit,

I'm a 3rd year student studying Computer Science in the UK. I've solidly decided 110/120 credits I can use, and need to choose another 10 credit module. 

There are two that I would really like to do - Data Mining, or Software Quality and Testing. I'm unsure which is the most 1) useful 2) interesting and 3) relevant to a future career in this subject. Software Q&T will be more universally useful, but there's so many situations that data mining can be applied to, that this module seems highly valuable as well. Neither of the lecturers for the modules are particularly fantastic, and I have friends in both modules, so these factors aren't affecting my choices. 

Would anyone with some more experience in either the subjects or real-life experience mind helping me to make up my mind, based around the subjects themselves?",2012-06-14 22:12:54
tzkvi,"Hey r/compsci, I'm having second thoughts about my current major and am considering switching to computer science. Can you guys tell me how the future looks for the profession, how the job market currently is, and if you guys would recommend it?","Hey guys, I'm currently doing pre-pharmacy and am having second thoughts about the career because of the huge increase in pharmacy schools and as a result, the over saturation of the profession. The future looks pretty bleak so I am considering switching to my plan B which is computer science. I took 3 years in HS and took intro to comp sci at my college already in my first semester of college to explore it so I have a decent background for a beginner. Anyway, thanks in advance for replying guys!",2012-05-22 18:02:35
tk4ag,OSes for multi- and many-cores?,Somebody in here with a grip on that subject who doesn't mind pointing me to cool papers and/or even sum up the state of the art in one or two sentences?,2012-05-12 21:21:45
sm3z7,Hey /r/Compsci I've got a quick question about majors and CS opportunities,"Hey y'all! I've come to a fork in my career, and I'm looking for advice as to which major I should choose, and what opportunities are available to me once I do pick one. I'm currently in the enviable position of having been formally invited into the CS major at my university by a professor, and I have extensive programming experience, but I'm also very interested in doing Applied Mathematics, or a Math major.

The Question: If I DO end up picking Applied Math or Math, what are my chances of being able to continue in areas that are heavy in CS, like computational numerics or modelling? The requirements for Applied Math end with basic C programming or basic OOP, and that scares me into thinking I won't be able to continue with the level of programming I'd like. 

Also, if I DO do CS, how hard would it be to say, continue into a Math MA? or Physics MA?

Thanks for listening!!!!

EDIT: I forgot to specify, I only have enough time to do 1 major, no minor. Pressure from parents.",2012-04-22 02:25:12
sfy36,Writing a report (final dissertation),"I'm producing a final report on a real-time character recognition program I created I have hit a dead end on things to write about, I was wondering if anyone had any links to good report writing for a technical degree? things to include in a technical report(I have all the obvious headings). Or anything that you have used that has really helped to create a great report.

Thanks in advanced :D",2012-04-18 13:16:52
r19ef,How are programs capable of being run on different architectures?,"In my Computer Systems class we have been looking at MIPS32 and how it is implemented. However  I know there are multiple types of assembly.

As I understand a MIPS command becomes a 32 bit string that will cause the CPU to do the desired task, I understand how this is achieved.

I also understand that when I compile a C program for instance, it is converted to an assembly instruction set and then object code? This program can then be run on almost any machine.

I do not understand, if each CPU is designed around a different instruction set, how my program can run on almost any machine when it the program was compiled using a specific instruction set? How does the program run on a computer whose CPU is designed around a different instruction set?",2012-03-17 21:41:33
p4dbo,I'll start to teach programming in a few days. What should I put in the program?,"I'm teaching a course named ""Advanced Programming"", with a few catches:

* it's the faculty of Arts, our degree is something like CS for the Humanities;
* it's not really ""advanced"", it's called like that because is the second of two courses, the first being ""introduction to programming"";
* it's only 7 weeks, four hours per week, of which two of lecture and two of practical sessions in lab;
* students should already know the basics: variables, control structures, functions. They also have played a bit with random numbers and simulation.
* Python will be used. Like it or not, I can't change this.

I should teach at least a bit of OOD and recursion, but I'm open to advices of any sort. ",2012-01-31 09:17:37
j3kvp,"CompSci BS and the military, amongst other things...(x-post from cscareerquestions)","I am about a year out from graduating with a BS in CS and am having serious qualms about the lifestyle that a CS degree seems to dictate.

I have been a student assistant in the networking unit of a government agency for the past 4 years. Being here in this prison cel..cubicle, as well as a recent traveling trip, has opened my eyes up to the possibilities the world has to offer. I don't think I will be happy sitting behind a desk for the rest of my life. I don't like the idea of working a job where the only people who benefit from me being there are those who work in the same building with me (ie: help desk and related). I feel the need to achieve something beneficial on a scale more grandiose than an office building.

My experiences at my current job have mostly been secretarial, as the ever increasing security policies have removed my access to in-production chassis and routers. It was however fulfilling when I was able to get my hands a little dirty. My programming experience resides solely in the college, as my job has not mandated any and I don't feel the desire to program on my own time.

I have read a lot of threads on this subreddit about how it depends on what you are programming and whether or not you enjoy the task at hand. I am unsure as to where I fall when thought about this way. Sure it is rewarding when I am finally able to push through that last part of the program and get it working to turn it, it feels great. But, I don't know if I can see that as a lifelong thing. Then again, perhaps I lack the experiences to really assess the possibility.

So after all of that rambling, I am looking into perhaps a military job that caters to our field. The Navy has an Information Warfare Officer which sounds like fun to me. Without having done extensive research yet, it feels like a job that would allow me to travel, be involved with computers, and feel like i am actually doing something meaningful.

I realize that this post might paint me to be someone who is in the wrong field, but I assure you I am confident in my choice to get a BS in CompSci. I truly enjoy computers and technology in general, and my CompSci classes teaching about theory and the logistics of how a computer works are very fascinating.

I am just not sure where I should be heading now that I only have another year or so until I need to hit the ground running.",2011-07-29 20:58:54
fubgm,No proof of P=NP after all (yet?),N/A,2011-02-28 14:45:14
fs8e0,CS Application?,In class we are talking about accessibility for the disabled to access interfaces. She gave the example that curbs aid those that cant walk but hinder those that cant see. She then asked for us to come up with an example of this in relation to interface accessibility. Ive thought and thought and cant come up with anything. any ideas?,2011-02-25 01:49:59
fq60c,Anyone with automata knowledge and some spare time available?,"I was wondering if anyone with some spare time wouldn't mind giving me some feedback on my homework. It's already done, I just was looking for someone to glance over it.

[Homework file](http://dl.dropbox.com/u/169215/hw2.pdf)
[My answers](http://dl.dropbox.com/u/169215/result.pdf)",2011-02-22 08:53:06
fdv5z,Thinking about going straight to doc. after BSc or should I complete a Masters degree first?,"I know there are some fields where you need a Masters degree to be accepted but not always.

Thinking about going one step further after my BSc but what are your opinions about this?

Not going to name the field I'm thinking about because I want to keep the question general so others could find use for it.",2011-02-02 16:11:28
fc0hq,"In two weeks I have to make an hour long presentation on ANY CS Theory topic, and can't think of anything. Any ideas?","It's me and two other people doing this, and we need to have a topic in soon, but are having a hard time thinking of a good topic. I know there's a lot out there, so what are some of the cool theory topics that excite you?

The class I'm doing this for is basically an exploration of many different theory topics. For reference, [this is what we've done in class](http://i.imgur.com/psJW4.png).",2011-01-30 22:34:21
edq1m,Did anyone else face a crisis of indecision in their last year of undergrad?,"I'm applying to do Master's work, but I still don't know what to indicate as my primary research interest (and the application deadline for my school of choice is less than two weeks away). 

I've really, really enjoyed all my theory courses so far, especially in computability and logic, so I'm tempted to choose that. But today, I talked to one of my theory profs who said two things that made me wary:

- I'll probably have to take a bunch of math courses (combinatorics, algebra, possibly number theory or analysis depending on my specialization), which I find scary. I did poorly in my required calculus and algebra courses, and I don't have a passion for them.
- Job prospects are not particularly good for theory students, especially if they don't go on to get their PhD.

If not theory, I don't know what else I would do. I've done some work with a professor in computational linguistics (which led to a paper), so I'd be in a pretty good position to apply to do that. I had a lot of fun on the project, and anything that gets me closer to meeting Ryan North is a good thing. But the field does sometimes feel to me a little [ill-defined](http://xkcd.com/114/), a little wishy-washy. (Also, when I mentioned my interest in CL to the aforementioned prof, she said that it was *another* area without a lot of industry demand.)

Other areas look interesting (networks, knowledge representation and reasoning), but I have no experience in them, so it would seem foolish to just take a gamble. 

I at least know for sure that I have no interest in graphics, computer vision, machine learning, human-computer interaction, scientific computing, or software engineering. So I guess that's something.

In addition to choosing my research interests, I need to decide whether grad school is actually what I want to do, rather than going straight into the industry. I'm honestly still not sure about that. I've thought about getting a job, but leaving myself the option of going back to school for my Master's/PhD after a few years (particularly if I don't like what I'm doing). Is that something people actually do?

Obviously I can't just ask you to tell me what to do, but I would really appreciate hearing stories from people who were facing similar decisions. What did you end up choosing, and why? Were you happy with it?

**TL;DR:** Read the first, and last two paragraphs.",2010-11-30 04:40:28
coqhy,Graphs not grids: How caches are corrupting young algorithms designers and how to fix it,N/A,2010-07-12 18:46:14
antls,Can you write a turing complete language in a non-turing complete language?,N/A,2010-01-10 14:08:22
ab1tw,The Probability of P=NP,N/A,2009-12-04 12:52:51
9j8nm,Is Computer Science a Science?,"Today someone made a very insightful comment. Most fields where the word ""science"" is appended are not really science. ",2009-09-10 16:46:44
8wqnj,Disorderly genius: How chaos drives the brain. Can Computer Science learn from this?,N/A,2009-06-29 19:08:07
86bhl,Anyone know what happened to LtU?,N/A,2009-03-21 01:22:43
7o5ho,Toshiba to show 512GB solid-state drive at CES,N/A,2009-01-08 01:17:21
7fy7l,About Peteris Krumins,N/A,2008-11-27 03:56:00
77gid,Bad systems or bad culture? Women in Computer Science,N/A,2008-10-16 08:07:27
6k4qdu,Oral Programming Language?,"Hello Software Engineers,


I just wanted to shoot some spitballs regarding the idea of an oral loose syntax programming language. Specifically in regards to it's practical feasability.
Before explaining further, I must admit I'm something of an idealist and the concept of an opensource universal oral programming language that even non-tech people could understand and use is an idea I find incredibly appealing.


You can call me naive, but understand that I'm a very novice programmer still taking baby steps in the world of CS. However, I am a dreamer and would like to civilly discuss this as a hypothetical concept. If anyone is inspired by the exchange of ideas here and wants to pursue this, I am by no means motivated by profit and would be happy tp help to bring this idea to fruition by any means and by any person.


The general picture behind it would be to use a discriminator from a generative adversarial network to check each orally given line of code. Instead of writing let's say 30 lines of code only to compile and see there's an error hidden somewhere between the lines, the the discriminator would check for errors every time you tabbed or spaced to the next line, using something like a quick visual queue. It could also apply to larger blocks of code and constantly check for fluidity and consistency between former lines to avoid bugs.


As for how it would understand human intonation an inunciation, there is a startup from Montreal called [Lyrebird](https://lyrebird.ai/) that seems to be onto something promising. Speech recognition isn't anything new and that's why I'm so surprised that no one has ever made any serious attempts at creating an orally spoken programming language.


In an ideal world, the syntax of this language would be so loose, that it would understand what tweaks you were trying to make to the source code even if it wasn't phrased using a rigid handcrafted command. In other words, imagine something like a Cortana, Siri, or Alexa but on steroids paired with recursive self-learning.
Something else I think could have potential would be to integrate block-chain technology into this language to make it truly open-sourced and decentralized, although I'm not entirely sure how that would work.


Remember if any of this sounds like the idea of some starry-eyed dev, it's because it absolutely is. That being said, I hope no one is too hard on me ;)",2017-06-29 00:12:12
1pnwiw,What CS phrase/quote would you put on the back of your sweater?,"The CS department of my university is selling CS hoodies where you can put a custom text on the back.  Most people put their major or have no text in the back.. but I want to put something cool yet I'm not sure what  exactly.  They didn't specify the word limit, but I've seen someone with an text embroidery that is 9 words long.  That guy (actually a professor) had the text ""I do not know if I halt or not"", referring to the halting problem which I thought was pretty awesome. 

What I can think of so far:
""Keep calm and debug""

So what would you put?",2013-11-01 02:42:40
4g69cm,Would it be possible to create a simulated 4D world inside a computer within our 3D realm?,"In one of my favourite SF series, [Iain Banks](https://en.m.wikipedia.org/wiki/Iain_Banks)'s Culture   series hyper AIs entities called Minds are the only characters capable of comprehending 4D space (which exists in the fictional universe of the books) because of thier programming. Is it actually possible to program 4D space into a 3D computer?",2016-04-24 01:24:52
43l4cy,Warm Data - Looking Beyond The 1s And 0s Of Big Data,N/A,2016-01-31 21:49:04
hcxnh,"Dear /r/compsci, would you be interested in making an /r/askcompsci happen?","I recently got the idea of creating a more focused version of /r/askscience that also tries its best to get people interested in Computer Science, part of it with a nice tone, and part of it without making everything sound complex. This is part of what [/r/askcompsci](http://www.reddit.com/r/AskCompSci/comments/h6t3a/raskcompsci_is_up_but_still_in_alpha/)

As someone who didn’t dabble that much in high school, learning programming and everything related can be an incredibly hostile experience, and, to be honest, most of the resources are crap, even if people keep referring you to it. The worst part is the people who have over ten years of experience and are absolute asses about people new to the field who want to try it out for the first time. I think everyone can relate to experiences like this either from the side of someone wanting to learn and someone who’s seen another guy berate someone else for not knowing the basics of some subject.

We seem to believe that even though all information is probably available online, it is also available in an accessible, intelligible format, which is far from the case. (And even if it were available, we would not always know where to find it.) Wikipedia articles oftentimes have all the facts, but the desire to cram every fact in them combined with the cornucopia of co-editors, the information is not presented in a proper didactic manner, which defeats the purpose.

If anyone sees a point to maintaining such a subreddit to inspire people to learn about Computer Science and everything related—even people who weren’t directly interested in the field itself, but just things like encryption, which serves as an entry way—please help and develop this idea [here](http://www.reddit.com/r/AskCompSci/comments/h6t3a/raskcompsci_is_up_but_still_in_alpha/).

I’ve elaborated on the idea in the sidebar description on the subreddit.

I once found some JSON for reddit, but I can’t find the bloody thing. But if I did, I would try to seem if I could cook up an automagically generated index of questions with a certain amount of activity and upvotes, so we would have a nice learning resource for the future.",2011-05-16 23:27:57
i6l0h7,Variance-Based Clustering,"Using a dataset of 2,619,033 Euclidean 3-vectors, that together comprise 5 statistical spheres, the clustering algorithm took only 16.5 seconds to cluster the dataset into exactly 5 clusters, with absolutely no errors at all, running on an iMac.

Code and explanation here:

https://www.researchgate.net/project/Information-Theory-SEE-PROJECT-LOG/update/5f304717ce377e00016c5e31

The actual complexity of the algorithm is as follows:

Sort the dataset by row values, and let X_min be the minimum element, and X_max be the maximum element.

Then take the norm of the difference between adjacent entries, Norm(i) = ||X(i) - X(i+1)||.

Let avg be the average over that set of norms.


The complexity is O(||X_min - X_max||/avg), i.e., it's independent of the number of vectors.


This assumes that all vectorized operations are truly parallel, which is probably not the case for extremely large datasets run on a home computer.

However, while I don't know the particulars of the implementation, it is clear, based upon actual performance, that languages such as MATLAB successfully implement vectorized operations in a parallel manner, even on a home computer.",2020-08-09 15:17:48
4r3y19,"One-Shot Learning - Fresh Machine Learning #1 (New series, hope you guys like it! - Siraj)",N/A,2016-07-03 21:35:54
2n0wrr,"Is a CS Master's thesis in the design and implementation of a programming language, which includes what my supervisor concurs is a novel design approach, along with the requisite implemented compiler, too academic or theoretical in nature to be appreciated by industry at large?",Could it prove detrimental to career possibilities in the future? Your feedback is appreciated.,2014-11-21 21:45:34
29obi9,How to Create a Computer Science Resume in Five Steps,N/A,2014-07-02 19:25:27
jjkbn,So I'm applying to a Phd program in November. Anything I can do in the next 3 months to help my chances?,"I graduated in spring 2010 and have been working as a programmer for the last year+ but have decided I really want to go back to school.  I've read all about grad school and know what a PhD entails so please spare me the ""Are you sure this is what you want to do?"" comments if you would be so kind :)  I've made up my mind.  That being said I was wondering if there was anything I could do to improve my chances of being accepted to a PhD program.  I know they want publications and research experience.  I fall short on the former category (no publications) but in my undergrad (I also was a psych major as well as com sci) we did a decent amount of actual research for projects and I also did an independent study with one of my computer science professors my senior year (which is the reason I want to go back to school so badly actually).  Anything I can do to help out my resume in the meantime?  If I didn't get in I was thinking about doing a master's first but don't have the money at the moment (too much undergrad debt) and would have to wait another year or 2.",2011-08-15 17:52:57
7xaov,The Computer Science Club of U-Waterloo celebrates No-Pants Day; former Prime Minister Paul Martin joins the fun.,N/A,2009-02-14 02:33:30
7tta0f,Perils of Backtesting,N/A,2018-01-29 16:04:52
g49sd,"Studying for algorithms midterm, just had to say:",N/A,2011-03-15 08:32:12
2a1iaw,Everyday Algorithms: Roadtrip Planning Algorithm,N/A,2014-07-07 11:47:08
1wnlje,University of Manitoba sends first-ever all-women team to CS Games,N/A,2014-01-31 16:51:20
2edvb0,Programmer Competency Matrix,N/A,2014-08-23 18:58:35
h95hr,"Deus Ex Machina: Computational metaphysics is helping philosophers answer age-old questions, such as whether God exists",N/A,2011-05-11 19:04:29
b7zbd,"To students who consider programming too ""technical""",N/A,2010-03-01 23:30:20
2n3ukt,ERASMUS - Help choosing University,"Hello everyone!

I'm currently in the 4th year of my Masters in CompSci and I'm thinking about going on Erasmus the first semester of the next year (2015/2016). 
The problem is I have no idea which University I want to go to. 

My university (University of Porto in Portugal) has protocols with many European universities and last year the openings for this year (2014/2015) were the following:

* Austria - Technische Universität Wien
* Belgium - Universiteit Gent 
* Belgium - Université de Mons 
* Croatia - University of Zagreb (FOI - Faculty of Organization and Informatics)
* France - École Centrale d'Electronique
* France - École Nationale Sup. des Mines de Saint Etienne
* France - Institut National des Sciences Appliquées de Toulouse
* Finland - Aalto University School of Science and Technology 
* Germany - Technische Universitat München
* Germany - Georg Simon Ohm Fachochschule Nümberg
* Greece - Panepistimio Dytikis Makedonias
* Hungary - Budapesti Műszaki és Gazdaságtudományi Egyetem
* Italy - Sapienza Università di Roma (Facoltà di Ingenieria dell' Informazione, Informatica e Statistica)
* Italy - Università Degli Studi di Ferrara
* Netherlands - Technische Universiteit Delft (probably not gonna get a spot there since there are only 2 slots and I'm only above average)
* Poland - Cracow University of Technology
* Poland - Uniwersytet Lódzki 
* Poland - Wyzsza Szkoła Informatyki i Zarzadzania w Rzeszowie
* Slovakia
* Spain - Universitat Politècnica de Cataluña (FIB ‐ Facultat d'Informàtica de Barcelona)
* Spain - Universidad de Jaén
* Spain - Universidad Politéncnica de Madrid
* Spain - Universidad Rey Juan Carlos
* Spain - Universidad de Santiago de Compostela
* Spain - Universidad de Sevilla
* Spain - Universidad Politéncnica de Valencia
* Spain - Universidad de Zaragoza
* UK - Coventry University
* UK - Cranfield University
* UK - University of Edinburgh

Does anyone have opinions about the Universities here specified?

Thanks in advance!",2014-11-22 20:28:59
4weaiv,Going to Washington State University to study Comp Sci B.S. Any tips?,"As the title states I am looking for any tips I could get for comp sci or anything that could help me if I know ahead of time. 
Thanks! ",2016-08-06 03:55:30
4dojh7,Recommend 2 courses for a engineer trying to immerse himself in computer science.,"I am an engineer at UT-Austin and I have already taken three CS courses, MATLAB, C, C++. Can ya'll recommend 2 more classes for me to take before I graduate. I am trying to immerse myself in the subject because I have recently learned how important CS is to any field. I have the following classes listed below. You can also recommend other classes too, my objective is to build a strong foundation to then be able to teach myself other subjects. I am especially interested in big data and how to implement it in the oil industry. Thanks guys.

CS 320N Topics in Computer Science
CS 324E Elements of Graphics and Visualization
CS 326E Elements of Networking
CS 327E Elements of Databases
C S 328E Topics in Elements of Computing (requires CS 303E as a pre-req)
Elements of Computing in Society
Intro to Game Development
Elements of Navigating Cyberspace
Elements of Security
CS 329E Topics in Elements of Computing (requires CS 303E and CS 313E as a pre-req)
Elements of Data Visualization
Elements of Mobile Computing
Elements of Web Programming
Elements of Programming Languages",2016-04-07 00:01:51
3s5gm0,What's it like being in the computer science field?,I am a computer science major and I'm wondering what to expect after I graduate from college.  What would an average day be like?  How is the job outlook?  What salary should I expect?  I really need an overview of what to expect and wouldn't mind people PMing me with more details so we can talk about it.,2015-11-09 16:47:30
11iiim,The Nobel Prize in Economics given to Roth and Shapley for there work in game theory (e.g. stable matching problem),N/A,2012-10-15 15:18:06
2ilhte,"My laptop has a GPU that just 'sits there', is there a way to harness its power for faster compilations/executions?","NVidia GeForce at home, Quadro at work that are barely used.
CPU and HDD Intensive compilation cycles. Already use a RAMDisk to speed that up but the GPU just sits there.

Is there a way to harness its power for work? TIA",2014-10-07 21:07:06
41nejq,Mihai Patrascu 1982-2012,N/A,2016-01-19 06:49:03
14m0j2,"Aspiring Computer Scientist, some questions inside.","Sorry this will be a long winded post, just like to get some background in as well as my questions. TL;DR at bottom if needed! 

Hey Reddit! I would love to go on to university to study Computer Science. I am a 16 year old male, so just got into college a couple of months ago to begin my A-Levels (I chose Maths, Physics and Chemistry - My college does not offer Further Maths), and am pretty confident I will get some good grades when I finish, hoping for A's in the Physics and Maths and at least a B in Chemistry. I have always wanted to work on a technology related job, and love the idea of programming (just the idea so far). I downloaded python a couple of months ago, and while I have not had as much time to use it as I would have liked these past months, due to personal issues, they are all set aside now so I once again have tonnes of free time. I suppose my main questions are (In the TL;DR).

Tl;DR

Is Python a good program to start with? 
If not, what is? 
What is the difference between the different Computer Science courses at university? 
What else can I do to get me ahead and give me an insight into the world of computer science?
",2012-12-10 17:02:20
9gv7x,A quite innovative SAT-Solver.,N/A,2009-09-03 08:39:56
6v9nz1,Got sick of cringey programming related backgrounds so I made two of my own. Can do more if you guys want,N/A,2017-08-22 08:35:59
4k0l6t,Are Macs OK for computer programming?,"In a few months I start college and will be majoring in information systems security. 

I'm going to be getting a laptop, and I'm faced with the decision of either windows or mac. 

Right off the bat, the obvious choice is windows. But I'm also heavily into music, writing, and creative stuff in general. + I really like the aesthetics of Mac OS so much more. 

So my question is: would it make sense to buy a Macbook for computer programming related classes? Would I be limited to something Macs can't do that windows can? ",2016-05-19 03:28:42
2qxysi,How I found the hidden connection between Pink Floyd and Justin Bieber,N/A,2014-12-31 19:13:10
2gmf6r,how do I get interested in algorithm analysis,"I'm a seasoned web developer, in my day job I don't have to use much of [read any of] active algorithm analysis [at least as I see it]. But this field is both intriguing and intimidating. I want to conquer the fear, but every time I start out, the moment any analysis involves adv mathematical concepts, i lose focus, and never get back to it. 

 I guess, what I'm asking for is how did you overcome those feelings, and how to make learning algorithms and their analysis more fun and practical.",2014-09-17 02:22:59
2203o1,Rafflesort: The most inefficient way to sort a list.,N/A,2014-04-02 10:12:15
1tgkwx,The newest 'Polynomial' SAT-Solver,N/A,2013-12-22 14:13:51
1oo9q7,An Unevaluated Proof that P != NP,N/A,2013-10-17 21:57:21
1hyb5q,New subreddit for students in or interested in REUs,N/A,2013-07-09 19:01:37
fe93d,Hey r/compsci is this a code in a craigslist post?,N/A,2011-02-03 03:32:47
7nwec,Quantum Cryptography - Using a Particle to Detect Eavesdropping,N/A,2009-01-07 02:31:27
792s7,Lisp50 Notes part I: JohnL Recalls How Sussman Revealed the Nature of Intelligence…,N/A,2008-10-24 08:53:25
i2tnnk,Taught myself core Java what's next?,"Hey guys i am new here and I basically joined because i needed some advice on how I can enhance my coding skills further, I have just finished learning the core java concepts and I am in 2nd year of CS degree, what should I do to make sure I am industry ready after I graduate?
Any advice is highly appreciated. 
Thankyou!!",2020-08-03 08:56:18
9hyvs3,Fetching the readable text from a document,"I am trying to extract the news article from given URL. I am basically creating DOM tree and then fetching <p> tags from it and collect all paragraphs. It works for some sites but for some sites I am getting garbage text. For example :

>Share on Facebook Twitter In the recent years, we have seen rise in the global temprature. Subscribe to newsletter

So basically I want to extract only readable text from this document which will be -

>In the recent years, we have seen rise in the global temprature.

Is there any way to achieve that?

&#x200B;",2018-09-22 11:03:37
83oxg2,FPL 2018,N/A,2018-03-11 19:25:25
4a848c,Any ideas on a title for a dissertation on Quantum Computing?,"I'm going to be writing a dissertation for school and it will be going towards the university I will be going to; so I want to base it around computing, more importantly Quantum Computing. 

So do you guys have any ideas on a title? I'm obviously not an expert on the topic but I know the basics. I would like to base the essay on the effects but also I would like to learn more about the specifics of Quantum Computing in the process. 

So do you guys have any ideas on a title? and can you recommend any good books?",2016-03-13 12:02:43
t0p9r,Do you think this is a secure way to store passwords in a database?,"Alright so now my question is bcrypt or pdkdf2? From what I've read bcrypt is supposed to be more secure than pdkdf2 however it's supposedly harder to implement...




**NOT IMPORTANT ANYMORE!**
Alright so I'm working on a project that will involve storing users passwords and I've been trying to come up with a good way to store them and I think I've (finally) come up with a way that seems secure to me.

**At Registration**

When the user signs up a token will be generated that will be saved in a db along with their login information. This token contains 8 numbers between 0 and 7. It is used later on to split up the hashed password.

**How It Works**

1. The password first gets hashed(sha512), this will be used as the salt.
2. The password (plain text, not hashed) is broken up into 4 (mostly equal) parts.
3. The password and hash are then mixed together.
4. This new salted password is then hashed(sha512)
5. The hashed value is split up into 8 equal parts.
6. The token created earlier is split up into an array of 8 elements.
7. The broken up hashed value is put back together according to the token.
8. What is created in step 7 is what gets stored in the database.

**Why I Think It Is Good**

For starters this manipulates the password quite a bit before it even gets hashed. Even if the hacker figured out what the hashed value was it would just be a jumble of random numbers and letters. This however didn't satisfy one requirement of a good salt which was two users with the exact same password should not have the same hash. I didn't want to simply add the user id to the password because that seemed pretty trivial. Instead the hash value that is stored is based on a random token that the user is assigned they sign up. This token could simply create a new hash of the 7th array element being repeated 8 times if the token was 77777777.

**Criticize Me!**

Alright so what do you think? Do you think this is a secure way of doing it, what recommendations do you have for me?",2012-05-01 00:35:17
f5d6su,Polynomial time?,"Hi all, I’m doing a school project on what would happen if P=NP but I’m not necessarily very savvy on this kinda thing (I just thought it seemed really interesting). I was hoping that maybe someone knows a link or a simple way to explain what polynomial time is. Thank you!

Edit: thank you for all your guys’ help! I am just a high school kid explaining P vs NP to a room of other high school kids. I am familiar with the main idea of P vs NP but I just wanted to get to know the differences better.",2020-02-17 18:31:56
5bhepq,Visual Studio Code 1.7.1,N/A,2016-11-06 19:09:23
52ogao,What are some good tips for a beginner?,"I just started computer science 1 at my school last week.  We are writing in Java and using the Eclipse application.  So far we have learned a few key terms and basics such as: class, src, ending every line with a semicolon, etc.  We started out simple with ""Hello World!!""  Any advice would be helpful.  Thanks!",2016-09-14 02:43:19
4xoqf2,what should I be doing in my junior year?,"I already passed both prog 1 and 2, data structures, etc. I'm also full time credit this fall semester. right now, I'm studying python with my free time. anything else that I should know at this point? ",2016-08-14 16:13:18
4wmzcl,What do you guys think about my articles on the IoT and AI?,"I have recently started my own site, [Deep Dive Science](http://www.deepdivescience.com/), where I write about computer science (and will eventually expand to other sciences).

So far, I have written two articles which are fairly in-depth on the topics of AI and the Internet of Things.

[IoT](http://www.deepdivescience.com/computer-science/internet-of-things/internet-of-things-overview/)

[AI](http://www.deepdivescience.com/computer-science/introduction-artificial-intelligence/)

I am yet to study Computer Science at university and so my researched knowledge may not be as accurate as those of you on this subreddit.

Please give me feedback on my articles.

Thanks,

Rory
",2016-08-07 22:07:13
4rkckd,What level of math?,What level of math should you be proficient in to understand and do well for programming?,2016-07-06 19:41:09
4bpalb,Question about quantum computing (languages/algorithms),"I am interested in quantum computing, namely the development of quantum programming languages as well as algorithms. First of all, is this field worth investigating ie. does it seem to have long term prospects (basically, is it worth my time?). If it's worth looking into, is there a place I should start? I don't normally hear of quantum computing theory when researching grad programs or classes, but I'd be really interested in learning.",2016-03-24 00:12:58
4absty,What type of programming has the best career prospects?,"I'm a 3rd year CS student working for a web development company while I get my degree. I feel like up until now, being a 'programmer' or being a compsci student was the goal. Now it's time to specialize and I'm trying to figure out what would be the best career choice. Of all of the branches of comp sci, what would guarantee me the best income/quality of life balance? ",2016-03-14 05:12:54
45fd7w,Best networking or meetup app/site for comp sci,"Is there a universal meet up app or site that people use for comp sci meet ups, networking event, free conference, etc?",2016-02-12 16:00:45
3tb4vn,Cognitive Systems And The Disappearance Of Dark Data,N/A,2015-11-18 16:17:35
3ppnyo,How To Find Simple And Interesting Multi-Gigabytes Data Set,N/A,2015-10-22 01:13:14
3ckc4q,10 Best Ways to Use Your Computer’s Spare Time-Distributed computing projects,N/A,2015-07-08 16:10:44
3bond4,Ram usage when watching a movie.,"I've taken a course on computer architecture, where we learn about how memory is allocated and used by programs. So when we watch a movie, is the whole movie filed loaded onto the ram, or just the program used to watch it, and then the data file is continuously fetched from the hard drive?  ",2015-06-30 22:08:19
3bhjd4,Blink of Code - Share and Read Interesting Code Snippets From All Languages,N/A,2015-06-29 07:18:35
397itf,I know a lot about networking and computer hardware but close to nothing about software,Where should I start,2015-06-09 20:36:10
38ka5e,GNU TeXmacs: Towards a scientific office suite.,N/A,2015-06-04 19:46:51
383xpv,Senior Project in Finance,"Can anyone suggest me a good senior project in finance which also involves programming?
",2015-06-01 18:00:25
380xby,Math major wanting to get into compsci,Long story short I want to get a job in computer science. I was wondering what if any can I do to be competitive.,2015-06-01 01:14:25
350tml,MatLab users: Any ideas for a cool program I can make using MatLab?,"I'm relatively new to the program (I took one semester of a class about it), so I'm not very good with the more complicated aspects of the program. Thanks so much guys!",2015-05-06 04:00:17
345kh8,A plea for volunteers.,"I am not a programer or developer or anything of the like. I am, however, involved in video editing and compilation, and I have a request. Many of you probably know about VLC - the amazing free and open source media player. What you may not know about is [VLMC](https://www.videolan.org/vlmc/), which is a project to create a free and robust non-linear video editing software package.

The project seems to be stuck in a rut for lack of developers. If you have the skills, please consider donating some of your time to this project. There are so many of us that are eagerly waiting for this project to finally come to fruition.

Thanks in advance.",2015-04-28 14:04:00
33wx5s,Parity bit question.,"hi guys, so just a quick question, if let say i am transmitting an even parity, and my p0 which covers all the bit are even, does that mean the error cannot be found since p0 checks all data bits to be correct?",2015-04-26 12:27:26
2yyc79,Uncertain about master degree and job,"Hi guys,
I'm an computer engineering student. 

I have got an undergraduate degree and I'm going to take a Master degree(other 2 years course) but I'm uncertain about these 4 fields:

- Data engineering (DBMS, Information system, ...)
- Software engineering
- Network engineering
- Embedded systems (low level things...)


I would like an advice about both the empoyment rate (job offers) and what you will really do at work.",2015-03-13 21:23:45
2wcb7r,What would be the reasons if any for a service which is not cpu-bound to be multi(threaded/process) ?,"Lets say I have a service which accepts tcp connections and responds to certain requests. I know beforehand that serving any request is not cpu bound, and can be done asynchronously with the select() call.

Now is there any need for the service to be multithreaded or multiprocessed ?",2015-02-18 19:13:52
1btbmf6,Use public variables; they exist for a reason,"Unpopular opinion: There's a strong cultural norm in CompSci with keeping data hidden behind layers of getters and setters, meant to protect our code. What I've seen in the work world though is that no one ever uses public variables; it seems to lead programmers to unnecessary complexity and hinders readability and debuggability.

Viewing our fellow authors within the same code base as threat adversaries who might misuse any piece of our data is both paranoid and counterproductive. This mindset and makes our code less accessible and harder to search and debug.

Public variables have their place. They offer a straightforward way to interact with data, enhancing the readability and approachability of our code. When used wisely, they can make our code more readable and debuggable and simpler to fix. Take for an example, any Vector3 implementation.

I'm not saying you should use public variables willy-nilly. But by dismissing them outright, we're living in a world where making code simple changes and debugging is a tedious multi-file process of looking into headers for every single damned thing.  


Feel free to downvote! I'd prefer a good conversation though.",2024-04-01 18:34:14
1btftge,"Is there anything about ""Intuitionistic Theory of Computer Science""?","Hi everyone,
I've been studying theory of computation and logic for the past two years, and I'm finding intuitionistic mathematics to be a useful framework. In my courses (computability theory, formal languages, complexity theory) and textbooks, the focus seems to be on standard definitions, applications, and theorems. While this is valuable, I'm interested in delving deeper into the foundations of these theories.
Recently, I began studying types and programming languages, and I suspect they might provide a strong foundation for understanding these theories. Are there any textbooks or articles that for example explore building complexity theory based on types and lambda calculus, or that discuss equivalent definitions of computational models and logic?
(I've already read Piergiorgio Odifreddi's ""Classical Recursion Theory."" Are there similar books with a more foundational approach?)
I'm open to any suggestions!
Thanks.",2024-04-01 21:09:39
1btean6,In-Depth Understanding of Internal Computer Operations,"Hello everyone,

I’m seeking detailed resources and explanations that go beyond basic computer science knowledge to deeply understand the internal workings of computers. I’m not interested in superficial descriptions of components like CPUs or GPUs, but rather in understanding exactly what happens inside these devices. I want to delve into topics such as the behavior of electrons in circuits, the management of watts and energy, and the microarchitecture of systems.

Can anyone recommend materials or courses that cover these topics in depth? I’m particularly interested in resources that explain how electrical signals represent and process data, and how hardware interacts at the physical and electronic level.

Thank you in advance for any help!",2024-04-01 20:14:02
1b21hzy,YouTube channels similar to No Boilerplate and Low-Level Learning,"I am currently learning Rust, and I have always been interested in lower-level CS topics such as OS, memory, etc. These YouTube channels have been awesome, and I wondered if anyone knows of similar content I can consume. Thanks!",2024-02-28 08:54:06
1b2qfie,Mastering Event Propagation in JavaScript: Bubbling vs. Capturing,N/A,2024-02-29 03:33:34
1b1oel3,Encoding tic-tac-toe in 13 bits,N/A,2024-02-27 21:59:57
1b0qnes,I created a algorithm for approximating the TSP in javascript. It outperforms the Lin-Kernighan Heuristic in O(n²) time. 4/5 runs tested were optimal.,"Ive been working on this algorithm for the Travelling Salesman Problem, using completely experimental techniques. I tested it against LKH against 5 ""Hard Instances"" of the TSP, as well as against two versions of Ant Colony (one i designed, and one created by gpt4). My algorithm, calling it TSPA for simplicity, has a very high chance (~80%) of getting the optimal solution for 200 node problems. The one time it didnt get the optimal solution it was within 0.00079% the optimal solution.

This might be amateur hour, since my approach was relatively unresearched and purely experimental, i tested it against a single LKH tool written in C (a totally different language), and i only tested it in detail against 5 instances (the last 5 hardest ones). Also theres a small calculation discrepancy (not sure why) for tours of 3M i would get 20-30 points less than the reported optimum (this wouldnt have changed any results i dont think).

Heres my approach, for those curious:

1) I generate some initial solutions using nearest neighbor, and variants of NN. This constitutes my ""exploration phase"", and provides a variety of starting geometries.

2) I splice the best tour, creating a hybrid of the variants.

3) I perform ""fine edge correction"", which is a efficient 2 opt that only swaps √n nearby neighbors (both swaps and subtour reversals), a sweep line to perform long range 2 opt selectively, and an iterative 6-node permutation to smooth out edges.

4) I perform 2 experimental exhaustive searches, designed to break out of local optima. One is called ""Edge Ejection"" Where i eject √n down to 1 consecutive nodes into nearby neighbor nodes. The other is called ""Split and Splice"", where i divide the tour in two, fine-edge-correct both sides, put them back together, then fine-edge-correct it again. Both were very effective at escaping local optima, so i perform them one after the other up to 10 times until theres no further improvements.

5) My algo runs for 32 iterations by default. Which means it will take the best tour, and up to the 31 second best tours, and perform the process on all of them. Caching is used to speed up repeat calculations.

Anyways i dont want to bore you. Heres the full testing data: 


TSPA, Ant Colony, and Genetic Ant Colony implemented in javascript vs Lin-Kernighan Heuristic implemented in C,

Using ""Hard to Solve Instances of the Euclidean Traveling Salesman Problem"" by Stefan Hougardy and Xianghui Zhong,

The last 5 problems are used since they are the hardest.


tnm187: 

Ant Colony (100x100): 3,068,046 at    179210 ms (104.1449262%)

Genetic Ant Colony:   2,968,505 at     13100 ms (100.7157131%)

TSPA (1 run):         2,946,090 at      4900 ms (100.0051257%)

TSPA (10 runs):       2,945,918 at      7800 ms (optimal)

TSPA (32 runs):       2,945,918 at     16790 ms (optimal)

LKH (Average/run):    2,948,705 at       590 ms (100.0938919%)

LKH (10 runs):        2,947,410 at      1230 ms (100.0499331%)

Ideal:                2,945,939 at 249657000 ms

Winner: TSPA (10 runs) at 2,945,918 in 7800 ms


tnm190: 

Ant Colony (100x100): 3,135,557 at    185870 ms (104.37039545)

Genetic Ant Colony:   3,033,991 at     15610 ms (100.9896616%)

TSPA (1 run):         3,005,936 at      3830 ms (100.0558207%)

TSPA (10 runs):       3,005,936 at      5660 ms (100.0558207%)

TSPA (32 runs):       3,004,248 at     13230 ms (optimal)

LKH (Average/run):    3,005,487 at       120 ms (100.0408753%)

LKH (10 runs):        3,004,274 at      1230 ms (100.0008654%)

Ideal/Concorde:       3,004,259 at 337307000 ms

Winner: TSPA (32 runs) at 3,004,248 in 13230 ms


tnm193: 

Ant Colony (100x100): 3,128,105 at    191222 ms (103.4579869%)

Genetic Ant Colony:   3,030,903 at     13390 ms (100.2431577%)

TSPA (1 run):         3,027,849 at      3800 ms (100.1421507%)

TSPA (10 runs):       3,024,223 at      6940 ms (100.0222255%)

TSPA (32 runs):       3,023,575 at     23800 ms (100.0007937%)

LKH (Average/run):    3,027,099 at       810 ms (100.1173454%)

LKH (10 runs):        3,025,052 at      8100 ms (100.0496436%)

Ideal/Concorde:       3,023,551 at 263334000 ms 

Winner: TSPA (32 runs) at 3,023,575 in 23800


tnm196: 

Ant Colony (100x100): 3,210,033 at    199234 ms (104.1688868%)

Genetic Ant Colony:   3,104,669 at     12790 ms (100.7497162%)

TSPA (1 run):         3,083,722 at      3670 ms (100.0699644%)

TSPA (10 runs):       3,083,722 at      5700 ms (100.0699644%)

TSPA (32 runs):       3,081,536 at     19850 ms (optimal)

LKH (Average/run):    3,084,479 at       760 ms (100.0945298%)

LKH (10 runs):        3,082,960 at      7610 ms (100.0452367%)

Ideal/Concorde:       3,081,566 at 300945000 ms

Winner: TSPA (32 runs) at 3,081,536 in 19850 ms

tnm199: 

Ant Colony (100x100): 3,268,565 at    209180 ms (104.1017868%)

Genetic Ant Colony:   3,151,615 at     16180 ms (100.3770011%)

TSPA (1 run):         3,141,011 at      6530 ms (100.0392702%)

TSPA (10 runs):       3,139,931 at     11610 ms (100.0048729%)

TSPA (32 runs):       3,139,757 at     24300 ms (optimal)

LKH (Average/run):    3,143,205 at      1170 ms (100.1091478%)

LKH (10 runs):        3,141,035 at     11000 ms (100.0400346%)

Ideal/Concorde:       3,139,778 at 411222000 ms

Winner: TSPA (32 runs) at 3,139,757 in 24300 ms

I hope this algorithm can potentially be of value to anyone who needs a tsp tool in javascript, and also for research purposes. Perhaps my approach can shine a light on new things to try (or not try).  Heres my code: https://gitlab.com/Spederan/tsp-solver-tool
",2024-02-26 19:44:08
1b0m8se,Can someone explain or give me links to understand Incremental Convex Hull algorithm?," I need to understand this algorithm for a project Im making and cant find a detailed description of this algorithm, all I found searching is some videos in a language I dont speak or in the wikipedia itself it just says ""Published in 1984 by Michael Kallay"" And in the paper it either uses a very complex terminology I cant comprehend (Im not a mathematician but a CS student) or I think it only describes how its complexity is calculated. ",2024-02-26 16:50:55
1b09ok5,Understanding the performance of mutual exclusion algorithms on modern multicore machines - 2018 doctoral thesis by now Oracle staff engineer Hugo Guiroux,N/A,2024-02-26 05:21:14
1b001pi,"""Designing Data-Intensive Applications"" - which programming language?","I am a newbie in the world of distributed data systems. I would like to specialize in the field covered by ""Designing Data-Intensive Applications"" by Martin Kleppmann. To be able to implement such systems, which programming language would you recommend me to focus on? I am torn between Java and C++.

Many thanks in advance!",2024-02-25 21:50:03
1az5acl,Favourite computer science books?,"What are your favourite books to do with the world of compsci and why? Mine right now is ""Elements of Computer Systems, Building a Modern Computer from First Principles"" as it peels back the layers of abstractions of hardware in an interesting way, plus being able to apply knowledge you gain in making your own computer system.",2024-02-24 21:02:21
1aythgu,Consistent hashing ring as an Infographic!,N/A,2024-02-24 12:33:28
1ayjap3,I made a AES visualizer in Angular,"Its not currently online, but I made this video using it:
https://youtu.be/I7o1ZEgoFvs?si=MUhaX0Uej-rKXmEc",2024-02-24 02:32:38
1ay1vfi,"The mark scheme says the parity bit should be 1, but I would've thought it could be 1 or 0 - Am I dumb?",N/A,2024-02-23 14:32:44
1axkgc2,What is your PhD about?,"Since I may soon start a PhD but haven't found the topic that interests me the most yet, I have three questions for all Computer Science PhD students here who are still pursuing their doctorate or have already obtained their PhD:

1. What is/was the main topic of your research?

2. How did you discover that your topic was your passion, and what do you find so intriguing about your subject?

3. How did you begin conducting research? For instance, did you delve into it on your own in your spare time, collaborate with your supervisor, etc.?

Thank you in advance!",2024-02-22 22:54:52
1atzt9c,Hash tables and preferred locations (the Bender hash table),"Some interesting work recently on finding the best possible balance between time and space for any hash table:

[https://www.quantamagazine.org/scientists-find-optimal-balance-of-data-storage-and-time-20240208/](https://www.quantamagazine.org/scientists-find-optimal-balance-of-data-storage-and-time-20240208/)

The innovation is that one can construct a hash table that has a primary structure and a secondary structure, with the data inside the primary structure dynamically reorganized so that data fit into ""preferred locations.""

The math is [here](https://arxiv.org/abs/2111.00602).

But don't all hash tables have their collisions worked out at insertion time, meaning once the index is calculated it's always a time-constant process of retrieving the data. If so, then how could shuffling data into preferred locations possibly make a difference to the performance of the hash table? In other words, why would there even be such a thing as ""preferred locations""...all you need is the index. It shouldn't matter where it's stored. ",2024-02-18 17:42:19
110wtw6,Voting Preference Sorting a list,"A list of eight items to be sorted s = {a, b, c, ... h}. Fifty voters each contribute their ordering preferences in the form of a three-item priority list: preferences = {first, second, third}

**What method sorts the eight items according to the set of fifty 3-item preferences**, without the introduction of any sort of arbitrary weighting?

*What have I tried:*

* A 3-dimensional count seems to leave me with three lists of counts, one for first, second, and third preference. That problem space looks to me like a partial set of permutations.
* Start with only one vote, which leads to a count of votes per item in the set. What happens when instead I specify a preference for the ordering of two items? Which looks to me a like a relationship between nodes, rather than just the nodes.",2023-02-13 02:16:11
10z3ciy,How do I traverse every point in a 3D area without backtracking and minimizing the least amount of turns possible?,"Alright, let's say I have an array of discrete 3D points that make a rectangle of x, y, and z length. I want to visit every point in the least amount of turns possible without backtracking. Let's say that to visit a point you can only increase x, y, and z by +-1 or 0. The pattern ends up being a snake-like pattern where the axis is traversed in descending order to minimize the number of turns. Though getting this to happen in code eloquently has been a real fucking bitch. 

So far, I've generated the area with no care in which order they're put in. Then I sort so the longest axis is moved through first, then I go through once and create subsets for every time two axis values have been changed (xChange && yChange) || (xChange && zChange) || (yChange && zChange) and add every one of those elements back to a new list where every other subset is in reverse order. Then I do that again but create a subset this time when every axis value has been changed (xChange && yChange && zChange). This cant be a novel problem, right? I can't find anything online about this.

Example input: https://pastebin.com/JbXx19rf
Example output: https://pastebin.com/sWsfXq3G",2023-02-10 21:17:39
10z1e0i,"Starting now: Reading group for ""The Joy of Abstraction"" by Eugenia Cheng",N/A,2023-02-10 20:00:04
10uxzr4,The story behind the Packing Chromatic Number paper,N/A,2023-02-06 04:52:19
10osvvj,"Normalization for multimodal type theory. ""We prove normalization for MTT, a general multimodal dependent type theory capable of expressing modal type theories for guarded recursion, internalized parametricity, and various other prototypical modal situations."" [abstract + link to PDF, 39pp]",N/A,2023-01-30 04:39:07
10njcpe,Don't fear the spin lock,"It's a common exercise in programming to synchronize access to data between threads. A simple mutex or other critical section tool will do the job. But sometimes, performance matters.

The problem with mutex's, or regular locks in high level languages, is that the waiting thread may be put to sleep since it cannot access the resource it wants.  And this behavior is usually desirable - except when it isn't.

There is a time cost associated with putting the waiting thread(s) to sleep and waking them when the resource is ready.

A simple heuristic can be used to determine whether you should try to upgrade regular wait locks to spin locks. A spin lock is where the thread actively tries to access the shared resource and doesn't go to sleep.

(h): if the shared resource is guaranteed to be locked for a sufficiently short period of time.

While working in [Orvina](https://github.com/webbersmak/Orvina), performance increased dramatically with a careful selection of locks to upgrade to spin locks - and the effort was less trouble than what was expected.

There are likely many programs out in the wild that would experience real world benefits with more diligence in the choice of locking mechanism implemented. It would be quite the feat if compilers could deduce or suggest a specific lock type and insert the correct one. Perhaps that's one improvement AI will contribute to.

https://preview.redd.it/c9t2dpu1ctea1.jpg?width=768&format=pjpg&auto=webp&s=da63c8768e2ab7d2176ff2e727ba4c0d5a717b0a",2023-01-28 16:41:41
10n5myp,Diagram layout engines: Minimizing hierarchical edge crossings,N/A,2023-01-28 04:05:20
10mc51c,What sparked everyone’s interest in CS?,"Aside from enjoying video games and having to choose something for a-levels (my case), what could spark an interest in computer science? I really want to hear everyone’s personal experiences and opinions.",2023-01-27 04:32:14
10kh45x,KHyperLogLog,N/A,2023-01-24 21:40:57
10k9ucv,Are there any machines that are powerful than Turing machines or has violated the Church-Turing hypothesis?,Basically the title.,2023-01-24 16:47:29
10jf8wy,Why Neural Nets Underperform Tree-Based Models on Tabular Data,"Hi guys,

I have made a video on YouTube [here](https://youtu.be/e62CBva4TYc) where I discuss about why deep neural networks fail to beat tree-based models on tabular datasets.

I hope it may be of use to some of you out there. As always, feedback is more than welcomed! :)",2023-01-23 15:34:18
10j3xod,how to benchmark a programming language,"I am working on building a programming language. The interpreter is written in Go.

Is there a way to benchmark programs written in that language vs the same program written in other programming language. For example a fibonacci program written in that language vs a fibonacci program written in Python",2023-01-23 04:37:55
10g85ww,Bio-Inspired Optical flow,N/A,2023-01-19 17:51:28
109rb0e,Recursive Types via Domain Theory // The Topos Lab,N/A,2023-01-12 05:23:27
108nwt0,ACM: The End of Programming,N/A,2023-01-10 22:58:10
108keej,GETCO 2022 / Uli Fahrenberg / Directed Topology and Concurrency,N/A,2023-01-10 20:43:22
107ta1b,Summer Geometry Initiative 2023 --- undergrad/MS summer research in geometry processing! Applications due 2/15/2023,N/A,2023-01-09 23:07:56
10766x6,How to Use K-means for Big Data Clustering?,N/A,2023-01-09 05:48:09
106ot4h,The Incredible World of Quantum Mechanics - How it is Used in Modern Quantum Computing,"Quantum mechanics is a field of quantum physics that studies the behavior and interactions between atoms and molecules. It's an incredibly complex topic, but it can be broken down into some basic concepts. The idea behind quantum mechanics is that even though we cannot see or touch them, there are tiny particles all around us! These particles behave in strange ways that break from our everyday experience with matter. Quantum computing is a relatively new way to use these particle waves to do calculations much more quickly than traditional computers can do today. In this post, I'll introduce the most basic concepts of quantum mechanics and explain why it's important for understanding quantum computing! 

Get started here: 

[https://deepboltzer.codes/the-incredible-world-of-quantum-mechanics](https://deepboltzer.codes/the-incredible-world-of-quantum-mechanics)",2023-01-08 17:29:05
104xvxk,A report on the Collatz problem,"As of January 6, 2023, the project [Convergence verification of the Collatz problem](https://pcbarina.fit.vutbr.cz/) was able to verify the validity of the Collatz conjecture for all numbers less than 660 × 2^(60) (≈ 2^(69.37)). The project started its operations on September 4, 2019. On May 7, 2020, it verified the convergence of all numbers below 2^(68), while on December 10, 2021, it verified all numbers up to 2^(69). The project consumed 5395 CPU-years of computing time (of which 5308 years using the CPU and 87 years using the GPU). The project uses work units of 2^(40) numbers. Verifying one such unit takes, on average, 5:25 minutes on the CPU and 12 seconds on the GPU.",2023-01-06 16:05:44
zxmnx7,"Formal definitions of ""events"" and ""messages"" in distributed systems?","I'm studying up on version vectors & vector clocks, but I'm held back on my fuzzy understanding of what an ""event"" actually is. From [Lamport '78](http://lamport.azurewebsites.net/pubs/time-clocks.pdf) :

> We assume that sending or receiving a message is an
event in a process.

But he never really defines what a message is, except to say 

> A distributed system consists of a collection of distinct
processes which are spatially separated, and which communicate with one another by exchanging **messages**.

Maybe I'm missing the forest for the trees here, but I feel like my intuitive understanding of what an event is or isn't is not enough.",2022-12-28 22:10:53
zsw39q,Proximal Policy Optimization - Dive into the Unknown,"Proximal Policy Optimization (PPO) is a policy search algorithm and an on-policy reinforcement learning algorithm. PPO algorithm aims to optimize the expected reward of a given policy by adjusting the parameters of that policy in order to maximize its probability of success. This makes it easy to deploy in real-world applications since it does not rely on complicated off-policy techniques, but instead on simple updates to the policy. In addition, it has been shown to be highly sample efficient, making it a good choice for applications with limited data and resources. PPO also provides better exploration than most other reinforcement learning algorithms, which ensures rapid convergence of policies in complex environments. Finally, PPO is well-suited to continuous action spaces and has been used in robotics applications. In this post we will explore the PPO algorithm in detail and dive into the unknown! So join us learning PPO together and discover how this great reinforcement learning algorithm can help you reach the best performance possible. 

[https://deepboltzer.codes/proximal-policy-optimization](https://deepboltzer.codes/proximal-policy-optimization)

Happy Learning!",2022-12-22 20:33:41
zshytl,Understanding the core concepts of Policy Gradient Methods," Let us understand the core concepts underlying various policy gradient algorithms! In simple terms, policy gradient methods are a type of reinforcement learning algorithm which allows us to learn the optimal parameters of a given environment in order to maximize rewards. As opposed to previously introduced methods - which suffered from the curse of dimensionality - it is not necessary to analyze the full action space to update the policy π. Instead of learning the parameters of a policy directly, the algorithm learns the gradient of expected rewards with respect to those parameters. The idea is that by taking small steps in the direction suggested by this gradient, we can converge on optimal policy parameters. So if you want to learn more about how policy gradient methods work, feel free to explore our latest blog post. We hope that this will help to get a better understanding of policy gradient methods! If you still have any questions or would like to discuss further, do not hesitate to reach out - we are always happy to help.

[https://deepboltzer.codes/introduction-to-policy-gradients](https://deepboltzer.codes/introduction-to-policy-gradients)

Happy learning!",2022-12-22 09:33:52
zs7skp,To what extent can a proof assistant like Lean verify its own correctness?,"I've been using the [proof assistant Lean](https://leanprover.github.io/about/) a bit recently, and it got me thinking about whether I can prove Lean to be correct or not.

Imagine that I wanted to prove the statement *P* = ""Lean will accept a proof as correct if and only if that proof is correct."" Is it actually possible to prove *P*? If so, is it possible to formalize that proof in Lean?

Even if we could formalize *P* in Lean and Lean accepted it as a valid proof, would that even be enough to verify Lean's correctness? After all, if Lean (incorrectly) accepted *any* theorem as true, wouldn't it accept *P* even if *P* was false?",2022-12-22 01:15:11
zs112z,Is there any decision making/predicting algorithm that can give a decision/prediction that can give a 100% probability of it being good/true?,N/A,2022-12-21 21:11:30
zqj1c0,arduino & raspberry components,N/A,2022-12-20 08:30:37
zpp0xp,Consistent hashing explained,N/A,2022-12-19 11:25:05
znj45h,What is your view on the Halting Problem of Turing Machines and how do you propose to solve it?,N/A,2022-12-16 16:46:08
zjymio,"If the day comes that quantum computers are commercially available, would it be possible to buy one and use it to crack my locked android phone's encryption?","So on my old Huawei phone I have alot of pictures from when I visited the US the summer of 2019. Nowadays I remember that trip as the best time of my life, but because my brain did a dumb I can't remember the 6-digit PIN to the phone and so all the photos are inaccesible. And no, they're not backed up anywhere :/. But I read somewhere that quantum computers will theoretically be able to crack AES-128 encryption, which is what I'm told android phones are using.

So my question is will this actually be practically possible, or is there perhaps some other caviot that I don't know about?

Oh and I don't know if it makes a difference but I haven't used up all my PIN chances so the phone isn't ""permanently"" locked yet.",2022-12-12 13:07:49
zjscuv,Competition-Level Code Generation with AlphaCode,"Deepmind proposed AlphaCode, a system for code generation that can create novel solutions to these problems that require deeper reasoning. In your opinion, what can we learn from it. What are the short- and long-term consequences?",2022-12-12 08:18:34
zjm6l2,Resources to understand compressed sensing?,"I'm reading a paper about compressed sensing and I was somewhat lost on the concept. Are there any good resources (e.g. videos, books, papers) I can use to gain some insight? Thanks!",2022-12-12 03:56:50
zfuuah,What is the use to data structures if we save and retrieve all the data in databases.,N/A,2022-12-08 10:03:43
zegkop,Is there always a non-amortized version of every data structure that matches the best amortized one?,"Often some operations on a data structure run in O(1) or O(log n) amortized time. However, I don't recall any such data structures without an equivalent one which supports the same operations with the same complexity without relying on amortization. Usually, the latter DS is much more convoluted and impractical, but that is irrelevant here.

I now started wondering whether there is a known result about this. Either there is an equivalent non-amortized DS for every amortized DS, or there is some amortized DS with no such equivalent. Perhaps there is no proof either way, but maybe there is some amortized DS with no known non-amortized equivalent. Does anyone know?",2022-12-06 20:07:19
ze4umd,We need search capability over AI-generated content,"The availability of language models such as GPT-3 (and the recent chat version #chatGPT) can be as disruptive as the search engines were in the past. New tools are good, in the sense that they can expand our productivity, but there can be some downsides. We have learned that not all we read on the internet is true, and the same goes for AI-generated content. This content can often be true, but it is produced to look plausible. Truth is often just an accident. 

One thing is true,  AI-generated content is very credible at first glance and hard to distinguish from human-generated content. Recently [Stack Overflow banned AI-generated content](https://www.theverge.com/2022/12/5/23493932/chatgpt-ai-generated-answers-temporarily-banned-stack-overflow-llms-dangers).  But how can we detect such content in an efficient way?

Probably the simplest solution is for the hosts of the language models, such as OpenAI, to store the outputs and provide search capability over past outputs.",2022-12-06 12:02:56
zd7tbv,Slitherlink / Fences / Takegaki / Ouroboros puzzle generator,"This game goes by many names but it's [this one](https://en.wikipedia.org/wiki/Slitherlink). I'm working on an implementation and I'm thinking that first and foremost, I should create the puzzle generator.

I'm thinking of utilizing a modified tree generation algorithm (perhaps Prim's?). Where some cells behave like ""walls"" in a typical maze.

My main question is... what do you think is the best data structure for this? I need to be able to check for cycles quickly. And I need to be able to associate each cell with the edges on its boundary.

I was thinking of perhaps just using a naive nxm 2D array for the cells, generating a ""maze"" on top of them, populating every cell with its ""clue value"" and then removing clues until the game is barely solvable.

In terms of gameplay, I was thinking I would maintain an array of arrays of the form `[[starting_i, starting_j], ...oneOfFourUnitVectors]` (which I call ""chains"", with each unit vector being a ""link""). So this would be an array of all unconnected ""chains"".

Thoughts?",2022-12-05 14:13:04
zd49vs,URL Shortening System Design,N/A,2022-12-05 11:23:56
zc5s2n,Advent(2) -- The System-Call Advent Calender,"Winter is coming and the ELFs have a lot of work to do in Santa's Christmas village. And the ELFs, as the name suggests, are big fans of Linux to get this work done in time. However, until now they only know about those old a crusty interfaces that we inherited from UNIX/POSIX. So, they require your help! On the way, you can learn something about old and new system calls of Linux.

[https://osg.tuhh.de/Advent/](https://osg.tuhh.de/Advent/)

The Operating System Group at the Hamburg University of Technology prepared a System-Call Advent calendar with 24 strace-filled doors for you. On every day of December, you will find a system-call, a concept or an interface of Linux that you might or might not yet know. Behind the door, there is a short article and a small programming exercise, for which we provide a commented solution on the following day.",2022-12-04 09:57:03
zc27ck,How Bios is able to display GUI,Without any OS or drivers how the bios is able to display a TUI or a full GUI(UEFI),2022-12-04 06:06:31
zc0av2,ICPC Archives: Collection of problems and solutions of final and regional ICPC contests,N/A,2022-12-04 04:24:29
zbmnqk,how to solve an alien problem you can't comprehend?,"Like for example if I give you a 10x10 Rubik's, you have never  solved, even a 3x3 Rubik's cube before. How would you approach it?",2022-12-03 18:17:31
zaezcd,Question about Predicate Transformer Semantics,"I'm trying to learn a little bit about Predicate Transformer Semantics (PTS) as part of a quick exploration of [Z3](https://github.com/Z3Prover/z3).

I'm reading the [wikipedia's article](https://en.wikipedia.org/wiki/Predicate_transformer_semantics) about PTS and I have some doubt about the [first wlp](https://en.wikipedia.org/wiki/Predicate_transformer_semantics#Partial_Correctness) for the *while loop*, i.e. the one ignoring termination.

First, I would replace the *if* in the formula with an *and* as I don't think the formula is syntactically correct the way it's written.

Second — this is my main doubt — I don't understand how we can be sure that the precondition, P,  given by that formula is still valid when we loop many times. Let's consider the forward direction: P makes sure that the INVariant is true, and that if the loop condition is true then, after we perform one iteration, the INVariant is still true. But how can we be sure that P is still valid for the next eventual iteration, though?

I also found a [more hands-on article](https://www.philipzucker.com/weakest-precondition-z3py/) about PTS. The author relies on Z3 and defines the statements as functions which return the associated wp functions. For instance, `if_(b<a, stmt1, stmt2)` returns the function `lambda post_cond: wp(if b<a then stmt1 else stmt2 end, post_cond)`. This way, by combining these statements, we can build the wp function for a whole algorithm. For instance:

    def twosort(a,b):
        if b < a:
            temp = a
            a = b
            b = temp
        else:
            pass
        return a,b

becomes

    a, b, temp = Ints(""a b temp"")
    prog = \
    if_(b < a,
        begin(
             set_(temp,a),
             set_(a, b),
             set_(b, temp)
             ),
        skip
       )

Here's the important bit. The author implements the while loop as follows:

    def while_(cond, inv, *body):
        def res(post):
            vs = list(get_vars(post))
            return And( inv , 
            ForAll(vs, And( Implies( And(cond, inv), begin(*body)(inv))
                            , Implies( And(Not(cond), inv), post) )))
        return res

This seems to agree with wikipedia's formulation except for that `ForAll`. I suspect the reason we might need that `ForAll` is connected with my doubt... or maybe not?

**edit**: added link to hands-on article!",2022-12-02 07:28:23
za3c9a,Good sites to learn how to ethically hack..for free (?),"The reason I say free is because I am a student with no financial income yet. Any courses that let you learn then pay for a certificate at the end are also fine, I just want a place to learn for free",2022-12-01 23:10:27
z9y67k,The Legacy of Peer-to-Peer Systems,"What happened to peer-to-peer as a technological concept? Actually, we still use a lot of that technology. Fresh blog post on this dive into the past [https://cacm.acm.org/blogs/blog-cacm/267236-the-legacy-of-peer-to-peer-systems/fulltext](https://cacm.acm.org/blogs/blog-cacm/267236-the-legacy-of-peer-to-peer-systems/fulltext)",2022-12-01 20:07:26
z9vhu4,Computer History Museum releases Adobe Postscript source code today!,"Hey Everyone,

Huzzah!

As promised, today the Computer History Museum is releasing the original Adobe Postscript source code. 

Read our introductory blog on the history of this cool technology and pick up your sources here:

[https://computerhistory.org/blog/postscript-a-digital-printing-press/](https://computerhistory.org/blog/postscript-a-digital-printing-press/)

This release is part of the Museum’s Art of Code program, which you can sing up to hear more about and get updates on code releases here: [https://info.computerhistory.org/subscribe-aoc](https://info.computerhistory.org/subscribe-aoc)

For background on our Art of Code program, be sure to read our Art of Code blog here: [https://computerhistory.org/blog/the-art-of-code-at-chm/](https://computerhistory.org/blog/the-art-of-code-at-chm/)

Coming soon…

Apple Lisa source code – release date: January, 2023

Xerox PARC Alto source code: release date: March, 2023

The Computer History Museum is home to the world’s largest collection of computer hardware, software, media, documentation and ephemera and everything we offer is free, but doing so is not without cost. If you’d like to support our efforts – even a small token amount sends us a signal you think we’re doing good work – have a look here: [https://chm.secure.nonprofitsoapbox.com/donate](https://chm.secure.nonprofitsoapbox.com/donate)

Would love to hear your feedback – publicly, or personally at my email below.

Thanks everyone – this is going to be a great year for software history!

\-- Dag.

Dag Spicer  
Senior Curator  
Computer History Museum  
E-m: [spicer@computerhistory.org](mailto:spicer@computerhistory.org)",2022-12-01 18:30:42
z8nlnd,Scientists Increasingly Can’t Explain How AI Works,N/A,2022-11-30 10:01:13
z8myj8,Is the Von-Neumann architecture used on GPUs?,"I’m sorry for my being illiterate on the topic. I’ve studied computer architectures before, and I was wondering first of all how do GPUs fit into the Von-Neumann template, and what do GPUs have. I know they use different names such as Maxwell, Ampere etc. for Nvidia, but are they actually different variations of Von-Neumann or completely different things? Thanks for your time :)",2022-11-30 09:22:49
z7pxpn,Multivariate Normal Distribution Explained,"Hi guys,

I have made a video on YouTube [here](https://youtu.be/UVvuwv-ne1I) where I explain what the multivariate normal distribution is, together with the meaning behind the equation that describes its behavior.

I hope it may be of use to some of you out there. As always, feedback is more than welcomed! :)",2022-11-29 10:12:57
z7kwcz,Easy to understand Blockchain Beginner Books [ Recommendation ],"Hi there, I want to learn blockchain. I am a complete newbie. All I know so far is that it's decentralized no single entity or organization is the owner of the data/stuff. Please let me know what book is easy to follow in the beginning in this field.",2022-11-29 05:46:26
z7hli4,Why Functional Programming Should Be the Future of Software Development,N/A,2022-11-29 03:08:11
z73qdl,"Temporal Programming, a new name for an old paradigm",N/A,2022-11-28 18:12:59
z6d38i,Online Portfolio Selection - Cover's Universal Portfolio,"Hi r/compsci

My 2nd blog on online portfolios is about Cover's Universal Portfolio algorithm. [https://sudeepraja.github.io/OPS2/](https://sudeepraja.github.io/OPS2/)

Theoretically, it has the best performance. But it is computationally expensive to implement. I give two different interpretations of this algorithm. One is based on Follow the regularized leader and the other is a kind of Bayesian update.

I implement it for the case of two stocks. Guess what happens when you use it for a leveraged ETF and its inverse like TQQQ, SQQQ - >!You lose money anyway.!<

My first blog on this topic is here: [https://sudeepraja.github.io/OPS1/](https://sudeepraja.github.io/OPS1/)",2022-11-27 21:25:23
z40sn5,Online Portfolio Selection - Introduction,"Hi r/compsci

I spent the last two years reading about online portfolios from a theoretical and practical standpoint. In a series of blogs, I intend to write about this problem. For me, this was a gateway into online algorithms, portfolio optimization, and quantitative finance. I also included code snippets to play around with. [https://sudeepraja.github.io/OPS1/](https://sudeepraja.github.io/OPS1/)

I appreciate all corrections and feedback.",2022-11-25 01:55:33
z3aapr,Can a new form of cryptography solve the internet’s privacy problem?,N/A,2022-11-24 04:31:45
z2czih,Linked lists and trees(help),"I'm a 2nd yr computer scince student and I'm currently struggling with linked lists and trees, the lectures don't seem to help, does anyone know any good youtubers that are good at explaining the programming side of these concepts?",2022-11-23 02:37:06
z21fak,Please recommended any good course on Blockchain development,I'm studying JavaScript right now because I have an interest in blockchain development. Anyone who has taken courses in blockchain development can help me out because I previously searched this question but am now totally confused.,2022-11-22 18:47:35
z1xo23,"Found this, easily explained and informative",[https://youtu.be/2cGtLD1r4bg](https://youtu.be/2cGtLD1r4bg),2022-11-22 16:18:06
z1aji8,Where next for program synthesis?,"Hi all, first of all I don't have an academic CS background so please forgive me if I am not up to date on the latest research. I am interested in program synthesis and where it is going, but lots of the debates I see online (HN etc) seem to descend into the usual GOFAI vs. ML fights and I lack the background to determine what seems credible.

My understanding is that until recently program synthesis focused on generating correct programs from example test cases by search or maybe ILP etc. To be honest, it seems that this didn't get very far. I have seen references to Flash Fill in Excel but I am not aware of anything else with large scale adoption or that can generate more that small algorithms (is this incorrect?).

Recently, systems such as Copilot use ML to generate likely code from prompts. The problem is that the model doesn't 'really understand' the output code and often it is incorrect or doesn't compile. Still, Copilot seems to have provided utility. On the other hand, GOFAI proponents might say that Copilot doesn't even know how to output correct code.

I have read ML proponents argue that more data and better models usually lead to a more capable system. For example, I believe GPT-3 can do arithmetic that GPT-2 couldn't do. However, Copilot has already been trained on all of Github's public code. Where would further data come from? I am aware that places like Salesforce have been using RL with test cases to improve results, but even so they are only getting 40% correct with 1000 attempts. Will better model architectures alone lead to much better results?",2022-11-21 21:17:10
yzna8w,Data Origin Authentication vs Non Repudiation?,"Hey all

I'm looking into how authenticated encryption primitives work and was wondering if non-repudiation is provided with these. Investigating further into them led to the answer being that **data origin authentication** (DAO) are provided by the primitives.

Now DAO is defined as ""the source of the information being verified"", providing integrity through MAC. Yet Non-repudiation is almost defined as the same thing, in which it provides proof of the origin and the creator of said data being **unable to deny** that they created the data.  

If they both say the same thing, then why is it that some sources state that authenticated primitives do not in fact have non-repudiation when they do? Some say that the seperate primitives that **are combined** result in non-repudiation being created, but I am so genuinely confused at what I'm supposed to take from this.",2022-11-19 21:58:52
yyqsrk,New data transmission record set using a single laser and a single optical chip,N/A,2022-11-18 18:19:54
yy4uxb,Borůvka's algorithm,N/A,2022-11-17 23:22:17
yxj21g,Feature of Artificial Intelligence,N/A,2022-11-17 06:43:25
yxchn2,15-816 Substructural Logics - Pfenning -- 2016,N/A,2022-11-17 01:24:25
yvcki1,How does Shor's algorithm break ECDSA?,"Hey all

So I was currently working on some piece of work related to Elliptical Curve Cryptography and Quantum computers and found a question asking if quantum computing could break ECDSA.

Shor's algorithm, from what I have researched, works by the probabilistic nature of qubits which drastically reduce the time taken for factorisation.

But maybe it is because that I do not understand how Elliptical curves work because I don't know how that relates into breaking through ECDSA, and I'm just perplexed at this point. Would appreciate an explanation as to how this all works.",2022-11-14 21:03:58
yur43x,Where am I wrong (reading the paper about NFA unambiguity check),"I'm reading an article ""An O(n^2) time algorithm for deciding whether a regular language is a code"" by Robert McCloskey. Everything is very simple and clear, it seems to me, that there is much more straightforward approach for this purpose, which provide more general result. It's so simple, that it seems like I'm wrong somewhere:

Suppose we have a set of regular expression. Construct an NFA in the following way:

For each expression build an NFA, such that for each acceptable string there is only one path from the initial state to any of terminal states in it. Then build one cyclic NFA as a disjunction of those, i. e. from new initial state add eps-moves to all initial states of previously constructed NFAs and from all terminal states of previously constructed NFAs add an eps-move to initial state. Make initial state of this complex NFA to the only terminal state of it.

As far as I understand, this NFA corresponds to the language, consisting of the words, that can be split into the strings accepted by some of the regular expressions, i. e. exactly the language, described in the article. Moreover, disambiguation problem can be reformulated in terms of this NFA in a very simple manner: we want to know, if there exist two different paths from initial state to terminal (i. e. to itself), spelling out the same word. And the latter problem can be easily solved using the same kind of a direct product of an NFA, described in the paper (we should check if there are paths from (init, init) to itself in the graph from p. 7, that go through at least one non-diagonal node).

Yes, algorithm from the article is also not too hard, but this one is even simpler. Therefore, it seems to me, that I have missed something important. I'd be very grateful for any idea of what can go wrong here",2022-11-14 06:35:16
ytvvmx,Programming and Order Theory,N/A,2022-11-13 08:36:54
yq6bwp,Is “x' = f(x)” a programming paradigm?,N/A,2022-11-09 02:40:53
ym0khu,Nearest-neighbor search in high-dimensional spaces,"- I have two sets of 20K, 100-dimensional vectors each.
- For each vector in set A, I want to find the closest vector in set B under Euclidean distance.
- I need an exact algorithm.
- I can afford some pre-processing time as I have quite a few of these sets, meaning I could construct an acceleration structure once per set and then re-use it for multiple queries.

What's the best algorithm/data structure here?",2022-11-04 14:30:56
ylq8ad,Reductions in complexity theory: difference between oracle access or none?,"I've seen two main ways people prove reductions of problems like X <= Y. One definition I see for this is essentially that there is a computable function which maps instances of X to instances of Y such that if x in X then f(x) is in Y.

I think I've also seen a definition like, if an algorithm can solve X with oracle access to Y, then X <= Y. Can anyone explain if these definitions are equivalent? Is there a way to phrase say, a Karp reduction ([https://en.wikipedia.org/wiki/Polynomial-time\_reduction#Many-one\_reductions](https://en.wikipedia.org/wiki/Polynomial-time_reduction#Many-one_reductions)), under both interpretations?",2022-11-04 05:51:15
